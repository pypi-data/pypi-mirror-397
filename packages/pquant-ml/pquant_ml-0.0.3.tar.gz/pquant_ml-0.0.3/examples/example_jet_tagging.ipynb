{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0177a-0354-437b-b13a-947144dba15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install da4ml\n",
    "# For da4ml, also required: !conda install conda-forge::verilator -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94033d11-b0c5-4ca6-9664-cd6dd0193c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "import keras\n",
    "keras.backend.set_image_data_format(\"channels_first\")\n",
    "from pquant.layers import PQDense\n",
    "from pquant.activations import PQActivation\n",
    "from pquant import get_ebops\n",
    "from da4ml.trace.ops import quantize, relu\n",
    "from da4ml.trace import comb_trace, FixedVariableArrayInput, FixedVariableArray\n",
    "from da4ml.codegen import VerilogModel\n",
    "import random\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1473a61e-955d-430a-9737-7fd2fc7ba59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def get_data(data_path: Path, seed=42):\n",
    "    try:\n",
    "        import zstd\n",
    "    except ImportError:\n",
    "        zstd = None\n",
    "    if not os.path.exists(data_path):\n",
    "        print('Downloading data...')\n",
    "        data = fetch_openml('hls4ml_lhc_jets_hlf')\n",
    "        buf = pkl.dumps(data)\n",
    "        with open(data_path, 'wb') as f:\n",
    "            if zstd is not None:\n",
    "                buf = zstd.compress(buf)\n",
    "            f.write(buf)\n",
    "    else:\n",
    "        os.makedirs(data_path.parent, exist_ok=True)\n",
    "        with open(data_path, 'rb') as f:\n",
    "            buf = f.read()\n",
    "            if zstd is not None:\n",
    "                buf = zstd.decompress(buf)\n",
    "            data = pkl.loads(buf)\n",
    "\n",
    "    X, y = data['data'], data['target']\n",
    "    codecs = {'g': 0, 'q': 1, 't': 4, 'w': 2, 'z': 3}\n",
    "    y = np.array([codecs[i] for i in y])\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "\n",
    "    X_train_val, X_test, y_train_val, y_test = X_train_val.astype(np.float32), X_test.astype(np.float32), y_train_val, y_test\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_val = scaler.fit_transform(X_train_val)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train_val = X_train_val.astype(np.float32)\n",
    "    y_train_val = y_train_val.astype(np.float32)\n",
    "\n",
    "    return X_train_val, X_test, y_train_val, y_test\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data(Path('/tmp/inp_data.zst'))\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2659f88-9f0c-45f4-a09d-8ef346915187",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "X_train_t = torch.from_numpy(X_train).float()\n",
    "X_test_t  = torch.from_numpy(X_test).float()\n",
    "\n",
    "y_train_idx = torch.from_numpy(y_train).long()\n",
    "y_test_idx  = torch.from_numpy(y_test).long()\n",
    "\n",
    "y_train_oh = F.one_hot(y_train_idx, num_classes=5).float()\n",
    "y_test_oh  = F.one_hot(y_test_idx,  num_classes=5).float()\n",
    "\n",
    "train_ds = TensorDataset(X_train_t, y_train_oh)\n",
    "test_ds  = TensorDataset(X_test_t,  y_test_oh)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=33200, shuffle=True, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=33200, shuffle=False, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03f950-15d5-47df-86bd-921956e98d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import cs_config, dst_config\n",
    "\n",
    "def build_model(config):\n",
    "    class Model(torch.nn.Module):\n",
    "        def __init__(self, config):\n",
    "            super().__init__()\n",
    "            self.dense1 = PQDense(config, 16, 64, \n",
    "                                  in_quant_bits = (1, 3, 3))\n",
    "            self.relu = PQActivation(config, \"relu\")\n",
    "            self.dense2 = PQDense(config, 64, 32)\n",
    "            self.dense3 = PQDense(config, 32, 32)\n",
    "            self.dense4 = PQDense(config, 32, 5, \n",
    "                                  quantize_output=True, \n",
    "                                  out_quant_bits=(1, 3, 3))\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.relu(self.dense1(x))\n",
    "            x = self.relu(self.dense2(x))\n",
    "            x = self.relu(self.dense3(x))\n",
    "            x = self.dense4(x)\n",
    "            return x\n",
    "    return Model(config)\n",
    "\n",
    "config = dst_config()\n",
    "config.training_parameters.epochs = 1000\n",
    "config.quantization_parameters.default_data_integer_bits = 3.\n",
    "config.quantization_parameters.default_data_fractional_bits = 2.\n",
    "config.quantization_parameters.default_weight_fractional_bits = 3.\n",
    "config.quantization_parameters.use_relu_multiplier = False\n",
    "model = build_model(config)\n",
    "\n",
    "model.to(\"cuda\")\n",
    "model(torch.rand(1, 16).to(\"cuda\")) # Call once to build Keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cc72e0-a4c5-4e19-a31d-ed9de6bee9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2f58dd-d4ab-4f2b-a1d1-5ac220569d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(lr=1e-2, params=model.parameters())\n",
    "scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[600, 800], gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983c6bad-310e-4d7c-a6a6-f0164f01808c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import get_layer_keep_ratio, get_model_losses\n",
    "train_accuracies = []\n",
    "\n",
    "def training_loop(model, trainloader, device, loss_func, optimizer, epoch, scheduler=None, *args, **kwargs):\n",
    "    for data in trainloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_func(outputs, labels)\n",
    "        losses = get_model_losses(model, torch.tensor(0.).to(device))\n",
    "        loss += losses\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch += 1\n",
    "        accuracy = torch.mean((torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).float())\n",
    "    if scheduler is not None:\n",
    "        scheduler.step()\n",
    "    train_accuracies.append(accuracy.cpu().numpy())\n",
    "\n",
    "val_accuracies = []\n",
    "remaining_weights = []\n",
    "ebops = []\n",
    "def validate_loop(model, testloader, device, loss_func, epoch, *args, **kwargs):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            accuracy = torch.mean((torch.argmax(outputs, dim=1) == torch.argmax(labels, dim=1)).float())\n",
    "        val_accuracies.append(accuracy.cpu().numpy())\n",
    "        ratio = get_layer_keep_ratio(model)\n",
    "        remaining_weights.append(ratio.cpu().numpy())\n",
    "        ebops.append(get_ebops(model).cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67b9c3b-00eb-4945-822f-ae9e0864d5d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pquant import train_model\n",
    "model.to(\"cuda\")\n",
    "trained_model = train_model(model = model, \n",
    "                                config = config, \n",
    "                                train_func = training_loop, \n",
    "                                valid_func = validate_loop, \n",
    "                                trainloader = train_loader, \n",
    "                                device=\"cuda\",\n",
    "                                testloader = test_loader, \n",
    "                                loss_func = loss_func,\n",
    "                                optimizer = optimizer,\n",
    "                                scheduler=scheduler\n",
    "                                )\n",
    "print(f\"Remaining weights={remaining_weights[-1] * 100:.2f}%\", f\"   EBOPs={int(ebops[-1])}\", f\"   Accuracy={val_accuracies[-1]*100:.2f}:%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bd9d0a-476b-4530-93aa-41ea2578a521",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c94d83bf-d7e6-4900-91ec-92cfc80132f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_accuracies, label=\"Train\")\n",
    "plt.plot(val_accuracies, label=\"Valid\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylim(0.6, 0.77)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(remaining_weights)\n",
    "plt.ylabel('Remaining weights')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(ebops)\n",
    "plt.ylabel('EBOPs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc9fead-b8ee-4d78-b2eb-5bd012b8a9b3",
   "metadata": {},
   "source": [
    "# da4ml\n",
    "For this part you need to have verilator installed (conda install conda-forge::verilator -y). We extract the weight and bias matrices from the model as numpy arrays, and build the forward pass of the model using numpy operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1beb03d-69c8-4f13-914d-376ae11578fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0, b0 = model.dense1.weight.detach().cpu().numpy(), model.dense1.bias.detach().cpu().numpy()\n",
    "w1, b1 = model.dense2.weight.detach().cpu().numpy(), model.dense2.bias.detach().cpu().numpy()\n",
    "w2, b2 = model.dense3.weight.detach().cpu().numpy(), model.dense3.bias.detach().cpu().numpy()\n",
    "w3, b3 = model.dense4.weight.detach().cpu().numpy(), model.dense4.bias.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54328c4-f12c-4c36-bf60-44d2d161f077",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_i = int(config.quantization_parameters.default_data_integer_bits)\n",
    "data_f = int(config.quantization_parameters.default_data_fractional_bits)\n",
    "data_np_test = np.clip(X_test_t, -(2**data_i), 2**data_i-2**(-data_f))\n",
    "import yaml\n",
    "if True:\n",
    "        inp = FixedVariableArrayInput((16))\n",
    "        x = quantize(inp, k=1, i=data_i, f=data_f, overflow_mode=\"WRAP\", round_mode=\"RND\")\n",
    "\n",
    "        x = w0 @ x\n",
    "        x = x + b0\n",
    "        x = quantize(x, k=0, i=data_i, f=data_f, overflow_mode=\"SAT\", round_mode=\"RND\")   \n",
    "        x = w1 @ x\n",
    "        x = x + b1\n",
    "        x = quantize(x, k=0, i=data_i, f=data_f, overflow_mode=\"SAT\", round_mode=\"RND\")   \n",
    "        x = w2 @ x\n",
    "        x = x + b2\n",
    "        x = quantize(x, k=0, i=data_i, f=data_f, overflow_mode=\"SAT\", round_mode=\"RND\")   \n",
    "        x = w3 @ x\n",
    "        x = x + b3\n",
    "        out = quantize(x, k=1, i=data_i, f=data_f, overflow_mode=\"SAT\", round_mode=\"RND\")   \n",
    "\n",
    "\n",
    "        comb_logic = comb_trace(inp, out)\n",
    "        verilog_model = VerilogModel(comb_logic, \"vmodel\", \"path_to_model_folder\", latency_cutoff=5, clock_uncertainty=0., part_name=\"xcu250-figd2104-2L-e\")\n",
    "        verilog_model.write()\n",
    "        verilog_model.compile(verbose=True)\n",
    "        \n",
    "verilog_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ac250-3896-4270-89bf-758282478a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319f4e6d-15c1-4154-843b-f998bb5c94d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f562e58-e6ed-4e5a-9e0f-04fdb74f8b47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4068cd60-1069-4400-adf1-87b4ff109b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pquantml-dev-kernel",
   "language": "python",
   "name": "pquantml-dev-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
