#!/usr/bin/env python3
"""
SpeakUB Reservoir v6.0 æ•ˆèƒ½ç›£æ§æ¡†æ¶

æä¾›ç”Ÿç”¢ç’°å¢ƒçš„æ°´ä½è®ŠåŒ–ç›£æ§ã€æ•ˆèƒ½æŒ‡æ¨™æ”¶é›†å’Œåƒæ•¸å„ªåŒ–å»ºè­°ã€‚
"""

import json
import logging
import time
from collections import deque
from dataclasses import dataclass
from typing import Dict, List, Optional

logger = logging.getLogger(__name__)


@dataclass
class BufferMetrics:
    """ç·©è¡å€æ•ˆèƒ½æŒ‡æ¨™"""
    timestamp: float
    buffer_level: float
    trigger_count: int
    consumption_rate: float
    network_latency: Optional[float] = None
    cpu_usage: Optional[float] = None


@dataclass
class PerformanceReport:
    """æ•ˆèƒ½å ±å‘Š"""
    period_start: float
    period_end: float
    total_triggers: int
    avg_buffer_level: float
    min_buffer_level: float
    max_buffer_level: float
    buffer_stability: float
    consumption_efficiency: float
    recommendations: List[str]


class ReservoirV6Monitor:
    """Reservoir v6.0 æ•ˆèƒ½ç›£æ§å™¨"""

    def __init__(self, history_size: int = 1000):
        self.metrics_history = deque(maxlen=history_size)
        self.current_session_start = time.time()
        self.last_trigger_count = 0

    def record_buffer_level(self, buffer_level: float, trigger_count: int,
                            network_latency: Optional[float] = None,
                            cpu_usage: Optional[float] = None):
        """è¨˜éŒ„ç·©è¡å€æ°´ä½"""
        consumption_rate = self._calculate_consumption_rate()

        metric = BufferMetrics(
            timestamp=time.time(),
            buffer_level=buffer_level,
            trigger_count=trigger_count,
            consumption_rate=consumption_rate,
            network_latency=network_latency,
            cpu_usage=cpu_usage
        )

        self.metrics_history.append(metric)

        # è¨˜éŒ„é¡¯è‘—äº‹ä»¶
        if len(self.metrics_history) >= 2:
            prev_metric = self.metrics_history[-2]

            # æª¢æ¸¬æ°´ä½æ€¥åŠ‡ä¸‹é™
            if prev_metric.buffer_level - buffer_level > 10:
                logger.warning(".2f")
            # æª¢æ¸¬éåº¦è§¸ç™¼
            if trigger_count > prev_metric.trigger_count + 5:
                logger.warning(
                    f"è§¸ç™¼é »ç‡ç•°å¸¸å¢åŠ : {prev_metric.trigger_count} -> {trigger_count}")

    def _calculate_consumption_rate(self) -> float:
        """è¨ˆç®—ç·©è¡æ¶ˆè€—ç‡"""
        if len(self.metrics_history) < 2:
            return 0.0

        recent_metrics = list(self.metrics_history)[-10:]  # æœ€è¿‘10å€‹æ•¸æ“šé»
        if len(recent_metrics) < 2:
            return 0.0

        time_span = recent_metrics[-1].timestamp - recent_metrics[0].timestamp
        buffer_change = recent_metrics[-1].buffer_level -
        recent_metrics[0].buffer_level

        if time_span > 0:
            return -buffer_change / time_span  # æ­£å€¼è¡¨ç¤ºæ¶ˆè€—ç‡
        return 0.0

    def generate_performance_report(self, period_hours: float = 1.0) -> PerformanceReport:
        """ç”Ÿæˆæ•ˆèƒ½å ±å‘Š"""
        cutoff_time = time.time() - (period_hours * 3600)
        recent_metrics = [
            m for m in self.metrics_history if m.timestamp >= cutoff_time]

        if not recent_metrics:
            return PerformanceReport(
                period_start=cutoff_time,
                period_end=time.time(),
                total_triggers=0,
                avg_buffer_level=0.0,
                min_buffer_level=0.0,
                max_buffer_level=0.0,
                buffer_stability=0.0,
                consumption_efficiency=0.0,
                recommendations=["ç„¡è¶³å¤ æ•¸æ“šç”Ÿæˆå ±å‘Š"]
            )

        # è¨ˆç®—åŸºæœ¬æŒ‡æ¨™
        buffer_levels = [m.buffer_level for m in recent_metrics]
        trigger_counts = [m.trigger_count for m in recent_metrics]

        total_triggers = max(trigger_counts) -
        min(trigger_counts) if trigger_counts else 0
        avg_buffer_level = sum(buffer_levels) / len(buffer_levels)
        min_buffer_level = min(buffer_levels)
        max_buffer_level = max(buffer_levels)

        # è¨ˆç®—ç©©å®šæ€§æŒ‡æ¨™ (0-1, 1ç‚ºæœ€ç©©å®š)
        if max_buffer_level > 0:
            buffer_stability = 1 - (max_buffer_level -
                                    min_buffer_level) / (max_buffer_level + 1)
        else:
            buffer_stability = 1.0

        # è¨ˆç®—æ¶ˆè€—æ•ˆç‡ (ç†æƒ³ç¯„åœ: 15-60ç§’)
        consumption_efficiency = 0.0
        if 15 <= avg_buffer_level <= 60:
            consumption_efficiency = 1.0
        elif avg_buffer_level < 15:
            consumption_efficiency = avg_buffer_level / 15.0  # ä½æ–¼15ç§’çš„æ‡²ç½°
        else:
            consumption_efficiency = 60.0 / avg_buffer_level  # é«˜æ–¼60ç§’çš„æ‡²ç½°

        # ç”Ÿæˆå»ºè­°
        recommendations = self._generate_recommendations(
            avg_buffer_level, min_buffer_level, max_buffer_level,
            buffer_stability, total_triggers, period_hours
        )

        return PerformanceReport(
            period_start=cutoff_time,
            period_end=time.time(),
            total_triggers=total_triggers,
            avg_buffer_level=avg_buffer_level,
            min_buffer_level=min_buffer_level,
            max_buffer_level=max_buffer_level,
            buffer_stability=buffer_stability,
            consumption_efficiency=consumption_efficiency,
            recommendations=recommendations
        )

    def _generate_recommendations(self, avg_buffer: float, min_buffer: float,
                                  max_buffer: float, stability: float,
                                  triggers: int, period_hours: float) -> List[str]:
        """ç”Ÿæˆå„ªåŒ–å»ºè­°"""
        recommendations = []

        # ç·©è¡æ°´ä½åˆ†æ
        if avg_buffer < 10:
            recommendations.append("âš ï¸ å¹³å‡ç·©è¡æ°´ä½éä½ï¼Œå»ºè­°é™ä½ LOW_WATERMARK æˆ–å¢åŠ ç¶²è·¯å„ªå…ˆç´š")
        elif avg_buffer > 70:
            recommendations.append("âš ï¸ å¹³å‡ç·©è¡æ°´ä½éé«˜ï¼Œå»ºè­°æé«˜ HIGH_WATERMARK æˆ–å¢åŠ æ¶ˆè€—ç‡")

        # ç©©å®šæ€§åˆ†æ
        if stability < 0.5:
            recommendations.append("âš ï¸ ç·©è¡æ°´ä½æ³¢å‹•éå¤§ï¼Œå»ºè­°æª¢æŸ¥ç¶²è·¯ç©©å®šæ€§æˆ–èª¿æ•´æ°´ä½é–¾å€¼")
        elif stability > 0.9:
            recommendations.append("âœ… ç·©è¡æ°´ä½éå¸¸ç©©å®šï¼Œç³»çµ±é‹è¡Œè‰¯å¥½")

        # è§¸ç™¼é »ç‡åˆ†æ
        trigger_rate = triggers / period_hours  # æ¯å°æ™‚è§¸ç™¼æ¬¡æ•¸
        if trigger_rate > 20:
            recommendations.append("âš ï¸ è§¸ç™¼é »ç‡éé«˜ï¼Œå»ºè­°å¢åŠ æ‰¹æ¬¡å¤§å°æˆ–é™ä½ LOW_WATERMARK")
        elif trigger_rate < 2:
            recommendations.append("â„¹ï¸ è§¸ç™¼é »ç‡åä½ï¼Œç³»çµ±é‹è¡Œé«˜æ•ˆ")

        # æ¥µç«¯æƒ…æ³åˆ†æ
        if min_buffer < 5:
            recommendations.append("ğŸš¨ æª¢æ¸¬åˆ°åš´é‡ä½æ°´ä½æƒ…æ³ï¼Œå»ºè­°ç«‹å³æª¢æŸ¥ç¶²è·¯é€£æ¥")
        if max_buffer > 100:
            recommendations.append("â„¹ï¸ ç·©è¡æ°´ä½ç¶“å¸¸éé«˜ï¼Œè€ƒæ…®å¢åŠ æ’­æ”¾é€Ÿåº¦æˆ–é™ä½ HIGH_WATERMARK")

        # æ•ˆèƒ½è©•ä¼°
        if stability > 0.7 and 15 <= avg_buffer <= 60:
            recommendations.append("âœ… ç³»çµ±æ•ˆèƒ½å„ªè‰¯ï¼Œæ°´ä½æ§åˆ¶é‹è¡Œæ­£å¸¸")
        elif stability < 0.3:
            recommendations.append("âŒ ç³»çµ±æ•ˆèƒ½ä¸ç©©å®šï¼Œéœ€è¦ç·Šæ€¥èª¿æ•´åƒæ•¸")

        return recommendations

    def export_metrics_to_json(self, filename: str):
        """åŒ¯å‡ºæŒ‡æ¨™æ•¸æ“šåˆ°JSONæ–‡ä»¶"""
        metrics_data = []
        for metric in self.metrics_history:
            metrics_data.append({
                'timestamp': metric.timestamp,
                'buffer_level': metric.buffer_level,
                'trigger_count': metric.trigger_count,
                'consumption_rate': metric.consumption_rate,
                'network_latency': metric.network_latency,
                'cpu_usage': metric.cpu_usage
            })

        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(metrics_data, f, indent=2, ensure_ascii=False)

        logger.info(f"æŒ‡æ¨™æ•¸æ“šå·²åŒ¯å‡ºåˆ° {filename}")

    def get_current_status(self) -> Dict:
        """ç²å–ç•¶å‰ç‹€æ…‹æ‘˜è¦"""
        if not self.metrics_history:
            return {"status": "no_data"}

        latest = self.metrics_history[-1]
        recent_avg = sum(m.buffer_level for m in list(
            self.metrics_history)[-10:]) / min(10, len(self.metrics_history))

        return {
            "current_buffer": latest.buffer_level,
            "recent_avg_buffer": recent_avg,
            "total_metrics": len(self.metrics_history),
            "session_duration": time.time() - self.current_session_start,
            "last_update": latest.timestamp
        }


class ParameterOptimizer:
    """åƒæ•¸å„ªåŒ–å»ºè­°ç”Ÿæˆå™¨"""

    @staticmethod
    def analyze_and_suggest_parameters(report: PerformanceReport,
                                       current_low_watermark: float = 15.0,
                                       current_high_watermark: float = 60.0) -> Dict:
        """åŸºæ–¼æ•ˆèƒ½å ±å‘Šåˆ†æä¸¦å»ºè­°åƒæ•¸èª¿æ•´"""

        suggestions = {
            "low_watermark": current_low_watermark,
            "high_watermark": current_high_watermark,
            "recommended_changes": [],
            "expected_improvements": []
        }

        # ä½æ°´ä½èª¿æ•´å»ºè­°
        if report.min_buffer_level < 8:
            new_low = max(8.0, current_low_watermark * 0.8)
            suggestions["low_watermark"] = new_low
            suggestions["recommended_changes"].append(
                f"é™ä½ LOW_WATERMARK: {current_low_watermark} -> {new_low}")
            suggestions["expected_improvements"].append("æ¸›å°‘ä½æ°´ä½è­¦å ±é »ç‡")

        elif report.avg_buffer_level < 12:
            new_low = max(10.0, current_low_watermark * 0.9)
            suggestions["low_watermark"] = new_low
            suggestions["recommended_changes"].append(
                f"é©åº¦é™ä½ LOW_WATERMARK: {current_low_watermark} -> {new_low}")
            suggestions["expected_improvements"].append("æå‡ç·©è¡æ•ˆç‡")

        # é«˜æ°´ä½èª¿æ•´å»ºè­°
        if report.max_buffer_level > 80:
            new_high = min(80.0, current_high_watermark * 1.2)
            suggestions["high_watermark"] = new_high
            suggestions["recommended_changes"].append(
                f"æé«˜ HIGH_WATERMARK: {current_high_watermark} -> {new_high}")
            suggestions["expected_improvements"].append("æ¸›å°‘ä¸å¿…è¦çš„ä¼‘çœ æ™‚é–“")

        elif report.avg_buffer_level > 70:
            new_high = min(75.0, current_high_watermark * 1.1)
            suggestions["high_watermark"] = new_high
            suggestions["recommended_changes"].append(
                f"é©åº¦æé«˜ HIGH_WATERMARK: {current_high_watermark} -> {new_high}")
            suggestions["expected_improvements"].append("å„ªåŒ–è³‡æºåˆ©ç”¨")

        # ç©©å®šæ€§èª¿æ•´å»ºè­°
        if report.buffer_stability < 0.5:
            suggestions["recommended_changes"].append("ç·©è¡æ³¢å‹•å¤§ï¼Œå»ºè­°æª¢æŸ¥ç¶²è·¯æ¢ä»¶")
            suggestions["expected_improvements"].append("æ”¹å–„ç¶²è·¯é€£æ¥ç©©å®šæ€§")

        return suggestions


def print_monitoring_guide():
    """åˆ—å°ç›£æ§ä½¿ç”¨æŒ‡å—"""
    print("\n" + "="*80)
    print("SPEAKUB RESERVOIR v6.0 æ•ˆèƒ½ç›£æ§æŒ‡å—")
    print("="*80)

    print("\n1. éƒ¨ç½²ç›£æ§")
    print("   - åœ¨æ‡‰ç”¨å•Ÿå‹•æ™‚å»ºç«‹ ReservoirV6Monitor å¯¦ä¾‹")
    print("   - åœ¨æ°´ä½è®ŠåŒ–æ™‚èª¿ç”¨ record_buffer_level()")
    print("   - å®šæœŸç”Ÿæˆæ•ˆèƒ½å ±å‘Š")

    print("\n2. é—œéµæŒ‡æ¨™ç›£æ§")
    print("   - å¹³å‡ç·©è¡æ°´ä½: ç†æƒ³ç¯„åœ 15-60ç§’")
    print("   - ç·©è¡ç©©å®šæ€§: >0.7 è¡¨ç¤ºé‹è¡Œè‰¯å¥½")
    print("   - è§¸ç™¼é »ç‡: æ­£å¸¸ç¯„åœ 2-20æ¬¡/å°æ™‚")
    print("   - æ¶ˆè€—æ•ˆç‡: >0.8 è¡¨ç¤ºé«˜æ•ˆ")

    print("\n3. å‘Šè­¦æ¢ä»¶")
    print("   - å¹³å‡ç·©è¡ < 10ç§’: ä½æ°´ä½å‘Šè­¦")
    print("   - ç©©å®šæ€§ < 0.3: æ³¢å‹•å‘Šè­¦")
    print("   - è§¸ç™¼é »ç‡ > 30æ¬¡/å°æ™‚: éè¼‰å‘Šè­¦")

    print("\n4. åƒæ•¸å„ªåŒ–")
    print("   - LOW_WATERMARK: æ ¹æ“šç¶²è·¯é€Ÿåº¦èª¿æ•´ (8-20ç§’)")
    print("   - HIGH_WATERMARK: æ ¹æ“šè¨˜æ†¶é«”é™åˆ¶èª¿æ•´ (40-80ç§’)")
    print("   - å®šæœŸè©•ä¼°ä¸¦èª¿æ•´åƒæ•¸")

    print("\n5. æ•¸æ“šåŒ¯å‡º")
    print("   - ä½¿ç”¨ export_metrics_to_json() åŒ¯å‡ºæ­·å²æ•¸æ“š")
    print("   - ç”¨æ–¼é›¢ç·šåˆ†æå’Œé•·æœŸè¶¨å‹¢ç ”ç©¶")


if __name__ == "__main__":
    print_monitoring_guide()
