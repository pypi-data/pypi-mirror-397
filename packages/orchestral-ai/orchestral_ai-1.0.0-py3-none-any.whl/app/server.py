"""
Enhanced FastAPI Server for Orchestral App with Conversation Persistence

Extends the web UI server with:
- Automatic conversation saving
- Conversation loading/listing
- Undo functionality
- Workspace directory management
"""

import os
import asyncio
from pathlib import Path
from typing import Optional

from fastapi import FastAPI, WebSocket, WebSocketDisconnect
from fastapi.responses import HTMLResponse, FileResponse
from fastapi.staticfiles import StaticFiles

from orchestral.agent.agent import Agent
from orchestral.ui.web.agent_handler import WebSocketAgentHandler
from app.conversation_manager import ConversationManager
from app.state import AppState
from app.handlers.registry import dispatch_message
from app.services import get_model_info
from app.services.workspace_service import extract_base_directory_from_tools
from app.approval_bridge import ApprovalBridge


# Create FastAPI app
app = FastAPI(title="Orchestral App", version="0.1.0")

# Application state (single-user local mode)
state = AppState()


def set_agent(agent: Agent, conversations_dir: Optional[str] = None):
    """
    Set the agent instance and initialize conversation manager.

    Args:
        agent: Configured Agent instance with tools
        conversations_dir: Directory to store conversations (defaults to app/conversations)
    """
    state.agent = agent
    state.current_conversation_id = None
    state.auto_name_generated = False

    # Store initial tools and base_directory for new conversations
    state.initial_tools = agent.llm.tools if agent.llm else []
    state.initial_base_directory = extract_base_directory_from_tools(state.initial_tools)

    # Remove any display hooks (we don't want terminal output in web mode)
    agent.display_hook = None

    # Use default conversations directory if not specified
    if conversations_dir is None:
        conversations_dir = str(Path(__file__).parent / "conversations")

    # Create mutable references for the handler
    show_model_names_ref = [state.show_model_names]
    streaming_enabled_ref = [state.streaming_enabled]
    state.agent_handler = WebSocketAgentHandler(agent, width=100, non_streaming_models=state.non_streaming_models, show_model_names_ref=show_model_names_ref, streaming_enabled_ref=streaming_enabled_ref)
    state.conversation_manager = ConversationManager(conversations_dir)

    # Store reference for updates
    state.agent_handler._show_model_names_global_ref = lambda: state.show_model_names


def _get_current_model_info() -> dict:
    """
    Get the current model provider and name from the agent.

    This is a wrapper around get_model_info service that uses the global state.
    Kept for backward compatibility with existing code.
    """
    return get_model_info(state)


# Serve static files from orchestral/ui/web/static
STATIC_DIR = Path(__file__).parent.parent / "orchestral" / "ui" / "web" / "static"
if STATIC_DIR.exists():
    app.mount("/static", StaticFiles(directory=str(STATIC_DIR)), name="static")


@app.get("/workspace-image/{file_path:path}")
async def serve_workspace_image(file_path: str):
    """
    Serve images from the workspace directory.

    This endpoint allows the frontend to display images generated by tools.
    Only serves files with image extensions for security.
    """
    # Get the workspace directory from the agent's tools
    workspace_dir = None
    if state.agent and state.agent.llm and state.agent.llm.tools:
        workspace_dir = extract_base_directory_from_tools(state.agent.llm.tools)

    # Fallback to default workspace if not found
    if not workspace_dir:
        workspace_dir = str(Path(__file__).parent / "workspace")

    # Validate that it's an image file (security check)
    allowed_extensions = {'.png', '.jpg', '.jpeg', '.gif', '.svg', '.webp', '.bmp'}
    file_ext = Path(file_path).suffix.lower()

    if file_ext not in allowed_extensions:
        return HTMLResponse(
            content=f"<p>Error: File type {file_ext} not allowed. Only image files can be served.</p>",
            status_code=403
        )

    # Construct full path
    full_path = Path(workspace_dir) / file_path

    # Security: Ensure the path is within workspace directory (prevent path traversal)
    try:
        full_path = full_path.resolve()
        workspace_path = Path(workspace_dir).resolve()
        if not str(full_path).startswith(str(workspace_path)):
            return HTMLResponse(
                content="<p>Error: Access denied - path outside workspace.</p>",
                status_code=403
            )
    except Exception:
        return HTMLResponse(
            content="<p>Error: Invalid path.</p>",
            status_code=400
        )

    # Check if file exists
    if not full_path.exists() or not full_path.is_file():
        return HTMLResponse(
            content=f"<p>Error: Image not found at {file_path}</p>",
            status_code=404
        )

    # Serve the file
    return FileResponse(full_path)


@app.get("/")
async def get_index():
    """Serve the main HTML page."""
    index_path = STATIC_DIR / "index.html"

    if not index_path.exists():
        return HTMLResponse(
            content="<h1>Orchestral App</h1><p>Static files not found. Run from orchestral_core directory.</p>",
            status_code=500
        )

    return FileResponse(index_path)


@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """
    WebSocket endpoint for agent communication with persistence.

    Protocol:
    - Client sends: {"type": "chat", "message": "user message"}
    - Client sends: {"type": "interrupt"}
    - Client sends: {"type": "clear"}
    - Client sends: {"type": "undo"}
    - Client sends: {"type": "get_history"}
    - Client sends: {"type": "list_conversations"}
    - Client sends: {"type": "load_conversation", "conversation_id": "..."}
    - Client sends: {"type": "save_conversation"}
    - Server sends: {"type": "user_message", "content": "html"}
    - Server sends: {"type": "agent_update", "content": "html"}
    - Server sends: {"type": "interrupted", "message": "..."}
    - Server sends: {"type": "complete"}
    - Server sends: {"type": "error", "message": "..."}
    - Server sends: {"type": "conversations_list", "conversations": [...]}
    """
    if state.agent is None or state.agent_handler is None or state.conversation_manager is None:
        await websocket.close(code=1011, reason="Server not initialized")
        return

    await websocket.accept()

    # Send current model info to frontend on connection
    model_info = _get_current_model_info()
    if model_info:
        await websocket.send_json({
            "type": "model_changed",
            "provider": model_info["provider"],
            "model": model_info["model"]
        })

    # Send current base directory to frontend
    if state.initial_base_directory:
        await websocket.send_json({
            "type": "base_directory_info",
            "base_directory": state.initial_base_directory
        })

    # Set up approval bridge for UserApprovalHook
    # Reuse existing bridge if available (preserves pending approval state across reconnects)
    if not hasattr(state, '_approval_bridge') or state._approval_bridge is None:
        approval_bridge = ApprovalBridge()
        state._approval_bridge = approval_bridge
        state.approval_callback = approval_bridge.request_approval
    else:
        approval_bridge = state._approval_bridge

    # Update the websocket connection (in case of reconnect)
    approval_bridge.set_websocket(websocket.send_json, asyncio.get_event_loop())

    # Update agent handler's websocket reference (in case of reconnect)
    if state.agent_handler and hasattr(state.agent_handler, 'current_websocket'):
        state.agent_handler.current_websocket = websocket
        state.agent_handler.event_loop = asyncio.get_event_loop()

    # Track the current message handling task
    current_task = None

    try:
        while True:
            # Receive message from client
            data = await websocket.receive_json()
            print(f"[App] Received message: {data}")

            message_type = data.get("type")

            # Dispatch message to appropriate handler
            current_task = await dispatch_message(
                message_type,
                websocket,
                data,
                state,
                _get_current_model_info
            )

            # Store the task in state so we can cancel it on reconnect
            if current_task:
                state.current_chat_task = current_task

    except WebSocketDisconnect:
        # Client disconnected - cancel any running task and deny pending approvals
        print("[App] WebSocket disconnected, canceling running tasks...")

        # Deny any pending approval (so the agent doesn't hang)
        if hasattr(state, '_approval_bridge') and state._approval_bridge:
            if state._approval_bridge.get_pending_approval_data():
                print("[App] Auto-denying pending approval due to disconnect")
                await state._approval_bridge.handle_approval_response(False, reason="disconnect")

        # Cancel the running chat task
        if hasattr(state, 'current_chat_task') and state.current_chat_task:
            state.current_chat_task.cancel()
            state.current_chat_task = None

    except Exception as e:
        # Unexpected error
        print(f"[App] WebSocket error: {e}")
        try:
            await websocket.send_json({
                "type": "error",
                "message": f"Server error: {str(e)}"
            })
        except:
            pass  # Connection already closed


@app.get("/health")
async def health_check():
    """Health check endpoint."""
    return {
        "status": "ok",
        "agent_initialized": state.agent is not None,
        "conversation_manager_initialized": state.conversation_manager is not None
    }


@app.get("/api/latex/orchestral-tex")
async def get_orchestral_tex():
    """Return the orchestral.tex LaTeX module content as JSON."""
    try:
        from orchestral.ui.latex.orchestral_tex_content import ORCHESTRAL_TEX_CONTENT
        return {"content": ORCHESTRAL_TEX_CONTENT}
    except Exception as e:
        return {"error": f"Error loading orchestral.tex: {str(e)}"}


@app.post("/api/message_to_latex")
async def message_to_latex(request: dict):
    """
    Convert a message to LaTeX format.

    Args:
        request: dict with 'message_index' key

    Returns:
        dict with 'latex' key containing the LaTeX code
    """
    from orchestral.ui.latex.converter import LatexConverter

    if not state.agent:
        return {"error": "No agent initialized"}

    message_index = request.get('message_index')
    if message_index is None:
        return {"error": "message_index required"}

    # Get message from context
    if not hasattr(state.agent.context, 'messages'):
        return {"error": "No messages in context"}

    messages = state.agent.context.messages

    # Debug: show message structure around the requested index
    print(f"\n[LaTeX API] message_index: {message_index}")
    for i in range(max(0, message_index - 2), min(len(messages), message_index + 5)):
        item = messages[i]
        if hasattr(item, 'message'):
            role = item.message.role
            has_tools = bool(getattr(item.message, 'tool_calls', None))
            num_tools = len(item.message.tool_calls) if has_tools else 0
            print(f"  [{i}] Response -> {role}, has_tool_calls={has_tools}, num_tools={num_tools}")
        elif hasattr(item, 'role'):
            role = item.role
            has_tools = bool(getattr(item, 'tool_calls', None))
            print(f"  [{i}] Message -> {role}, has_tool_calls={has_tools}")

    if message_index < 0 or message_index >= len(messages):
        return {"error": f"Invalid message_index: {message_index}"}

    # Extract all messages from the context (unwrap Responses)
    unwrapped_messages = []
    for msg_item in messages:
        if hasattr(msg_item, 'message'):
            unwrapped_messages.append(msg_item.message)
        elif hasattr(msg_item, 'role'):
            unwrapped_messages.append(msg_item)

    # Get the message at the specified index
    if message_index < 0 or message_index >= len(unwrapped_messages):
        return {"error": f"Invalid message_index after unwrapping: {message_index}"}

    message = unwrapped_messages[message_index]

    # If this is an assistant message WITHOUT tool calls, it might be the continuation
    # of a previous assistant message that had tool calls. We need to find the start.
    actual_message_index = message_index

    if message.role == 'assistant' and not message.tool_calls:
        # Look backwards to find an assistant message with tool calls
        for i in range(message_index - 1, -1, -1):
            prev_msg = unwrapped_messages[i]

            # Stop if we hit a user or system message (different turn)
            if prev_msg.role in ('user', 'system'):
                break

            # Found an assistant message with tool calls - this is the panel start!
            if prev_msg.role == 'assistant' and prev_msg.tool_calls:
                actual_message_index = i
                message = prev_msg
                break

    # Convert message to LaTeX (the converter handles tool matching internally)
    converter = LatexConverter()

    try:
        latex_code = converter.convert_message_to_latex(
            message,
            all_messages=unwrapped_messages,
            message_index=actual_message_index
        )

        return {"latex": latex_code}
    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"error": f"Conversion failed: {str(e)}"}


def run_server(agent: Agent, host: str = "127.0.0.1", port: int = 8000, open_browser: bool = True):
    """
    Run the app server with conversation persistence.

    Args:
        agent: Configured Agent instance
        host: Host to bind to (default: localhost)
        port: Port to bind to (default: 8000)
        open_browser: Whether to auto-open browser
    """
    import uvicorn

    # Set the agent and initialize conversation manager
    set_agent(agent)

    # Open browser if requested
    if open_browser:
        import webbrowser
        import threading

        def open_browser_delayed():
            import time
            time.sleep(1.5)  # Wait for server to start
            webbrowser.open(f"http://{host}:{port}")

        threading.Thread(target=open_browser_delayed, daemon=True).start()

    # Run server
    print(f"\nüåê Orchestral App (with conversation persistence)")
    print(f"   Open in browser: http://{host}:{port}")
    print("   Features: Auto-save, conversation history, undo, sidebar")
    print("   Press Ctrl+C to stop\n")

    uvicorn.run(
        app,
        host=host,
        port=port,
        log_level="warning"  # Reduce noise
    )


if __name__ == "__main__":
    print("Orchestral App Server")
    print("\nUsage:")
    print("  from orchestral import Agent")
    print("  from app.server import run_server")
    print("")
    print("  agent = Agent(tools=[...])")
    print("  run_server(agent)")
