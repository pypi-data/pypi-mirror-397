[
  {
    "id": 1,
    "damaId": 6,
    "name": "Ability to represent null values",
    "category": "Format",
    "definition": "The degree to which a format allows null values in an attribute.",
    "unitOfMeasure": "Yes/No",
    "icon": "bi-file-earmark-code",
    "examplePoor": [
      "Logistics: A required field (e.g., 'Hazardous Material Class') does not allow nulls, forcing users to enter a default non-hazardous class when the real value is unknown or not applicable for a non-hazardous item.",
      "HR: A 'Termination Date' field in an employee system does not allow nulls, forcing entry of a dummy future date for active employees.",
      "E-commerce: A 'Discount Code Applied' field in an order form cannot be left blank, requiring a 'NONE' value instead of a true null."
    ],
    "exampleGood": [
      "Logistics: An optional field (e.g., 'Special Handling Instructions') correctly allows null values when no special instructions are needed.",
      "HR: A 'Middle Name' field in an employee record correctly allows null if the employee does not have one.",
      "E-commerce: A 'Customer Loyalty ID' field in a guest checkout form allows nulls, as guests wouldn't have one."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Accurate representation of missing or inapplicable information, preventing misinterpretation.",
        "Improved data integrity by distinguishing between a zero value and an unknown value.",
        "More effective data analysis as nulls can be handled appropriately (e.g., excluded or imputed).",
        "Reduced data entry errors caused by forcing users to input dummy values."
      ],
      "negative": [
        "Misinterpretation of data if nulls are not allowed and dummy values (e.g., 0, 'N/A') are used inconsistently.",
        "Skewed analytical results if dummy values are treated as real data.",
        "Increased data cleansing effort to identify and correct inappropriately used dummy values.",
        "Process failures if systems expect true nulls but receive ambiguous placeholders."
      ]
    },
    "illustrativeKpis": [
      "Data Cleansing Effort/Cost",
      "Analytical Model Accuracy",
      "Report Accuracy",
      "Data Entry Error Rate"
    ]
  },
  {
    "id": 2,
    "damaId": 1,
    "name": "Access security",
    "category": "Datasets",
    "definition": "The degree to which access to datasets is restricted.",
    "unitOfMeasure": "Grade",
    "icon": "bi-shield-lock",
    "examplePoor": [
      "Logistics: Customer contract details and pricing accessible by all terminal operations staff.",
      "Finance: All employees can view salary information for everyone in the company.",
      "Healthcare: Patient medical history datasets are accessible via a shared network drive with no specific access controls."
    ],
    "exampleGood": [
      "Logistics: Access to sensitive financial data (e.g., terminal revenue) is restricted based on user roles (e.g., finance department only).",
      "Finance: Only HR managers and direct line managers can access employee performance review datasets.",
      "Healthcare: Access to patient electronic health records (EHR) is strictly controlled by role-based access, logged, and audited."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Protection of sensitive company, customer, and employee data, maintaining trust and legal standing.",
        "Reduced risk of data breaches, leading to avoidance of financial losses, regulatory fines, and reputational damage.",
        "Ensured compliance with data privacy regulations (e.g., GDPR, CCPA, HIPAA).",
        "Preservation of competitive advantage by safeguarding intellectual property and strategic plans."
      ],
      "negative": [
        "Data breaches resulting in direct financial costs (remediation, fines), legal liabilities, and loss of intellectual property.",
        "Severe reputational damage and erosion of customer, partner, and employee trust.",
        "Unauthorized access, modification, or misuse of sensitive information leading to competitive disadvantage or operational disruption.",
        "Non-compliance with data privacy laws, attracting significant penalties and sanctions."
      ]
    },
    "illustrativeKpis": [
      "Number of Security Incidents/Breaches",
      "Cost of Compliance Fines (Security)",
      "Customer Churn Rate (post-breach)",
      "Brand Reputation Score",
      "Time to Detect Security Incidents"
    ]
  },
  {
    "id": 3,
    "damaId": 2,
    "name": "Accessibility",
    "category": "Data",
    "definition": "The ease with which data can be consulted or retrieved.",
    "unitOfMeasure": "Grade",
    "icon": "bi-key",
    "examplePoor": [
      "Logistics: Yard planners cannot easily access real-time container location data; requires logging into multiple slow, disparate systems.",
      "Retail: Store managers need to request sales reports from HQ, which takes 2 days to generate, hindering timely stock decisions.",
      "Research: Historical experiment data is stored in proprietary formats on offline tapes, making it very difficult to access for new analysis."
    ],
    "exampleGood": [
      "Logistics: Planners have a single, responsive dashboard providing fast access to up-to-date container locations and vessel schedules.",
      "Retail: A self-service BI portal allows store managers to instantly generate custom sales reports for their location.",
      "Research: All research data is archived in a well-documented, searchable digital repository with open-format options."
    ],
    "damaAppendix3Title": "Availability",
    "synonyms": [
      "Obtainability of data"
    ],
    "relatedDamaDimensionIds": [
      37
    ],
    "indicators": [
      "Yes or No",
      "The effort it takes to make data available (hours)"
    ],
    "notes": [
      "Data can be partly available."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Faster, more informed decision-making through quick and easy access to necessary information.",
        "Increased employee productivity and operational efficiency as less time is wasted searching for data.",
        "Improved collaboration and knowledge sharing as data can be readily consulted by authorized users.",
        "Enhanced agility in responding to customer needs, market changes, or operational issues."
      ],
      "negative": [
        "Delayed or suboptimal decision-making due to difficulties in finding, retrieving, or understanding available data.",
        "Reduced employee productivity, increased frustration, and wasted resources searching for information.",
        "Information silos hindering cross-departmental collaboration and a unified view of the business.",
        "Slower response times to market opportunities, competitive threats, or critical operational events."
      ]
    },
    "illustrativeKpis": [
      "Time to Decision",
      "Employee Productivity Rate",
      "Project Completion Time",
      "Customer Service Resolution Time",
      "Data Search Time"
    ]
  },
  {
    "id": 4,
    "damaId": 3,
    "name": "Accuracy",
    "category": "Data values",
    "definition": "The degree of closeness of data values to real values.",
    "unitOfMeasure": "%",
    "icon": "bi-bullseye",
    "examplePoor": [
      "Logistics: Incorrect container weight recorded differs significantly from actual weight, causing unsafe lifts or incorrect billing.",
      "Healthcare: Patient's date of birth recorded as 10/15/2023 instead of 10/15/1983 in their medical record.",
      "Finance: Stock price in a portfolio tracking system shows $150.00 but the actual current market price is $152.50."
    ],
    "exampleGood": [
      "Logistics: Package weight in system matches verified gross mass (VGM), ensuring safe handling and accurate charges.",
      "Healthcare: Patient's allergy information in the Electronic Health Record (EHR) accurately reflects all their known allergies.",
      "Finance: The account balance displayed to a customer matches the confirmed ledger balance after all transactions are processed for the day."
    ],
    "damaAppendix3Title": "Accuracy",
    "synonyms": [
      "Correctness of data values"
    ],
    "relatedDamaDimensionIds": [],
    "indicators": [
      "Percentage or number of inaccurate data values."
    ],
    "notes": [
      "The data producer or consumer must define when he/she considers a data value as inaccurate and define criteria for inaccuracy.",
      "The impact of an inaccuracy is different for each attribute.",
      "Generally, accuracy will be measured for individual attributes, e.g., the accuracy of the product name."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Improved strategic and operational decision-making based on reliable, factual data.",
        "Increased operational efficiency by reducing errors, rework, and waste (e.g., accurate shipping, correct billing, precise manufacturing).",
        "Enhanced customer trust and satisfaction (e.g., correct personal details, accurate product information, fair pricing).",
        "Reliable financial reporting, forecasting, auditability, and investor confidence.",
        "Foundation for trustworthy and effective AI/ML model outputs and predictions."
      ],
      "negative": [
        "Flawed strategic decisions based on incorrect data leading to misallocated resources or missed opportunities.",
        "Financial losses due to errors (e.g., mis-shipments, incorrect invoicing, compliance penalties for inaccurate reporting, flawed inventory counts).",
        "Operational inefficiencies and increased costs from rework, correcting mistakes, and handling exceptions.",
        "Damaged customer relationships and loss of trust (e.g., wrong deliveries, incorrect billing, unfair treatment).",
        "Inaccurate AI predictions leading to poor business outcomes, biased results, or operational failures."
      ]
    },
    "illustrativeKpis": [
      "Customer Satisfaction Score (CSAT)",
      "Operational Cost",
      "Return on Investment (ROI)",
      "AI Model Prediction Accuracy",
      "Compliance Breach Incidents",
      "Order Fulfillment Accuracy",
      "Inventory Shrinkage"
    ]
  },
  {
    "id": 5,
    "damaId": 4,
    "name": "Appropriateness",
    "category": "Format",
    "definition": "The degree to which the format is suitable for use.",
    "unitOfMeasure": "%",
    "icon": "bi-file-earmark-code",
    "examplePoor": [
      "Logistics: Storing numerical quantities (like TEU count) as text strings with embedded commas prevents direct calculations.",
      "Manufacturing: Sensor timestamps stored as Unix epoch time without timezone information, leading to ambiguity in event sequencing across plants.",
      "Marketing: Customer survey responses (e.g., 'satisfaction score') stored as free-text instead of a numerical scale, making aggregation hard."
    ],
    "exampleGood": [
      "Logistics: Using a standard date format (YYYY-MM-DD HH:MM:SS) for all event timestamps allows for easy sorting and duration calculations.",
      "Manufacturing: Storing temperature readings as floating-point numbers with a defined unit (Celsius/Fahrenheit) in metadata.",
      "Marketing: Using a standardized country code format (ISO 3166-1 alpha-2) for customer addresses ensures compatibility with analytics tools."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Seamless data processing and integration between systems due to suitable data formats.",
        "Reduced need for complex data transformations, saving time and resources.",
        "Improved usability of data for analytics, reporting, and automated processes.",
        "Enhanced interoperability with partner systems and industry standards."
      ],
      "negative": [
        "Data processing errors or failures when formats are unsuitable for receiving systems or analytical tools.",
        "Increased development and maintenance costs for data transformation routines.",
        "Limited usability of data, hindering analytics, automation, or calculations.",
        "Difficulties in data exchange with external partners or compliance with industry data format standards."
      ]
    },
    "illustrativeKpis": [
      "Data Integration Success Rate",
      "ETL Development Cost/Time",
      "System Interoperability Score",
      "Data Processing Error Rate"
    ]
  },
  {
    "id": 6,
    "damaId": 5,
    "name": "Availability",
    "category": "Data",
    "definition": "The degree to which data can be consulted or retrieved by data consumers or a process.",
    "unitOfMeasure": "Grade",
    "icon": "bi-key",
    "examplePoor": [
      "Logistics: The reporting server for terminal performance dashboards is frequently down during peak operational hours.",
      "E-commerce: Product inventory data is not updated in real-time on the website, leading to orders for out-of-stock items.",
      "Public Sector: Critical public safety information system experiences frequent outages during emergencies."
    ],
    "exampleGood": [
      "Logistics: The data warehouse has high uptime (e.g., 99.99%) and performance, ensuring vessel schedules and cargo data are readily available for analysis.",
      "E-commerce: The customer order history is consistently available through the online portal 24/7.",
      "Public Sector: Emergency response coordination data is accessible through redundant, highly available systems."
    ],
    "damaAppendix3Title": "Availability",
    "synonyms": [
      "Obtainability of data"
    ],
    "relatedDamaDimensionIds": [
      37
    ],
    "indicators": [
      "Yes or No",
      "The effort it takes to make data available (hours)"
    ],
    "notes": [
      "Data are not available because they are not processed yet such as the number of casualties of a recent incident.",
      "Personal data are not available to the public.",
      "Data are not available for reasons of competition.",
      "Data are not available because they are confidential or secret.",
      "Data are not available because they not archived in a professional manner.",
      "Data can be partly available."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Uninterrupted business operations and continuous service delivery to customers and internal users.",
        "Timely access to critical data for operational control, strategic decision-making, and customer support.",
        "Enhanced customer experience and satisfaction through reliable access to services and information.",
        "Ability to consistently meet Service Level Agreements (SLAs) for data and system uptime."
      ],
      "negative": [
        "Business disruptions, system downtime, and lost revenue if critical data or systems are unavailable.",
        "Delayed or impossible decision-making when needed data cannot be accessed during critical periods.",
        "Poor customer experience, frustration, and potential customer loss due to inaccessible services or information.",
        "Failure to meet SLAs, potentially leading to contractual penalties, loss of business, or reputational damage."
      ]
    },
    "illustrativeKpis": [
      "System Uptime Percentage",
      "Service Availability Rate",
      "Mean Time To Recovery (MTTR)",
      "Customer Self-Service Success Rate",
      "Lost Revenue Due to Downtime"
    ]
  },
  {
    "id": 7,
    "damaId": 7,
    "name": "Clarity",
    "category": "Metadata",
    "definition": "The ease with which data consumers can understand the metadata.",
    "unitOfMeasure": "Grade",
    "icon": "bi-info-circle",
    "examplePoor": [
      "Logistics: Data dictionary definition for 'TEU Factor' is ambiguous, missing, or uses highly technical jargon not understood by business users.",
      "Finance: The metadata for a financial report column 'AdjNetRev' does not explain what adjustments were made or the source of the net revenue figure.",
      "Scientific Research: A dataset's metadata lacks clear descriptions of experimental variables or the units of measurement used."
    ],
    "exampleGood": [
      "Logistics: Metadata clearly defines 'Dwell Time' calculation, including source systems, specific filters applied, and the unit of measure (e.g., hours).",
      "Finance: The business glossary clearly defines 'Customer Lifetime Value (CLV)' including the formula, data sources, and assumptions.",
      "Scientific Research: Metadata for a climate dataset thoroughly documents each variable, its units, collection methodology, and any known data quality issues."
    ],
    "damaAppendix3Title": "Clarity",
    "synonyms": [
      "Unambiguity",
      "readability"
    ],
    "relatedDamaDimensionIds": [],
    "indicators": [
      "A grade (1-10)"
    ],
    "notes": [
      "Other quality dimensions of metadata are completeness, correctness, and availability."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Faster and more accurate data interpretation, analysis, and usage by all stakeholders.",
        "Reduced ambiguity and miscommunication regarding data meaning, lineage, and business rules.",
        "Improved data governance, easier onboarding for new data users, and effective self-service analytics.",
        "Increased confidence and trust in data, leading to more data-driven decisions."
      ],
      "negative": [
        "Misinterpretation of data leading to incorrect conclusions, flawed strategies, and poor business decisions.",
        "Wasted time, resources, and duplicated effort trying to understand poorly defined or undocumented data.",
        "Inconsistent data usage and reporting across the organization due to varying interpretations.",
        "Reduced trust in data and analytics, hindering adoption of data-driven culture."
      ]
    },
    "illustrativeKpis": [
      "Time to Insight",
      "Data User Onboarding Time",
      "Number of Data Misinterpretation Incidents",
      "Adoption Rate of BI/Analytics Tools",
      "Data Governance Maturity Score"
    ]
  },
  {
    "id": 8,
    "damaId": 8,
    "name": "Coherence",
    "category": "Composition of datasets",
    "definition": "The degree to which datasets can be combined.",
    "unitOfMeasure": "Story",
    "icon": "bi-puzzle",
    "examplePoor": [
      "Logistics: Sales data uses 'CustomerID' (integer) while shipping data uses 'Customer_Ref_Code' (alphanumeric string) for the same customer, preventing easy joins.",
      "Retail: Product data from the e-commerce platform uses 'SKU_Online' while the ERP system uses 'MaterialNumber', hindering unified inventory views.",
      "Healthcare: Datasets from different hospital departments use varying patient identifier schemes, making it difficult to create a longitudinal patient record."
    ],
    "exampleGood": [
      "Logistics: Both inventory and order datasets use the same standardized 'ProductSKU' and 'LocationID', allowing seamless combination for stock analysis across locations.",
      "Retail: All customer-facing systems (CRM, PoS, Online Store) use a globally unique 'CustomerMasterID', enabling a 360-degree customer view.",
      "Healthcare: All clinical datasets within an organization use a common Master Patient Index (MPI) identifier, ensuring data can be reliably combined for patient care and research."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to create a unified, consistent view of business entities (e.g., 360-degree customer view, end-to-end product lifecycle).",
        "Enhanced data integration capabilities for comprehensive and reliable enterprise-wide analysis.",
        "Improved consistency and comparability in reporting and analytics across different datasets and business units.",
        "Streamlined data exchange and improved interoperability between internal systems and with external partners."
      ],
      "negative": [
        "Difficulty in combining data from different sources, leading to a fragmented and incomplete understanding of the business.",
        "Inconsistent or conflicting insights when analyzing disparate datasets, leading to confusion and distrust.",
        "Increased complexity, cost, and time required for data integration and reconciliation efforts.",
        "Siloed information hindering strategic alignment and operational coordination."
      ]
    },
    "illustrativeKpis": [
      "Data Integration Project Success Rate/Cost",
      "Time to Consolidate Enterprise Reports",
      "Customer Data Completeness (360 view %)",
      "Inter-departmental Process Efficiency Score"
    ]
  },
  {
    "id": 9,
    "damaId": 9,
    "name": "Comparability of populations",
    "category": "Data values",
    "definition": "The degree to which data values representing two populations have the same definition and are measured in the same way.",
    "unitOfMeasure": "Grade",
    "icon": "bi-people",
    "examplePoor": [
      "Logistics: Comparing 'Revenue' from Warehouse A (which includes Value Added Services income) with 'Revenue' from Warehouse B (which only includes handling charges) gives misleading performance results.",
      "Education: Comparing student test scores from two different regions where one region uses a standardized national test and the other uses a locally developed test.",
      "Marketing: Comparing 'customer satisfaction' scores from surveys conducted with different question phrasing or scales across two product lines."
    ],
    "exampleGood": [
      "Logistics: Both terminals report 'Package Throughput' using the exact same counting rules (e.g., including/excluding transshipment moves consistently, same definition of TEU).",
      "Education: Student performance across different schools is compared using results from the same standardized assessment administered under identical conditions.",
      "Marketing: 'Website conversion rates' for different campaigns are compared using the same definition of 'conversion' and the same tracking methodology."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Fair and meaningful comparisons of performance or characteristics across different groups or segments.",
        "Reliable benchmarking against peers or different business units.",
        "Improved accuracy of market analysis and demographic studies.",
        "Evidence-based policy making and resource allocation."
      ],
      "negative": [
        "Misleading conclusions when comparing groups based on inconsistently defined or measured data.",
        "Unfair or inaccurate performance evaluations or resource allocations.",
        "Flawed market segmentation or competitor analysis.",
        "Ineffective policies based on non-comparable data."
      ]
    },
    "illustrativeKpis": [
      "Benchmarking Accuracy",
      "Market Share Analysis Reliability",
      "Policy Effectiveness Measurement",
      "Resource Allocation Equity"
    ]
  },
  {
    "id": 10,
    "damaId": 10,
    "name": "Comparability over time",
    "category": "Data values",
    "definition": "The degree to which data values over time have the same definition and are measured in the same way.",
    "unitOfMeasure": "Grade",
    "icon": "bi-graph-up",
    "examplePoor": [
      "Logistics: The calculation method for 'Yard Utilization' changed last year without documentation or adjustment of historical data, making trend analysis unreliable.",
      "Finance: The company changed its revenue recognition policy mid-year, but historical financial reports were not restated, making year-over-year comparisons inaccurate.",
      "Environment: Air quality monitoring stations changed their sensor calibration methods, but historical readings were not adjusted, skewing long-term pollution trends."
    ],
    "exampleGood": [
      "Logistics: The definition and measurement of 'Truck Turnaround Time' have remained consistent for the past 5 years, allowing accurate trend analysis and benchmarking.",
      "Finance: Key financial ratios are calculated using consistent formulas and data sources across all reporting periods, enabling meaningful trend analysis.",
      "Environment: A consistent methodology for measuring water pollutant levels has been used for a decade, allowing for reliable tracking of environmental changes."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Accurate trend analysis and reliable tracking of performance changes over time.",
        "Consistent historical reporting for long-term strategic planning and forecasting.",
        "Ability to effectively measure the impact of changes or interventions over periods.",
        "Enhanced understanding of business evolution and seasonal patterns."
      ],
      "negative": [
        "Unreliable or misleading trend analysis due to changes in definitions or measurement methods.",
        "Inability to accurately compare past performance with current results.",
        "Difficulty in assessing the true impact of strategic initiatives or market shifts over time.",
        "Flawed forecasting models based on inconsistent historical data."
      ]
    },
    "illustrativeKpis": [
      "Forecast Accuracy",
      "Historical Reporting Consistency",
      "Long-term KPI Trend Reliability",
      "Return on Investment (Time-Series Analysis)"
    ]
  },
  {
    "id": 11,
    "damaId": 11,
    "name": "Completeness (Attributes)",
    "category": "Attributes",
    "definition": "The degree to which all required attributes in the dataset are present.",
    "unitOfMeasure": "%",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: The 'Customer' dataset is missing the 'Tax ID' attribute, which is required for compliant invoicing in certain regions.",
      "Product Management: A new 'Product' dataset schema omits the 'Country of Origin' attribute, which is legally required for import/export documentation.",
      "HR: The employee dataset template does not include an attribute for 'Emergency Contact Information'."
    ],
    "exampleGood": [
      "Logistics: The 'Supplier' dataset includes all necessary attributes like Name, Address, Tax ID, Contact Person, and Payment Terms.",
      "Product Management: The 'Item Master' dataset schema contains all mandatory attributes such as 'Item Description', 'Unit of Measure', 'Weight', 'Dimensions', and 'Safety Stock Level'.",
      "HR: The 'Employee' dataset design includes attributes for all legally required information plus essential operational fields."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures data models and datasets capture all necessary characteristics of an entity for business processes.",
        "Facilitates comprehensive data analysis and richer feature engineering for AI/ML.",
        "Reduces the need for ad-hoc data collection or inferring missing structural information.",
        "Supports better data understanding and context as all relevant facets are defined."
      ],
      "negative": [
        "Inability to perform required business functions if critical attributes are missing from the data structure.",
        "Limited analytical capabilities due to lack of necessary descriptive data points.",
        "Increased effort to augment datasets with missing structural elements.",
        "Poor data modeling leading to systems that don't fully support business needs."
      ]
    },
    "illustrativeKpis": [
      "Data Model Fitness for Purpose Score",
      "Analytical Richness Score",
      "Time to Develop New Reports/Analyses",
      "Business Process Exception Rate (due to missing attributes)"
    ]
  },
  {
    "id": 12,
    "damaId": 12,
    "name": "Completeness (Records)",
    "category": "Records",
    "definition": "The degree to which all required records in the dataset are present.",
    "unitOfMeasure": "%",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: Daily gate transaction log missing records for several hours due to a system outage, skewing throughput reports.",
      "Healthcare: Not all patient encounters or administered medications are being recorded in the EHR system, leading to incomplete medical histories and potential safety risks.",
      "Sales: The CRM is missing contact records for key accounts that were onboarded last quarter due to a data import failure."
    ],
    "exampleGood": [
      "Logistics: Transport Unit arrival notification feed contains records for all expected vessel calls based on port schedules.",
      "Healthcare: All diagnostic test results ordered for patients are successfully recorded and linked to the respective patient record within 24 hours.",
      "Sales: Every lead generated from the website inquiry form is successfully created as a new lead record in the sales automation system."
    ],
    "damaAppendix3Title": "Completeness (1)",
    "synonyms": [
      "Coverage"
    ],
    "relatedDamaDimensionIds": [],
    "indicators": [
      "Percentage or number of the required records that are present."
    ],
    "notes": [
      "Not all products are present in a product file.",
      "Not all inhabitants of a city are registered.",
      "A file of trees also contains shrubs (superfluous records)",
      "Incomplete records are also called missing units."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Comprehensive and accurate understanding of business operations, customer populations, and market activities.",
        "More reliable reporting, robust analytics, and trustworthy forecasting based on full datasets.",
        "Reduced risk of missed opportunities, unaddressed customer issues, or hidden operational gaps.",
        "Improved compliance by ensuring all required transactional or entity records are present and accounted for."
      ],
      "negative": [
        "Incomplete view of business performance leading to skewed analysis, biased insights, and flawed decisions.",
        "Inaccurate or misleading reports and forecasts due to missing segments of data.",
        "Missed sales opportunities, customer service failures, or unidentified operational inefficiencies.",
        "Non-compliance if required transactional, regulatory, or customer records are missing."
      ]
    },
    "illustrativeKpis": [
      "Sales Coverage Rate",
      "Customer Database Completeness %",
      "Operational Process Audit Completeness",
      "Audit Pass Rate (Record Integrity)"
    ]
  },
  {
    "id": 13,
    "damaId": 13,
    "name": "Completeness (Data files)",
    "category": "Data files",
    "definition": "The degree to which all required data files are present.",
    "unitOfMeasure": "%, Number",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: The monthly financial data feed from a subsidiary terminal is missing for the last two months.",
      "Manufacturing: Daily production log files from one of the assembly lines were not received by the central data repository.",
      "Retail: The point-of-sale system failed to upload the end-of-day transaction file for three stores yesterday."
    ],
    "exampleGood": [
      "Logistics: All expected daily sensor reading files from equipment (e.g., cranes, RTGs) are received and processed by the IoT platform.",
      "Manufacturing: All required compliance documentation files (e.g., safety inspection reports) for each piece of equipment are present in the asset management system.",
      "Retail: The weekly sales data files from all regional offices are consistently delivered on time to the central analytics server."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures all necessary data feeds and files are available for batch processing and system updates.",
        "Reliable execution of scheduled data integration and reporting tasks.",
        "Avoidance of process interruptions or incomplete analyses due to missing input files.",
        "Improved operational stability for data-dependent workflows."
      ],
      "negative": [
        "Failure or delay of critical business processes (e.g., payroll, billing, inventory updates) if input files are missing.",
        "Incomplete or outdated information in downstream systems and reports.",
        "Increased manual effort to track down missing files and re-run processes.",
        "Potential for financial or operational impact due to missed data updates."
      ]
    },
    "illustrativeKpis": [
      "Batch Job Success Rate",
      "Data Pipeline Reliability",
      "End-of-Day Processing Completion Rate",
      "Manual Intervention Rate (for missing files)"
    ]
  },
  {
    "id": 14,
    "damaId": 14,
    "name": "Completeness (Data values)",
    "category": "Data values",
    "definition": "The degree to which all required data values are present.",
    "unitOfMeasure": "%",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: Dangerous goods flag (value) missing for a container carrying hazardous materials, leading to improper storage and safety risks.",
      "Customer Service: The 'Resolution Code' field is blank for many closed customer support tickets, preventing analysis of issue resolution types.",
      "Order Processing: The 'Shipping Address' field is empty in several customer orders, halting the fulfillment process."
    ],
    "exampleGood": [
      "Logistics: All required flags (e.g., DG, Reefer Temperature Setting, Out-of-Gauge dimensions) have populated values for containers where applicable.",
      "Customer Service: Every customer feedback record has a value for the 'Satisfaction Score' (e.g., 1-5 scale).",
      "Order Processing: The 'Quantity Ordered' field contains a valid numerical value for every line item in an order."
    ],
    "damaAppendix3Title": "Completeness (2)",
    "synonyms": [],
    "relatedDamaDimensionIds": [],
    "indicators": [
      "Percentage of the possible data values that are present."
    ],
    "notes": [
      "In a product file the attribute supplier is not completed in every record.",
      "In a questionnaire a respondent did not answer all questions.",
      "Incomplete data values are also called missing values."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "More effective and efficient execution of business processes that rely on complete data fields for each record.",
        "Enhanced ability to segment markets, personalize customer interactions, and tailor services based on full attribute sets.",
        "Improved data quality and reliability for downstream analytics, BI reporting, and AI/ML models.",
        "Reduced exceptions, manual interventions, and fallbacks in automated processes and decision engines."
      ],
      "negative": [
        "Process failures, delays, or incorrect execution due to missing critical data values (e.g., missing shipping address, undefined product category).",
        "Inability to effectively personalize marketing, target specific customer segments, or make accurate risk assessments due to incomplete profiles.",
        "Poor performance, bias, or failure of AI/ML models trained or operating on data with many missing values.",
        "Increased manual effort and cost to fill in missing data, handle exceptions, or perform data cleansing."
      ]
    },
    "illustrativeKpis": [
      "Process Automation Rate",
      "Marketing Campaign Effectiveness/Targeting Accuracy",
      "AI Model Performance Metrics (e.g., F1 score, AUC)",
      "Manual Data Entry/Correction Hours"
    ]
  },
  {
    "id": 15,
    "damaId": 15,
    "name": "Completeness (Data values of an attribute)",
    "category": "Data values of an attribute",
    "definition": "The degree to which all required data values of an attribute are present.",
    "unitOfMeasure": "%",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: Many records in the 'Customer' table have a blank 'PhoneNumber' field, hindering communication for delivery coordination.",
      "HR: The 'Date of Birth' attribute is missing for 20% of employee records, impacting benefits administration.",
      "Inventory: The 'Stock Location' attribute is null for a significant number of items in the warehouse management system, making them hard to find."
    ],
    "exampleGood": [
      "Logistics: The 'PackageStatus' attribute has a non-null value (e.g., 'In Yard', 'On Transport Unit', 'Gated Out') for every container record in the ERP.",
      "HR: The 'EmployeeID' attribute is populated for 100% of the records in the active employee table.",
      "Inventory: The 'Last Stock Count Date' attribute is filled for all items that underwent a recent cycle count."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures specific critical attributes are consistently populated across all records, supporting key processes.",
        "Improved reliability of analyses or reports that depend heavily on certain key attributes.",
        "Reduced need to make assumptions or impute values for frequently missing attributes.",
        "Better targeting and segmentation if key profiling attributes are consistently filled."
      ],
      "negative": [
        "Inability to execute specific functions if a required attribute is frequently blank (e.g., cannot send email if email address attribute is empty).",
        "Skewed or unreliable analysis if a key analytical attribute has many missing values.",
        "Increased uncertainty in data-driven decisions if critical information points are often missing.",
        "Operational delays or errors when processes require specific attribute values to proceed."
      ]
    },
    "illustrativeKpis": [
      "Fill Rate for Critical Attributes (%)",
      "Targeted Communication Success Rate",
      "Specific Process Step Completion Rate",
      "Report Field Population Rate"
    ]
  },
  {
    "id": 16,
    "damaId": 16,
    "name": "Completeness (Metadata)",
    "category": "Metadata",
    "definition": "The degree to which the metadata are fully described.",
    "unitOfMeasure": "%",
    "icon": "bi-check2-square",
    "examplePoor": [
      "Logistics: Data dictionary definition for 'TEU Factor' is ambiguous or missing crucial details like how different container sizes are converted.",
      "Finance: The metadata for a financial report lacks information on the source systems for each data element or the last refresh date.",
      "Data Science: A dataset provided for analysis has no metadata describing the meaning of column headers or the range of possible values."
    ],
    "exampleGood": [
      "Logistics: Metadata clearly defines 'Dwell Time' calculation, including source systems, specific filters applied, the unit of measure, and business owner.",
      "Finance: A data catalog provides comprehensive metadata for all key financial metrics, including business definitions, technical lineage, data steward, and update frequency.",
      "Data Science: Each dataset in the repository is accompanied by metadata detailing its schema, data types, descriptions of variables, collection methods, and known limitations."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Thorough understanding of data assets, including definitions, lineage, business rules, and ownership.",
        "Facilitates effective data discovery, self-service analytics, and data governance.",
        "Reduces reliance on tribal knowledge and accelerates onboarding of new data users.",
        "Builds trust in data as its context and meaning are fully documented."
      ],
      "negative": [
        "Difficulty in finding, understanding, or trusting data due to missing or inadequate descriptions.",
        "Increased risk of data misinterpretation and misuse.",
        "Inefficient data management and governance efforts.",
        "Slower development of new analytics, reports, or AI models due to lack of data understanding."
      ]
    },
    "illustrativeKpis": [
      "Data Catalog Completion Rate (%)",
      "Self-Service BI Adoption Rate",
      "Time to Understand a Dataset",
      "Data Governance Audit Findings (Metadata)"
    ]
  },
  {
    "id": 17,
    "damaId": 17,
    "name": "Compliance with laws, regulations, or standards (Data)",
    "category": "Data",
    "definition": "The degree to which data is in accordance with laws, regulations, or standards.",
    "unitOfMeasure": "Story",
    "icon": "bi-shield-check",
    "examplePoor": [
      "Logistics: Storing customer personal data (e.g., consignee contact details) without required consent or for longer than permitted violates GDPR.",
      "Healthcare: Patient records are not de-identified according to HIPAA standards before being used for research.",
      "Finance: Financial transaction data does not include all fields required by anti-money laundering (AML) regulations."
    ],
    "exampleGood": [
      "Logistics: Hazardous material data includes all fields (e.g., UN number, proper shipping name) required by international shipping regulations (IMDG Code).",
      "Healthcare: All patient data handling processes adhere to GDPR or HIPAA requirements for consent, security, and breach notification.",
      "Finance: Customer identification data collected during onboarding meets Know Your Customer (KYC) regulatory requirements."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Avoidance of legal penalties, significant fines, and sanctions from regulatory bodies.",
        "Enhanced corporate reputation, stakeholder trust, and brand image.",
        "Reduced risk of litigation, legal challenges, and associated costs.",
        "Smoother audits, easier regulatory reviews, and maintenance of licenses to operate."
      ],
      "negative": [
        "Significant financial penalties, legal costs, and potential business disruptions for non-compliance with laws (e.g., GDPR, SOX, HIPAA).",
        "Severe damage to brand reputation, public trust, and customer loyalty.",
        "Increased scrutiny from regulators, potential operational shutdowns, or loss of certifications.",
        "Litigation risks from affected parties (customers, employees, shareholders) due to data misuse or non-compliance."
      ]
    },
    "illustrativeKpis": [
      "Number of Regulatory Compliance Breaches",
      "Cost of Regulatory Fines & Penalties",
      "Audit Finding Severity/Frequency",
      "Legal Expenditure on Compliance Issues",
      "Customer Trust Index"
    ]
  },
  {
    "id": 18,
    "damaId": 18,
    "name": "Compliance with laws, regulations, or standards (Composition of datasets)",
    "category": "Composition of datasets",
    "definition": "The degree to which the composition of datasets is in accordance with laws, regulations, or standards.",
    "unitOfMeasure": "Story",
    "icon": "bi-shield-check",
    "examplePoor": [
      "Logistics: Combining employee performance data with anonymous survey data in a way that inadvertently allows re-identification of individuals, violating privacy policies.",
      "Marketing: Creating customer profiles by combining data from various sources without explicit consent for such aggregation, potentially violating data privacy laws.",
      "Research: A dataset compiled for public release aggregates sensitive demographic data in such a way that small population groups could be identified, breaching ethical guidelines."
    ],
    "exampleGood": [
      "Logistics: Aggregated financial reports derived from multiple subsidiary datasets comply with IFRS or GAAP reporting standards.",
      "Marketing: Customer segments created for targeted advertising are based on aggregated, anonymized data that respects privacy regulations and user consent.",
      "Research: When combining datasets for a study, all data linkage and aggregation methods follow strict protocols to maintain anonymity and comply with IRB approvals."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures aggregated or derived datasets meet reporting standards and legal requirements.",
        "Mitigates risks associated with inappropriate data aggregation or linkage (e.g., re-identification).",
        "Supports ethical data use and responsible AI by adhering to composition rules.",
        "Facilitates compliant data sharing and collaboration."
      ],
      "negative": [
        "Violation of privacy laws or ethical guidelines through improper data aggregation or de-anonymization.",
        "Non-compliant reporting if dataset composition does not meet specific standards (e.g., financial reporting rules).",
        "Legal and reputational risks from misuse of combined datasets.",
        "Barriers to data sharing if composition standards are not met."
      ]
    },
    "illustrativeKpis": [
      "Data Aggregation Compliance Rate",
      "Ethical AI Review Pass Rate",
      "Regulatory Reporting Accuracy (Composition)",
      "Data Sharing Agreement Violations"
    ]
  },
  {
    "id": 19,
    "damaId": 19,
    "name": "Confidentiality",
    "category": "Data",
    "definition": "The degree to which disclosure of data should be restricted to authorized data consumers.",
    "unitOfMeasure": "Grade",
    "icon": "bi-shield-lock",
    "examplePoor": [
      "Logistics: Competitively sensitive customer contract details and pricing information are accessible by unauthorized personnel or through poorly secured APIs.",
      "HR: Employee salary and performance review data is stored in a shared folder accessible to all network users.",
      "R&D: Unpatented research findings and new product designs are stored on systems without adequate access controls, risking industrial espionage."
    ],
    "exampleGood": [
      "Logistics: Access to sensitive financial data, such as terminal profitability reports, is strictly restricted based on user roles and multi-factor authentication.",
      "HR: Personal Identifiable Information (PII) of employees is encrypted at rest and in transit, with access logged and audited regularly.",
      "R&D: Intellectual property and trade secrets are stored in a highly secured environment with granular access permissions and continuous monitoring for unauthorized access attempts."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Protection of sensitive business, customer, and personal information from unauthorized disclosure or theft.",
        "Maintenance of customer and employee privacy, fostering trust and loyalty.",
        "Safeguarding of valuable trade secrets, intellectual property, and competitive intelligence.",
        "Adherence to data privacy and security mandates, avoiding breaches and associated penalties."
      ],
      "negative": [
        "Leakage or theft of sensitive data leading to competitive disadvantage, financial loss, or personal harm to individuals.",
        "Severe erosion of customer, partner, and employee trust if privacy or confidential information is breached.",
        "Loss of intellectual property, strategic plans, or M&A information.",
        "Legal and financial repercussions, including fines and lawsuits, for failing to protect confidential data."
      ]
    },
    "illustrativeKpis": [
      "Number of Confidentiality Incidents/Data Spills",
      "Value of Intellectual Property Lost",
      "Employee/Customer Trust Score (Privacy)",
      "Data Loss Prevention (DLP) Effectiveness Rate",
      "Cost of Data Breach Remediation"
    ]
  },
  {
    "id": 20,
    "damaId": 20,
    "name": "Consistency (Data values)",
    "category": "Data values",
    "definition": "The degree to which data values of two sets of attributes comply with a rule.",
    "unitOfMeasure": "%",
    "icon": "bi-link-45deg",
    "examplePoor": [
      "Logistics: Warehouse Operating System (ERP) shows a container in Yard Block A, but the Gate System shows the same container exited the terminal 1 hour ago.",
      "Retail: The price of a product on the shelf tag is $9.99, but it scans at $10.99 at the point-of-sale.",
      "Finance: The total sum of individual departmental budgets does not match the overall approved company budget in the financial planning system."
    ],
    "exampleGood": [
      "Logistics: All systems (ERP, Gate System, Handheld Scanners) show the same, current, and accurate location for a specific container.",
      "Retail: The product price listed on the e-commerce website matches the price in the inventory management system and the price at the physical store checkout.",
      "Finance: The customer's outstanding balance in the billing system is identical to the balance shown in the accounts receivable ledger."
    ],
    "damaAppendix3Title": "Consistency",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      38
    ],
    "indicators": [
      "Percentage of inconsistencies."
    ],
    "notes": [
      "A company is registered in the city of Paris in the country of Belgium.",
      "Overlap are gaps in file with address history of a person. For example: Address A from 1 Jan 2003 \u2013 1 May 2019 and Address B from 1 March \u2013 until now."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Reliable, coherent, and trustworthy data across different systems, reports, and analytical outputs.",
        "Reduced confusion, ambiguity, and misinterpretation for data users and decision-makers.",
        "Improved data integrity and accuracy of consolidated views and enterprise-wide reporting.",
        "More efficient and predictable business processes due to harmonious and predictable data interactions."
      ],
      "negative": [
        "Conflicting or contradictory information leading to confusion, distrust in data, and poor or delayed decision-making.",
        "Erosion of trust in information systems, BI tools, and analytical insights.",
        "Wasted effort, time, and resources in reconciling discrepancies between different data sources or reports.",
        "Process breakdowns, errors, or inefficiencies when systems or people encounter inconsistent data values."
      ]
    },
    "illustrativeKpis": [
      "Data Reconciliation Effort (Hours/Cost)",
      "Report Generation Accuracy & Consistency",
      "User Trust in Data Score",
      "Cross-System Process Error Rate",
      "Decision Reversal Rate (due to conflicting data)"
    ]
  },
  {
    "id": 21,
    "damaId": 21,
    "name": "Consistency (Temporal)",
    "category": "Data values of a set of attributes of a dataset at different points in time (temporal consistency)",
    "definition": "The degree to which the data values of a set of attributes of a dataset at different points in time comply with a rule.",
    "unitOfMeasure": "%",
    "icon": "bi-link-45deg",
    "examplePoor": [
      "Logistics: A container's status changes from 'Gated Out' back to 'In Yard' in the system's event log without a corresponding gate-in event record.",
      "Banking: A customer's account balance for yesterday is reported as $100, but today's report for the same historical date shows $150 without any correcting transaction.",
      "Inventory: The stock level of an item is recorded as 50 units at 9 AM, then 40 units at 10 AM (due to a sale), but then back to 50 units at 11 AM without any new stock arrival record."
    ],
    "exampleGood": [
      "Logistics: Monthly revenue figures consistently sum up to the correct quarterly and annual totals when aggregated over time.",
      "Banking: An account's transaction history, when replayed, always results in the currently reported balance.",
      "Inventory: If an item's stock level decreases, there is a corresponding sales or stock adjustment record; if it increases, there's a purchase or return record."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Reliable tracking of changes and states over time.",
        "Accurate historical analysis and trend identification.",
        "Trustworthy audit trails for transactional data.",
        "Predictable behavior of time-series dependent models and forecasts."
      ],
      "negative": [
        "Inability to accurately reconstruct historical states or event sequences.",
        "Misleading trend analysis if data changes illogically over time.",
        "Compromised audit trails and difficulty in investigating historical transactions.",
        "Unreliable time-series forecasts or AI models."
      ]
    },
    "illustrativeKpis": [
      "Historical Data Reconstruction Accuracy",
      "Audit Trail Integrity Score",
      "Time-Series Forecast Error Rate",
      "Event Sequence Anomaly Rate"
    ]
  },
  {
    "id": 22,
    "damaId": 22,
    "name": "Consistency (Across Datasets)",
    "category": "Data values of two sets of attributes between datasets (across datasets)",
    "definition": "The degree to which data values of two sets of attributes between datasets comply with a rule.",
    "unitOfMeasure": "%",
    "icon": "bi-link-45deg",
    "examplePoor": [
      "Logistics: Total container moves reported in the operational system for a vessel do not match the total moves used for billing that vessel in the financial system.",
      "HR: The number of active employees in the HR payroll system differs from the number of active user accounts in the IT directory.",
      "Manufacturing: The quantity of raw materials consumed reported by the production system does not align with the quantity depleted from the inventory system."
    ],
    "exampleGood": [
      "Logistics: Customer ID in the Orders dataset successfully matches a valid and active Customer ID in the Customer Master dataset.",
      "HR: The list of employees eligible for a bonus in the performance management system is identical to the list used by payroll for bonus disbursement.",
      "Manufacturing: The bill of materials (BOM) in the engineering system is consistent with the BOM used by the procurement system for ordering components."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Single version of truth for key entities and metrics across the enterprise.",
        "Improved accuracy of enterprise-wide reporting and analytics.",
        "Reduced data integration complexity and cost.",
        "Enhanced ability to make holistic business decisions."
      ],
      "negative": [
        "Conflicting reports and analyses from different departments or systems.",
        "Difficulty in achieving a unified view of customers, products, or operations.",
        "Increased manual effort for data reconciliation between systems.",
        "Suboptimal decisions based on fragmented or contradictory information."
      ]
    },
    "illustrativeKpis": [
      "Cross-Departmental Report Discrepancy Rate",
      "Data Silo Reduction Index",
      "Enterprise Data Warehouse Accuracy",
      "Strategic Alignment Score"
    ]
  },
  {
    "id": 23,
    "damaId": 23,
    "name": "Consistency (Cross-Record)",
    "category": "Data values of two sets of attributes between records (cross record)",
    "definition": "The degree to which data values of two sets of attributes between records comply with a rule.",
    "unitOfMeasure": "%",
    "icon": "bi-link-45deg",
    "examplePoor": [
      "Logistics: Two different employee records in the HR system show the same unique Social Security Number.",
      "E-commerce: Multiple customer records exist with the exact same email address but different customer IDs.",
      "Asset Management: Two distinct asset records in the maintenance system share the same unique serial number."
    ],
    "exampleGood": [
      "Logistics: All orders belonging to the same shipment share the same unique Transport Unit Voyage number.",
      "E-commerce: Within a single order, all line items correctly reference the same unique Order ID.",
      "Asset Management: All maintenance tasks scheduled for a specific piece of equipment correctly link to that equipment's unique asset ID."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures that unique identifiers or key attributes are not improperly duplicated across different records representing distinct entities.",
        "Maintains the integrity of relationships where one record should uniquely map to another based on specific rules (e.g. one primary contact per account).",
        "Prevents ambiguity when linking records based on supposedly unique shared attributes.",
        "Supports accurate aggregation and counting when business rules dictate unique relationships between records."
      ],
      "negative": [
        "Incorrect linkage of records leading to flawed analysis or operational errors (e.g. attributing multiple SSNs to one person indirectly).",
        "Violation of business rules that define unique relationships between different types of records.",
        "Difficulty in accurately identifying distinct entities when linking data based on shared attributes that should be unique in one table but map to multiple in another.",
        "Skewed counts or aggregations if cross-record uniqueness rules are violated."
      ]
    },
    "illustrativeKpis": [
      "Unique Constraint Violation Rate (Cross-Record Rules)",
      "Data Relationship Integrity Score",
      "Accuracy of Network Analysis",
      "False Positive/Negative Linkage Rate"
    ]
  },
  {
    "id": 24,
    "damaId": 24,
    "name": "Consistency (Record-Level)",
    "category": "Data values of two sets of attributes within a record (record level)",
    "definition": "The degree to which data values of two sets of attributes within a record comply with a rule.",
    "unitOfMeasure": "%",
    "icon": "bi-link-45deg",
    "examplePoor": [
      "Logistics: A shipment record shows 'DateShipped' is earlier than 'DateBooked'.",
      "HR: An employee record has a 'TerminationDate' that is before their 'HireDate'.",
      "Finance: An invoice record has a 'DueDate' earlier than its 'IssueDate'."
    ],
    "exampleGood": [
      "Logistics: In an employee record, 'HireDate' is always earlier than or equal to 'TerminationDate' (if the latter is present).",
      "HR: An employee's age calculated from 'DateOfBirth' is consistent with their listed 'AgeGroup' category.",
      "Finance: In a loan application record, the 'LoanAmountRequested' is less than or equal to the 'MaximumLoanAmountAllowed' for that loan type."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures logical sense and adherence to business rules within individual data records.",
        "Prevents internal contradictions within a record that could lead to processing errors or misinterpretation.",
        "Improved data quality at the most granular level, forming a reliable base for aggregation.",
        "Reduced exceptions in automated data validation and processing."
      ],
      "negative": [
        "Illogical data entries (e.g., shipment date before order date) leading to process failures or incorrect calculations.",
        "Increased manual effort to identify and correct internal inconsistencies within records.",
        "Reduced reliability of individual records used in decision-making or customer interactions.",
        "Poor performance of AI models if training data contains internally inconsistent records."
      ]
    },
    "illustrativeKpis": [
      "Internal Record Error Rate",
      "Automated Validation Exception Rate",
      "Data Quality Score (Record Level)",
      "Process Straight-Through Processing (STP) Rate"
    ]
  },
  {
    "id": 25,
    "damaId": 25,
    "name": "Credibility",
    "category": "Data values",
    "definition": "The degree to which data values are regarded as true and believable by data consumers.",
    "unitOfMeasure": "Grade",
    "icon": "bi-person-check",
    "examplePoor": [
      "Logistics: Users distrust the sales forecast report for shipping volumes because past forecasts have been consistently and wildly inaccurate.",
      "News Media: A news article citing data from an unverified source is met with skepticism by readers.",
      "Market Research: A market share report based on a very small or biased sample size is not considered credible by industry analysts."
    ],
    "exampleGood": [
      "Logistics: The vessel ETA provided by the terminal operating system is trusted because it's consistently updated with reliable AIS data and historical performance.",
      "News Media: Financial data published by reputable government statistical agencies is generally considered highly credible.",
      "Market Research: A clinical trial result published in a peer-reviewed journal with transparent methodology and data is seen as credible."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Increased trust and confidence in data among users and decision-makers.",
        "Higher adoption rates for data-driven insights, BI tools, and analytical reports.",
        "Stronger foundation for making critical business decisions based on believable information.",
        "Enhanced reputation of data sources and data providers within the organization."
      ],
      "negative": [
        "Users ignoring or distrusting data and reports, leading to decisions based on gut feel or intuition.",
        "Wasted investment in BI and analytics systems if users do not believe the data.",
        "Reluctance to act on data-driven recommendations.",
        "Poor data culture and skepticism towards data initiatives."
      ]
    },
    "illustrativeKpis": [
      "User Trust in Data (Survey Score)",
      "BI/Analytics Tool Adoption Rate",
      "Data-Driven Decision Rate",
      "Perceived Reliability of Data Sources"
    ]
  },
  {
    "id": 26,
    "damaId": 26,
    "name": "Currency",
    "category": "Data values",
    "definition": "The degree to which data values are up to date.",
    "unitOfMeasure": "%",
    "icon": "bi-clock-history",
    "examplePoor": [
      "Logistics: Reefer container temperature shown in the monitoring system is from 2 hours ago. The cargo might have spoiled if the reefer unit failed since that last update.",
      "Finance: The stock portfolio valuation on a trading platform displays prices from the previous day's close, not real-time market prices.",
      "Customer Service: The customer's contact information in the CRM was last updated 3 years ago and is likely outdated."
    ],
    "exampleGood": [
      "Logistics: Package location data is updated in near real-time (e.g., within seconds or minutes) as it moves through the yard or is scanned.",
      "Finance: Foreign exchange rates used for international transactions are updated every few minutes from a reliable market feed.",
      "Customer Service: A customer's shipping address is confirmed and updated (if necessary) during every new order placement."
    ],
    "damaAppendix3Title": "Currency",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      53
    ],
    "indicators": [
      "Percentage of data that are up to date in a point of time."
    ],
    "notes": [
      "Outdated prices in the product file."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Decisions based on the most up-to-date and recent information available, reflecting current reality.",
        "Enhanced responsiveness and agility in reacting to real-time events, market changes, or operational fluctuations.",
        "Improved accuracy of operational monitoring, control systems, and short-term forecasting.",
        "Better customer service and personalized interactions through access to current customer status and preferences."
      ],
      "negative": [
        "Outdated information leading to incorrect assumptions, flawed analyses, and suboptimal or risky decisions.",
        "Missed opportunities, delayed responses, or competitive disadvantage due to reliance on stale data.",
        "Operational inefficiencies or errors if actions are based on old information (e.g., outdated inventory levels, incorrect customer contact details).",
        "Poor customer experience and dissatisfaction if interactions or services are based on non-current data."
      ]
    },
    "illustrativeKpis": [
      "Time to Market for New Products/Services (Data Refresh Rate)",
      "Inventory Accuracy (Real-time vs. Batch)",
      "Customer Complaint Rate (due to outdated info)",
      "Effectiveness of Real-time Alerts & Monitoring",
      "Data Freshness Index"
    ]
  },
  {
    "id": 27,
    "damaId": 27,
    "name": "Equivalence",
    "category": "Attributes",
    "definition": "The degree to which attributes stored in multiple datasets are conceptually equal.",
    "unitOfMeasure": "%",
    "icon": "bi-arrow-left-right",
    "examplePoor": [
      "Logistics: One system uses 'CustID' (integer, primary key) while another system uses 'CustomerIdentifier' (alphanumeric string, business key) for the same customer concept, making automated joins difficult.",
      "Product Management: 'ProductWeight' in the catalog system is in kilograms, while 'Item_Wt' in the shipping system is in pounds, for the same product attribute.",
      "HR: 'Employee_Status' in one system might use codes ('A', 'T', 'L' for Active, Terminated, Leave) while another uses full text ('Active', 'Former Employee', 'On Leave')."
    ],
    "exampleGood": [
      "Logistics: Both the terminal planning system and the execution system use the attribute 'Transport UnitVoyageID' with the same definition, data type, and format.",
      "Product Management: All systems that store product dimensions (length, width, height) use the same attribute names (e.g., 'ProductLengthCM', 'ProductWidthCM', 'ProductHeightCM') and consistently use centimeters as the unit.",
      "HR: The attribute 'EmployeeStartDate' has the exact same meaning (first day of employment) and date format across the HRIS, payroll, and benefits systems."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Simplified data integration and mapping between different systems or datasets.",
        "Reduced ambiguity when attributes representing the same concept have different names or formats.",
        "Improved consistency in understanding and using conceptually similar data across the organization.",
        "Facilitates creation of a common business vocabulary and semantic layer."
      ],
      "negative": [
        "Increased complexity and cost in data integration due to mismatches in attribute definitions.",
        "Risk of misinterpreting or incorrectly joining data if conceptually equivalent attributes are not recognized.",
        "Inconsistent reporting or analysis if different terms are used for the same underlying business concept.",
        "Barriers to establishing a shared understanding of data across business units."
      ]
    },
    "illustrativeKpis": [
      "Data Mapping Effort/Complexity",
      "Semantic Consistency Score",
      "Common Business Vocabulary Adoption",
      "Cross-System Data Harmonization Rate"
    ]
  },
  {
    "id": 28,
    "damaId": 28,
    "name": "Granularity (Attributes)",
    "category": "Attributes",
    "definition": "The degree to which a single characteristic is subdivided in attributes.",
    "unitOfMeasure": "Story",
    "icon": "bi-grid-1x2",
    "examplePoor": [
      "Logistics: A single 'Address' attribute in the customer table holds the entire address: Street, City, Postal Code, and Country, making it hard to query by city.",
      "Contact Management: A 'FullName' attribute stores first name, middle name, and last name together.",
      "Event Logging: A single 'EventDetails' attribute contains timestamp, event type, and user ID concatenated together."
    ],
    "exampleGood": [
      "Logistics: 'Address' is broken down into separate, well-defined attributes: StreetAddress, City, PostalCode, State, Country.",
      "Contact Management: 'FirstName', 'MiddleName', 'LastName' are stored as distinct attributes.",
      "Event Logging: 'EventTimestamp', 'EventType', 'UserID' are stored as individual attributes for easier filtering and analysis."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Enables precise data capture and more detailed analysis.",
        "Improved flexibility in querying, filtering, and aggregating data based on specific sub-components.",
        "Better support for complex business rules that depend on fine-grained attribute details.",
        "Enhanced data quality as validation can be applied to more specific data points."
      ],
      "negative": [
        "Loss of detail, limiting the depth of analysis and insight generation (e.g., cannot analyze by city if only full address is stored).",
        "Difficulty in applying specific business rules or validations if attributes are too broad.",
        "Increased complexity in parsing or splitting combined attributes for specific uses.",
        "Inability to answer specific business questions requiring finer detail."
      ]
    },
    "illustrativeKpis": [
      "Analytical Depth Score",
      "Data Query Flexibility",
      "Business Rule Implementation Complexity",
      "Report Customization Capability"
    ]
  },
  {
    "id": 29,
    "damaId": 29,
    "name": "Granularity (Records)",
    "category": "Records",
    "definition": "The degree to which objects are aggregated to records.",
    "unitOfMeasure": "Story",
    "icon": "bi-grid-1x2",
    "examplePoor": [
      "Logistics: Sales data for container movements is only available aggregated at the monthly level, preventing analysis of daily operational trends or peak hour demands.",
      "Retail: Website traffic data is only stored as daily summaries, losing information about user navigation paths or hourly visit patterns.",
      "Manufacturing: Quality control checks are recorded only as a pass/fail summary per batch, not detailing individual item defects within the batch."
    ],
    "exampleGood": [
      "Logistics: Gate transactions are recorded individually for each container move (in and out), allowing detailed analysis by hour, shift, day, or truck company.",
      "Retail: Every click and page view on the e-commerce site is logged as an individual event record, enabling detailed customer journey analysis.",
      "Manufacturing: Each individual product unit coming off the assembly line has its own quality inspection record detailing all measurements and checks."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to perform detailed, low-level analysis of transactions, events, or individual entities.",
        "More accurate and nuanced understanding of patterns, trends, and anomalies.",
        "Foundation for building more precise predictive models or detailed operational reports.",
        "Flexibility to aggregate data to various summary levels as needed."
      ],
      "negative": [
        "Inability to analyze data at the required level of detail, obscuring important insights.",
        "Loss of information when data is pre-aggregated too early in the lifecycle.",
        "Difficulty in identifying root causes of issues or understanding specific event details.",
        "Limited ability to drill down into summary data for deeper investigation."
      ]
    },
    "illustrativeKpis": [
      "Drill-Down Capability Index",
      "Root Cause Analysis Effectiveness",
      "Predictive Model Granularity Fit",
      "Lowest Level of Detail Available for Analysis"
    ]
  },
  {
    "id": 30,
    "damaId": 30,
    "name": "Integrity",
    "category": "Data values",
    "definition": "The degree of absence of data value loss or corruption.",
    "unitOfMeasure": "%",
    "icon": "bi-gem",
    "examplePoor": [
      "Logistics: Data transmission errors cause container numbers to be corrupted (e.g., 'MSCU12?4567' instead of 'MSCU1234567') during EDI exchange.",
      "Database: A database restore process fails, and a portion of transaction data from the last backup is permanently lost.",
      "File Transfer: A large CSV file is truncated during FTP transfer, resulting in incomplete records in the destination system."
    ],
    "exampleGood": [
      "Logistics: Checksums and validation rules are used during data transmission to ensure container details are not corrupted when moving between systems.",
      "Database: Robust backup and recovery procedures are in place, and regular tests confirm that data can be restored completely and without corruption.",
      "File Transfer: Secure file transfer protocols (like SFTP) with built-in error checking are used to ensure complete and uncorrupted file delivery."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Preservation of data accuracy and completeness during storage, processing, and transmission.",
        "Reduced risk of data corruption, unauthorized modification, or accidental loss.",
        "Increased trust in the reliability and wholeness of data assets.",
        "More stable and dependable system operations and data pipelines."
      ],
      "negative": [
        "Data corruption leading to inaccurate information, process failures, or system errors.",
        "Loss of critical data due to system malfunctions, transmission errors, or inadequate controls.",
        "Reduced confidence in data if its integrity is questionable.",
        "Increased costs for data recovery, correction, and validation."
      ]
    },
    "illustrativeKpis": [
      "Data Corruption Rate",
      "Data Loss Incident Frequency",
      "System Error Rate (Data Integrity related)",
      "Data Validation Success Rate"
    ]
  },
  {
    "id": 31,
    "damaId": 31,
    "name": "Interpretability",
    "category": "Data",
    "definition": "The degree to which data are in an appropriate language and units of measure.",
    "unitOfMeasure": "%",
    "icon": "bi-info-circle",
    "examplePoor": [
      "Logistics: A report shows 'Package Weight' as a numerical value but doesn't specify if it's in kilograms (KG) or pounds (LBS).",
      "International Trade: Product descriptions are only available in one language, making them difficult for international partners to understand.",
      "Scientific Data: A dataset contains a column labeled 'Temp' with numerical values, but no indication of whether it's Celsius, Fahrenheit, or Kelvin."
    ],
    "exampleGood": [
      "Logistics: All financial reports clearly state the currency used (e.g., USD, EUR, JPY) for all monetary values.",
      "International Trade: Product specifications are available in multiple languages, and all measurements clearly state their units (e.g., 'Length: 10 meters', 'Weight: 500 Kilograms').",
      "Scientific Data: All data values are accompanied by metadata defining their units (e.g., 'Temperature (Celsius)', 'Pressure (Pascals)')."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Clear understanding of data by users, regardless of their technical background.",
        "Reduced misinterpretation and more accurate application of data in business contexts.",
        "Improved communication and collaboration when discussing data-driven insights.",
        "Enhanced data literacy across the organization."
      ],
      "negative": [
        "Misunderstanding of data leading to flawed conclusions, poor decisions, or incorrect actions.",
        "Wasted time as users struggle to decipher cryptic codes, ambiguous terms, or unclear units.",
        "Barriers to effective data use, particularly for non-technical business users.",
        "Low data literacy and reluctance to engage with data."
      ]
    },
    "illustrativeKpis": [
      "Data Literacy Score",
      "User Comprehension Test Score (for data reports)",
      "Time to Understand Reports/Dashboards",
      "Error Rate in Data Application"
    ]
  },
  {
    "id": 32,
    "damaId": 32,
    "name": "Latency",
    "category": "Data",
    "definition": "The period of time between the point when the data is created and the point when it is available for use.",
    "unitOfMeasure": "Duration",
    "icon": "bi-clock-history",
    "examplePoor": [
      "Logistics: It takes 24 hours for gate move data (container entering/leaving terminal) to appear in the central reporting system, delaying operational analysis.",
      "Financial Trading: Real-time stock price data feed has a 15-minute delay, making it unsuitable for high-frequency trading decisions.",
      "Emergency Services: GPS location updates from emergency vehicles are delayed by 5 minutes, impacting dispatch efficiency."
    ],
    "exampleGood": [
      "Logistics: Real-time crane position data and reefer temperature alerts are available to the planning and monitoring systems within seconds of the event.",
      "Financial Trading: A low-latency market data feed provides stock price updates within milliseconds of market changes.",
      "Emergency Services: Ambulance location data is transmitted to the dispatch center with sub-second latency."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Real-time or near real-time availability of data for immediate operational decisions and actions.",
        "Enhanced ability to monitor dynamic situations and respond quickly to events.",
        "Improved performance of time-sensitive applications (e.g., fraud detection, algorithmic trading).",
        "Better customer experience through instant access to up-to-the-second information."
      ],
      "negative": [
        "Delayed availability of critical data, hindering timely responses and effective decision-making.",
        "Inability to effectively manage real-time operations or capitalize on fleeting opportunities.",
        "Poor performance or failure of applications that require low-latency data.",
        "Suboptimal customer experience if information or services are delayed."
      ]
    },
    "illustrativeKpis": [
      "Data Refresh Rate/Frequency",
      "Real-time Decision Window Adherence",
      "Algorithmic Trading Profitability (Latency Impact)",
      "Customer Wait Time (Information Dependent)"
    ]
  },
  {
    "id": 33,
    "damaId": 33,
    "name": "Linkability",
    "category": "Data files",
    "definition": "The degree to which records of one data file can be correctly coupled with records of another data file.",
    "unitOfMeasure": "%",
    "icon": "bi-link",
    "examplePoor": [
      "Logistics: Inconsistent formatting or typos in vessel names (e.g., 'MSC New York' vs 'MSC_NewYork' vs 'MSCNWY') prevents accurately linking vessel schedule data with operational data for that vessel.",
      "Customer Management: The customer ID in the sales order system is a different format than the customer ID in the support ticket system, making it hard to get a unified view of customer interactions.",
      "Healthcare: Patient records from different clinics use different identifier schemes with no common key, making it impossible to link a patient's full medical history."
    ],
    "exampleGood": [
      "Logistics: Using standardized, globally unique container IDs (ISO 6346) allows reliably linking information about a container from the Warehouse Operating System, gate system, customs declarations, and shipping line manifest.",
      "Customer Management: A master customer ID is used consistently across all systems (CRM, ERP, Marketing Automation), enabling a complete view of the customer journey.",
      "Healthcare: A Master Patient Index (MPI) provides a unique identifier for each patient, allowing their records from various departments (radiology, lab, pharmacy) to be correctly linked."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to create comprehensive, interconnected views of business entities and processes (e.g., 360-degree customer view, supply chain visibility).",
        "Deeper insights from analyzing relationships, networks, and flows between different data entities.",
        "Improved data integration efficiency for BI, advanced analytics, and AI/ML applications.",
        "Enhanced master data management capabilities and establishment of a connected data ecosystem."
      ],
      "negative": [
        "Inability to connect related information across disparate datasets, leading to fragmented understanding and missed insights.",
        "Missed opportunities for value creation that could be derived from analyzing linked data relationships.",
        "Costly, complex, and error-prone data integration projects due to difficulties in establishing reliable links.",
        "Challenges in building accurate master data records and understanding complex interdependencies."
      ]
    },
    "illustrativeKpis": [
      "Master Data Record Accuracy & Linkage Completeness",
      "Customer Lifetime Value (CLV) Calculation Accuracy",
      "Supply Chain End-to-End Visibility Percentage",
      "Analytical Query Performance on Joins",
      "Network Analysis Effectiveness"
    ]
  },
  {
    "id": 34,
    "damaId": 34,
    "name": "Metadata compliance",
    "category": "Data values",
    "definition": "The degree to which the data values are in accordance with their definition, format specification and value domain.",
    "unitOfMeasure": "%",
    "icon": "bi-shield-check",
    "examplePoor": [
      "Logistics: A 'PackageType' field, defined in metadata to accept values like '20GP', '40HC', sometimes contains invalid codes like '20 Standard' or free text.",
      "Finance: An 'InvoiceDate' field, specified to be in YYYY-MM-DD format, contains values like '15/03/2024' or 'March 15, 2024'.",
      "HR: An 'EmployeeStatusCode' field, with a defined value domain of {Active, Terminated, OnLeave}, contains an unexpected value like 'Pending_Review'."
    ],
    "exampleGood": [
      "Logistics: All values in the 'PackageLength' field are valid lengths (e.g., 20, 40, 45) as per its defined value domain and data type (integer).",
      "Finance: All transaction amounts in the 'TransactionValue' field adhere to the defined format (e.g., numeric with two decimal places) and are within a plausible range (e.g., not negative for sales).",
      "HR: The 'DepartmentID' in employee records always corresponds to a valid ID present in the official 'Departments' reference table."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures data values adhere to their defined business rules, formats, and value domains.",
        "Improved data consistency and predictability, reducing processing errors.",
        "Easier data validation and quality control through automated checks against metadata.",
        "Increased trust in data as it conforms to its documented specifications."
      ],
      "negative": [
        "Data errors and inconsistencies when values violate defined metadata rules (e.g., wrong data type, out-of-range values).",
        "System failures or incorrect processing if data does not match expected formats or structures.",
        "Increased manual effort for data cleansing and correction.",
        "Reduced reliability of analytics and reports if based on non-compliant data."
      ]
    },
    "illustrativeKpis": [
      "Data Validation Error Rate",
      "Automated Data Quality Rule Pass Rate",
      "Data Conformance to Schema (%)",
      "Data Transformation Error Rate (due to non-compliance)"
    ]
  },
  {
    "id": 35,
    "damaId": 35,
    "name": "Naturalness",
    "category": "Composition of datasets",
    "definition": "The degree to which the composition of datasets is aligned with the real-world objects that they represent.",
    "unitOfMeasure": "Grade",
    "icon": "bi-tree",
    "examplePoor": [
      "Logistics: Storing individual container move details, vessel visit information, and customer billing data all within the same highly complex, denormalized table.",
      "E-commerce: A single 'Product' table contains attributes for physical products, digital downloads, and service subscriptions, making the schema overly complicated and hard to manage.",
      "University: A 'Student_Course_Enrollment_Grade_Faculty' dataset combines too many distinct real-world concepts, leading to data redundancy and update anomalies."
    ],
    "exampleGood": [
      "Logistics: Having separate, well-defined datasets (or tables) for Transport Units, Packages, Moves, Customers, and Invoices, each reflecting distinct real-world entities and their relationships.",
      "E-commerce: Separate datasets for 'Products', 'Customers', 'Orders', and 'Order_Items' naturally model the business domain.",
      "University: Datasets are structured around 'Students', 'Courses', 'Faculty', and 'Enrollments', aligning with how the university actually operates and thinks about its data."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data models that intuitively reflect real-world business entities and processes.",
        "Easier understanding and use of data by business users and analysts.",
        "More stable and maintainable data structures that adapt well to business changes.",
        "Reduced complexity in data modeling and database design."
      ],
      "negative": [
        "Complex and counter-intuitive data models that are difficult for users to understand and query.",
        "Increased risk of misinterpreting data due to unnatural or convoluted structures.",
        "Higher maintenance costs and difficulties in evolving data models as business needs change.",
        "Overly denormalized or poorly structured data leading to redundancy and update anomalies."
      ]
    },
    "illustrativeKpis": [
      "Data Model Understandability Score",
      "Query Complexity Index",
      "Data Model Maintenance Effort",
      "User Satisfaction with Data Structure"
    ]
  },
  {
    "id": 36,
    "damaId": 36,
    "name": "Objectivity",
    "category": "Data values",
    "definition": "The degree to which the data values are created in an unbiased manner.",
    "unitOfMeasure": "Grade",
    "icon": "bi-person",
    "examplePoor": [
      "Logistics: Sales forecasts for shipping volumes are consistently overestimated due to overly optimistic assumptions from the sales team who are incentivized on targets.",
      "Performance Reviews: Employee performance ratings are subjectively influenced by a manager's personal relationship with the employee rather than objective criteria.",
      "Surveys: Leading questions in a customer satisfaction survey are designed to elicit positive responses, skewing the results."
    ],
    "exampleGood": [
      "Logistics: Incident reports for equipment damage capture factual descriptions of events based on evidence, without assigning blame or making subjective judgments.",
      "Performance Reviews: Employee evaluations are based on pre-defined, measurable Key Performance Indicators (KPIs) and documented achievements.",
      "Surveys: Customer feedback is collected using neutral, well-phrased questions, and responses are analyzed without pre-conceived biases."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data collection and recording processes are free from personal bias or subjective influence.",
        "More trustworthy and impartial data for decision-making and performance evaluation.",
        "Fairer and more equitable outcomes when data is used for assessments or allocations.",
        "Increased credibility of analyses and reports based on unbiased data."
      ],
      "negative": [
        "Skewed or biased data leading to unfair decisions, inaccurate assessments, or flawed conclusions.",
        "Erosion of trust if data is perceived as being manipulated or subjectively influenced.",
        "Potential for discriminatory outcomes if biased data is used in AI models or decision-making processes.",
        "Difficulty in achieving consensus or buy-in for decisions based on questionable data."
      ]
    },
    "illustrativeKpis": [
      "Data Bias Audit Findings",
      "Fairness Metrics for AI Models",
      "Employee/Customer Perception of Fairness Score",
      "Decision Appeal Rate (due to perceived bias)"
    ]
  },
  {
    "id": 37,
    "damaId": 37,
    "name": "Obtainability",
    "category": "Data",
    "definition": "The degree to which the data can be acquired.",
    "unitOfMeasure": "Grade",
    "icon": "bi-key",
    "examplePoor": [
      "Logistics: Historical maintenance records for port equipment are stored only on paper archives in a remote, difficult-to-access location.",
      "Market Research: Competitor pricing data is proprietary and not publicly available or easily purchasable.",
      "Supply Chain: Real-time inventory levels from a key supplier are not shared electronically and require manual phone calls to obtain."
    ],
    "exampleGood": [
      "Logistics: Weather forecast data relevant to port operations is easily and reliably obtained via a subscription to a meteorological service API.",
      "Market Research: Publicly available government statistics on import/export volumes can be readily downloaded from official websites.",
      "Supply Chain: Key suppliers provide access to their inventory data through a secure B2B portal or EDI feeds."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data needed for business processes and decision-making can be readily acquired when needed.",
        "Reduced delays in accessing critical information.",
        "Improved efficiency as users do not struggle to locate or gain permission for data.",
        "Better support for ad-hoc analysis and time-sensitive tasks."
      ],
      "negative": [
        "Inability to acquire necessary data, leading to incomplete analysis or stalled processes.",
        "Significant delays and inefficiencies if data is hard to find, access-restricted without clear process, or in unusable formats.",
        "Missed opportunities if time-critical data cannot be obtained quickly.",
        "Frustration among users unable to get the data they need to perform their jobs."
      ]
    },
    "illustrativeKpis": [
      "Time to Acquire Data",
      "Data Access Request Fulfillment Time",
      "User Frustration Score (Data Access)",
      "Process Cycle Time (Data Dependent Steps)"
    ]
  },
  {
    "id": 38,
    "damaId": 38,
    "name": "Plausibility",
    "category": "Data values",
    "definition": "The degree to which data values match knowledge of the real world.",
    "unitOfMeasure": "Story",
    "icon": "bi-lightbulb",
    "examplePoor": [
      "Logistics: A container move is recorded in the system as taking only 0.1 seconds, which is physically impossible.",
      "Healthcare: A patient's recorded age is 150 years, or their recorded body temperature is 5 degrees Celsius.",
      "Retail: An order record shows a quantity of -10 for an item, or a product price of $0.00 for a high-value item."
    ],
    "exampleGood": [
      "Logistics: Recorded vessel speeds are within the known operational range for that specific vessel type and current sea conditions.",
      "Healthcare: A patient's recorded height and weight are within expected human physiological ranges.",
      "Retail: The total order value is consistent with the sum of the prices of individual items and applied discounts."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Early detection of potential data errors or anomalies that contradict real-world knowledge.",
        "Increased confidence in data that aligns with expected norms and common sense.",
        "Reduced risk of making absurd decisions based on clearly illogical data values.",
        "Improved data quality through validation against known constraints and business understanding."
      ],
      "negative": [
        "Data containing values that are clearly impossible or highly improbable (e.g., negative age, future transaction dates for past events).",
        "Erosion of trust in data if it frequently contains implausible entries.",
        "Potential for serious errors if automated systems act on nonsensical data.",
        "Wasted effort investigating or explaining data that defies basic logic."
      ]
    },
    "illustrativeKpis": [
      "Data Anomaly Detection Rate",
      "Number of Implausible Data Values Flagged",
      "User Reported Data Absurdities",
      "Automated Decision Override Rate (due to implausible inputs)"
    ]
  },
  {
    "id": 39,
    "damaId": 39,
    "name": "Portability (Data)",
    "category": "Data",
    "definition": "The degree to which data can be installed, replaced or moved from one system to another while preserving the existing quality.",
    "unitOfMeasure": "Story",
    "icon": "bi-file-earmark-zip",
    "examplePoor": [
      "Logistics: Data exported from the legacy terminal operating system is in a proprietary binary format that is unusable by the new system without complex, lossy conversion.",
      "CRM: Customer data is locked into a specific cloud CRM vendor's platform with no easy way to export it completely and accurately for migration to another CRM.",
      "Archival: Historical data archived in an obsolete software format can no longer be opened or read by current applications."
    ],
    "exampleGood": [
      "Logistics: Master data for customers, vessels, and locations can be exported from the current system in standard, open formats like CSV or JSON, allowing for easy migration or sharing with other systems.",
      "CRM: The CRM system allows full export of all customer data, including custom fields and attachments, in a well-documented, non-proprietary format.",
      "Archival: Data is archived using industry-standard formats (e.g., XML, Parquet) along with its schema and metadata, ensuring long-term accessibility and usability."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to easily migrate data between systems, platforms, or cloud providers.",
        "Reduced vendor lock-in and greater flexibility in choosing technology solutions.",
        "Simplified data sharing with partners or for regulatory purposes.",
        "Enhanced disaster recovery and business continuity options."
      ],
      "negative": [
        "Difficulty and high cost in moving data from legacy systems or proprietary formats.",
        "Increased vendor lock-in, limiting technological agility and negotiating power.",
        "Barriers to data sharing or collaboration due to incompatible data structures.",
        "Complicated and risky data migration projects during system upgrades or replacements."
      ]
    },
    "illustrativeKpis": [
      "Data Migration Cost/Time",
      "Vendor Switching Cost Index",
      "Data Sharing Compatibility Score",
      "Disaster Recovery Test Success Rate (Data Portability)"
    ]
  },
  {
    "id": 40,
    "damaId": 40,
    "name": "Portability (Format)",
    "category": "Format",
    "definition": "The degree to which a format can be applied in a wide range of situations.",
    "unitOfMeasure": "Story",
    "icon": "bi-file-earmark-code",
    "examplePoor": [
      "Logistics: Using a highly specific, internal XML schema for data exchange that external partners or new software cannot easily parse or adapt to.",
      "Reporting: Financial reports are generated only in a proprietary ",
      " A file format that can only be opened by one specific, outdated software.",
      "Collaboration: Project plans are created using a niche project management tool whose file format is not compatible with commonly used tools by contractors."
    ],
    "exampleGood": [
      "Logistics: Adopting industry-standard EDI formats (e.g., EDIFACT IFTMIN for booking instructions) or widely supported APIs (e.g., RESTful JSON) for exchanging shipping information with partners.",
      "Reporting: Generating reports in common formats like PDF, CSV, and XLSX ensures they can be easily viewed and used by various stakeholders and software.",
      "Collaboration: Using standard office document formats (.docx, .pptx, .xlsx) or cloud-based platforms with broad compatibility for sharing project documentation."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data formats that are widely supported and can be used across various applications and platforms.",
        "Improved interoperability and ease of data exchange with internal and external systems.",
        "Reduced need for custom format conversions, saving time and development effort.",
        "Long-term accessibility of data as standard formats are less likely to become obsolete."
      ],
      "negative": [
        "Data stored in proprietary or obscure formats that limit its usability and accessibility.",
        "Difficulties in sharing data with partners or integrating with new technologies.",
        "Increased costs and complexities associated with developing and maintaining format converters.",
        "Risk of data becoming inaccessible if the software supporting a proprietary format is discontinued."
      ]
    },
    "illustrativeKpis": [
      "Format Conversion Effort/Cost",
      "Industry Standard Adoption Rate (Formats)",
      "Number of Systems Supporting Data Format",
      "Long-Term Data Accessibility Risk Score"
    ]
  },
  {
    "id": 41,
    "damaId": 41,
    "name": "Precision (1 - Recording Accuracy)",
    "category": "Data values",
    "definition": "The degree of accuracy with which data values are recorded or classified.",
    "unitOfMeasure": "Depends on data or metadata",
    "icon": "bi-rulers",
    "examplePoor": [
      "Logistics: Recording container temperatures only to the nearest 5 degrees Celsius when the cargo requires monitoring to +/- 0.5 degrees.",
      "Manufacturing: Measuring component dimensions only to the nearest millimeter when engineering tolerances require micron-level precision.",
      "Finance: Rounding all currency transactions to the nearest dollar when cents are significant for accounting."
    ],
    "exampleGood": [
      "Logistics: Measuring vessel draft to the nearest centimeter, providing the necessary precision for safe navigation and berth planning.",
      "Manufacturing: Using calibrated instruments to measure product weights to the nearest gram, as required by quality control standards.",
      "Finance: Recording financial transactions with precision to the smallest currency unit (e.g., cents, pence) as defined by accounting standards."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data recorded with sufficient detail and exactness to meet business or analytical requirements.",
        "Accurate calculations and measurements based on precisely captured values.",
        "Improved ability to distinguish between small but significant variations in data.",
        "Better fit for applications requiring high levels of detail (e.g., scientific research, engineering design)."
      ],
      "negative": [
        "Loss of information if data is recorded with insufficient precision (e.g., rounding errors obscuring true values).",
        "Inaccurate calculations or analysis if measurements are too coarse.",
        "Inability to detect subtle changes or make fine distinctions in data.",
        "Unsuitability of data for tasks requiring high precision."
      ]
    },
    "illustrativeKpis": [
      "Measurement Error Rate",
      "Calculation Accuracy (Precision Dependent)",
      "Smallest Detectable Change (Data Sensitivity)",
      "Fitness for Purpose (High Precision Tasks)"
    ]
  },
  {
    "id": 42,
    "damaId": 42,
    "name": "Precision (2 - Statistical Spread)",
    "category": "Data values",
    "definition": "The degree to which the error in data values spreads around zero (in statistics).",
    "unitOfMeasure": "%",
    "icon": "bi-graph-down",
    "examplePoor": [
      "Logistics: Weight measurements from a specific, uncalibrated scale consistently read 5kg too high (low precision because of systematic bias, although individual readings might be close to each other).",
      "Scientific Measurement: Readings from a sensor show very wide random variations around the true value, even if the average is correct (high variance = low precision).",
      "Polling: A political poll with a very small sample size has a large margin of error, meaning the results are not very precise."
    ],
    "exampleGood": [
      "Logistics: Repeated measurements of the same standard weight on a calibrated scale show very small random variations around the true value (high precision, low random error).",
      "Scientific Measurement: An instrument provides readings that are tightly clustered around the actual value being measured, with minimal random scatter.",
      "Polling: A well-designed survey with a large, representative sample yields results with a small margin of error, indicating high precision."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "High degree of repeatability and low random error in measurements or data collection processes.",
        "Increased confidence in the stability and reliability of data points.",
        "More accurate statistical analysis and modeling due to reduced noise and variance.",
        "Better process control if data used for monitoring has low variability."
      ],
      "negative": [
        "High variability or wide spread of data values around the true mean, indicating inconsistency or random error.",
        "Reduced confidence in individual data points due to large statistical error margins.",
        "Less reliable statistical inferences and model predictions.",
        "Difficulty in controlling processes if monitoring data is inherently noisy."
      ]
    },
    "illustrativeKpis": [
      "Standard Deviation/Variance of Measurements",
      "Confidence Interval Width",
      "Signal-to-Noise Ratio",
      "Process Capability Index (Cp/Cpk)"
    ]
  },
  {
    "id": 43,
    "damaId": 43,
    "name": "Punctuality",
    "category": "Dataset availability",
    "definition": "The degree to which the period between the actual and target point of time of availability of a dataset is appropriate.",
    "unitOfMeasure": "Duration",
    "icon": "bi-clock-fill",
    "examplePoor": [
      "Logistics: The daily sales report for container volumes, expected by 9 AM for the morning planning meeting, often arrives after midday.",
      "Finance: Month-end financial statements, required by the 5th working day, are consistently delivered on the 10th.",
      "Supply Chain: Advance shipping notices (ASNs) from a supplier, due 24 hours before delivery, frequently arrive only a few hours before or even after the goods."
    ],
    "exampleGood": [
      "Logistics: Transport Unit stowage plans are consistently available in the system 24 hours before estimated vessel arrival, as per the agreed service level.",
      "Finance: Regulatory compliance reports are submitted to the authorities by the official deadline without exception.",
      "Supply Chain: Daily inventory status files from third-party warehouses are received every morning by 8 AM as scheduled."
    ],
    "damaAppendix3Title": "Punctuality",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      53
    ],
    "indicators": [
      "The period between the actual and target point in time of availability of a dataset (days, hours, minutes).",
      "Percentage of times that datasets were available too late (or too early)."
    ],
    "notes": [
      "The dataset should be available on 1 July 2020 but is released on 3 July 2020. Too late.",
      "The dataset should be available on 1 July 2020 at 10:00 am but is released at 9.45 am. Too early.",
      "A dataset can also consist of one transaction.",
      "If no target time is agreed or planned, punctuality cannot be measured."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Reliable and predictable delivery of data and reports according to agreed schedules.",
        "Smooth execution of time-dependent business processes and workflows.",
        "Improved planning and coordination as stakeholders can count on timely information.",
        "Enhanced trust in data providers and information systems."
      ],
      "negative": [
        "Delays in critical business processes if data or reports are not delivered on time.",
        "Disruption to planning and decision-making cycles.",
        "Wasted resources and inefficiencies waiting for late information.",
        "Reduced confidence in data delivery reliability, leading to workarounds or mistrust."
      ]
    },
    "illustrativeKpis": [
      "On-Time Data Delivery Rate (%)",
      "Schedule Adherence for Reports",
      "Process Delay Time (Waiting for Data)",
      "User Satisfaction with Data Punctuality"
    ]
  },
  {
    "id": 44,
    "damaId": 44,
    "name": "Reasonability",
    "category": "Data pattern",
    "definition": "The degree to which a data pattern meets expectations.",
    "unitOfMeasure": "Grade",
    "icon": "bi-graph-up-arrow",
    "examplePoor": [
      "Logistics: Reported daily container throughput for the terminal suddenly drops to zero for a full day without any explanation (e.g., not a public holiday, no known strike or system outage).",
      "Retail: Online sales figures show a 1000% increase overnight for a specific product without any corresponding marketing campaign or external event.",
      "Utility: Water consumption for a household shows a sustained tenfold increase compared to its historical average, suggesting a possible leak or meter malfunction."
    ],
    "exampleGood": [
      "Logistics: Monthly maintenance costs for port equipment show expected seasonal variations (e.g., higher in off-peak seasons when more maintenance can be scheduled).",
      "Retail: Sales of winter clothing show an expected increase during colder months and a decrease during summer.",
      "Utility: Electricity usage patterns for a commercial building align with its known business hours and operational load."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data patterns and trends align with business expectations and known behaviors.",
        "Early identification of unexpected or anomalous data that may indicate underlying issues.",
        "Increased confidence in data that follows logical and predictable patterns.",
        "Better basis for forecasting and planning if historical patterns are reasonable."
      ],
      "negative": [
        "Data exhibits erratic, unexplainable, or counter-intuitive patterns, raising suspicion.",
        "Difficulty in distinguishing genuine anomalies from systemic data quality problems.",
        "Reduced trust in data if it frequently deviates from expected behaviors without clear cause.",
        "Flawed forecasts if based on unreasonable historical data patterns."
      ]
    },
    "illustrativeKpis": [
      "Data Pattern Anomaly Rate",
      "Number of Unexplained Data Fluctuations",
      "Forecast Deviation from Expected Patterns",
      "User Confidence in Data Predictability"
    ]
  },
  {
    "id": 45,
    "damaId": 45,
    "name": "Recoverability",
    "category": "Datasets",
    "definition": "The degree to which datasets are preserved in the event of incident.",
    "unitOfMeasure": "Story",
    "icon": "bi-save",
    "examplePoor": [
      "Logistics: Critical operational data from the Warehouse Operating System is only stored locally on a single server with no automated backups or disaster recovery plan.",
      "Finance: The only copy of the company's general ledger database exists on a primary server; a hardware failure could lead to permanent data loss.",
      "Research: Years of irreplaceable research data are stored on a single external hard drive without any secondary copies."
    ],
    "exampleGood": [
      "Logistics: Databases for critical systems are backed up daily to an offsite, secure location, with regularly tested recovery procedures to ensure data can be restored within a defined Recovery Time Objective (RTO).",
      "Finance: Financial systems utilize database replication to a secondary disaster recovery site, allowing for quick failover and minimal data loss in case of a primary site outage.",
      "Research: Research datasets are backed up to multiple locations, including cloud storage, and version control is used to track changes and allow rollback if needed."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to restore data and resume business operations quickly after an incident (e.g., system failure, cyber-attack, disaster).",
        "Minimized data loss and reduced downtime in a crisis.",
        "Compliance with business continuity and disaster recovery requirements.",
        "Increased organizational resilience and stakeholder confidence."
      ],
      "negative": [
        "Significant data loss or prolonged downtime following an incident, leading to severe financial and operational impact.",
        "Inability to meet Recovery Time Objectives (RTO) and Recovery Point Objectives (RPO).",
        "Non-compliance with business continuity regulations or contractual obligations.",
        "Damage to reputation and loss of customer trust if data cannot be recovered."
      ]
    },
    "illustrativeKpis": [
      "Recovery Time Objective (RTO) Adherence",
      "Recovery Point Objective (RPO) Adherence",
      "Data Loss Percentage (Post-Incident)",
      "Disaster Recovery Test Success Rate",
      "Cost of Downtime"
    ]
  },
  {
    "id": 46,
    "damaId": 46,
    "name": "Redundancy",
    "category": "Data",
    "definition": "The degree to which logically identical data are stored more than once.",
    "unitOfMeasure": "Number",
    "icon": "bi-files",
    "examplePoor": [
      "Logistics: Customer address information is stored redundantly in the sales system, billing system, and shipping system, leading to inconsistencies when an address changes and isn't updated in all places.",
      "HR: Employee emergency contact details are captured in the HRIS, a separate departmental spreadsheet, and a local manager's contact list.",
      "Product Management: The same product specifications (e.g., dimensions, weight) are manually entered and stored in the ERP, the e-commerce platform, and the marketing collateral database."
    ],
    "exampleGood": [
      "Logistics: Customer address is stored once in a central Customer Master Data system, and all other systems reference this single source of truth.",
      "HR: Employee data is mastered in the HRIS, and other systems requiring employee information access it via integration or replication from this authoritative source.",
      "Product Management: Product Information Management (PIM) system acts as the central repository for all product data, which is then syndicated to other channels."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Reduced data storage costs and streamlined data management.",
        "Improved data consistency as updates only need to be made in one place (if mastered).",
        "Simplified data landscapes and reduced complexity.",
        "Lower risk of inconsistencies arising from multiple, out-of-sync copies of data."
      ],
      "negative": [
        "Increased storage costs and inefficient use of resources.",
        "Higher risk of data inconsistencies if redundant copies are not synchronized perfectly.",
        "Increased complexity in data management, updates, and reconciliation.",
        "Wasted effort in maintaining and validating multiple instances of the same data."
      ]
    },
    "illustrativeKpis": [
      "Data Storage Costs",
      "Data Consistency Rate Across Systems",
      "Data Management Overhead",
      "Data Reconciliation Effort"
    ]
  },
  {
    "id": 47,
    "damaId": 47,
    "name": "Referential integrity",
    "category": "Data files",
    "definition": "The degree to which data values of the primary key of one data file and data values of the foreign key of another data file are equal.",
    "unitOfMeasure": "%",
    "icon": "bi-link",
    "examplePoor": [
      "Logistics: An order record in the sales system references a Customer ID that no longer exists (or never existed) in the customer master table, creating an 'orphan' record.",
      "University: An enrollment record links to a 'CourseID' that has been deleted from the official course catalog.",
      "Manufacturing: A production order references a 'PartNumber' in its bill of materials that is not defined in the item master data."
    ],
    "exampleGood": [
      "Logistics: All foreign keys in the shipment table (e.g., Transport UnitID, PortOfLoadingID, CustomerID) correctly reference existing primary keys in their respective master tables (Transport Unit, Port, Customer).",
      "University: Database constraints ensure that a student cannot be enrolled in a course unless the 'CourseID' exists in the 'Courses' table and the 'StudentID' exists in the 'Students' table.",
      "Manufacturing: The ERP system enforces referential integrity, preventing the creation of work orders if any component part numbers in the BOM do not exist in the material master."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures valid and consistent relationships between data in different tables, files, or datasets.",
        "Prevents orphan records (e.g., orders without customers) and maintains logical data linkages.",
        "Improved data accuracy and reliability for joined datasets and relational queries.",
        "More stable, predictable, and robust database operations and application behavior."
      ],
      "negative": [
        "Orphan records leading to incomplete information, erroneous reports, or process failures.",
        "Data inconsistencies and inaccuracies when related records are missing, mismatched, or incorrectly linked.",
        "Errors in applications, analytics, and reports that rely on the integrity of data relationships.",
        "Potential for database instability, data corruption, or application crashes in severe cases."
      ]
    },
    "illustrativeKpis": [
      "Number of Orphan Records/Broken Relationships",
      "Data Processing Error Rate (due to linkage issues)",
      "Application Stability Score (Data Dependent)",
      "Database Maintenance Effort (Integrity Checks)"
    ]
  },
  {
    "id": 48,
    "damaId": 48,
    "name": "Relevance",
    "category": "Composition of datasets",
    "definition": "The degree to which the composition of datasets meets the needs of the data consumer.",
    "unitOfMeasure": "Story",
    "icon": "bi-filter-circle",
    "examplePoor": [
      "Logistics: A safety incident report for yard operations includes highly detailed equipment maintenance logs from the past 5 years, which are not directly relevant to analyzing the specific incident.",
      "Marketing: A weekly sales performance dashboard sent to regional sales managers includes detailed IT system server logs, which they don't need or understand.",
      "Executive Reporting: A monthly financial summary for the CEO is cluttered with hundreds of line-item transaction details instead of focusing on key performance indicators and trends."
    ],
    "exampleGood": [
      "Logistics: The sales performance dashboard provided to account managers includes only the KPIs directly related to their sales targets, customer activity, and pipeline for their assigned accounts.",
      "Marketing: A campaign analysis report focuses on metrics relevant to campaign objectives, such as click-through rates, conversion rates, and cost per acquisition, omitting irrelevant operational data.",
      "Executive Reporting: A concise executive dashboard presents high-level summaries of financial health, market share, and strategic goal progress, with drill-down capabilities for details if needed."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Users receive information that is pertinent, applicable, and useful for their specific roles, tasks, and decisions.",
        "Reduced information overload and improved focus on key data points that matter.",
        "More efficient and effective decision-making as users are not sifting through irrelevant or distracting data.",
        "Higher adoption rates and perceived value of reports, dashboards, and analytics tools."
      ],
      "negative": [
        "Information overload leading to analysis paralysis, user fatigue, or users ignoring reports and data altogether.",
        "Wasted time, cognitive effort, and resources for users trying to find truly relevant information within large, unfocused datasets.",
        "Poor or delayed decisions if critical relevant data is obscured by a high volume of irrelevant information.",
        "Low user satisfaction with data systems, reports, and BI tools that don't meet their specific needs."
      ]
    },
    "illustrativeKpis": [
      "Report/Dashboard Usage Statistics",
      "User Satisfaction Score with BI Tools (Relevance)",
      "Time to Find Relevant Information",
      "Decision Effectiveness & Speed",
      "Actionable Insight Rate from Data"
    ]
  },
  {
    "id": 49,
    "damaId": 49,
    "name": "Reliability",
    "category": "Initial data value",
    "definition": "The closeness of the initial data value to the subsequent data value.",
    "unitOfMeasure": "%",
    "icon": "bi-arrow-repeat",
    "examplePoor": [
      "Logistics: Sensor readings for reefer container temperatures fluctuate wildly (e.g., jumping between -10\u00b0C and +5\u00b0C every few seconds) even when the actual measured condition is stable, indicating a faulty sensor or transmission.",
      "Manufacturing: A weighing scale gives significantly different readings for the same item when weighed multiple times in quick succession.",
      "Environmental Monitoring: An air quality sensor produces highly erratic CO2 level readings that don't correlate with known environmental conditions or other nearby sensors."
    ],
    "exampleGood": [
      "Logistics: Repeated readings of a container's internal temperature under stable ambient conditions and reefer setpoint yield very similar values (e.g., within +/- 0.2\u00b0C).",
      "Manufacturing: A calibrated torque wrench consistently applies the same amount of force when tested repeatedly on a test rig.",
      "Environmental Monitoring: A water quality sensor provides stable and consistent pH readings when sampling from a controlled, stable solution."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Consistent and dependable data values over repeated measurements or observations under stable conditions.",
        "Increased trust in the stability and predictability of data from specific sources or processes.",
        "More accurate tracking of changes when they genuinely occur, as opposed to random fluctuations.",
        "Better foundation for process control and monitoring systems."
      ],
      "negative": [
        "Data values that fluctuate erratically or unpredictably even when the underlying phenomenon is stable.",
        "Reduced confidence in data due to high variability or inconsistent readings.",
        "Difficulty in distinguishing true signals or changes from inherent data noise or source instability.",
        "Ineffective process control if monitoring data is unreliable."
      ]
    },
    "illustrativeKpis": [
      "Measurement System Variation (Gage R&R)",
      "Data Point Stability Index",
      "False Alarm Rate (Monitoring Systems)",
      "Process Control Chart Stability"
    ]
  },
  {
    "id": 50,
    "damaId": 50,
    "name": "Reproducibility",
    "category": "Dataset",
    "definition": "The degree to which a dataset can be recreated with the same data values.",
    "unitOfMeasure": "Story",
    "icon": "bi-arrow-clockwise",
    "examplePoor": [
      "Logistics: Running the same 'Monthly Throughput Report' query at different times yields slightly different results due to underlying operational data changes not being versioned or timestamped for historical reporting.",
      "Scientific Research: A published research paper's results cannot be replicated by other scientists because the original dataset or the exact data processing steps are not available or documented.",
      "Financial Modeling: A complex financial forecast model produces varying outputs even with the same input parameters due to non-deterministic elements or undocumented manual adjustments in the process."
    ],
    "exampleGood": [
      "Logistics: A financial statement or regulatory compliance report can be exactly reproduced by rerunning the documented consolidation and calculation process on the source data from that specific, versioned accounting period.",
      "Scientific Research: A research study provides open access to its anonymized dataset and detailed code/scripts for analysis, allowing independent verification and reproduction of its findings.",
      "Financial Modeling: A risk assessment model is fully documented, uses version-controlled input data, and all calculation steps are deterministic, ensuring that the same inputs always produce the same outputs."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to recreate datasets, reports, or analytical results consistently using the same inputs and processes.",
        "Enhanced auditability and verifiability of data and findings.",
        "Increased trust in results that can be independently confirmed.",
        "Facilitates scientific rigor, regulatory compliance, and debugging of data pipelines."
      ],
      "negative": [
        "Inability to consistently reproduce results, leading to questions about validity and reliability.",
        "Difficulties in auditing processes or verifying findings if they are not reproducible.",
        "Reduced trust in analyses or reports that yield different outcomes on different runs.",
        "Challenges in debugging data processing errors or understanding variations in AI model outputs."
      ]
    },
    "illustrativeKpis": [
      "Audit Pass Rate (Reproducibility)",
      "Scientific Validation Success Rate",
      "Report Consistency Score (Across Runs)",
      "AI Model Output Variance (Fixed Inputs)"
    ]
  },
  {
    "id": 51,
    "damaId": 51,
    "name": "Reputation",
    "category": "Data",
    "definition": "The degree to which data are trusted or highly regarded in terms of their source or content.",
    "unitOfMeasure": "Grade",
    "icon": "bi-patch-check-fill",
    "examplePoor": [
      "Logistics: Data originating from a known unreliable spreadsheet that is manually updated by many users with no validation is treated with skepticism by managers.",
      "News: Information from an unverified social media account with a history of spreading misinformation has a poor reputation.",
      "Market Data: Financial forecasts from an analyst with a poor track record of accuracy are not highly regarded by investors."
    ],
    "exampleGood": [
      "Logistics: Official customs declarations or data from major, audited shipping lines are generally considered reputable sources for cargo details and vessel movements.",
      "News: Data published by established government statistical agencies (e.g., Bureau of Labor Statistics, Eurostat) or highly respected international organizations (e.g., World Bank, IMF) generally has a strong reputation.",
      "Market Data: Market analysis reports from well-known, independent research firms with a long history of insightful and accurate reporting are trusted by businesses."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data from specific sources or systems is widely trusted and highly regarded within and outside the organization.",
        "Increased willingness to use and act upon data from reputable sources.",
        "Enhanced credibility for decisions and communications based on such data.",
        "Stronger brand image if the organization is known for high-quality, reputable data."
      ],
      "negative": [
        "Data from certain sources is viewed with skepticism or outright distrust due to past issues or perceived bias.",
        "Reluctance by users to rely on data from sources with a poor reputation.",
        "Reduced impact of insights or recommendations if the underlying data is not considered reputable.",
        "Damage to organizational credibility if decisions are based on data from untrustworthy sources."
      ]
    },
    "illustrativeKpis": [
      "Data Source Trust Score (User Survey)",
      "Adoption Rate of Data from Specific Sources",
      "Perceived Credibility of Reports (Source Dependent)",
      "Brand Trust Index (Data Handling)"
    ]
  },
  {
    "id": 52,
    "damaId": 52,
    "name": "Retention period",
    "category": "Datasets",
    "definition": "The period that datasets are available until they can or must be deleted.",
    "unitOfMeasure": "Duration",
    "icon": "bi-calendar-x",
    "examplePoor": [
      "Logistics: Financial records related to shipping transactions are deleted after only one year, violating legal retention requirements which mandate 7 years.",
      "Healthcare: Patient medical records are purged too soon, potentially impacting long-term patient care or legal inquiries.",
      "E-commerce: Customer order history is kept indefinitely without a clear policy, increasing storage costs and potential privacy risks over time."
    ],
    "exampleGood": [
      "Logistics: A clear data retention policy, aligned with legal and business requirements, defines how long different types of data (e.g., operational logs, personnel records, contracts) must be kept and when they should be securely disposed of.",
      "Healthcare: Electronic Health Records are retained for the patient's lifetime plus a legally mandated period post-mortem, in compliance with regulations.",
      "E-commerce: A data lifecycle management policy specifies that anonymized customer transaction data is archived after 5 years and fully deleted after 10 years, balancing analytical needs with privacy considerations."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Compliance with legal, regulatory, and business requirements for data archival and disposal.",
        "Availability of historical data for long-term analysis, audits, or legal discovery.",
        "Optimized storage costs by disposing of data that is no longer needed.",
        "Reduced risk associated with holding outdated or irrelevant sensitive data."
      ],
      "negative": [
        "Non-compliance with data retention laws, leading to fines or legal action (e.g., keeping data too long or deleting too soon).",
        "Inability to access critical historical data for business analysis, legal defense, or regulatory audits.",
        "Excessive storage costs for keeping unnecessary data indefinitely.",
        "Increased privacy or security risks from retaining sensitive data beyond its useful or legally mandated life."
      ]
    },
    "illustrativeKpis": [
      "Data Retention Policy Compliance Rate (%)",
      "Storage Cost Savings (from disposal)",
      "Audit Findings (Retention Related)",
      "Legal Discovery Cost/Time"
    ]
  },
  {
    "id": 53,
    "damaId": 53,
    "name": "Timeliness",
    "category": "Dataset availability",
    "definition": "The degree to which the period between the time of creation of the real value and the time that the dataset is available is appropriate.",
    "unitOfMeasure": "Duration",
    "icon": "bi-alarm-fill",
    "examplePoor": [
      "Logistics: Customs release status for imported containers is updated in the terminal system only once daily, causing potential truck delays at the gate if the release happened earlier but isn't yet visible.",
      "Retail: Inventory updates from Point-of-Sale systems take 4 hours to reflect in the online store, leading to customers ordering items that are actually out of stock.",
      "Emergency Response: Information about a critical incident (e.g., a chemical spill) takes 30 minutes to reach the relevant emergency response teams via the official communication system."
    ],
    "exampleGood": [
      "Logistics: Transport Unit arrival times are updated in the port community system within minutes of the actual event (e.g., vessel crossing port limits, berthing).",
      "Retail: Online product availability is updated within 5 minutes of a sale or stock replenishment in the physical store or warehouse.",
      "Emergency Response: Real-time GPS location of ambulances is available to dispatchers with a delay of less than 10 seconds."
    ],
    "damaAppendix3Title": "Timeliness",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      43,
      26
    ],
    "indicators": [
      "Percentage of times a dataset was not available in a timely manner."
    ],
    "notes": [
      "The date of birth of a person is available in a dataset after 23 days. It should be available within one week.",
      "Data about quarterly returns of VAT are available 3 months after the end of the quarter. The requirement is 1 month after the end of the quarter.",
      "Timeliness can only be measured if there is a norm for timeliness, e.g., one week after the event.",
      "Timeliness is dependent on the duration of a process.",
      "Data can be available punctually but not timely and the other way around."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ability to make decisions and take actions based on data that accurately reflects recent events and current conditions.",
        "Improved operational agility, faster response to market changes, and enhanced real-time monitoring.",
        "Better customer experience through prompt information updates, service delivery, and issue resolution.",
        "Effective operational control and ability to capitalize on time-sensitive opportunities."
      ],
      "negative": [
        "Decisions based on outdated information that no longer reflects the current business reality, leading to suboptimal outcomes.",
        "Slow response to critical events, customer needs, or market shifts, resulting in missed opportunities or increased risks.",
        "Operational inefficiencies, delays, or errors if processes rely on delayed data updates.",
        "Customer dissatisfaction and frustration due to lack of timely information, slow service, or outdated product details."
      ]
    },
    "illustrativeKpis": [
      "Order-to-Cash Cycle Time",
      "Incident Response Time",
      "Customer Issue Resolution Time",
      "Real-time Process Adherence Rate",
      "Data Lag Time (Creation to Availability)"
    ]
  },
  {
    "id": 54,
    "damaId": 54,
    "name": "Traceability",
    "category": "Data",
    "definition": "The degree to which data lineage is available.",
    "unitOfMeasure": "Story",
    "icon": "bi-signpost-split",
    "examplePoor": [
      "Logistics: Business users are unsure where the 'estimated time of arrival' (ETA) data for a vessel originated, what transformations it underwent, or if it was manually adjusted.",
      "Finance: A key figure in a regulatory report cannot be easily traced back to its source transactions or calculation logic, making audits difficult.",
      "Data Analytics: A machine learning model's predictions cannot be explained because the lineage of the training data (sources, preprocessing steps) is not documented."
    ],
    "exampleGood": [
      "Logistics: Data lineage tools show that the vessel ETA originated from the shipping line's EDI feed, was then updated based on AIS tracking data, and subsequently adjusted by the port agent, with timestamps and user IDs for each change.",
      "Finance: An auditable data trail exists for all financial reporting, allowing any number to be traced back through aggregation and transformation steps to its source general ledger entries.",
      "Data Analytics: A data catalog provides complete lineage for all datasets, showing their origin, transformations, dependencies, and usage in models and reports."
    ],
    "damaAppendix3Title": "Traceability",
    "synonyms": [],
    "relatedDamaDimensionIds": [],
    "indicators": [
      "A grade (1-10)"
    ],
    "notes": [
      "Data lineage is metadata that identifies the sources of data and the transformations through which it has passed up to the point of consumption."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Increased trust, transparency, and confidence in data by understanding its origin, journey, and transformations.",
        "Easier and faster root cause analysis for data errors, anomalies, or unexpected analytical results.",
        "Improved auditability and demonstrable compliance with data governance policies and regulatory requirements.",
        "Enhanced ability to manage data changes effectively and assess their downstream impact.",
        "Key enabler for explainable AI (XAI), understanding model behavior, and debugging AI systems."
      ],
      "negative": [
        "Lack of trust in data if its provenance and processing history are unknown (black box data).",
        "Difficulty and significant effort in identifying and resolving data quality issues at their source.",
        "Challenges in meeting audit and regulatory requirements for data provenance and process transparency.",
        "Inability to accurately assess the impact of changes in source systems on downstream reports, analytics, and AI models.",
        "Difficult or impossible to explain AI model outputs or biases if data lineage is unclear or unavailable."
      ]
    },
    "illustrativeKpis": [
      "Audit Trail Completeness & Accessibility",
      "Time to Resolve Data Issues (Root Cause Analysis)",
      "Data Governance Compliance Rate (Traceability aspect)",
      "AI Model Explainability Score",
      "Impact Analysis Accuracy (for data changes)"
    ]
  },
  {
    "id": 55,
    "damaId": 55,
    "name": "Uniqueness (Objects)",
    "category": "Objects",
    "definition": "The degree to which objects (of the real world) occur only once as a record in a data file.",
    "unitOfMeasure": "%",
    "icon": "bi-person-badge",
    "examplePoor": [
      "Logistics: The same physical container (e.g., MSCU1234567) appears as two different records in the terminal inventory list due to a minor typo in one of the ID entries or being recorded by two different systems without reconciliation.",
      "Customer Management: The same individual customer exists as three separate records in the CRM because they used different email addresses or had slight name variations when interacting with the company.",
      "Asset Management: A single piece of equipment (e.g., a specific crane) is listed multiple times in the asset register under different asset tags."
    ],
    "exampleGood": [
      "Logistics: Each distinct physical vessel calling at the port has exactly one corresponding master record in the vessel database, identified by its unique IMO number.",
      "Customer Management: A robust Master Data Management (MDM) process ensures that each unique customer (individual or organization) is represented by a single 'golden record' in the system.",
      "Asset Management: Every physical asset owned by the company has one unique record in the asset tracking system, identified by a unique serial number or asset ID."
    ],
    "damaAppendix3Title": "Uniqueness",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      56
    ],
    "indicators": [
      "Percentage of duplicates in a data file."
    ],
    "notes": [
      "A record that occurs twice in a data file is called a duplicate.",
      "Uniqueness of object is the degree to which objects (of the real world) occur only once as a record in a dataset.",
      "Three different problems can occur: a. One record with one key value occurs more than once in a dataset (duplicate with identical key values). The two records are not unique. b. One record with more than one key value occurs more than once in a dataset (duplicate with different key values). Object John is not unique in the dataset. c. One record has the same key as another record, and both occur in a dataset (false duplicate). Key 22 is not unique."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Accurate counting, reporting, and representation of real-world entities (e.g., customers, products, employees, assets).",
        "Avoidance of duplicated operational effort, wasted marketing spend, and customer confusion caused by multiple records for the same entity.",
        "Reliable foundation for Master Data Management (MDM) initiatives and achieving a true single source of truth.",
        "Improved accuracy and reliability of analytics, segmentation, and reporting based on unique, de-duplicated entities."
      ],
      "negative": [
        "Skewed analytics, inaccurate reports, and flawed business intelligence due to double-counting or fragmented views of key entities.",
        "Inefficient processes, wasted resources, and increased operational costs dealing with duplicate entities (e.g., multiple customer profiles, redundant inventory items).",
        "Poor customer experience, inconsistent service, and brand damage if interactions are fragmented across duplicate customer records.",
        "Compromised MDM initiatives and inability to establish a true, reliable single source of truth for critical data domains."
      ]
    },
    "illustrativeKpis": [
      "Customer Record Duplication Rate (%)",
      "Product Master Duplication Rate (%)",
      "Marketing Spend Effectiveness (Impacted by targeting duplicates)",
      "Data Cleansing & De-duplication Costs",
      "MDM 'Golden Record' Accuracy"
    ]
  },
  {
    "id": 56,
    "damaId": 56,
    "name": "Uniqueness (Records)",
    "category": "Records",
    "definition": "The degree to which records occur only once in a data file.",
    "unitOfMeasure": "%",
    "icon": "bi-exclude",
    "examplePoor": [
      "Logistics: A duplicate Bill of Lading record exists in the shipping documentation system, potentially leading to double-billing or incorrect cargo release.",
      "Online Orders: The same online order is recorded twice in the order management system due to a user clicking the 'submit' button multiple times or a system glitch.",
      "Event Ticketing: Two identical seat reservation records are created for the same event and seat, assigned to different customers."
    ],
    "exampleGood": [
      "Logistics: Each gate transaction record (container in/out) has a unique transaction ID within the daily log file.",
      "Online Orders: The order processing system assigns a unique order number to every successfully submitted order, preventing duplicates.",
      "Event Ticketing: The ticketing system ensures that each combination of event, seat, and date can only have one active reservation record."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Ensures each record in a dataset is distinct and not an exact duplicate, preventing processing errors.",
        "Accurate aggregation and counting where each record represents a unique instance or transaction.",
        "Improved data integrity and reliability of datasets used for operations or analytics.",
        "Reduced storage waste from identical duplicate records."
      ],
      "negative": [
        "Processing errors, incorrect aggregations, or skewed analytics if identical records are counted multiple times.",
        "Potential for duplicated actions in operational systems (e.g., double billing, repeated order fulfillment).",
        "Increased data storage and processing overhead due to redundant identical records.",
        "Reduced confidence in dataset integrity if plagued by exact duplicates."
      ]
    },
    "illustrativeKpis": [
      "Exact Duplicate Record Rate (%)",
      "Transactional Error Rate (due to duplicates)",
      "Report Aggregation Accuracy",
      "Storage Utilization Efficiency"
    ]
  },
  {
    "id": 57,
    "damaId": 57,
    "name": "Validity",
    "category": "Data values",
    "definition": "The degree to which data values comply with rules.",
    "unitOfMeasure": "%",
    "icon": "bi-shield-check",
    "examplePoor": [
      "Logistics: A container number in the system is 'ABCD123456X' which doesn't conform to the ISO 6346 standard format (e.g., invalid check digit or owner code).",
      "Order Entry: An order record contains an invalid date like '31/02/2024' or a 'ProductStatusCode' of 'X' when only 'A', 'I', 'D' are allowed.",
      "User Registration: A user enters 'N/A' in a required 'PhoneNumber' field that expects a numerical format."
    ],
    "exampleGood": [
      "Logistics: All container numbers stored in the system follow the ISO 6346 standard format, including a valid owner code, serial number, and check digit.",
      "Order Entry: All 'OrderDate' fields contain valid calendar dates in the YYYY-MM-DD format, and 'CountryCode' fields use valid ISO 3166-1 alpha-2 codes.",
      "User Registration: Email addresses entered by users are validated against a standard email format pattern (e.g., user@domain.com)."
    ],
    "damaAppendix3Title": "Validity",
    "synonyms": [],
    "relatedDamaDimensionIds": [
      3,
      14,
      20
    ],
    "indicators": [
      "Percentage of data values that do not comply with rules."
    ],
    "notes": [
      "A city that does not exist in a list of cities.",
      "A birth data that is out of range of valid birth dates.",
      "A data value can be valid but not accurate.",
      "A data value can be valid but incomplete. Absence of certain data values may be permitted.",
      "A valid data value is part of a value domain.",
      "Consistency is about comparing two or more data values."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Smooth data processing, system interoperability, and adherence to defined data structures.",
        "Reduced data entry errors and improved data capture accuracy through conformance to formats and rules.",
        "Consistent application of business rules and data standards across the organization.",
        "More reliable and predictable data for automated processes, decision engines, and AI model inputs."
      ],
      "negative": [
        "System errors, application crashes, and process failures when data does not conform to expected formats, types, or value ranges.",
        "Increased manual effort, time, and cost to cleanse, correct, or transform invalid data entries.",
        "Inconsistent application of business rules leading to operational discrepancies and unreliable reporting.",
        "Poor performance or failure of automated systems and AI models that rely on valid, well-structured data inputs."
      ]
    },
    "illustrativeKpis": [
      "Data Entry Error Rate (Format/Type)",
      "System Processing Failure Rate (due to invalid data)",
      "Automated Decision Accuracy & Reliability",
      "Data Transformation Success Rate",
      "Data Quality Rule Pass Rate (Validity Checks)"
    ]
  },
  {
    "id": 58,
    "damaId": 58,
    "name": "Value",
    "category": "Data",
    "definition": "The degree to which data provide advantages from their use.",
    "unitOfMeasure": "Grade",
    "icon": "bi-currency-dollar",
    "examplePoor": [
      "Logistics: Collecting highly detailed equipment sensor data (e.g., vibration readings every second) that is never analyzed, used for predictive maintenance, or contributes to any business decision.",
      "Marketing: Investing heavily in a complex customer segmentation model whose outputs are too difficult for the sales team to understand or act upon.",
      "Operations: Generating numerous daily operational reports that are not read or used by anyone to improve processes."
    ],
    "exampleGood": [
      "Logistics: Analyzing historical container throughput data and vessel turnaround times helps optimize resource allocation (labor, equipment), berth planning, and significantly improve terminal efficiency, leading to cost savings.",
      "Marketing: Using customer purchase history data to personalize product recommendations results in a measurable increase in conversion rates and average order value.",
      "Operations: Real-time tracking data for delivery vehicles is used to optimize routes, reduce fuel consumption, and improve on-time delivery performance, directly impacting customer satisfaction and operational costs."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Data assets directly contribute to achieving specific business objectives and key strategic goals.",
        "Demonstrable and quantifiable Return on Investment (ROI) from data, analytics, and AI initiatives.",
        "Improved strategic and operational decision-making leading to competitive advantage, revenue growth, and cost optimization.",
        "Efficient resource allocation, optimized processes, and new revenue streams based on valuable data-driven insights."
      ],
      "negative": [
        "Collection, storage, and management of data that provides no discernible business benefit, leading to wasted resources and data hoarding.",
        "Missed business opportunities because the potential value of existing data assets is not understood, accessed, or realized.",
        "Substantial investments in data infrastructure, analytics tools, or AI projects that do not yield expected returns or tangible business outcomes.",
        "Difficulty in justifying data-related expenditures and initiatives to business stakeholders due to lack of clear value demonstration."
      ]
    },
    "illustrativeKpis": [
      "Return on Data Investment (RODI)",
      "Revenue Growth Attributable to Data Insights",
      "Cost Savings from Data-Driven Optimizations",
      "Strategic Goal Achievement Rate (Data-linked goals)",
      "New Product/Service Success Rate (Data-informed)"
    ]
  },
  {
    "id": 59,
    "damaId": 59,
    "name": "Variety",
    "category": "Data",
    "definition": "The degree to which data are available from different data sources.",
    "unitOfMeasure": "Story",
    "icon": "bi-diagram-3",
    "examplePoor": [
      "Logistics: Relying solely on manual input from operators for recording operational status (e.g., equipment breakdowns), without cross-referencing system logs, sensor data, or maintenance records.",
      "Market Analysis: Basing market trend predictions only on internal sales data without considering broader economic indicators, competitor activities, or industry reports.",
      "Customer Insights: Understanding customer sentiment only through direct complaints, without analyzing social media mentions, survey feedback, or product reviews."
    ],
    "exampleGood": [
      "Logistics: Combining data from the Warehouse Operating System (ERP), vessel AIS feeds, weather services, gate camera OCR, and customs systems provides a comprehensive and robust operational picture for decision-making.",
      "Market Analysis: Integrating internal sales data with external market research reports, economic forecasts, social media trends, and news feeds to build a more accurate and holistic market model.",
      "Customer Insights: Creating a 360-degree customer view by consolidating data from CRM, e-commerce transactions, website analytics, support tickets, social media interactions, and satisfaction surveys."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Richer insights and more robust models from integrating diverse data types and sources (structured, unstructured, internal, external).",
        "More comprehensive understanding of complex phenomena by considering multiple perspectives.",
        "Enhanced innovation and discovery through the combination of previously siloed information.",
        "Improved resilience of analytical models by training on a wider range of data scenarios."
      ],
      "negative": [
        "Limited analytical capabilities and potentially biased insights if relying on a narrow set of data sources.",
        "Missed opportunities that could be uncovered by combining different types of data.",
        "Difficulty in creating a holistic view of customers, markets, or operations.",
        "Models that are not robust or generalizable to new, unseen data types."
      ]
    },
    "illustrativeKpis": [
      "Number of Data Sources Integrated",
      "Richness of Analytical Features",
      "Predictive Model Generalizability Score",
      "Innovation Rate (Data-driven ideas)",
      "Completeness of 360-Degree Views"
    ]
  },
  {
    "id": 60,
    "damaId": 60,
    "name": "Volatility",
    "category": "Data values",
    "definition": "The degree to which data values change over time.",
    "unitOfMeasure": "%",
    "icon": "bi-lightning-charge-fill",
    "examplePoor": [
      "Logistics: Customer contact information (e.g., primary contact person, phone number for a shipping company) changes frequently, but the update process for the master data is slow and manual, leading to many outdated records.",
      "Stock Market: Real-time stock prices are highly volatile, changing many times per second, requiring very frequent updates for accurate trading systems.",
      "Product Catalog: Product prices in a fast-moving consumer goods (FMCG) industry change weekly due to promotions, but the pricing system is only updated monthly."
    ],
    "exampleGood": [
      "Logistics: Reference data like ISO country codes or port UN/LOCODEs are very stable and change extremely infrequently, making them reliable for long-term use.",
      "Stock Market: Historical end-of-day stock prices are static once the trading day is closed and verified.",
      "Product Catalog: Core product attributes like 'Material Safety Data Sheet (MSDS) ID' for a chemical product are non-volatile once established."
    ],
    "potentialBusinessImpacts": {
      "positive": [
        "Accurate reflection of highly dynamic data environments where change is frequent and expected.",
        "Ability to track and analyze rapid changes for time-sensitive decision making.",
        "Systems designed to handle high change rates can maintain accuracy and currency.",
        "Understanding data volatility helps in designing appropriate data refresh and validation strategies."
      ],
      "negative": [
        "Difficulty in maintaining data accuracy and currency if data changes faster than update processes can cope.",
        "Increased risk of decisions based on stale data in highly dynamic environments.",
        "Higher data management overhead to track and reconcile frequent changes.",
        "Instability in reports or analyses if based on constantly shifting, unmanaged volatile data."
      ]
    },
    "illustrativeKpis": [
      "Data Staleness Rate (for volatile data)",
      "Real-time Monitoring Accuracy (in volatile systems)",
      "Data Update Frequency vs. Change Rate Gap",
      "Cost of Managing High-Volatility Data"
    ]
  }
]