import numpy as np
from typing import Dict, Any, List
from openvino.runtime import Core
import os

class TransformerSignRecognizer:
    """åŸºäºTransformerçš„æ‰‹è¯­è¯†åˆ«æ¨¡å‹å°è£…ç±»"""
    
    def __init__(self, model_path: str, confidence_threshold: float = 0.7):
        """
        åˆå§‹åŒ–Transformeræ‰‹è¯­è¯†åˆ«æ¨¡å‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.xmlæ–‡ä»¶ï¼‰
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
        """
        self.model_path = model_path
        self.confidence_threshold = confidence_threshold
        self.core = Core()
        self.model = None
        self.compiled_model = None
        self.input_tensor_name = None
        self.output_tensor_name = None
        
        # æ‰©å±•æ‰‹è¯­ç±»åˆ«ï¼Œä¸åŸæœ‰æ¨¡å‹ä¿æŒä¸€è‡´
        self.class_names = [
            # é—®å€™ç±»
            "ä½ å¥½", "è°¢è°¢", "å†è§", "æ—©ä¸Šå¥½", "æ™šä¸Šå¥½", "æ¬¢è¿", "è¯·é—®", "æ²¡å…³ç³»", "ä¸å®¢æ°”", "ä¹…ä»°", 
            # æƒ…æ„Ÿç±»
            "æˆ‘çˆ±ä½ ", "å–œæ¬¢", "ç”Ÿæ°”", "æ‚²ä¼¤", "å¼€å¿ƒ", "æƒŠè®¶", "æ„ŸåŠ¨", "å®³æ€•", "éª„å‚²", "å¤±æœ›", 
            # å›ç­”ç±»
            "æ˜¯", "å¦", "ä¸çŸ¥é“", "å¯èƒ½", "å½“ç„¶", "æŠ±æ­‰", "æ˜¯çš„", "ä¸æ˜¯", "ä¹Ÿè®¸", "ä¸€å®š", 
            # è¯·æ±‚ç±»
            "è¯·", "å¸®åŠ©", "éœ€è¦", "æƒ³è¦", "ç»™æˆ‘", "å€Ÿæˆ‘", "è¯·é—®", "éº»çƒ¦", "æ‹œæ‰˜", "è®©ä¸€ä¸‹", 
            # èº«ä»½ç±»
            "æˆ‘", "ä½ ", "ä»–", "å¥¹", "æˆ‘ä»¬", "ä½ ä»¬", "ä»–ä»¬", "è€å¸ˆ", "åŒ»ç”Ÿ", "å­¦ç”Ÿ", 
            # ç”Ÿæ´»ç±»
            "å®¶", "å­¦æ ¡", "å·¥ä½œ", "åŒ»é™¢", "å•†åº—", "å…¬å›­", "é¤å…", "é“¶è¡Œ", "è¶…å¸‚", "é‚®å±€", 
            # ç‰©å“ç±»
            "é£Ÿç‰©", "æ°´", "é¥®æ–™", "è¡£æœ", "é‹å­", "å¸½å­", "æ‰‹æœº", "ç”µè„‘", "ä¹¦åŒ…", "ä¹¦æœ¬", 
            "ç¬”", "çº¸", "æ¯å­", "ç­·å­", "å‹ºå­", "ç¢—", "ç›˜å­", "æ¡Œå­", "æ¤…å­", "åºŠ", 
            # åŠ¨ä½œç±»
            "èµ°", "è·‘", "å", "ç«™", "åƒ", "å–", "çœ‹", "å¬", "è¯´", "å†™", 
            "è¯»", "ç”»", "å”±", "è·³", "ç¡", "é†’", "æ¥", "å»", "ä¸Š", "ä¸‹", 
            # æ•°é‡ç±»
            "ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "ä¸ƒ", "å…«", "ä¹", "å", 
            "ç™¾", "åƒ", "ä¸‡", "é›¶", "åŠ", "ä¸¤", "å¤š", "å°‘", "ç¬¬ä¸€", "ç¬¬äºŒ", 
            # å…¶ä»–
            "æ—¶é—´", "ä»Šå¤©", "æ˜å¤©", "æ˜¨å¤©", "æ˜ŸæœŸ", "æœˆä»½", "å¹´", "é’±", "ä»·æ ¼", "é¢œè‰²", 
            "çº¢è‰²", "è“è‰²", "ç»¿è‰²", "é»„è‰²", "é»‘è‰²", "ç™½è‰²", "ç´«è‰²", "æ©™è‰²", "ç²‰è‰²", "ç°è‰²", 
            "å¤§", "å°", "é•¿", "çŸ­", "é«˜", "çŸ®", "èƒ–", "ç˜¦", "çƒ­", "å†·", 
            "æ—©", "æ™š", "å¿«", "æ…¢", "å¥½", "å", "å¯¹", "é”™", "æ–°", "æ—§",
            # æ‰©å±•ç±»åˆ«
            "æœ‹å‹", "å®¶äºº", "çˆ¶æ¯", "å…„å¼Ÿ", "å§å¦¹", "å­©å­", "è€äºº", "å¹´è½»äºº", "ç”·äºº", "å¥³äºº",
            "æ°´æœ", "è”¬èœ", "è‚‰ç±»", "ç±³é¥­", "é¢æ¡", "é¢åŒ…", "ç‰›å¥¶", "æœæ±", "å’–å•¡", "èŒ¶",
            "æ±½è½¦", "ç«è½¦", "é£æœº", "åœ°é“", "å…¬äº¤", "è‡ªè¡Œè½¦", "æ­¥è¡Œ", "é©¾é©¶", "ä¹˜å", "åˆ°è¾¾",
            "å¼€å§‹", "ç»“æŸ", "ç»§ç»­", "åœæ­¢", "ç­‰å¾…", "å‡ºå‘", "è¿”å›", "ç¦»å¼€", "åˆ°è¾¾", "åœç•™"
        ]
        
        # åºåˆ—è¯†åˆ«æ”¯æŒ
        self.sequence_buffer = []
        self.sequence_length = 10
        self.sequence_weights = np.linspace(0.1, 1.0, self.sequence_length)
        self.sequence_weights /= np.sum(self.sequence_weights)
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def load_model(self):
        """åŠ è½½Transformeræ‰‹è¯­è¯†åˆ«æ¨¡å‹"""
        try:
            print(f"ğŸš€ åŠ è½½Transformeræ‰‹è¯­è¯†åˆ«æ¨¡å‹: {self.model_path}")
            
            # è¯»å–æ¨¡å‹
            self.model = self.core.read_model(self.model_path)
            
            # ç¼–è¯‘æ¨¡å‹
            self.compiled_model = self.core.compile_model(self.model, "AUTO")
            
            # è·å–è¾“å…¥è¾“å‡ºå¼ é‡
            self.input_tensor_name = next(iter(self.compiled_model.inputs))
            self.output_tensor_name = next(iter(self.compiled_model.outputs))
            
            print("âœ… Transformeræ‰‹è¯­è¯†åˆ«æ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½Transformeræ‰‹è¯­è¯†åˆ«æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def preprocess(self, keypoints: List[Dict[str, float]]) -> np.ndarray:
        """
        é¢„å¤„ç†å…³é”®ç‚¹æ•°æ®
        
        Args:
            keypoints: å…³é”®ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…³é”®ç‚¹åŒ…å«x, y, confidence
            
        Returns:
            np.ndarray: é¢„å¤„ç†åçš„å…³é”®ç‚¹æ•°æ®ï¼Œæ ¼å¼ä¸º (1, åºåˆ—é•¿åº¦, å…³é”®ç‚¹æ•°é‡ * 2)
        """
        # æå–x, yåæ ‡
        coords = []
        for kp in keypoints:
            coords.append([kp["x"], kp["y"]])
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        coords = np.array(coords)
        
        # å½’ä¸€åŒ–åˆ° [-1, 1] èŒƒå›´
        if coords.shape[0] > 0:
            min_vals = coords.min(axis=0)
            max_vals = coords.max(axis=0)
            range_vals = max_vals - min_vals
            range_vals[range_vals == 0] = 1.0
            coords = 2.0 * (coords - min_vals) / range_vals - 1.0
        
        # è°ƒæ•´å½¢çŠ¶ä¸º (1, åºåˆ—é•¿åº¦, å…³é”®ç‚¹æ•°é‡ * 2)
        input_tensor = np.expand_dims(coords.flatten(), axis=0)
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        return input_tensor.astype(np.float32)
    
    def predict(self, keypoints: List[Dict[str, float]]) -> Dict[str, Any]:
        """
        å¯¹æ‰‹è¯­è¿›è¡Œé¢„æµ‹
        
        Args:
            keypoints: å…³é”®ç‚¹åˆ—è¡¨ï¼Œæ¯ä¸ªå…³é”®ç‚¹åŒ…å«x, y, confidence
            
        Returns:
            dict: é¢„æµ‹ç»“æœï¼ŒåŒ…å«ç±»åˆ«ã€ç½®ä¿¡åº¦ç­‰ä¿¡æ¯
        """
        try:
            if not self.model or not self.compiled_model:
                return {
                    "success": False,
                    "message": "Transformeræ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆä¸‹è½½å¹¶é€‰æ‹©æœ‰æ•ˆçš„æ¨¡å‹",
                    "predicted_class": "",
                    "confidence": 0.0
                }
            
            # é¢„å¤„ç†å…³é”®ç‚¹æ•°æ®
            input_tensor = self.preprocess(keypoints)
            
            # æ¨ç†
            result = self.compiled_model.infer_new_request({self.input_tensor_name: input_tensor})
            output = result[self.output_tensor_name]
            
            # åå¤„ç†
            probabilities = self.softmax(output[0])
            confidence = np.max(probabilities)
            predicted_idx = np.argmax(probabilities)
            predicted_class = self.class_names[predicted_idx % len(self.class_names)] if confidence >= self.confidence_threshold else ""
            
            return {
                "success": True,
                "message": "è¯†åˆ«æˆåŠŸ",
                "predicted_class": predicted_class,
                "confidence": float(confidence),
                "probabilities": probabilities.tolist(),
                "class_index": int(predicted_idx)
            }
            
        except Exception as e:
            print(f"âŒ Transformeræ¨¡å‹æ¨ç†å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"æ¨ç†å¤±è´¥: {str(e)}",
                "predicted_class": "",
                "confidence": 0.0
            }
    
    def predict_sequence(self, sequence_keypoints: List[List[Dict[str, float]]]) -> Dict[str, Any]:
        """
        å¯¹è¿ç»­å…³é”®ç‚¹åºåˆ—è¿›è¡Œé¢„æµ‹
        
        Args:
            sequence_keypoints: å…³é”®ç‚¹åºåˆ—åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯ä¸€å¸§çš„å…³é”®ç‚¹
            
        Returns:
            dict: åºåˆ—é¢„æµ‹ç»“æœ
        """
        try:
            if not self.model or not self.compiled_model:
                return {
                    "success": False,
                    "message": "Transformeræ¨¡å‹æœªåŠ è½½",
                    "predicted_class": "",
                    "confidence": 0.0
                }
            
            # æ‰¹é‡é¢„å¤„ç†
            batch_input = []
            valid_frames = []
            
            for kps in sequence_keypoints:
                if kps:
                    input_tensor = self.preprocess(kps)
                    batch_input.append(input_tensor)
                    valid_frames.append(True)
                else:
                    valid_frames.append(False)
            
            if not batch_input:
                return {
                    "success": False,
                    "message": "æ— æ•ˆçš„å…³é”®ç‚¹åºåˆ—",
                    "predicted_class": "",
                    "confidence": 0.0
                }
            
            # åˆå¹¶ä¸ºæ‰¹é‡è¾“å…¥
            batch_input = np.concatenate(batch_input, axis=0)
            
            # æ‰¹é‡æ¨ç†
            result = self.compiled_model.infer_new_request({self.input_tensor_name: batch_input})
            outputs = result[self.output_tensor_name]
            
            # åå¤„ç†
            frame_predictions = []
            for i, output in enumerate(outputs):
                probabilities = self.softmax(output)
                confidence = np.max(probabilities)
                predicted_idx = np.argmax(probabilities)
                predicted_class = self.class_names[predicted_idx % len(self.class_names)] if confidence >= self.confidence_threshold else ""
                
                frame_predictions.append({
                    "predicted_class": predicted_class,
                    "confidence": float(confidence),
                    "probabilities": probabilities
                })
            
            # åºåˆ—èåˆ
            final_probabilities = self.fuse_sequence_predictions(frame_predictions)
            final_confidence = np.max(final_probabilities)
            final_predicted_idx = np.argmax(final_probabilities)
            final_predicted_class = self.class_names[final_predicted_idx % len(self.class_names)] if final_confidence >= self.confidence_threshold else ""
            
            return {
                "success": True,
                "message": "åºåˆ—è¯†åˆ«æˆåŠŸ",
                "predicted_class": final_predicted_class,
                "confidence": float(final_confidence),
                "frame_predictions": frame_predictions,
                "sequence_length": len(valid_frames),
                "valid_frames": sum(valid_frames)
            }
            
        except Exception as e:
            print(f"âŒ åºåˆ—é¢„æµ‹å¤±è´¥: {e}")
            return {
                "success": False,
                "message": f"åºåˆ—é¢„æµ‹å¤±è´¥: {str(e)}",
                "predicted_class": "",
                "confidence": 0.0
            }
    
    def fuse_sequence_predictions(self, predictions: List[Dict[str, Any]]) -> np.ndarray:
        """
        èåˆåºåˆ—é¢„æµ‹ç»“æœ
        
        Args:
            predictions: å¸§é¢„æµ‹ç»“æœåˆ—è¡¨
            
        Returns:
            np.ndarray: èåˆåçš„æ¦‚ç‡åˆ†å¸ƒ
        """
        if not predictions:
            return np.zeros(len(self.class_names))
        
        # è°ƒæ•´æƒé‡é•¿åº¦
        current_length = len(predictions)
        weights = self.sequence_weights[-current_length:] if current_length < self.sequence_length else self.sequence_weights
        weights = weights[:current_length] / np.sum(weights[:current_length])
        
        # åˆå§‹åŒ–èåˆæ¦‚ç‡
        fused_probabilities = np.zeros(len(self.class_names))
        
        # åŠ æƒèåˆ
        for i, pred in enumerate(predictions):
            fused_probabilities += weights[i] * pred["probabilities"]
        
        return fused_probabilities
    
    def softmax(self, x: np.ndarray) -> np.ndarray:
        """
        è®¡ç®—softmaxå€¼
        
        Args:
            x: è¾“å…¥æ•°ç»„
            
        Returns:
            np.ndarray: softmaxç»“æœ
        """
        try:
            # é¿å…æ•°å€¼æº¢å‡ºï¼Œå‡å»æœ€å¤§å€¼
            max_val = np.max(x)
            e_x = np.exp(x - max_val)
            
            # è®¡ç®—æ€»å’Œï¼Œæ·»åŠ æå°å€¼é¿å…é™¤ä»¥é›¶
            sum_e_x = np.sum(e_x) + 1e-10
            
            return e_x / sum_e_x
            
        except Exception as e:
            print(f"âŒ softmaxè®¡ç®—å¤±è´¥: {e}")
            # è¿”å›å‡åŒ€åˆ†å¸ƒä½œä¸º fallback
            return np.ones_like(x) / len(x) if len(x) > 0 else np.array([1.0])
    
    def get_model_info(self) -> Dict[str, Any]:
        """
        è·å–æ¨¡å‹ä¿¡æ¯
        
        Returns:
            dict: æ¨¡å‹ä¿¡æ¯
        """
        return {
            "model_path": self.model_path,
            "model_type": "transformer",
            "confidence_threshold": self.confidence_threshold,
            "class_count": len(self.class_names),
            "class_names": self.class_names,
            "model_loaded": self.model is not None,
            "sequence_length": self.sequence_length
        }
    
    def update_confidence_threshold(self, threshold: float):
        """
        æ›´æ–°ç½®ä¿¡åº¦é˜ˆå€¼
        
        Args:
            threshold: æ–°çš„ç½®ä¿¡åº¦é˜ˆå€¼
        """
        if 0.0 <= threshold <= 1.0:
            self.confidence_threshold = threshold
            print(f"ç½®ä¿¡åº¦é˜ˆå€¼å·²æ›´æ–°ä¸º: {threshold}")
        else:
            print("ç½®ä¿¡åº¦é˜ˆå€¼å¿…é¡»åœ¨ [0.0, 1.0] èŒƒå›´å†…")
    
    def close(self):
        """é‡Šæ”¾æ¨¡å‹èµ„æº"""
        try:
            if self.model is not None:
                self.model = None
            if self.compiled_model is not None:
                self.compiled_model = None
            print("âœ… Transformeræ¨¡å‹èµ„æºå·²é‡Šæ”¾")
        except Exception as e:
            print(f"âŒ é‡Šæ”¾Transformeræ¨¡å‹èµ„æºå¤±è´¥: {e}")
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        self.close()