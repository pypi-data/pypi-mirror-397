import numpy as np
import cv2
from typing import List, Dict, Any, Optional, Tuple
import os
from openvino.runtime import Core

class YOLOv8HandDetector:
    """YOLOv8næ‰‹éƒ¨æ£€æµ‹å™¨"""
    
    def __init__(self, model_path: str):
        """
        åˆå§‹åŒ–YOLOv8næ‰‹éƒ¨æ£€æµ‹å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.xmlæ–‡ä»¶ï¼‰
        """
        self.model_path = model_path
        self.core = Core()
        self.model = None
        self.compiled_model = None
        self.input_tensor_name = None
        self.output_tensor_name = None
        self.class_names = [
            "person", "bicycle", "car", "motorcycle", "airplane", "bus", "train", "truck", "boat", "traffic light",
            "fire hydrant", "stop sign", "parking meter", "bench", "bird", "cat", "dog", "horse", "sheep", "cow",
            "elephant", "bear", "zebra", "giraffe", "backpack", "umbrella", "handbag", "tie", "suitcase", "frisbee",
            "skis", "snowboard", "sports ball", "kite", "baseball bat", "baseball glove", "skateboard", "surfboard",
            "tennis racket", "bottle", "wine glass", "cup", "fork", "knife", "spoon", "bowl", "banana", "apple",
            "sandwich", "orange", "broccoli", "carrot", "hot dog", "pizza", "donut", "cake", "chair", "couch",
            "potted plant", "bed", "dining table", "toilet", "tv", "laptop", "mouse", "remote", "keyboard", "cell phone",
            "microwave", "oven", "toaster", "sink", "refrigerator", "book", "clock", "vase", "scissors", "teddy bear",
            "hair drier", "toothbrush"
        ]
        
        # æ‰‹éƒ¨ç›¸å…³ç±»åˆ«ç´¢å¼•
        self.hand_related_classes = [47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80]
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def load_model(self):
        """åŠ è½½YOLOv8næ¨¡å‹"""
        try:
            print(f"ğŸš€ åŠ è½½YOLOv8næ¨¡å‹: {self.model_path}")
            
            # è¯»å–æ¨¡å‹
            self.model = self.core.read_model(self.model_path)
            
            # ç¼–è¯‘æ¨¡å‹
            self.compiled_model = self.core.compile_model(self.model, "AUTO")
            
            # è·å–è¾“å…¥è¾“å‡ºå¼ é‡
            self.input_tensor_name = next(iter(self.compiled_model.inputs))
            self.output_tensor_name = next(iter(self.compiled_model.outputs))
            
            print("âœ… YOLOv8næ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½YOLOv8næ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†å›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦, é€šé“)
            
        Returns:
            np.ndarray: é¢„å¤„ç†åçš„å›¾åƒï¼Œæ ¼å¼ä¸º (1, é€šé“, é«˜åº¦, å®½åº¦)
        """
        # è°ƒæ•´å›¾åƒå¤§å°
        resized = cv2.resize(image, (640, 640))
        
        # è½¬æ¢ä¸ºRGB
        if resized.shape[-1] == 4:
            resized = resized[..., :3]
        
        # è½¬æ¢ä¸º(é€šé“, é«˜åº¦, å®½åº¦)æ ¼å¼
        input_tensor = resized.transpose(2, 0, 1)
        
        # æ·»åŠ batchç»´åº¦
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        # å½’ä¸€åŒ–
        input_tensor = input_tensor.astype(np.float32) / 255.0
        
        return input_tensor
    
    def detect(self, image: np.ndarray, confidence_threshold: float = 0.5, iou_threshold: float = 0.45) -> List[Dict[str, Any]]:
        """
        æ£€æµ‹å›¾åƒä¸­çš„æ‰‹éƒ¨
        
        Args:
            image: è¾“å…¥å›¾åƒ
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            List[Dict[str, Any]]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        if self.model is None or self.compiled_model is None:
            return []
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            input_tensor = self.preprocess(image)
            
            # æ¨ç†
            result = self.compiled_model.infer_new_request({self.input_tensor_name: input_tensor})
            
            # è·å–è¾“å‡º
            output = result[self.output_tensor_name]
            
            # åå¤„ç†
            detections = self.postprocess(output, image.shape, confidence_threshold, iou_threshold)
            
            return detections
            
        except Exception as e:
            print(f"âŒ YOLOv8næ£€æµ‹å¤±è´¥: {e}")
            return []
    
    def postprocess(self, output: np.ndarray, image_shape: Tuple[int, int, int], confidence_threshold: float, iou_threshold: float) -> List[Dict[str, Any]]:
        """
        åå¤„ç†YOLOv8nè¾“å‡º
        
        Args:
            output: æ¨¡å‹è¾“å‡º
            image_shape: åŸå§‹å›¾åƒå½¢çŠ¶ (é«˜åº¦, å®½åº¦, é€šé“)
            confidence_threshold: ç½®ä¿¡åº¦é˜ˆå€¼
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            List[Dict[str, Any]]: æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        detections = []
        
        # YOLOv8è¾“å‡ºæ ¼å¼: (batch_size, num_detections, 85)
        # å…¶ä¸­85 = x, y, w, h, confidence, class1, class2, ..., class80
        
        # éå†æ‰€æœ‰æ£€æµ‹ç»“æœ
        for detection in output[0]:
            x_center, y_center, width, height, confidence, *class_scores = detection
            
            # è¿‡æ»¤ä½ç½®ä¿¡åº¦æ£€æµ‹
            if confidence < confidence_threshold:
                continue
            
            # è·å–ç±»åˆ«
            class_id = np.argmax(class_scores)
            class_score = class_scores[class_id]
            
            # è¿‡æ»¤éæ‰‹éƒ¨ç›¸å…³ç±»åˆ«
            if class_id not in self.hand_related_classes:
                continue
            
            # è®¡ç®—è¾¹ç•Œæ¡†
            x1 = int((x_center - width / 2) * (image_shape[1] / 640))
            y1 = int((y_center - height / 2) * (image_shape[0] / 640))
            x2 = int((x_center + width / 2) * (image_shape[1] / 640))
            y2 = int((y_center + height / 2) * (image_shape[0] / 640))
            
            # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
            x1 = max(0, x1)
            y1 = max(0, y1)
            x2 = min(image_shape[1], x2)
            y2 = min(image_shape[0], y2)
            
            # è®¡ç®—è¾¹ç•Œæ¡†å®½åº¦å’Œé«˜åº¦
            w = x2 - x1
            h = y2 - y1
            
            # æ·»åŠ åˆ°æ£€æµ‹ç»“æœ
            detections.append({
                "class_id": int(class_id),
                "class_name": self.class_names[class_id],
                "confidence": float(confidence * class_score),
                "bbox": (x1, y1, w, h),
                "x1": x1,
                "y1": y1,
                "x2": x2,
                "y2": y2
            })
        
        # æŒ‰ç½®ä¿¡åº¦æ’åº
        detections.sort(key=lambda x: x["confidence"], reverse=True)
        
        # éæå¤§å€¼æŠ‘åˆ¶
        nms_detections = self.nms(detections, iou_threshold)
        
        return nms_detections
    
    def nms(self, detections: List[Dict[str, Any]], iou_threshold: float) -> List[Dict[str, Any]]:
        """
        éæå¤§å€¼æŠ‘åˆ¶
        
        Args:
            detections: æ£€æµ‹ç»“æœåˆ—è¡¨
            iou_threshold: IoUé˜ˆå€¼
            
        Returns:
            List[Dict[str, Any]]: NMSåçš„æ£€æµ‹ç»“æœåˆ—è¡¨
        """
        if len(detections) == 0:
            return []
        
        # æå–è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
        boxes = np.array([det["bbox"] for det in detections])
        confidences = np.array([det["confidence"] for det in detections])
        
        # è½¬æ¢è¾¹ç•Œæ¡†æ ¼å¼ (x1, y1, w, h) -> (x1, y1, x2, y2)
        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]
        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]
        
        # ä½¿ç”¨OpenCVçš„NMS
        indices = cv2.dnn.NMSBoxes(boxes.tolist(), confidences.tolist(), 0.0, iou_threshold)
        
        # è·å–NMSåçš„æ£€æµ‹ç»“æœ
        nms_detections = [detections[i] for i in indices.flatten()] if len(indices) > 0 else []
        
        return nms_detections
    
    def detect_hand(self, image: np.ndarray) -> Optional[Tuple[np.ndarray, Tuple[int, int, int, int]]]:
        """
        æ£€æµ‹æ‰‹éƒ¨å¹¶è¿”å›æ‰‹éƒ¨åŒºåŸŸ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            Optional[Tuple[np.ndarray, Tuple[int, int, int, int]]]: (æ‰‹éƒ¨åŒºåŸŸå›¾åƒ, è¾¹ç•Œæ¡†) æˆ– None
        """
        # æ£€æµ‹æ‰€æœ‰ç‰©ä½“
        detections = self.detect(image, confidence_threshold=0.3, iou_threshold=0.45)
        
        if not detections:
            return None
        
        # å¯»æ‰¾æœ€å¤§çš„æ‰‹éƒ¨ç›¸å…³æ£€æµ‹
        max_area = 0
        best_hand = None
        
        for det in detections:
            x, y, w, h = det["bbox"]
            area = w * h
            
            if area > max_area:
                max_area = area
                best_hand = det
        
        if best_hand is None:
            return None
        
        # æå–æ‰‹éƒ¨åŒºåŸŸ
        x, y, w, h = best_hand["bbox"]
        
        # æ‰©å±•è¾¹ç•Œæ¡†ï¼Œç¡®ä¿åŒ…å«å®Œæ•´æ‰‹éƒ¨
        margin = 20
        x1 = max(0, x - margin)
        y1 = max(0, y - margin)
        x2 = min(image.shape[1], x + w + margin)
        y2 = min(image.shape[0], y + h + margin)
        
        # æå–æ‰‹éƒ¨åŒºåŸŸ
        hand_region = image[y1:y2, x1:x2]
        
        return hand_region, (x1, y1, x2 - x1, y2 - y1)
    
    def close(self):
        """é‡Šæ”¾æ¨¡å‹èµ„æº"""
        try:
            if self.model is not None:
                self.model = None
            if self.compiled_model is not None:
                self.compiled_model = None
            print("âœ… YOLOv8næ¨¡å‹èµ„æºå·²é‡Šæ”¾")
        except Exception as e:
            print(f"âŒ é‡Šæ”¾YOLOv8næ¨¡å‹èµ„æºå¤±è´¥: {e}")
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        self.close()