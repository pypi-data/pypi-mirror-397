import numpy as np
import cv2
from typing import List, Dict, Any, Optional, Tuple
from openvino.runtime import Core

class HandPoseEstimator:
    """åŸºäºOpenVINOçš„æ‰‹éƒ¨å…³é”®ç‚¹æå–å™¨"""
    
    def __init__(self, model_path: str):
        """
        åˆå§‹åŒ–æ‰‹éƒ¨å…³é”®ç‚¹æå–å™¨
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾„ï¼ˆ.xmlæ–‡ä»¶ï¼‰
        """
        self.model_path = model_path
        self.core = Core()
        self.model = None
        self.compiled_model = None
        self.input_tensor_name = None
        self.output_tensor_name = None
        
        # æ‰‹éƒ¨å…³é”®ç‚¹ç´¢å¼•
        self.hand_keypoint_indices = [5, 6, 7, 8, 9,  # å·¦æ‰‹
                                     10, 11, 12, 13, 14]  # å³æ‰‹
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def load_model(self):
        """åŠ è½½æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹"""
        try:
            print(f"ğŸš€ åŠ è½½æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹: {self.model_path}")
            
            # è¯»å–æ¨¡å‹
            self.model = self.core.read_model(self.model_path)
            
            # ç¼–è¯‘æ¨¡å‹
            self.compiled_model = self.core.compile_model(self.model, "AUTO")
            
            # è·å–è¾“å…¥è¾“å‡ºå¼ é‡
            self.input_tensor_name = next(iter(self.compiled_model.inputs))
            self.output_tensor_name = next(iter(self.compiled_model.outputs))
            
            print("âœ… æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹åŠ è½½æˆåŠŸ!")
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def preprocess(self, image: np.ndarray) -> np.ndarray:
        """
        é¢„å¤„ç†å›¾åƒ
        
        Args:
            image: è¾“å…¥å›¾åƒï¼Œæ ¼å¼ä¸º (é«˜åº¦, å®½åº¦, é€šé“)
            
        Returns:
            np.ndarray: é¢„å¤„ç†åçš„å›¾åƒï¼Œæ ¼å¼ä¸º (1, é€šé“, é«˜åº¦, å®½åº¦)
        """
        # è°ƒæ•´å›¾åƒå¤§å°
        resized = cv2.resize(image, (640, 480))
        
        # è½¬æ¢ä¸ºRGB
        if resized.shape[-1] == 4:
            resized = resized[..., :3]
        
        # è½¬æ¢ä¸º(é€šé“, é«˜åº¦, å®½åº¦)æ ¼å¼
        input_tensor = resized.transpose(2, 0, 1)
        
        # æ·»åŠ batchç»´åº¦
        input_tensor = np.expand_dims(input_tensor, axis=0)
        
        # å½’ä¸€åŒ–
        input_tensor = input_tensor.astype(np.float32) / 255.0
        
        return input_tensor
    
    def estimate_pose(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        ä¼°è®¡äººä½“å§¿åŠ¿
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            Optional[Dict[str, Any]]: å§¿åŠ¿ä¼°è®¡ç»“æœï¼ŒåŒ…å«å…³é”®ç‚¹åæ ‡ç­‰ä¿¡æ¯
        """
        if self.model is None or self.compiled_model is None:
            return None
        
        try:
            # é¢„å¤„ç†å›¾åƒ
            input_tensor = self.preprocess(image)
            
            # æ¨ç†
            result = self.compiled_model.infer_new_request({self.input_tensor_name: input_tensor})
            
            # è·å–è¾“å‡º
            output = result[self.output_tensor_name]
            
            # åå¤„ç†
            pose_result = self.postprocess(output, image.shape)
            
            return pose_result
            
        except Exception as e:
            print(f"âŒ å§¿åŠ¿ä¼°è®¡å¤±è´¥: {e}")
            return None
    
    def postprocess(self, output: np.ndarray, image_shape: Tuple[int, int, int]) -> Dict[str, Any]:
        """
        åå¤„ç†å§¿åŠ¿ä¼°è®¡è¾“å‡º
        
        Args:
            output: æ¨¡å‹è¾“å‡º
            image_shape: åŸå§‹å›¾åƒå½¢çŠ¶ (é«˜åº¦, å®½åº¦, é€šé“)
            
        Returns:
            Dict[str, Any]: åå¤„ç†åçš„å§¿åŠ¿ä¼°è®¡ç»“æœ
        """
        # human-pose-estimation-0001 è¾“å‡ºæ ¼å¼:
        # (batch_size, num_joints, height, width) æˆ– (batch_size, num_joints * 3, height, width)
        
        # è§£æå…³é”®ç‚¹
        batch_size, num_channels, height, width = output.shape
        num_joints = num_channels // 3
        
        # æå–ç½®ä¿¡åº¦å›¾
        conf_maps = output[0, num_joints:, :, :]
        
        # æå–åç§»é‡
        offsets = output[0, :num_joints*2, :, :]
        
        # æå–å…³é”®ç‚¹åæ ‡
        keypoints = []
        for i in range(num_joints):
            # æ‰¾åˆ°ç½®ä¿¡åº¦æœ€é«˜ç‚¹
            conf_map = conf_maps[i, :, :]
            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(conf_map)
            
            # è®¡ç®—å®é™…åæ ‡
            x = (max_loc[0] / width) * image_shape[1]
            y = (max_loc[1] / height) * image_shape[0]
            confidence = max_val
            
            # åº”ç”¨åç§»é‡
            offset_x = offsets[i, max_loc[1], max_loc[0]]
            offset_y = offsets[i + num_joints, max_loc[1], max_loc[0]]
            
            x += offset_x
            y += offset_y
            
            keypoints.append({
                "x": float(x),
                "y": float(y),
                "confidence": float(confidence)
            })
        
        return {
            "keypoints": keypoints,
            "num_joints": num_joints,
            "confidence": float(np.mean([kp["confidence"] for kp in keypoints]))
        }
    
    def extract_hand_keypoints(self, image: np.ndarray) -> Optional[Dict[str, Any]]:
        """
        æå–æ‰‹éƒ¨å…³é”®ç‚¹
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            Optional[Dict[str, Any]]: æ‰‹éƒ¨å…³é”®ç‚¹ç»“æœ
        """
        # ä¼°è®¡å§¿åŠ¿
        pose_result = self.estimate_pose(image)
        
        if pose_result is None:
            return None
        
        # æå–æ‰‹éƒ¨å…³é”®ç‚¹
        keypoints = pose_result["keypoints"]
        hand_keypoints = [kp for i, kp in enumerate(keypoints) if i in self.hand_keypoint_indices]
        
        # è®¡ç®—æ‰‹éƒ¨å…³é”®ç‚¹ç½®ä¿¡åº¦
        hand_confidence = np.mean([kp["confidence"] for kp in hand_keypoints])
        
        # æ£€æµ‹æ˜¯å¦æœ‰æ‰‹
        has_hand = hand_confidence > 0.2
        
        return {
            "hand_keypoints": hand_keypoints,
            "has_hand": has_hand,
            "confidence": float(hand_confidence),
            "full_keypoints": keypoints
        }
    
    def detect_hand_from_keypoints(self, image: np.ndarray) -> Optional[Tuple[np.ndarray, Tuple[int, int, int, int]]]:
        """
        ä»å…³é”®ç‚¹æ£€æµ‹æ‰‹éƒ¨åŒºåŸŸ
        
        Args:
            image: è¾“å…¥å›¾åƒ
            
        Returns:
            Optional[Tuple[np.ndarray, Tuple[int, int, int, int]]]: (æ‰‹éƒ¨åŒºåŸŸå›¾åƒ, è¾¹ç•Œæ¡†) æˆ– None
        """
        # æå–æ‰‹éƒ¨å…³é”®ç‚¹
        hand_result = self.extract_hand_keypoints(image)
        
        if hand_result is None or not hand_result["has_hand"]:
            return None
        
        # è·å–æ‰‹éƒ¨å…³é”®ç‚¹
        hand_keypoints = hand_result["hand_keypoints"]
        
        # è®¡ç®—æ‰‹éƒ¨è¾¹ç•Œæ¡†
        x_coords = [kp["x"] for kp in hand_keypoints]
        y_coords = [kp["y"] for kp in hand_keypoints]
        
        if not x_coords or not y_coords:
            return None
        
        # è®¡ç®—è¾¹ç•Œæ¡†
        x1 = max(0, int(min(x_coords) - 20))
        y1 = max(0, int(min(y_coords) - 20))
        x2 = min(image.shape[1], int(max(x_coords) + 20))
        y2 = min(image.shape[0], int(max(y_coords) + 20))
        
        # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆ
        if x1 >= x2 or y1 >= y2:
            return None
        
        # æå–æ‰‹éƒ¨åŒºåŸŸ
        hand_region = image[y1:y2, x1:x2]
        
        return hand_region, (x1, y1, x2 - x1, y2 - y1)
    
    def close(self):
        """é‡Šæ”¾æ¨¡å‹èµ„æº"""
        try:
            if self.model is not None:
                self.model = None
            if self.compiled_model is not None:
                self.compiled_model = None
            print("âœ… æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹èµ„æºå·²é‡Šæ”¾")
        except Exception as e:
            print(f"âŒ é‡Šæ”¾æ‰‹éƒ¨å…³é”®ç‚¹æ¨¡å‹èµ„æºå¤±è´¥: {e}")
    
    def __del__(self):
        """ææ„å‡½æ•°"""
        self.close()