# Copyright 2025 Snowflake Inc.
# SPDX-License-Identifier: Apache-2.0
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
# http://www.apache.org/licenses/LICENSE-2.0
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import logging

from functools import wraps
from pathlib import Path
from typing import Annotated

import typer

from snowflake.snowflake_data_validation.common_cli.cli_partitioning import (
    run_column_partitioning_helper,
    run_row_partitioning_helper,
)
from snowflake.snowflake_data_validation.comparison_orchestrator import (
    ComparisonOrchestrator,
)
from snowflake.snowflake_data_validation.configuration.configuration_loader import (
    ConfigurationLoader,
)
from snowflake.snowflake_data_validation.redshift.model.redshift_credentials_connection import (
    RedshiftCredentialsConnection,
)
from snowflake.snowflake_data_validation.redshift.redshift_arguments_manager import (
    RedshiftArgumentsManager,
)
from snowflake.snowflake_data_validation.utils import configuration_file_generator
from snowflake.snowflake_data_validation.utils.arguments_manager_factory import (
    create_validation_environment_from_config,
)
from snowflake.snowflake_data_validation.utils.console_output_handler import (
    ConsoleOutputHandler,
)
from snowflake.snowflake_data_validation.utils.constants import (
    CREDENTIALS_CONNECTION_MODE,
    ExecutionMode,
    Platform,
)
from snowflake.snowflake_data_validation.utils.logging_config import setup_logging
from snowflake.snowflake_data_validation.utils.validation_utils import (
    build_snowflake_credentials,
    validate_snowflake_credentials,
)


redshift_app = typer.Typer()
LOGGER = logging.getLogger(__name__)


def handle_validation_errors(func):
    """Handle validation errors and provide user-friendly messages."""

    @wraps(func)
    def wrapper(*args, **kwargs):
        try:
            return func(*args, **kwargs)
        except typer.BadParameter as e:
            error_msg = f"Invalid parameter: {e}"
            LOGGER.error("Parameter validation failed: %s", str(e))
            typer.secho(error_msg, fg=typer.colors.RED, err=True)
            raise typer.Exit(1) from None
        except FileNotFoundError as e:
            error_msg = f"Configuration file not found: {e}"
            LOGGER.error("File not found error: %s", str(e))
            typer.secho(error_msg, fg=typer.colors.RED, err=True)
            raise typer.Exit(1) from None
        except ConnectionError as e:
            error_msg = f"Connection error: {e}"
            LOGGER.error("Database connection failed: %s", str(e))
            typer.secho(error_msg, fg=typer.colors.RED, err=True)
            raise typer.Exit(1) from None
        except Exception as e:
            error_msg = f"Operation failed: {e}"
            LOGGER.exception("Unexpected error occurred: %s", str(e))
            typer.secho(error_msg, fg=typer.colors.RED, err=True)
            raise typer.Exit(1) from None

    return wrapper


@redshift_app.command("run-validation")
@handle_validation_errors
def redshift_run_validation(
    data_validation_config_file: Annotated[
        str,
        typer.Option(
            "--data-validation-config-file",
            "-dvf",
            help="Data validation configuration file path. ",
        ),
    ],
    log_level: Annotated[
        str,
        typer.Option(
            "--log-level",
            "-ll",
            help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL). Defaults to INFO.",
        ),
    ] = "INFO",
):
    """Run data validation for Redshift."""
    # Load configuration to check for logging settings
    from pathlib import Path

    from snowflake.snowflake_data_validation.configuration.configuration_loader import (
        ConfigurationLoader,
    )

    config_loader = ConfigurationLoader(Path(data_validation_config_file))
    config_model = config_loader.get_configuration_model()

    # CLI parameter takes precedence over config file settings
    if config_model.logging_configuration and log_level == "INFO":
        # Use config file settings only if CLI parameter is default (INFO)
        logging_config = config_model.logging_configuration
        setup_logging(
            log_level=logging_config.level,
            console_level=logging_config.console_level,
            file_level=logging_config.file_level,
        )
    else:
        # Use CLI parameter (overrides config file)
        setup_logging(log_level=log_level)

    typer.secho("Starting Redshift validation...", fg=typer.colors.BLUE)

    validation_env = _create_environment_from_config(
        data_validation_config_file, ExecutionMode.SYNC_VALIDATION
    )
    orchestrator = ComparisonOrchestrator.from_validation_environment(
        validation_env  # type: ignore
    )
    orchestrator.run_sync_comparison()
    typer.secho("Validation completed successfully!", fg=typer.colors.GREEN)


@redshift_app.command("run-async-validation")
@handle_validation_errors
def redshift_run_async_validation(
    data_validation_config_file: Annotated[
        str,
        typer.Option(
            "--data-validation-config-file",
            "-dvf",
            help="Data validation configuration file path. ",
        ),
    ],
    log_level: Annotated[
        str,
        typer.Option(
            "--log-level",
            "-ll",
            help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL). Defaults to INFO.",
        ),
    ] = "INFO",
):
    """Run async data validation for Redshift to Snowflake."""
    # Load configuration to check for logging settings
    from pathlib import Path

    from snowflake.snowflake_data_validation.configuration.configuration_loader import (
        ConfigurationLoader,
    )

    config_loader = ConfigurationLoader(Path(data_validation_config_file))
    config_model = config_loader.get_configuration_model()

    # CLI parameter takes precedence over config file settings
    if config_model.logging_configuration and log_level == "INFO":
        # Use config file settings only if CLI parameter is default (INFO)
        logging_config = config_model.logging_configuration
        setup_logging(
            log_level=logging_config.level,
            console_level=logging_config.console_level,
            file_level=logging_config.file_level,
        )
    else:
        # Use CLI parameter (overrides config file)
        setup_logging(log_level=log_level)

    typer.secho(
        "Starting Redshift to Snowflake async validation...", fg=typer.colors.BLUE
    )

    validation_env = _create_environment_from_config(
        data_validation_config_file, ExecutionMode.ASYNC_VALIDATION
    )
    orchestrator = ComparisonOrchestrator.from_validation_environment(
        validation_env  # type: ignore
    )
    orchestrator.run_async_comparison()
    typer.secho("Validation completed successfully!", fg=typer.colors.GREEN)


@redshift_app.command("source-validate")
@handle_validation_errors
def redshift_source_validate(
    data_validation_config_file: Annotated[
        str,
        typer.Option(
            "--data-validation-config-file",
            "-dvf",
            help="Data validation configuration file path. ",
        ),
    ],
    log_level: Annotated[
        str,
        typer.Option(
            "--log-level",
            "-ll",
            help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL). Defaults to INFO.",
        ),
    ] = "INFO",
) -> None:
    """Execute validation queries on source only and save results as Parquet files.

    This command extracts schema and metrics data from the source Redshift database
    without performing any validation or comparison. Results are saved as Parquet
    files for later validation without needing source database access.
    """
    # Load configuration to check for logging settings
    from pathlib import Path

    from snowflake.snowflake_data_validation.configuration.configuration_loader import (
        ConfigurationLoader,
    )

    config_loader = ConfigurationLoader(Path(data_validation_config_file))
    config_model = config_loader.get_configuration_model()

    # CLI parameter takes precedence over config file settings
    if config_model.logging_configuration and log_level == "INFO":
        # Use config file settings only if CLI parameter is default (INFO)
        logging_config = config_model.logging_configuration
        setup_logging(
            log_level=logging_config.level,
            console_level=logging_config.console_level,
            file_level=logging_config.file_level,
        )
    else:
        # Use CLI parameter (overrides config file)
        setup_logging(log_level=log_level)

    typer.secho("Starting Redshift source validation...", fg=typer.colors.BLUE)

    validation_env = _create_environment_from_config(
        data_validation_config_file, ExecutionMode.SOURCE_VALIDATION
    )
    orchestrator = ComparisonOrchestrator.from_validation_environment(
        validation_env  # type: ignore
    )
    orchestrator.run_source_validation()
    typer.secho(
        "Source validation completed - data saved as Parquet files!",
        fg=typer.colors.GREEN,
    )


@redshift_app.command("run-validation-ipc", hidden=True)
@handle_validation_errors
def redshift_run_validation_ipc(
    source_host: Annotated[
        str, typer.Option("--source-host", "-srch", help="Source Host name")
    ],
    source_username: Annotated[
        str, typer.Option("--source-username", "-srcu", help="Source Username")
    ],
    source_password: Annotated[
        str, typer.Option("--source-password", "-srcpw", help="Source Password")
    ],
    source_database: Annotated[
        str, typer.Option("--source-database", "-srcd", help="Source Database used")
    ],
    snow_account: Annotated[
        str, typer.Option("--snow-account", "-sa", help="Snowflake account name")
    ],
    snow_username: Annotated[
        str, typer.Option("--snow_username", "-su", help="Snowflake Username")
    ],
    snow_database: Annotated[
        str, typer.Option("--snow_database", "-sd", help="Snowflake Database used")
    ],
    snow_warehouse: Annotated[
        str, typer.Option("--snow_warehouse", "-sw", help="Snowflake Warehouse used")
    ],
    source_port: Annotated[
        int, typer.Option("--source-port", "-srcp", help="Source Port number")
    ] = 5439,
    snow_schema: Annotated[
        str | None,
        typer.Option("--snow_schema", "-ss", help="Snowflake Schema used"),
    ] = None,
    snow_role: Annotated[
        str | None, typer.Option("--snow_role", "-sr", help="Snowflake Role used")
    ] = None,
    snow_authenticator: Annotated[
        str | None,
        typer.Option(
            "--snow_authenticator", "-sau", help="Snowflake Authenticator method used"
        ),
    ] = None,
    snow_password: Annotated[
        str | None, typer.Option("--snow_password", "-sp", help="Snowflake Password")
    ] = None,
    snow_private_key_file: Annotated[
        str | None,
        typer.Option(
            "--snow_private_key_file", "-spk", help="Snowflake Private Key File"
        ),
    ] = None,
    snow_private_key_passphrase: Annotated[
        str | None,
        typer.Option(
            "--snow_private_key_passphrase",
            "-spkp",
            help="Snowflake Private Key Passphrase",
        ),
    ] = None,
    data_validation_config_file: Annotated[
        str | None,
        typer.Option(
            "--data-validation-config-file",
            "-dvf",
            help="Data validation configuration file path.",
        ),
    ] = None,
    log_level: Annotated[
        str,
        typer.Option(
            "--log-level",
            "-ll",
            help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL). Defaults to INFO.",
        ),
    ] = "INFO",
):
    """Run data validation for Redshift to Snowflake with IPC (In-Process Communication).

    This command allows direct specification of connection parameters without requiring
    pre-saved connection files.
    """
    # Set up logging with the specified level
    setup_logging(log_level=log_level)

    args_manager = RedshiftArgumentsManager()

    snow_credential_object = build_snowflake_credentials(
        account=snow_account,
        username=snow_username,
        database=snow_database,
        schema=snow_schema,
        warehouse=snow_warehouse,
        role=snow_role,
        authenticator=snow_authenticator,
        password=snow_password,
        private_key_file=snow_private_key_file,
        private_key_passphrase=snow_private_key_passphrase,
    )

    validate_snowflake_credentials(snow_credential_object)

    redshift_credentials = RedshiftCredentialsConnection(
        host=source_host,
        port=source_port,
        username=source_username,
        password=source_password,
        database=source_database,
    )
    redshift_credentials.model_validate(redshift_credentials)

    if data_validation_config_file:
        configuration = args_manager.load_configuration(
            data_validation_config_file=data_validation_config_file
        )
        output_directory_path = configuration.output_directory_path
    else:
        output_directory_path = None

    validation_env = args_manager.setup_validation_environment(
        source_connection_config=redshift_credentials,
        target_connection_config=snow_credential_object,
        data_validation_config_file=data_validation_config_file or "default",
        output_directory_path=output_directory_path,
        output_handler=ConsoleOutputHandler(enable_console_output=False),
        execution_mode=ExecutionMode.SYNC_VALIDATION,
    )

    orchestrator = ComparisonOrchestrator.from_validation_environment(
        validation_env  # type: ignore
    )
    orchestrator.run_sync_comparison()
    typer.secho("Validation completed successfully!", fg=typer.colors.GREEN)


@redshift_app.command("generate-validation-scripts")
@handle_validation_errors
def redshift_run_async_generation(
    data_validation_config_file: Annotated[
        str,
        typer.Option(
            "--data-validation-config-file",
            "-dvf",
            help="Data validation configuration file path. ",
        ),
    ],
    log_level: Annotated[
        str,
        typer.Option(
            "--log-level",
            "-ll",
            help="Logging level (DEBUG, INFO, WARNING, ERROR, CRITICAL). Defaults to INFO.",
        ),
    ] = "INFO",
):
    """Generate validation scripts for Redshift to Snowflake."""
    # Load configuration to check for logging settings
    from pathlib import Path

    from snowflake.snowflake_data_validation.configuration.configuration_loader import (
        ConfigurationLoader,
    )

    config_loader = ConfigurationLoader(Path(data_validation_config_file))
    config_model = config_loader.get_configuration_model()

    # CLI parameter takes precedence over config file settings
    if config_model.logging_configuration and log_level == "INFO":
        # Use config file settings only if CLI parameter is default (INFO)
        logging_config = config_model.logging_configuration
        setup_logging(
            log_level=logging_config.level,
            console_level=logging_config.console_level,
            file_level=logging_config.file_level,
        )
    else:
        # Use CLI parameter (overrides config file)
        setup_logging(log_level=log_level)

    typer.secho(
        "Starting Redshift to Snowflake validation script generation...",
        fg=typer.colors.BLUE,
    )

    validation_env = _create_environment_from_config(
        data_validation_config_file, ExecutionMode.ASYNC_GENERATION
    )
    orchestrator = ComparisonOrchestrator.from_validation_environment(
        validation_env  # type: ignore
    )
    orchestrator.run_async_generation()
    typer.secho(
        "Validation script generation completed successfully!", fg=typer.colors.GREEN
    )


@redshift_app.command(
    "get-configuration-files", help="Get configuration files for Redshift validation."
)
@handle_validation_errors
def redshift_get_configuration_files(
    templates_directory: Annotated[
        str | None,
        typer.Option(
            "--templates-directory",
            "-td",
            help="Directory to save the configuration templates.",
        ),
    ] = None,
    query_templates: Annotated[
        bool,
        typer.Option(
            "--query-templates",
            help="Include J2 query template files in the output.",
        ),
    ] = False,
):
    """Get configuration files for Redshift validation."""
    try:
        typer.secho(
            "Retrieving Redshift validation configuration files...",
            fg=typer.colors.BLUE,
        )
        args_manager = RedshiftArgumentsManager()
        output_dir = templates_directory if templates_directory else "."
        args_manager.dump_and_write_yaml_templates(
            source=Platform.REDSHIFT.value,
            templates_directory=output_dir,
            query_templates=query_templates,
        )
        typer.secho("Configuration files were generated ", fg=typer.colors.GREEN)
    except PermissionError as e:
        permission_error_msg = f"Permission denied while writing template files: {e}"
        LOGGER.error(permission_error_msg)
        raise RuntimeError(permission_error_msg) from e
    except Exception as e:
        runtime_error_msg = f"Failed to generate configuration files: {e}"
        LOGGER.error(runtime_error_msg)
        raise RuntimeError(runtime_error_msg) from e


@redshift_app.command(
    "auto-generated-configuration-file",
    help="Generate a basic configuration file by prompting for Redshift connection parameters.",
)
@handle_validation_errors
def redshift_auto_generated_configuration_file():
    """Generate a basic configuration file by prompting for Redshift connection parameters."""
    typer.secho(
        "Generating basic configuration file for Redshift validation...",
        fg=typer.colors.BLUE,
    )
    typer.secho(
        "Please provide the following connection information:\n",
        fg=typer.colors.CYAN,
    )

    # Prompt for Redshift connection parameters
    source_host = typer.prompt("Redshift host", type=str)
    source_port = typer.prompt("Redshift port", type=int, default=5439)
    source_username = typer.prompt("Redshift username", type=str)
    source_password = typer.prompt("Redshift password", type=str, hide_input=True)
    source_database = typer.prompt("Redshift database", type=str)
    source_schema = typer.prompt("Redshift schema", type=str)

    output_path = typer.prompt(
        "Output directory path for the configuration file", type=str
    )

    redshift_connection = RedshiftCredentialsConnection(
        mode=CREDENTIALS_CONNECTION_MODE,
        host=source_host,
        port=source_port,
        username=source_username,
        password=source_password,
        database=source_database,
    )
    try:
        success = configuration_file_generator.generate_configuration_file(
            platform=Platform.REDSHIFT,
            credentials_connection=redshift_connection,
            database=source_database,
            schema=source_schema,
            output_path=output_path,
        )

        if success:
            typer.secho(
                "Configuration file generated successfully!", fg=typer.colors.GREEN
            )
            LOGGER.info("Configuration file generated successfully at: %s", output_path)
        else:
            typer.secho("Failed to generate configuration file.", fg=typer.colors.RED)
            LOGGER.warning("Failed to generate configuration file.")

    except Exception as e:
        typer.secho(f"Error generating configuration file: {e}", fg=typer.colors.RED)
        LOGGER.error("Error generating configuration file: %s", e)


def _create_environment_from_config(
    data_validation_config_file: str,
    execution_mode: ExecutionMode,
    console_output: bool = True,
):
    """Create validation environment from configuration file."""
    config_path = Path(data_validation_config_file)
    config_loader = ConfigurationLoader(config_path)
    config_model = config_loader.get_configuration_model()

    return create_validation_environment_from_config(
        config_model=config_model,
        data_validation_config_file=data_validation_config_file,
        execution_mode=execution_mode,
        output_handler=ConsoleOutputHandler(enable_console_output=console_output),
    )


@redshift_app.command(
    "row-partitioning-helper",
    help="Interactive helper to configure row partitioning for tables in the configuration file.",
)
@redshift_app.command("table-partitioning-helper", hidden=True)
@handle_validation_errors
def redshift_row_partitioning_helper():
    """Generate a configuration file for Redshift row partitioning.

    This interactive helper function processes each table in the configuration file,
    allowing users to either skip row partitioning or specify row partitioning parameters
    for each table.
    """
    run_row_partitioning_helper(Platform.REDSHIFT)


@redshift_app.command(
    "column-partitioning-helper",
    help="Interactive helper to configure column partitioning for tables in the configuration file.",
)
@handle_validation_errors
def redshift_column_partitioning_helper():
    """Generate a configuration file for Redshift column partitioning.

    This interactive helper function processes each table in the configuration file,
    allowing users to either skip column partitioning or specify column partitioning parameters
    for each table.
    """
    run_column_partitioning_helper(Platform.REDSHIFT)
