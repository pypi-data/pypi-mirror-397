import numpy as np
from pyteomics import mass

import peppy_sage as ps
#from peppy_sage import Precursor, Spectrum, Scorer, IndexedDatabase
import polars as pl


def test_database_build():
    print("\n--- Database Build ---")

    df = pl.read_csv('trimmed_lib.tsv', separator='\t')
    print(df)
    # Create indexed database
    db = ps.IndexedDatabase.from_library(
        library=df,
        bucket_size=128,
        ion_kinds=["b", "y"],
        min_ion_index=0,
        generate_decoys=False,
        decoy_tag="rev_",
        peptide_min_mass=0.0,
        peptide_max_mass=5000.0,
    )


    print("Peptide count:", len(db.peptides))
    for p in db.peptides:
        print("  â†’", p.sequence)

    print("Fragment summary:", db.debug_fragment_summary())

    return db


def test_spectrum_build():
    print("\n--- Spectrum Build ---")

    proton_mass = 1.0072764
    # 1. Precursor setup
    precursor = ps.Precursor(mz=(956.55240+proton_mass)/2, charge=0, isolation_window=(-2.4, 2.4))
    #precursor = ps.Precursor(mz=(1056.55240+proton_mass)/2, charge=0, isolation_window=(-2.4, 2.4))

    # 2. Peak data
    mz_arr = [72.04444,
     143.08155,
     214.11866,
     285.15578,
     356.19289,
     427.23000,
     498.26712,
     611.35118,
     739.40976,
     810.44687,
     938.54183,
     956.55240,
     885.51528,
     814.47817,
     743.44106,
     672.40394,
     601.36683,
     530.32972,
     459.29260,
     346.20854,
     218.14996,
     147.11285]

    mz_arr = sorted(mz_arr)
    #mz_arr = [mz - proton_mass for mz in mz_arr]  # Convert to neutral masses

    # Testing mz_arr with dummy mod of 1000
    #mz_arr = [mz + 5.0 for mz in mz_arr]

    int_arr = mz_arr  # dummy intensities for test

    # 3. Build processed spectrum
    spectrum = ps.Spectrum(
        id="Scan_100",
        file_id=1,
        scan_start_time=10.5,
        mz_array=mz_arr,
        intensity_array=int_arr,
        precursors=[precursor],
    )

    print(f"Spectrum ID: {spectrum.id}")
    print(f"Peak count: {len(spectrum.peaks)}")
    print(f"Peaks: {spectrum.peaks}")
    print(f"Precursor MZ: {spectrum.precursors[0].mz:.5f}")

    return spectrum


def test_scoring(db, spectrum):
    print("\n--- Scoring Test ---")

    scorer = ps.Scorer(
        precursor_tol_da=(-1, 1),
        fragment_tol_ppm=(-5, 5),
        annotate_matches=True,
        report_psms=10,
        chimera=False
    )

    scorer = ps.Scorer(
        precursor_tol_da=(-1,1), # TODO placeholder
        fragment_tol_ppm=(-10,10),
        min_isotope_err=0,
        max_isotope_err=0,
        wide_window=True,
        chimera=False,
        annotate_matches=True,
        report_psms=100
    )

    spectra = [spectrum]

    BATCH_SIZE = 10000
    feature_arrays = None # Start with None or PyFeatureArrays()

    for i in range(0, len(spectra), BATCH_SIZE):
        batch_spectra = spectra[i:i + BATCH_SIZE]

        # 1. Get the columnar results for the current batch
        batch_arrays = scorer.score_many(db, batch_spectra)

        if feature_arrays is None:
            # Initialize the total container with the first batch
            feature_arrays = batch_arrays
        else:
            # 2. Append the new batch's data using the highly efficient Rust-side extend
            feature_arrays.extend(batch_arrays)

    import pandas as pd

    col_names = feature_arrays.get_column_names()
    df = pd.DataFrame({name: getattr(feature_arrays, name) for name in col_names})
    print(df.columns)
    print(df['expmass'], df['calcmass'])


if __name__ == "__main__":
    db = test_database_build()
    spectrum = test_spectrum_build()
    test_scoring(db, spectrum)