{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README Examples Validation\n",
    "\n",
    "This notebook contains all code examples from the README.md file.\n",
    "Run this notebook to verify that:\n",
    "1. All examples execute without errors\n",
    "2. Outputs match what's documented in the README\n",
    "\n",
    "**After making changes to blox**, run this notebook and update the README if outputs have changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:09.473637Z",
     "iopub.status.busy": "2025-12-17T18:05:09.472266Z",
     "iopub.status.idle": "2025-12-17T18:05:10.041909Z",
     "shell.execute_reply": "2025-12-17T18:05:10.040318Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup: ensure blox is importable and configure devices\n",
    "import sys\n",
    "\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "# Set up 4 CPU devices for sharding examples.\n",
    "# Must be done before JAX is imported.\n",
    "import chex\n",
    "\n",
    "chex.set_n_cpu_devices(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Start: Define your layers\n",
    "\n",
    "From README section: \"Define your layers\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:10.044453Z",
     "iopub.status.busy": "2025-12-17T18:05:10.044095Z",
     "iopub.status.idle": "2025-12-17T18:05:10.112305Z",
     "shell.execute_reply": "2025-12-17T18:05:10.110346Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomLinear defined successfully!\n"
     ]
    }
   ],
   "source": [
    "import blox as bx\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "\n",
    "class CustomLinear(bx.Module):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      graph: bx.Graph,\n",
    "      output_size: int,\n",
    "  ) -> None:\n",
    "    super().__init__(graph)\n",
    "    self.output_size = output_size\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      params: bx.Params,\n",
    "      inputs: jax.Array,\n",
    "  ) -> tuple[jax.Array, bx.Params]:\n",
    "    # Param initialization is lazy which serves two important purposes:\n",
    "    # 1. Avoids the need to specify input dimensions at construction.\n",
    "    # 2. Prevents accidental allocation of params on device.\n",
    "    kernel, params = self.get_param(\n",
    "        params=params,\n",
    "        name='kernel',\n",
    "        shape=(inputs.shape[-1], self.output_size),\n",
    "        init=jax.nn.initializers.glorot_uniform(),\n",
    "    )\n",
    "    bias, params = self.get_param(\n",
    "        params=params,\n",
    "        name='bias',\n",
    "        shape=(self.output_size,),\n",
    "        init=jax.nn.initializers.zeros,\n",
    "    )\n",
    "    return inputs @ kernel + bias, params\n",
    "\n",
    "\n",
    "print('CustomLinear defined successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composition & Dependency Injection\n",
    "\n",
    "From README section: \"Composition & Dependency Injection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:10.161631Z",
     "iopub.status.busy": "2025-12-17T18:05:10.161319Z",
     "iopub.status.idle": "2025-12-17T18:05:10.168452Z",
     "shell.execute_reply": "2025-12-17T18:05:10.167548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CustomMLP defined successfully!\n"
     ]
    }
   ],
   "source": [
    "class CustomMLP(bx.Module):\n",
    "\n",
    "  def __init__(\n",
    "      self,\n",
    "      graph: bx.Graph,\n",
    "      hidden_size: int,\n",
    "      # We can inject externally created modules...\n",
    "      output_projection: bx.Module,\n",
    "  ) -> None:\n",
    "    super().__init__(graph)\n",
    "    # ... or create new ones internally.\n",
    "    self.hidden_proj = CustomLinear(graph.child('hidden'), hidden_size)\n",
    "    self.output_projection = output_projection\n",
    "\n",
    "  def __call__(\n",
    "      self,\n",
    "      params: bx.Params,\n",
    "      inputs: jax.Array,\n",
    "  ) -> tuple[jax.Array, bx.Params]:\n",
    "    # Chain the functional transformations.\n",
    "    hidden, params = self.hidden_proj(params, inputs)\n",
    "    hidden = jax.nn.relu(hidden)\n",
    "    return self.output_projection(params, hidden)\n",
    "\n",
    "\n",
    "print('CustomMLP defined successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization & Inspection\n",
    "\n",
    "From README section: \"Initialization & Inspection\"\n",
    "\n",
    "**Important**: The output of `bx.display()` should match the README. If it differs, update the README!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:10.170654Z",
     "iopub.status.busy": "2025-12-17T18:05:10.170469Z",
     "iopub.status.idle": "2025-12-17T18:05:11.673585Z",
     "shell.execute_reply": "2025-12-17T18:05:11.671952Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script> (()=>{ if (customElements.get('treescope-container') === undefined) { class TreescopeContainer extends HTMLElement { constructor() { super(); this.attachShadow({mode: \"open\"}); this.defns = {}; this.state = {}; } } customElements.define(\"treescope-container\", TreescopeContainer); } if (customElements.get('treescope-run-here') === undefined) { class RunHere extends HTMLElement { constructor() { super() } connectedCallback() { const run = child => { const fn = new Function(child.textContent); child.textContent = \"\"; fn.call(this); this.remove(); }; const child = this.querySelector(\"script\"); if (child) { run(child); } else { new MutationObserver(()=>{ run(this.querySelector(\"script\")); }).observe(this, {childList: true}); } } } customElements.define(\"treescope-run-here\", RunHere); } })(); </script> <treescope-container class=\"treescope_out_4324319287b1473c858bf95f1a5b1e0d\" style=\"display:block\"></treescope-container> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_4324319287b1473c858bf95f1a5b1e0d\")) .filter((elt) => !elt.dataset.setup) )[0]; root.dataset.setup = 1; const msg = document.createElement(\"span\"); msg.style = \"color: #cccccc; font-family: monospace;\"; msg.textContent = \"(Loading...)\"; root.state.loadingMsg = msg; root.shadowRoot.appendChild(msg); root.state.chain = new Promise((resolve, reject) => { const observer = new IntersectionObserver((entries) => { for (const entry of entries) { if (entry.isIntersecting) { resolve(); observer.disconnect(); return; } } }, {rootMargin: \"1000px\"}); window.setTimeout(() => { observer.observe(root); }, 0); }); root.state.deferring = false; const _insertNode = (node) => { for (let oldScript of node.querySelectorAll(\"script\")) { let newScript = document.createElement(\"script\"); newScript.type = oldScript.type; newScript.textContent = oldScript.textContent; oldScript.parentNode.replaceChild(newScript, oldScript); } if (root.state.loadingMsg) { root.state.loadingMsg.remove(); root.state.loadingMsg = null; } root.shadowRoot.appendChild(node); }; root.defns.insertContent = ((contentNode, compressed) => { if (compressed) { root.state.deferring = true; } if (root.state.deferring) { root.state.chain = (async () => { await root.state.chain; if (compressed) { const encoded = contentNode.textContent; const blob = new Blob([ Uint8Array.from(atob(encoded), (m) => m.codePointAt(0)) ]); const reader = blob.stream().pipeThrough( new DecompressionStream(\"deflate\") ).pipeThrough( new TextDecoderStream(\"utf-8\") ).getReader(); const parts = []; while (true) { const step = await reader.read(); if (step.done) { break; } parts.push(step.value); } const tpl = document.createElement('template'); tpl.innerHTML = parts.join(\"\"); _insertNode(tpl.content); } else { _insertNode(contentNode.content); } })(); } else { _insertNode(contentNode.content); } }); </script></treescope-run-here><div style=\"display:none\"> <script type=\"application/octet-stream\" >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</script> <treescope-run-here><script type=\"application/octet-stream\"> const root = ( Array.from(document.getElementsByClassName( \"treescope_out_4324319287b1473c858bf95f1a5b1e0d\")) .filter((elt) => !elt.dataset['step0']) )[0]; root.dataset['step0'] = 1; root.defns.insertContent( this.parentNode.querySelector('script[type=\"application/octet-stream\"]'), true ); this.parentNode.remove(); </script></treescope-run-here> </div>"
      ],
      "text/plain": [
       "net: Graph # Param: 387 (1.5 KB)(\n",
       "  readout=CustomLinear # Param: 33 (132 B)(\n",
       "    __init__=CustomLinear(output_size=1), # Repeated python obj at 0x70725c28cf80\n",
       "    kernel=Param[T](\n",
       "      shape=(32, 1),\n",
       "      dtype='float32',\n",
       "      value=<jax.Array float32(32, 1) ≈-0.048 ±0.21 [≥-0.38, ≤0.35] nonzero:32>,\n",
       "    ),\n",
       "    bias=Param[T](shape=(1,), dtype='float32', value=<jax.Array([0.], dtype=float32)>),\n",
       "  ),\n",
       "  mlp=CustomMLP # Param: 352 (1.4 KB)(\n",
       "    __init__=CustomMLP(hidden_size=32, output_projection=CustomLinear(output_size=1)),\n",
       "    hidden=CustomLinear # Param: 352 (1.4 KB)(__init__=CustomLinear(output_size=32), kernel=Param[T](shape=(10, 32), dtype='float32', value=<jax.Array float32(10, 32) ≈-0.0016 ±0.22 [≥-0.37, ≤0.38] nonzero:320>), bias=Param[T](shape=(32,), dtype='float32', value=<jax.Array float32(32,) ≈0.0 ±0.0 [≥0.0, ≤0.0] zero:32>)),\n",
       "  ),\n",
       "  rng=Rng # Param: 2 (12 B)(\n",
       "    __init__=Rng(seed=42),\n",
       "    base_key=Param[N](shape=(), dtype='key<fry>', metadata={'tag': 'rng_base_key'}, value=<jax.Array key<fry>()>),\n",
       "    counter=Param[N](shape=(), dtype='uint32', metadata={'tag': 'rng_counter'}, value=<jax.Array(2, dtype=uint32)>),\n",
       "  ),\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the structure for wiring modules.\n",
    "graph = bx.Graph('net')\n",
    "\n",
    "# Create the output layer explicitly and use it to create our CustomMLP.\n",
    "readout = CustomLinear(graph.child('readout'), output_size=1)\n",
    "model = CustomMLP(graph.child('mlp'), hidden_size=32, output_projection=readout)\n",
    "\n",
    "# Create dummy input data to infer shapes.\n",
    "inputs = jnp.ones((1, 10))\n",
    "\n",
    "# Initialize the parameters.\n",
    "# Params requires an Rng module for handling randomness.\n",
    "rng = bx.Rng(graph.child('rng'), seed=42)\n",
    "params = bx.Params(rng=rng)\n",
    "\n",
    "# Run a forward pass to trigger lazy initialization.\n",
    "unused_outputs, params = model(params, inputs)\n",
    "\n",
    "# Finalize Params to prevent accidental structure changes later.\n",
    "params = params.finalized()\n",
    "\n",
    "# Visualize the full graph and parameter structure.\n",
    "bx.display(graph, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Expected output structure** (values may vary due to random initialization):\n",
    "- `readout` and `mlp` should be siblings\n",
    "- `hidden` should be nested inside `mlp`\n",
    "- `output_projection` in `mlp` should show as a reference to `readout`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Execution (vmap & shard_map)\n",
    "\n",
    "From README section: \"Parallel Execution\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:11.682033Z",
     "iopub.status.busy": "2025-12-17T18:05:11.681746Z",
     "iopub.status.idle": "2025-12-17T18:05:13.901144Z",
     "shell.execute_reply": "2025-12-17T18:05:13.900375Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batched outputs shape: (4, 8)\n",
      "Each batch element has different dropout mask (check non-zero counts):\n",
      "  Batch 0: 5 non-zero\n",
      "  Batch 1: 5 non-zero\n",
      "  Batch 2: 5 non-zero\n",
      "  Batch 3: 1 non-zero\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh graph for this example\n",
    "graph2 = bx.Graph('dropout_net')\n",
    "dropout = bx.Dropout(\n",
    "    graph2.child('dropout'),\n",
    "    rate=0.5,\n",
    "    rng=bx.Rng(graph2.child('dropout_rng'), seed=0),\n",
    ")\n",
    "rng2 = bx.Rng(graph2.child('rng'), seed=42)\n",
    "params2 = bx.Params(rng=rng2)\n",
    "\n",
    "# Initialize dropout\n",
    "dummy_input = jnp.ones((4, 8))\n",
    "_, params2 = dropout(params2, dummy_input, is_training=True)\n",
    "params2 = params2.finalized()\n",
    "\n",
    "\n",
    "def apply_model(params, inputs):\n",
    "  # Fold in the batch axis so each batch element gets a unique RNG stream.\n",
    "  params = params.fold_in_axes('batch')\n",
    "  outputs, params = dropout(params, inputs, is_training=True)\n",
    "  # Fold out before returning to restore the replicated state structure.\n",
    "  return outputs, params.fold_out_axes('batch')\n",
    "\n",
    "\n",
    "# Note that params (including the Rng) are replicated.\n",
    "inputs_batch = jnp.ones((4, 8))  # 4 batch elements\n",
    "batched_outputs, _ = jax.vmap(\n",
    "    apply_model, in_axes=(None, 0), out_axes=(0, None), axis_name='batch'\n",
    ")(params2, inputs_batch)\n",
    "\n",
    "print('Batched outputs shape:', batched_outputs.shape)\n",
    "print('Each batch element has different dropout mask (check non-zero counts):')\n",
    "for i in range(4):\n",
    "  print(f'  Batch {i}: {jnp.sum(batched_outputs[i] != 0).item()} non-zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Metadata & Sharding\n",
    "\n",
    "From README section: \"Parameter Metadata & Sharding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:13.903160Z",
     "iopub.status.busy": "2025-12-17T18:05:13.902982Z",
     "iopub.status.idle": "2025-12-17T18:05:14.473455Z",
     "shell.execute_reply": "2025-12-17T18:05:14.471638Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_57576/3953293415.py:27: DeprecationWarning: The default axis_types will change in JAX v0.9.0 to jax.sharding.AxisType.Explicit. To maintain the old behavior, pass `axis_types=(jax.sharding.AxisType.Auto,) * len(axis_names)`. To opt-into the new behavior, pass `axis_types=(jax.sharding.AxisType.Explicit,) * len(axis_names)\n",
      "  mesh = jax.make_mesh((4,), ('model',))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: (4, 1024)\n",
      "Sharding example completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import functools\n",
    "\n",
    "from jax.sharding import NamedSharding\n",
    "from jax.sharding import PartitionSpec as P\n",
    "\n",
    "graph3 = bx.Graph('net')\n",
    "linear = bx.Linear(\n",
    "    graph3.child('linear'),\n",
    "    output_size=1024,\n",
    "    kernel_metadata={'sharding': (None, 'model')},\n",
    "    bias_metadata={'sharding': ('model',)},\n",
    ")\n",
    "rng3 = bx.Rng(graph3.child('rng'), 42)\n",
    "\n",
    "\n",
    "# Define an initialization function.\n",
    "def init(x):\n",
    "  _, params = linear(bx.Params(rng=rng3), x)\n",
    "  return params.finalized()\n",
    "\n",
    "\n",
    "# Abstract evaluation to get the Params structure (no memory allocation).\n",
    "inputs3 = jnp.ones((4, 4))\n",
    "abstract_params = jax.eval_shape(init, inputs3)\n",
    "\n",
    "# Create the sharding specification from metadata.\n",
    "mesh = jax.make_mesh((4,), ('model',))\n",
    "\n",
    "params_sharding = jax.tree.map(\n",
    "    lambda p: NamedSharding(mesh, P(*p.sharding)),\n",
    "    abstract_params,\n",
    "    is_leaf=lambda x: isinstance(x, bx.Param),\n",
    ")\n",
    "\n",
    "# JIT-compile the init function with out_shardings.\n",
    "# Params are created directly on the correct devices, with no memory overhead.\n",
    "sharded_init = jax.jit(init, out_shardings=params_sharding)\n",
    "sharded_params = sharded_init(inputs3)\n",
    "\n",
    "\n",
    "@functools.partial(jax.jit, in_shardings=(params_sharding, None))\n",
    "def forward(params, x):\n",
    "  return linear(params, x)\n",
    "\n",
    "\n",
    "out, new_params = forward(sharded_params, inputs3)\n",
    "\n",
    "print('Output shape:', out.shape)\n",
    "print('Sharding example completed successfully!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrence & Scanning\n",
    "\n",
    "From README section: \"Recurrence & Scanning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:14.480038Z",
     "iopub.status.busy": "2025-12-17T18:05:14.479759Z",
     "iopub.status.idle": "2025-12-17T18:05:15.632393Z",
     "shell.execute_reply": "2025-12-17T18:05:15.631578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs shape: (2, 10, 128)\n",
      "Final hidden state shape: (2, 128)\n",
      "Final cell state shape: (2, 128)\n"
     ]
    }
   ],
   "source": [
    "# Create a fresh graph for LSTM example\n",
    "graph4 = bx.Graph('lstm_net')\n",
    "lstm = bx.LSTM(graph4.child('lstm'), hidden_size=128)\n",
    "rng4 = bx.Rng(graph4.child('rng'), seed=42)\n",
    "params4 = bx.Params(rng=rng4)\n",
    "\n",
    "# Create sequence input [Batch, Time, Features]\n",
    "inputs_sequence = jnp.ones((2, 10, 64))  # 2 batches, 10 timesteps, 64 features\n",
    "\n",
    "# Initialize the LSTM state.\n",
    "state, params4 = lstm.initial_state(\n",
    "    params4, inputs_sequence[:, 0, :]\n",
    ")  # Use single timestep for init\n",
    "\n",
    "# Run efficient compiled scan over a sequence [Batch, Time, Features].\n",
    "# It automatically handles carry propagation.\n",
    "(outputs, final_state), params4 = lstm.apply(\n",
    "    params4, inputs_sequence, prev_state=state\n",
    ")\n",
    "\n",
    "print('LSTM outputs shape:', outputs.shape)\n",
    "print('Final hidden state shape:', final_state.hidden.shape)\n",
    "print('Final cell state shape:', final_state.cell.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training (JIT & Gradients)\n",
    "\n",
    "From README section: \"Training (JIT & Gradients)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-17T18:05:15.634968Z",
     "iopub.status.busy": "2025-12-17T18:05:15.634719Z",
     "iopub.status.idle": "2025-12-17T18:05:16.246612Z",
     "shell.execute_reply": "2025-12-17T18:05:16.245698Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss after 5 steps: 0.002367\n",
      "Training example completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Use the model from the Quick Start section\n",
    "# Re-create to have fresh params\n",
    "graph5 = bx.Graph('train_net')\n",
    "readout5 = CustomLinear(graph5.child('readout'), output_size=1)\n",
    "model5 = CustomMLP(\n",
    "    graph5.child('mlp'), hidden_size=32, output_projection=readout5\n",
    ")\n",
    "rng5 = bx.Rng(graph5.child('rng'), seed=42)\n",
    "params5 = bx.Params(rng=rng5)\n",
    "\n",
    "# Initialize\n",
    "train_inputs = jnp.ones((8, 10))  # 8 samples, 10 features\n",
    "_, params5 = model5(params5, train_inputs)\n",
    "params5 = params5.finalized()\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def train_step(params, inputs, targets):\n",
    "  # Split params into two sets.\n",
    "  # Trainable: weights, biases (we want gradients for these).\n",
    "  # Non-trainable: Rng, batch stats, EMA (we just want the updated values).\n",
    "  trainable, non_trainable = params.split()\n",
    "\n",
    "  def loss_fn(t, nt):\n",
    "    # Merge parameters to run the forward pass.\n",
    "    predictions, new_params = model5(t.merge(nt), inputs)\n",
    "\n",
    "    # Calculate the loss.\n",
    "    loss = jnp.mean((predictions - targets) ** 2)\n",
    "\n",
    "    # Extract the updated non-trainable state to pass it out.\n",
    "    _, new_non_trainable = new_params.split()\n",
    "    return loss, new_non_trainable\n",
    "\n",
    "  # Calculate gradients and capture the auxiliary state (non_trainable updates).\n",
    "  grads, new_non_trainable = jax.grad(loss_fn, has_aux=True)(\n",
    "      trainable, non_trainable\n",
    "  )\n",
    "\n",
    "  # Update the trainable weights using SGD.\n",
    "  new_trainable = jax.tree.map(lambda w, g: w - 0.01 * g, trainable, grads)\n",
    "\n",
    "  # Merge the updated weights with the updated non-trainable state.\n",
    "  return new_trainable.merge(new_non_trainable)\n",
    "\n",
    "\n",
    "# Run a few training steps\n",
    "targets = jnp.zeros((8, 1))  # Target outputs\n",
    "for step in range(5):\n",
    "  params5 = train_step(params5, train_inputs, targets)\n",
    "\n",
    "# Verify training worked by checking loss decreased\n",
    "predictions, _ = model5(params5, train_inputs)\n",
    "final_loss = jnp.mean((predictions - targets) ** 2)\n",
    "print(f'Final loss after 5 steps: {final_loss:.6f}')\n",
    "print('Training example completed successfully!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
