{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fb27b941602401d91542211134fc71a",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "# MNIST Classification with blox\n",
    "\n",
    "This tutorial demonstrates how to train a Convolutional Neural Network (CNN) on MNIST using **blox**.\n",
    "\n",
    "We will strictly follow a probabilistic approach:\n",
    "1.  **Model**: Defines a conditional distribution $P(Y | X)$.\n",
    "2.  **Objective**: Maximize the likelihood of the data (minimize Negative Log Likelihood).\n",
    "\n",
    "We use **Distrax** to handle the probability distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acae54e37e7d407bbb7b55eff062a284",
   "metadata": {
    "id": "install-deps"
   },
   "outputs": [],
   "source": [
    "# Install necessary packages.\n",
    "!pip install -q jax-blox optax tensorflow tensorflow-datasets matplotlib distrax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a63283cbaf04dbcab1f6479b197f3a8",
   "metadata": {
    "id": "imports"
   },
   "outputs": [],
   "source": [
    "import blox as bx\n",
    "import distrax\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import optax\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd0d8092fe74a7c96281538738b07e2",
   "metadata": {
    "id": "load-data"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_steps = 1200\n",
    "eval_every = 200\n",
    "\n",
    "\n",
    "def get_datasets(batch_size: int, train_steps: int):\n",
    "  \"\"\"Load MNIST datasets as tf.data Datasets.\"\"\"\n",
    "\n",
    "  def normalize(sample):\n",
    "    image = tf.cast(sample['image'], tf.float32) / 255.0\n",
    "    return {'image': image, 'label': sample['label']}\n",
    "\n",
    "  train_ds = tfds.load('mnist', split='train')\n",
    "  train_ds = train_ds.map(normalize)\n",
    "  train_ds = train_ds.repeat().shuffle(1024)\n",
    "  train_ds = train_ds.batch(batch_size, drop_remainder=True)\n",
    "  train_ds = train_ds.take(train_steps).prefetch(1)\n",
    "\n",
    "  test_ds = tfds.load('mnist', split='test')\n",
    "  test_ds = test_ds.map(normalize)\n",
    "  test_ds = test_ds.batch(batch_size, drop_remainder=True).prefetch(1)\n",
    "\n",
    "  return train_ds, test_ds\n",
    "\n",
    "\n",
    "train_ds, test_ds = get_datasets(batch_size, train_steps)\n",
    "sample_batch = next(iter(train_ds.as_numpy_iterator()))\n",
    "print(f'Batch shape: {sample_batch[\"image\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eea5119410473aa328ad9291626812",
   "metadata": {
    "id": "define-model"
   },
   "outputs": [],
   "source": [
    "class CNN(bx.Module):\n",
    "  \"\"\"A probabilistic CNN classifier.\"\"\"\n",
    "\n",
    "  def __init__(self, graph: bx.Graph, num_classes: int = 10):\n",
    "    super().__init__(graph)\n",
    "    self.conv1 = bx.Conv(\n",
    "        graph.child('conv1'), output_channels=32, kernel_size=3\n",
    "    )\n",
    "    self.conv2 = bx.Conv(\n",
    "        graph.child('conv2'), output_channels=64, kernel_size=3\n",
    "    )\n",
    "    self.linear1 = bx.Linear(graph.child('linear1'), output_size=256)\n",
    "    self.linear2 = bx.Linear(graph.child('linear2'), output_size=num_classes)\n",
    "    self.dropout = bx.Dropout(graph.child('dropout'), rate=0.5)\n",
    "\n",
    "  def __call__(self, params: bx.Params, x: jax.Array, is_training: bool = True):\n",
    "    # Convolutional feature extraction.\n",
    "    x, params = self.conv1(params, x)\n",
    "    x = jax.nn.relu(x)\n",
    "    x = bx.avg_pool(x, window_shape=2, strides=2)\n",
    "\n",
    "    x, params = self.conv2(params, x)\n",
    "    x = jax.nn.relu(x)\n",
    "    x = bx.avg_pool(x, window_shape=2, strides=2)\n",
    "\n",
    "    # Flatten and dense layers.\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "    x, params = self.linear1(params, x)\n",
    "    x = jax.nn.relu(x)\n",
    "    x, params = self.dropout(params, x, is_training=is_training)\n",
    "\n",
    "    # Output logits for the Categorical distribution.\n",
    "    logits, params = self.linear2(params, x)\n",
    "    return logits, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edb47106e1a46a883d545849b8ab81b",
   "metadata": {
    "id": "init-model"
   },
   "outputs": [],
   "source": [
    "# Create model components.\n",
    "graph = bx.Graph('mnist_cnn')\n",
    "model = CNN(graph)\n",
    "rng = bx.Rng(graph.child('rng'), seed=0)\n",
    "\n",
    "# Initialize params with a sample batch item.\n",
    "params = bx.Params(rng=rng)\n",
    "_, params = model(params, sample_batch['image'][:1], is_training=False)\n",
    "params = params.finalized()\n",
    "\n",
    "# Create a separate eval key for evaluation.\n",
    "eval_key = jax.random.key(1)\n",
    "\n",
    "bx.display(model.graph, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10185d26023b46108eb7d9f57d49d2b3",
   "metadata": {
    "id": "train-step"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def train_step(params, opt_state, batch_images, batch_labels, optimizer):\n",
    "  trainable, non_trainable = params.split()\n",
    "\n",
    "  def loss_fn(trainable):\n",
    "    params = trainable.merge(non_trainable)\n",
    "    logits, new_params = model(params, batch_images, is_training=True)\n",
    "\n",
    "    # Probabilistic Loss: Negative Log Likelihood.\n",
    "    # We model the output as a Categorical distribution.\n",
    "    dist = distrax.Categorical(logits=logits)\n",
    "    loss = -dist.log_prob(batch_labels).mean()\n",
    "\n",
    "    _, new_non_trainable = new_params.split()\n",
    "    return loss, new_non_trainable\n",
    "\n",
    "  (loss, new_non_trainable), grads = jax.grad(loss_fn, has_aux=True)(trainable)\n",
    "  updates, new_opt_state = optimizer.update(grads, opt_state, trainable)\n",
    "  new_trainable = optax.apply_updates(trainable, updates)\n",
    "\n",
    "  return new_trainable.merge(new_non_trainable), new_opt_state, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763a12b2bbd4a93a75aff182afb95dc",
   "metadata": {
    "id": "eval-step"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def eval_step(params, batch_images, batch_labels):\n",
    "  logits, params = model(params, batch_images, is_training=False)\n",
    "  # The mode of the distribution is the prediction.\n",
    "  dist = distrax.Categorical(logits=logits)\n",
    "  predicted_class = dist.mode()\n",
    "  accuracy = jnp.mean(predicted_class == batch_labels)\n",
    "  return accuracy, params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7623eae2785240b9bd12b16a66d81610",
   "metadata": {
    "id": "training-loop"
   },
   "outputs": [],
   "source": [
    "def train_model(params):\n",
    "  optimizer = optax.adamw(1e-3)\n",
    "  trainable_params, _ = params.split()\n",
    "  opt_state = optimizer.init(trainable_params)\n",
    "\n",
    "  # Track eval counter separately to avoid reusing RNG keys during evaluation.\n",
    "  eval_counter = 0\n",
    "\n",
    "  history = {'loss': [], 'val_acc': []}\n",
    "\n",
    "  for step, batch in enumerate(train_ds.as_numpy_iterator()):\n",
    "    params, opt_state, loss = train_step(\n",
    "        params, opt_state, batch['image'], batch['label'], optimizer\n",
    "    )\n",
    "    history['loss'].append(float(loss))\n",
    "\n",
    "    # Evaluate periodically.\n",
    "    if (step + 1) % eval_every == 0:\n",
    "      # Use separate eval key to avoid interfering with training RNG.\n",
    "      eval_params = rng.set_base_key(params, eval_key)\n",
    "      eval_params = rng.set_counter(eval_params, eval_counter)\n",
    "\n",
    "      test_accs = []\n",
    "      for test_batch in test_ds.as_numpy_iterator():\n",
    "        acc, eval_params = eval_step(\n",
    "            eval_params, test_batch['image'], test_batch['label']\n",
    "        )\n",
    "        test_accs.append(acc)\n",
    "\n",
    "      # Save eval counter for next evaluation.\n",
    "      eval_counter, _ = rng.get_counter(eval_params)\n",
    "\n",
    "      test_acc = np.mean(test_accs)\n",
    "      history['val_acc'].append(test_acc)\n",
    "\n",
    "      print(f'Step {step + 1}, Loss: {loss:.4f}, Test Acc: {test_acc:.4f}')\n",
    "\n",
    "  return params, history\n",
    "\n",
    "\n",
    "trained_params, history = train_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cdc8c89c7104fffa095e18ddfef8986",
   "metadata": {
    "id": "viz"
   },
   "outputs": [],
   "source": [
    "# Visualize Training Progress.\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['loss'], label='Training Loss')\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Negative Log Likelihood')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(\n",
    "    [eval_every * (i + 1) for i in range(len(history['val_acc']))],\n",
    "    history['val_acc'],\n",
    "    label='Test Accuracy',\n",
    "    color='orange',\n",
    ")\n",
    "plt.xlabel('Step')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Visualize Predictions.\n",
    "def show_predictions(params, count=5):\n",
    "  test_batch = next(iter(test_ds.as_numpy_iterator()))\n",
    "  images = test_batch['image'][:count]\n",
    "  labels = test_batch['label'][:count]\n",
    "  logits, _ = model(params, images, is_training=False)\n",
    "\n",
    "  # Probabilistic prediction.\n",
    "  dist = distrax.Categorical(logits=logits)\n",
    "  preds = dist.mode()\n",
    "\n",
    "  fig, axes = plt.subplots(1, count, figsize=(15, 3))\n",
    "  for i, ax in enumerate(axes):\n",
    "    ax.imshow(images[i].squeeze(), cmap='gray')\n",
    "    ax.set_title(f'True: {labels[i]}, Pred: {preds[i]}')\n",
    "    ax.axis('off')\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "show_predictions(trained_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
