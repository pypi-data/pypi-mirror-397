"""Parse markdown files with YAML frontmatter.

This module provides utilities for parsing markdown files that include YAML
frontmatter, including those generated by deep-research-client or conforming
to similar formats, extracting frontmatter metadata and converting them to a
format suitable for browser generation.
"""

import re
from datetime import datetime
from pathlib import Path
from typing import Any, Optional

import yaml

from .cache import extract_title_from_markdown, preprocess_markdown


def parse_frontmatter(content: str) -> tuple[dict[str, Any], str]:
    """Parse YAML frontmatter from markdown content.

    Args:
        content: Raw markdown content with potential frontmatter

    Returns:
        Tuple of (frontmatter_dict, body_content)

    >>> fm, body = parse_frontmatter("---\\nprovider: test\\n---\\n# Hello")
    >>> fm['provider']
    'test'
    >>> body.strip()
    '# Hello'
    >>> fm, body = parse_frontmatter("No frontmatter here")
    >>> fm
    {}
    >>> body
    'No frontmatter here'
    """
    if not content.startswith('---'):
        return {}, content

    lines = content.split('\n')
    end_index = None

    for i, line in enumerate(lines[1:], start=1):
        if line.strip() == '---':
            end_index = i
            break

    if end_index is None:
        return {}, content

    frontmatter_lines = lines[1:end_index]
    frontmatter_text = '\n'.join(frontmatter_lines)

    try:
        frontmatter = yaml.safe_load(frontmatter_text) or {}
    except yaml.YAMLError:
        return {}, content

    body = '\n'.join(lines[end_index + 1:])
    return frontmatter, body


def extract_sections(body: str) -> dict[str, str]:
    """Extract standard sections from markdown body.

    Looks for ## Question, ## Output, ## Citations sections.

    Args:
        body: Markdown body without frontmatter

    Returns:
        Dict with 'question', 'output', 'citations' keys

    >>> sections = extract_sections("## Question\\n\\nWhat is X?\\n\\n## Output\\n\\nX is...\\n\\n## Citations\\n\\n1. Source")
    >>> sections['question']
    'What is X?'
    >>> 'X is' in sections['output']
    True
    """
    sections = {
        'question': '',
        'output': '',
        'citations': ''
    }

    # Pattern to match ## Section headers (allow any header text)
    section_pattern = re.compile(r'^##\s+([^\n]+?)\s*$', re.MULTILINE)

    matches = list(section_pattern.finditer(body))

    for i, match in enumerate(matches):
        section_name = match.group(1).lower()
        start = match.end()

        # End is either start of next section or end of body
        if i + 1 < len(matches):
            end = matches[i + 1].start()
        else:
            end = len(body)

        content = body[start:end].strip()

        if section_name in sections:
            sections[section_name] = content

    return sections


def extract_citations_list(citations_text: str) -> list[str]:
    """Extract individual citations from citations section text.

    Args:
        citations_text: Text from ## Citations section

    Returns:
        List of citation strings

    >>> extract_citations_list("1. First citation\\n2. Second citation")
    ['First citation', 'Second citation']
    >>> extract_citations_list("")
    []
    """
    if not citations_text.strip():
        return []

    citations = []
    # Match numbered list items: "1. citation text"
    pattern = re.compile(r'^\d+\.\s+(.+)$', re.MULTILINE)

    for match in pattern.finditer(citations_text):
        citations.append(match.group(1).strip())

    return citations


def parse_markdown_file(file_path: Path) -> dict[str, Any]:
    """Parse a single markdown file into browser-compatible format.

    Args:
        file_path: Path to markdown file

    Returns:
        Dict compatible with browser generation (same format as export_for_browser)

    >>> from pathlib import Path
    >>> import tempfile
    >>> with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
    ...     _ = f.write("---\\nprovider: test\\nmodel: gpt-4\\n---\\n\\n## Question\\n\\nTest?\\n\\n## Output\\n\\n# Answer\\n\\nHello")
    ...     path = Path(f.name)
    >>> result = parse_markdown_file(path)
    >>> result['provider']
    'test'
    >>> result['model']
    'gpt-4'
    >>> 'Answer' in result['title']
    True
    >>> path.unlink()
    """
    content = file_path.read_text(encoding='utf-8')
    frontmatter, body = parse_frontmatter(content)
    sections = extract_sections(body)

    # Get file modification time for date
    modified_ts = file_path.stat().st_mtime
    modified_dt = datetime.fromtimestamp(modified_ts)
    date_str = modified_dt.strftime("%Y-%m-%d")

    # Extract query from Question section
    query = sections.get('question', '')
    query_preview = ' '.join(query.split())[:200]
    if len(query) > 200:
        query_preview += "..."

    # Get markdown content from Output section (or full body if no sections)
    markdown = sections.get('output', '') or body

    # Preprocess and extract title
    preprocessed_md = preprocess_markdown(markdown, query)
    title = frontmatter.get('title') or extract_title_from_markdown(preprocessed_md)

    # Calculate word count
    word_count = len(preprocessed_md.split()) if preprocessed_md else 0

    # Extract citations
    citations_text = sections.get('citations', '')
    citations = extract_citations_list(citations_text)

    # Build browser-friendly record
    record: dict[str, Any] = {
        "id": file_path.stem,
        "filename": file_path.name,
        "source_path": str(file_path.absolute()),
        "provider": frontmatter.get("provider", "unknown"),
        "model": frontmatter.get("model") or "default",
        "title": title,
        "keywords": frontmatter.get("keywords") or [],
        "query_preview": query_preview,
        "date": date_str,
        "size_kb": round(file_path.stat().st_size / 1024, 1),
        "duration_seconds": frontmatter.get("duration_seconds"),
        "citation_count": len(citations) or frontmatter.get("citation_count", 0),
        "word_count": word_count,
        "has_title": bool(title),
        "has_keywords": bool(frontmatter.get("keywords")),
        "template_file": frontmatter.get("template_file") or "",
        # Full content for page generation
        "markdown": preprocessed_md,
        "citations": citations,
        "template_variables": frontmatter.get("template_variables") or {},
        "provider_config": frontmatter.get("provider_config") or {},
    }

    # Add author/contributors if present
    record["author"] = frontmatter.get("author") or ""
    record["contributors"] = frontmatter.get("contributors") or []

    return record


def parse_markdown_files(
    files: Optional[list[Path]] = None,
    directory: Optional[Path] = None,
    pattern: str = "**/*.md",
    include_content: bool = True,
) -> list[dict[str, Any]]:
    """Parse multiple markdown files into browser-compatible format.

    Args:
        files: Explicit list of file paths to parse
        directory: Directory to search for files (used with pattern)
        pattern: Glob pattern for finding files (default: **/*.md)
        include_content: If True, include full markdown and citations

    Returns:
        List of dicts compatible with browser generation

    Raises:
        ValueError: If neither files nor directory is provided

    >>> from pathlib import Path
    >>> import tempfile
    >>> with tempfile.NamedTemporaryFile(mode='w', suffix='.md', delete=False) as f:
    ...     _ = f.write("---\\nprovider: p1\\n---\\n\\n# Doc 1")
    ...     path1 = Path(f.name)
    >>> results = parse_markdown_files(files=[path1])
    >>> len(results)
    1
    >>> results[0]['provider']
    'p1'
    >>> path1.unlink()
    """
    if files is None and directory is None:
        raise ValueError("Either 'files' or 'directory' must be provided")

    paths: list[Path] = []

    if files:
        paths = [Path(f) if not isinstance(f, Path) else f for f in files]
    elif directory:
        dir_path = Path(directory) if not isinstance(directory, Path) else directory
        paths = list(dir_path.glob(pattern))

    results: list[dict[str, Any]] = []

    for path in paths:
        if not path.exists():
            continue
        if not path.is_file():
            continue
        if path.suffix.lower() != '.md':
            continue

        record = parse_markdown_file(path)

        if not include_content:
            record.pop("markdown", None)
            record.pop("citations", None)

        results.append(record)

    # Sort by date, newest first
    results.sort(key=lambda x: str(x.get("date", "")), reverse=True)

    return results
