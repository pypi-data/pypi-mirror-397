# This file was auto-generated by Fern from our API Definition.

import typing

from ..core.client_wrapper import AsyncClientWrapper, SyncClientWrapper
from ..core.request_options import RequestOptions
from ..types.replacement_rule import ReplacementRule
from ..types.speech_to_text_model import SpeechToTextModel
from ..types.transcript_language_code import TranscriptLanguageCode
from ..types.transcript_output_format import TranscriptOutputFormat
from ..types.transcription_model_identifier import TranscriptionModelIdentifier
from ..types.transcription_response import TranscriptionResponse
from .raw_client import AsyncRawSpeechToTextClient, RawSpeechToTextClient

# this is used as the default value for optional parameters
OMIT = typing.cast(typing.Any, ...)


class SpeechToTextClient:
    def __init__(self, *, client_wrapper: SyncClientWrapper):
        self._raw_client = RawSpeechToTextClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> RawSpeechToTextClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        RawSpeechToTextClient
        """
        return self._raw_client

    def transcribe(
        self,
        *,
        model: TranscriptionModelIdentifier,
        request: typing.Union[bytes, typing.Iterator[bytes], typing.AsyncIterator[bytes]],
        language: typing.Optional[TranscriptLanguageCode] = None,
        output_format: typing.Optional[TranscriptOutputFormat] = None,
        ruleset_id: typing.Optional[str] = None,
        punctuation: typing.Optional[bool] = None,
        diarization: typing.Optional[bool] = None,
        initial_prompt: typing.Optional[str] = None,
        temperature: typing.Optional[float] = None,
        speakers_expected: typing.Optional[int] = None,
        custom_vocabulary: typing.Optional[typing.Union[str, typing.Sequence[str]]] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranscriptionResponse:
        """
        This endpoint allows you to send raw audio data in the request body for transcription.
        You can specify the desired model, language, output format, and various provider-specific features using query parameters.
        Suitable for transcribing local audio files.

        Parameters
        ----------
        model : TranscriptionModelIdentifier
            The identifier of the speech-to-text model to use for the transcription, in the format `provider.model`. See the `/speech-to-text-models` endpoint for available models.

        request : typing.Union[bytes, typing.Iterator[bytes], typing.AsyncIterator[bytes]]

        language : typing.Optional[TranscriptLanguageCode]
            The language of the audio file in ISO 639-1 format (e.g., `en`, `es`, `fr`). Specify `auto` for automatic language detection (if supported by the model). Defaults to `en` if not provided. Providing the correct language improves accuracy and latency.

        output_format : typing.Optional[TranscriptOutputFormat]
            The desired format for the transcription output. Can be plain text, JSON objects (simple or detailed), or subtitle formats (SRT, VTT). Defaults to `text`.

        ruleset_id : typing.Optional[str]
            The unique identifier (UUID) of a pre-defined replacement ruleset to apply to the final transcription text. Create rulesets using the `/replacement-rulesets` endpoint.

        punctuation : typing.Optional[bool]
            Enable automatic punctuation (commas, periods, question marks) in the transcription. Support varies by model/provider (e.g., Deepgram, AssemblyAI). Defaults to `true`.

        diarization : typing.Optional[bool]
            Enable speaker diarization to identify and label different speakers in the audio. Support and quality vary by model/provider. Defaults to `false`. When enabled, the `speaker` field may be populated in the response segments.

        initial_prompt : typing.Optional[str]
            An optional text prompt to provide context, guide the model's style (e.g., spelling of specific names), or improve accuracy for subsequent audio segments. Support varies by model (e.g., OpenAI models).

        temperature : typing.Optional[float]
            Controls the randomness of the output for certain models (e.g., OpenAI). A value between 0 and 1. Lower values (e.g., 0.2) make the output more deterministic, while higher values (e.g., 0.8) make it more random. Defaults vary by model.

        speakers_expected : typing.Optional[int]
            Provides a hint to the diarization process about the number of expected speakers. May improve accuracy for some providers (e.g., RevAI, Deepgram).

        custom_vocabulary : typing.Optional[typing.Union[str, typing.Sequence[str]]]
            Provide a list of specific words or phrases (e.g., proper nouns, jargon) to increase their recognition likelihood. Support varies by provider (e.g., Deepgram, AssemblyAI).

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranscriptionResponse
            Successful transcription response. The content type and structure depend on the `output_format` parameter specified in the request.
            - `application/json`: Returned for `output_format=json` or `json_text`. See `TranscriptionResponse` schema (`TranscriptionDetailed` or `TranscriptionOnlyText`).
            - `text/plain`: Returned for `output_format=text`.
        """
        _response = self._raw_client.transcribe(
            model=model,
            request=request,
            language=language,
            output_format=output_format,
            ruleset_id=ruleset_id,
            punctuation=punctuation,
            diarization=diarization,
            initial_prompt=initial_prompt,
            temperature=temperature,
            speakers_expected=speakers_expected,
            custom_vocabulary=custom_vocabulary,
            request_options=request_options,
        )
        return _response.data

    def transcribe_remote(
        self,
        *,
        file_url: str,
        model: TranscriptionModelIdentifier,
        replacement_ruleset: typing.Optional[typing.Sequence[ReplacementRule]] = OMIT,
        language: typing.Optional[TranscriptLanguageCode] = OMIT,
        output_format: typing.Optional[TranscriptOutputFormat] = OMIT,
        ruleset_id: typing.Optional[str] = OMIT,
        punctuation: typing.Optional[bool] = OMIT,
        diarization: typing.Optional[bool] = OMIT,
        initial_prompt: typing.Optional[str] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        speakers_expected: typing.Optional[int] = OMIT,
        custom_vocabulary: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranscriptionResponse:
        """
        This endpoint allows you to transcribe an audio file hosted at a publicly accessible URL.
        Provide the URL and transcription options within the JSON request body.
        Useful for transcribing files already stored online.

        Parameters
        ----------
        file_url : str
            The publicly accessible URL of the audio file to transcribe. The API server must be able to fetch the audio from this URL.

        model : TranscriptionModelIdentifier
            The identifier of the speech-to-text model to use.

        replacement_ruleset : typing.Optional[typing.Sequence[ReplacementRule]]
            An array of replacement rules to be applied directly to this transcription request, in order. This allows defining rules inline instead of (or in addition to) using a pre-saved `ruleset_id`.

        language : typing.Optional[TranscriptLanguageCode]
            The language code (ISO 639-1) of the audio. Defaults to `en`. Use `auto` for automatic detection if supported.

        output_format : typing.Optional[TranscriptOutputFormat]
            The desired format for the transcription output. Defaults to `text`.

        ruleset_id : typing.Optional[str]
            The unique identifier (UUID) of a pre-defined replacement ruleset to apply to the final transcription text.

        punctuation : typing.Optional[bool]
            Whether to add punctuation. Support varies by model (e.g., Deepgram, AssemblyAI). Defaults to `true`.

        diarization : typing.Optional[bool]
            Enable speaker diarization. Defaults to `false`.

        initial_prompt : typing.Optional[str]
            Optional text prompt to guide the transcription model. Support varies (e.g., OpenAI).

        temperature : typing.Optional[float]
            Controls output randomness for supported models (e.g., OpenAI). Value between 0 and 1.

        speakers_expected : typing.Optional[int]
            Hint for the number of expected speakers for diarization (e.g., RevAI, Deepgram).

        custom_vocabulary : typing.Optional[typing.Sequence[str]]
            List of custom words/phrases to improve recognition (e.g., Deepgram, AssemblyAI).

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranscriptionResponse
            Successful transcription response. The content type and structure depend on the `output_format` parameter specified in the request.
            - `application/json`: Returned for `output_format=json` or `json_text`. See `TranscriptionResponse` schema (`TranscriptionDetailed` or `TranscriptionOnlyText`).
            - `text/plain`: Returned for `output_format=text`.

        Examples
        --------
        from speechall import SpeechallApi

        client = SpeechallApi(
            token="YOUR_TOKEN",
        )
        client.speech_to_text.transcribe_remote(
            model="openai.whisper-1",
            language="en",
            output_format="json",
            diarization=True,
            file_url="https://example.com/path/to/audio.mp3",
        )
        """
        _response = self._raw_client.transcribe_remote(
            file_url=file_url,
            model=model,
            replacement_ruleset=replacement_ruleset,
            language=language,
            output_format=output_format,
            ruleset_id=ruleset_id,
            punctuation=punctuation,
            diarization=diarization,
            initial_prompt=initial_prompt,
            temperature=temperature,
            speakers_expected=speakers_expected,
            custom_vocabulary=custom_vocabulary,
            request_options=request_options,
        )
        return _response.data

    def list_speech_to_text_models(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[SpeechToTextModel]:
        """
        Returns a detailed list of all STT models accessible through the Speechall API.
        Each model entry includes its identifier (`provider.model`), display name, description,
        supported features (languages, formats, punctuation, diarization), and performance characteristics.
        Use this endpoint to discover available models and their capabilities before making transcription requests.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[SpeechToTextModel]
            A list of available speech-to-text models and their properties.

        Examples
        --------
        from speechall import SpeechallApi

        client = SpeechallApi(
            token="YOUR_TOKEN",
        )
        client.speech_to_text.list_speech_to_text_models()
        """
        _response = self._raw_client.list_speech_to_text_models(request_options=request_options)
        return _response.data


class AsyncSpeechToTextClient:
    def __init__(self, *, client_wrapper: AsyncClientWrapper):
        self._raw_client = AsyncRawSpeechToTextClient(client_wrapper=client_wrapper)

    @property
    def with_raw_response(self) -> AsyncRawSpeechToTextClient:
        """
        Retrieves a raw implementation of this client that returns raw responses.

        Returns
        -------
        AsyncRawSpeechToTextClient
        """
        return self._raw_client

    async def transcribe(
        self,
        *,
        model: TranscriptionModelIdentifier,
        request: typing.Union[bytes, typing.Iterator[bytes], typing.AsyncIterator[bytes]],
        language: typing.Optional[TranscriptLanguageCode] = None,
        output_format: typing.Optional[TranscriptOutputFormat] = None,
        ruleset_id: typing.Optional[str] = None,
        punctuation: typing.Optional[bool] = None,
        diarization: typing.Optional[bool] = None,
        initial_prompt: typing.Optional[str] = None,
        temperature: typing.Optional[float] = None,
        speakers_expected: typing.Optional[int] = None,
        custom_vocabulary: typing.Optional[typing.Union[str, typing.Sequence[str]]] = None,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranscriptionResponse:
        """
        This endpoint allows you to send raw audio data in the request body for transcription.
        You can specify the desired model, language, output format, and various provider-specific features using query parameters.
        Suitable for transcribing local audio files.

        Parameters
        ----------
        model : TranscriptionModelIdentifier
            The identifier of the speech-to-text model to use for the transcription, in the format `provider.model`. See the `/speech-to-text-models` endpoint for available models.

        request : typing.Union[bytes, typing.Iterator[bytes], typing.AsyncIterator[bytes]]

        language : typing.Optional[TranscriptLanguageCode]
            The language of the audio file in ISO 639-1 format (e.g., `en`, `es`, `fr`). Specify `auto` for automatic language detection (if supported by the model). Defaults to `en` if not provided. Providing the correct language improves accuracy and latency.

        output_format : typing.Optional[TranscriptOutputFormat]
            The desired format for the transcription output. Can be plain text, JSON objects (simple or detailed), or subtitle formats (SRT, VTT). Defaults to `text`.

        ruleset_id : typing.Optional[str]
            The unique identifier (UUID) of a pre-defined replacement ruleset to apply to the final transcription text. Create rulesets using the `/replacement-rulesets` endpoint.

        punctuation : typing.Optional[bool]
            Enable automatic punctuation (commas, periods, question marks) in the transcription. Support varies by model/provider (e.g., Deepgram, AssemblyAI). Defaults to `true`.

        diarization : typing.Optional[bool]
            Enable speaker diarization to identify and label different speakers in the audio. Support and quality vary by model/provider. Defaults to `false`. When enabled, the `speaker` field may be populated in the response segments.

        initial_prompt : typing.Optional[str]
            An optional text prompt to provide context, guide the model's style (e.g., spelling of specific names), or improve accuracy for subsequent audio segments. Support varies by model (e.g., OpenAI models).

        temperature : typing.Optional[float]
            Controls the randomness of the output for certain models (e.g., OpenAI). A value between 0 and 1. Lower values (e.g., 0.2) make the output more deterministic, while higher values (e.g., 0.8) make it more random. Defaults vary by model.

        speakers_expected : typing.Optional[int]
            Provides a hint to the diarization process about the number of expected speakers. May improve accuracy for some providers (e.g., RevAI, Deepgram).

        custom_vocabulary : typing.Optional[typing.Union[str, typing.Sequence[str]]]
            Provide a list of specific words or phrases (e.g., proper nouns, jargon) to increase their recognition likelihood. Support varies by provider (e.g., Deepgram, AssemblyAI).

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranscriptionResponse
            Successful transcription response. The content type and structure depend on the `output_format` parameter specified in the request.
            - `application/json`: Returned for `output_format=json` or `json_text`. See `TranscriptionResponse` schema (`TranscriptionDetailed` or `TranscriptionOnlyText`).
            - `text/plain`: Returned for `output_format=text`.
        """
        _response = await self._raw_client.transcribe(
            model=model,
            request=request,
            language=language,
            output_format=output_format,
            ruleset_id=ruleset_id,
            punctuation=punctuation,
            diarization=diarization,
            initial_prompt=initial_prompt,
            temperature=temperature,
            speakers_expected=speakers_expected,
            custom_vocabulary=custom_vocabulary,
            request_options=request_options,
        )
        return _response.data

    async def transcribe_remote(
        self,
        *,
        file_url: str,
        model: TranscriptionModelIdentifier,
        replacement_ruleset: typing.Optional[typing.Sequence[ReplacementRule]] = OMIT,
        language: typing.Optional[TranscriptLanguageCode] = OMIT,
        output_format: typing.Optional[TranscriptOutputFormat] = OMIT,
        ruleset_id: typing.Optional[str] = OMIT,
        punctuation: typing.Optional[bool] = OMIT,
        diarization: typing.Optional[bool] = OMIT,
        initial_prompt: typing.Optional[str] = OMIT,
        temperature: typing.Optional[float] = OMIT,
        speakers_expected: typing.Optional[int] = OMIT,
        custom_vocabulary: typing.Optional[typing.Sequence[str]] = OMIT,
        request_options: typing.Optional[RequestOptions] = None,
    ) -> TranscriptionResponse:
        """
        This endpoint allows you to transcribe an audio file hosted at a publicly accessible URL.
        Provide the URL and transcription options within the JSON request body.
        Useful for transcribing files already stored online.

        Parameters
        ----------
        file_url : str
            The publicly accessible URL of the audio file to transcribe. The API server must be able to fetch the audio from this URL.

        model : TranscriptionModelIdentifier
            The identifier of the speech-to-text model to use.

        replacement_ruleset : typing.Optional[typing.Sequence[ReplacementRule]]
            An array of replacement rules to be applied directly to this transcription request, in order. This allows defining rules inline instead of (or in addition to) using a pre-saved `ruleset_id`.

        language : typing.Optional[TranscriptLanguageCode]
            The language code (ISO 639-1) of the audio. Defaults to `en`. Use `auto` for automatic detection if supported.

        output_format : typing.Optional[TranscriptOutputFormat]
            The desired format for the transcription output. Defaults to `text`.

        ruleset_id : typing.Optional[str]
            The unique identifier (UUID) of a pre-defined replacement ruleset to apply to the final transcription text.

        punctuation : typing.Optional[bool]
            Whether to add punctuation. Support varies by model (e.g., Deepgram, AssemblyAI). Defaults to `true`.

        diarization : typing.Optional[bool]
            Enable speaker diarization. Defaults to `false`.

        initial_prompt : typing.Optional[str]
            Optional text prompt to guide the transcription model. Support varies (e.g., OpenAI).

        temperature : typing.Optional[float]
            Controls output randomness for supported models (e.g., OpenAI). Value between 0 and 1.

        speakers_expected : typing.Optional[int]
            Hint for the number of expected speakers for diarization (e.g., RevAI, Deepgram).

        custom_vocabulary : typing.Optional[typing.Sequence[str]]
            List of custom words/phrases to improve recognition (e.g., Deepgram, AssemblyAI).

        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        TranscriptionResponse
            Successful transcription response. The content type and structure depend on the `output_format` parameter specified in the request.
            - `application/json`: Returned for `output_format=json` or `json_text`. See `TranscriptionResponse` schema (`TranscriptionDetailed` or `TranscriptionOnlyText`).
            - `text/plain`: Returned for `output_format=text`.

        Examples
        --------
        import asyncio

        from speechall import AsyncSpeechallApi

        client = AsyncSpeechallApi(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.speech_to_text.transcribe_remote(
                model="openai.whisper-1",
                language="en",
                output_format="json",
                diarization=True,
                file_url="https://example.com/path/to/audio.mp3",
            )


        asyncio.run(main())
        """
        _response = await self._raw_client.transcribe_remote(
            file_url=file_url,
            model=model,
            replacement_ruleset=replacement_ruleset,
            language=language,
            output_format=output_format,
            ruleset_id=ruleset_id,
            punctuation=punctuation,
            diarization=diarization,
            initial_prompt=initial_prompt,
            temperature=temperature,
            speakers_expected=speakers_expected,
            custom_vocabulary=custom_vocabulary,
            request_options=request_options,
        )
        return _response.data

    async def list_speech_to_text_models(
        self, *, request_options: typing.Optional[RequestOptions] = None
    ) -> typing.List[SpeechToTextModel]:
        """
        Returns a detailed list of all STT models accessible through the Speechall API.
        Each model entry includes its identifier (`provider.model`), display name, description,
        supported features (languages, formats, punctuation, diarization), and performance characteristics.
        Use this endpoint to discover available models and their capabilities before making transcription requests.

        Parameters
        ----------
        request_options : typing.Optional[RequestOptions]
            Request-specific configuration.

        Returns
        -------
        typing.List[SpeechToTextModel]
            A list of available speech-to-text models and their properties.

        Examples
        --------
        import asyncio

        from speechall import AsyncSpeechallApi

        client = AsyncSpeechallApi(
            token="YOUR_TOKEN",
        )


        async def main() -> None:
            await client.speech_to_text.list_speech_to_text_models()


        asyncio.run(main())
        """
        _response = await self._raw_client.list_speech_to_text_models(request_options=request_options)
        return _response.data
