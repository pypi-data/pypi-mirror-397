Metadata-Version: 2.4
Name: zea
Version: 0.0.9
Summary: A Toolbox for Cognitive Ultrasound Imaging. Provides a set of tools for processing of ultrasound data, all built in your favorite machine learning framework.
License-File: LICENSE
Keywords: ultrasound,machine learning,beamforming
Author: Tristan Stevens
Author-email: t.s.w.stevens@tue.nl
Requires-Python: >=3.10,<3.13
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Intended Audience :: Science/Research
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Natural Language :: English
Classifier: Topic :: Scientific/Engineering
Provides-Extra: backends
Provides-Extra: dev
Provides-Extra: display
Provides-Extra: display-headless
Provides-Extra: docs
Provides-Extra: jax
Provides-Extra: models
Provides-Extra: tests
Requires-Dist: IPython ; extra == "dev"
Requires-Dist: IPython ; extra == "docs"
Requires-Dist: PyStemmer ; extra == "dev"
Requires-Dist: PyStemmer ; extra == "docs"
Requires-Dist: cloudpickle (>=3.1.1) ; extra == "dev"
Requires-Dist: cloudpickle (>=3.1.1) ; extra == "tests"
Requires-Dist: decorator (>=5)
Requires-Dist: furo ; extra == "dev"
Requires-Dist: furo ; extra == "docs"
Requires-Dist: h5py (>=3.11)
Requires-Dist: huggingface_hub (>=0.26)
Requires-Dist: imageio[ffmpeg] (>=2.0)
Requires-Dist: ipykernel (>=6.29.5) ; extra == "dev"
Requires-Dist: ipykernel (>=6.29.5) ; extra == "tests"
Requires-Dist: ipywidgets ; extra == "dev"
Requires-Dist: ipywidgets ; extra == "tests"
Requires-Dist: jax ; extra == "backends"
Requires-Dist: jax[cuda12-pip] (>=0.4.26) ; extra == "jax"
Requires-Dist: keras (>=3.12)
Requires-Dist: matplotlib (>=3.8)
Requires-Dist: mock ; extra == "dev"
Requires-Dist: mock ; extra == "docs"
Requires-Dist: myst-parser ; extra == "dev"
Requires-Dist: myst-parser ; extra == "docs"
Requires-Dist: nbsphinx ; extra == "dev"
Requires-Dist: nbsphinx ; extra == "docs"
Requires-Dist: numpy (>=1.24)
Requires-Dist: onnxruntime (>=1.15) ; extra == "dev"
Requires-Dist: onnxruntime (>=1.15) ; extra == "models"
Requires-Dist: opencv-python (>=4) ; extra == "display"
Requires-Dist: opencv-python-headless (>=4) ; extra == "dev"
Requires-Dist: opencv-python-headless (>=4) ; extra == "display-headless"
Requires-Dist: papermill (>=2.4) ; extra == "dev"
Requires-Dist: papermill (>=2.4) ; extra == "tests"
Requires-Dist: pillow (>=10)
Requires-Dist: pre-commit ; extra == "dev"
Requires-Dist: pre-commit ; extra == "tests"
Requires-Dist: pytest (>=8.1) ; extra == "dev"
Requires-Dist: pytest (>=8.1) ; extra == "tests"
Requires-Dist: pytest-cov ; extra == "dev"
Requires-Dist: pytest-cov ; extra == "tests"
Requires-Dist: pyyaml (>=6)
Requires-Dist: ruff ; extra == "dev"
Requires-Dist: ruff ; extra == "tests"
Requires-Dist: schema (>=0.7)
Requires-Dist: scikit-image (>=0.23)
Requires-Dist: scikit-learn (>=1.4)
Requires-Dist: scipy (>=1.13)
Requires-Dist: simpleitk (>=2.2.1) ; extra == "dev"
Requires-Dist: simpleitk (>=2.2.1) ; extra == "tests"
Requires-Dist: sphinx ; extra == "dev"
Requires-Dist: sphinx ; extra == "docs"
Requires-Dist: sphinx-argparse ; extra == "dev"
Requires-Dist: sphinx-argparse ; extra == "docs"
Requires-Dist: sphinx-autobuild ; extra == "dev"
Requires-Dist: sphinx-autobuild ; extra == "docs"
Requires-Dist: sphinx-autodoc-typehints ; extra == "dev"
Requires-Dist: sphinx-autodoc-typehints ; extra == "docs"
Requires-Dist: sphinx-copybutton ; extra == "dev"
Requires-Dist: sphinx-copybutton ; extra == "docs"
Requires-Dist: sphinx-reredirects ; extra == "dev"
Requires-Dist: sphinx-reredirects ; extra == "docs"
Requires-Dist: sphinx_design ; extra == "dev"
Requires-Dist: sphinx_design ; extra == "docs"
Requires-Dist: sphinxcontrib-bibtex ; extra == "dev"
Requires-Dist: sphinxcontrib-bibtex ; extra == "docs"
Requires-Dist: tensorflow ; extra == "backends"
Requires-Dist: torch ; extra == "backends"
Requires-Dist: tqdm (>=4)
Requires-Dist: wandb (>=0.18)
Requires-Dist: wget (>=3.2)
Project-URL: Homepage, https://github.com/tue-bmd/zea/
Project-URL: Repository, https://github.com/tue-bmd/zea/
Description-Content-Type: text/markdown

# zea <img src="https://raw.githubusercontent.com/tue-bmd/zea/main/docs/_static/zea-logo.png" width="120" height="120" align="right" alt="zea Logo" />


[![PyPI version](https://img.shields.io/pypi/v/zea)](https://pypi.org/project/zea/)
[![Continuous integration](https://github.com/tue-bmd/zea/actions/workflows/tests.yaml/badge.svg)](https://github.com/tue-bmd/zea/actions/workflows/tests.yaml)
[![Documentation Status](https://readthedocs.org/projects/zea/badge/?version=latest)](https://zea.readthedocs.io/en/latest/?badge=latest)
[![License](https://img.shields.io/github/license/tue-bmd/zea)](https://github.com/tue-bmd/zea/blob/main/LICENSE)
[![codecov](https://codecov.io/gh/tue-bmd/zea/branch/main/graph/badge.svg)](https://codecov.io/gh/tue-bmd/zea)
[![status](https://joss.theoj.org/papers/fa923917ca41761fe0623ca6c350017d/status.svg)](https://joss.theoj.org/papers/fa923917ca41761fe0623ca6c350017d)
[![arXiv](https://img.shields.io/badge/arXiv-B31B1B?style=flat&logo=arXiv&logoColor=white)](https://arxiv.org/abs/2512.01433)
[![Hugging Face](https://img.shields.io/badge/Hugging%20Face-FFD21E?logo=huggingface&logoColor=black)](https://huggingface.co/zeahub)
[![GitHub stars](https://img.shields.io/github/stars/tue-bmd/zea?style=social)](https://github.com/tue-bmd/zea/stargazers)

Welcome to the `zea` package: *A Toolbox for Cognitive Ultrasound Imaging.*

- ðŸ“š Full documentation: [zea.readthedocs.io](https://zea.readthedocs.io)
- ðŸ”¬ Try hands-on examples (with Colab): [Examples & Tutorials](https://zea.readthedocs.io/en/latest/examples.html)
- âš™ï¸ Installation guide: [Installation](https://zea.readthedocs.io/en/latest/installation.html)

`zea` is a Python library that offers ultrasound signal processing, image reconstruction, and deep learning. Currently, `zea` offers:

- A flexible ultrasound signal processing and image reconstruction pipeline written in your favorite deep learning framework.
- A complete set of data acquisition loading tools for ultrasound data and acquisition parameters, designed for deep learning workflows.
- A collection of pretrained models for ultrasound image and signal processing.
- **Multi-Backend Support via [Keras3](https://keras.io/keras_3/):** You can use [PyTorch](https://github.com/pytorch/pytorch), [TensorFlow](https://github.com/tensorflow/tensorflow), or [JAX](https://github.com/google/jax).

> [!WARNING]
> **Beta!**
> This package is highly experimental and under active development. It is mainly used to support [our research](https://www.tue.nl/en/research/research-groups/signal-processing-systems/biomedical-diagnostics-lab) and as a basis for our publications. That being said, we are happy to share it with the ultrasound community and hope it will be useful for your research as well.

> [!NOTE]
> ðŸ“– Please cite `zea` in your publications if it helps your research. You can find citation info [here](https://zea.readthedocs.io/en/latest/getting-started.html#citation).

