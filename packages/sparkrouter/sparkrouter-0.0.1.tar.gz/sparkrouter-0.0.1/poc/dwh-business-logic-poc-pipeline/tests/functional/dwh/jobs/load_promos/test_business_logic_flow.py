"""
Test to replicate the exact business logic transformation flow
"""
import pytest
from pyspark.sql.functions import col, lit, current_timestamp, row_number, when, array_join, transform
from pyspark.sql.window import Window
from dwh.data.dl_base.promotion.promotion_data_builder import PromotionDataBuilder
from dwh.data.data_serializer import DataSerializer

pytestmark = pytest.mark.functional


class TestLoadPromosBusinessLogicFlow:
    """Test the exact business logic transformation flow for load_promos job
    
    This is a functional test that validates core business logic transformations
    using actual Spark DataFrames and business rules. It tests the transformation
    logic that would be used by the actual load_promos job components.
    """

    def test_promotion_transformation_flow(self, spark_session, schema_service):
        """Test the exact transformation flow from PromotionsSQLHarnessTask
        
        This functional test validates:
        - Complex nested data structure handling
        - Column mapping and transformation logic
        - Window functions and deduplication
        - Schema evolution and field access patterns
        - Business rule implementations
        
        Uses spark_session fixture to test actual business logic components.
        """
        spark = spark_session
        
        try:
            # Use PromotionDataBuilder to create test data
            builder = (PromotionDataBuilder(schema_service)
                      .with_id("PROMO1")
                      .with_name("CODE1")
                      .with_promotion_type("PERCENTAGE_DISCOUNT")
                      .with_tags("test", "promo")
            )
            
            # Generate DataFrame for business logic testing
            df = DataSerializer.to_dataframe(builder, spark)
            
            print("=== Source DataFrame (Generated by PromotionDataBuilder) ===")
            df.printSchema()
            df.show(truncate=False)
            
            # Verify builder generated correct data for business logic testing
            assert df.count() == 1, "DataFrame should have exactly one record"
            row = df.collect()[0]
            assert row["_id"] == "PROMO1", "Builder should set correct ID"
            assert row["name"] == "CODE1", "Builder should set correct name"
            assert "test" in row["tags"], "Builder should set correct tags"
            
            # Step 1: Initial transformations (like in business logic)
            print("\\n=== Step 1: Initial transformations ===")
            result_df = (
                df
                .withColumn("promotionid", col("_id"))
                .withColumn("promotioncode", col("name"))
                .withColumn("promotiondescription", col("description"))
                .withColumn("promotiontype", col("properties_promotionType"))
                .withColumn("promotionstartdate", col("schedule_startDate"))
                .withColumn("promotionenddate", col("schedule_endDate"))
                .withColumn("eventupdtime", col("updatedate"))  # Add eventupdtime for window function
                .distinct()
            )
            
            print("After initial transformations:")
            result_df.printSchema()
            
            # Step 2: Complex transformations (like _add_complex_transformations)
            print("\\n=== Step 2: Complex transformations ===")
            columns = result_df.columns
            print(f"Available columns: {columns}")
            
            # Test accessing bundles_bundleA (this should work)
            try:
                result_df = result_df.withColumn(
                    "bundleskus",
                    when(
                        array_join(transform(col("bundles_bundleA.promotionSkus"), lambda x: x.skuOrCategoryId), ",") == "",
                        lit(None).cast("string")
                    ).otherwise(
                        array_join(transform(col("bundles_bundleA.promotionSkus"), lambda x: x.skuOrCategoryId), ",")
                    )
                )
                print("SUCCESS: bundles_bundleA access worked")
            except Exception as e:
                print(f"ERROR accessing bundles_bundleA: {e}")
            
            # Step 3: Add metadata columns
            print("\\n=== Step 3: Add metadata columns ===")
            result_df = result_df.withColumn("dwcreatedby", lit("test"))
            result_df = result_df.withColumn("dwcreatedat", current_timestamp())
            result_df = result_df.withColumn("ptn_constant", lit("One"))
            
            # Step 4: Window function with row_number
            print("\\n=== Step 4: Window function ===")
            try:
                window_spec = Window.partitionBy("promotionid").orderBy(col("eventupdtime").desc())
                result_df = result_df.withColumn("rn", row_number().over(window_spec))
                result_df = result_df.filter(col("rn") == 1).drop("rn")
                print("SUCCESS: Window function worked")
            except Exception as e:
                print(f"ERROR in window function: {e}")
            
            print("\\n=== Final DataFrame ===")
            result_df.printSchema()
            
            # Step 5: Try to access _id (this might be where the error occurs)
            print("\\n=== Step 5: Test _id access ===")
            try:
                test_df = result_df.select("_id", "promotionid")
                test_df.show()
                print("SUCCESS: Can still access _id")
            except Exception as e:
                print(f"ERROR accessing _id: {type(e).__name__}: {e}")
            
            # Step 6: Select only final columns (like what would be written to JDBC)
            print("\\n=== Step 6: Final column selection ===")
            final_columns = ["promotionid", "promotioncode", "promotiondescription", "promotiontype", 
                           "promotionstartdate", "promotionenddate", "bundleskus", "dwcreatedby", "dwcreatedat", "ptn_constant"]
            
            try:
                final_df = result_df.select(*final_columns)
                print("Final DataFrame schema:")
                final_df.printSchema()
                final_df.show()
                print("SUCCESS: Final selection worked")
                
                # Add business logic validations
                assert final_df.count() == 1, "Should have exactly one promotion record"
                
                row = final_df.collect()[0]
                assert row["promotionid"] == "PROMO1", "Promotion ID should be mapped correctly"
                assert row["promotioncode"] == "CODE1", "Promotion code should be mapped correctly"
                assert row["bundleskus"] == "SKU123", "Bundle SKUs should be extracted correctly"
                assert row["ptn_constant"] == "One", "Partition constant should be set"
                assert row["promotiontype"] == "PERCENTAGE_DISCOUNT", "Promotion type should be mapped correctly"
                
                print("SUCCESS: All business logic validations passed")
                
            except Exception as e:
                print(f"ERROR in final selection: {type(e).__name__}: {e}")
                raise
                
        except Exception as e:
            print(f"OVERALL ERROR: {e}")
            import traceback
            traceback.print_exc()
            raise