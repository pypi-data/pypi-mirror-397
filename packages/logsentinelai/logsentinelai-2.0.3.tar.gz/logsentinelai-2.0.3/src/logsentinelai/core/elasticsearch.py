"""
Elasticsearch integration module
Handles connection, indexing, and data transmission to Elasticsearch
"""
import datetime
import json
from typing import Dict, Any, Optional
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import ConnectionError, RequestError
from rich import print_json

from .config import ELASTICSEARCH_HOST, ELASTICSEARCH_USER, ELASTICSEARCH_PASSWORD, ELASTICSEARCH_INDEX
from .commons import setup_logger
from ..utils.general import get_host_metadata
import logging

logger = setup_logger("logsentinelai.elasticsearch")

def get_elasticsearch_client() -> Optional[Elasticsearch]:
    """
    Create an Elasticsearch client and test the connection.
    
    Returns:
        Elasticsearch: Connected client object or None (on connection failure)
    """
    try:
        client = Elasticsearch(
            [ELASTICSEARCH_HOST],
            basic_auth=(ELASTICSEARCH_USER, ELASTICSEARCH_PASSWORD),
            verify_certs=False,
            ssl_show_warn=False
        )
        if client.ping():
            logger.info(f"Elasticsearch connection successful: {ELASTICSEARCH_HOST}")
            return client
        else:
            logger.error(f"Elasticsearch ping failed: {ELASTICSEARCH_HOST}")
            return None
    except ConnectionError as e:
        logger.error(f"Elasticsearch connection error: {e}")
        return None
    except Exception as e:
        logger.error(f"Elasticsearch client creation error: {e}")
        return None

def send_to_elasticsearch_raw(data: Dict[str, Any], log_type: str, chunk_id: Optional[int] = None) -> bool:
    """
    Send analysis results to Elasticsearch.
    
    Args:
        data: Analysis data to send (JSON format)
        log_type: Log type ("httpd_access", "httpd_server", "linux_system")
        chunk_id: Chunk number (optional)
    
    Returns:
        bool: Whether transmission was successful
    """
    
    logger.debug(f"send_to_elasticsearch_raw called with log_type={log_type}, chunk_id={chunk_id}")
    print(f"[ES][DEBUG] send_to_elasticsearch_raw called with log_type={log_type}, chunk_id={chunk_id}")
    
    try:
        # Generate document identification ID
        timestamp = datetime.datetime.utcnow().strftime("%Y%m%d_%H%M%S_%f")
        doc_id = f"{log_type}_{timestamp}"
        if chunk_id is not None:
            doc_id += f"_chunk_{chunk_id}"

        # Add metadata
        host_metadata = get_host_metadata()
        enriched_data = {
            **data,
            "@timestamp": datetime.datetime.utcnow().isoformat(),
            "@log_type": log_type,
            "@document_id": doc_id,
            **host_metadata
        }

        # --- Telegram Alert: Configured severity level events OR processing failure ---
        from .config import TELEGRAM_ENABLED, TELEGRAM_ALERT_LEVEL
        
        def get_severity_priority(severity: str) -> int:
            """Get numeric priority for severity level (lower number = higher priority)"""
            severity_map = {
                "CRITICAL": 1,
                "HIGH": 2,
                "MEDIUM": 3,
                "LOW": 4,
                "INFO": 5
            }
            return severity_map.get(severity.upper(), 999)
        
        if TELEGRAM_ENABLED:
            alert_threshold_priority = get_severity_priority(TELEGRAM_ALERT_LEVEL)
            print(f"[TELEGRAM][DEBUG] Telegram alerts enabled - checking events for {TELEGRAM_ALERT_LEVEL}+ severity and processing result...")
            try:
                from ..utils.telegram_alert import send_telegram_alert
                
                events = enriched_data.get("events")
                processing_result = enriched_data.get("@processing_result", "unknown")
                
                print(f"[TELEGRAM][DEBUG] Found {len(events) if events else 0} events, processing_result: {processing_result}")
                
                # ì•Œë¦¼ ì¡°ê±´ ì²´í¬: TELEGRAM_ALERT_LEVEL ì´ìƒì˜ ì´ë²¤íŠ¸ OR ì²˜ë¦¬ ì‹¤íŒ¨
                alert_events = []
                if events:
                    for event in events:
                        event_severity = str(event.get("severity", "")).upper()
                        event_priority = get_severity_priority(event_severity)
                        if event_priority <= alert_threshold_priority:
                            alert_events.append(event)
                
                has_alert_events = len(alert_events) > 0
                has_failure = processing_result != "success"
                
                if has_alert_events or has_failure:
                    # ì•Œë¦¼ íƒ€ì…ì— ë”°ë¥¸ ë¡œê¹… ë° ë©”ì‹œì§€ ì¤€ë¹„
                    if has_alert_events and has_failure:
                        alert_type = f"{TELEGRAM_ALERT_LEVEL}+ EVENTS + PROCESSING FAILURE"
                        logger.info(f"[TELEGRAM] {TELEGRAM_ALERT_LEVEL}+ events AND processing failure detected in chunk {chunk_id}")
                    elif has_alert_events:
                        alert_type = f"{TELEGRAM_ALERT_LEVEL}+ EVENTS"
                        logger.info(f"[TELEGRAM] {TELEGRAM_ALERT_LEVEL}+ event(s) detected in chunk {chunk_id}")
                    else:  # has_failure
                        alert_type = "PROCESSING FAILURE"
                        logger.info(f"[TELEGRAM] Processing failure detected in chunk {chunk_id}")
                    
                    print(f"[TELEGRAM][DEBUG] Alert type: {alert_type}")
                    
                    # ì²­í¬ ì „ì²´ ì •ë³´ë¥¼ ê°€ë…ì„± ì¢‹ê²Œ í¬ë§·íŒ…
                    msg_lines = []
                    
                    # ì „ì²´ ë¶„ì„ì˜ requires_immediate_attention í‘œì‹œ (ì•Œë¦¼ ì´ë²¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°)
                    requires_immediate_attention = enriched_data.get("requires_immediate_attention", False)
                    if has_alert_events:
                        highest_severity = enriched_data.get("highest_severity", "UNKNOWN")
                        msg_lines.append(f"ğŸš¨ [{alert_type}] ğŸš¨")
                        msg_lines.append(f"  â€¢ Highest Severity: {highest_severity}")
                        msg_lines.append(f"  â€¢ Immediate Attention: {'Required' if requires_immediate_attention else 'Not Required'}")
                        msg_lines.append("")
                    else:
                        msg_lines.append(f"ğŸš¨ [{alert_type}] ğŸš¨")
                        msg_lines.append("")
                    
                    # ì²˜ë¦¬ ì‹¤íŒ¨ì¸ ê²½ìš° ì—ëŸ¬ ì •ë³´ í‘œì‹œ
                    if has_failure:
                        error_type = enriched_data.get("@error_type", "unknown_error")
                        error_message = enriched_data.get("@error_message", "No error message")
                        msg_lines.append("âŒ Processing Failure:")
                        msg_lines.append(f"  â€¢ Error Type: {error_type}")
                        msg_lines.append(f"  â€¢ Error Message: {error_message}")
                        msg_lines.append("")
                    
                    # ì „ì²´ ì´ë²¤íŠ¸ ìš”ì•½ (ì„¤ì •ëœ ë ˆë²¨ ì´ìƒë§Œ í‘œì‹œ) - Summary ì•ìœ¼ë¡œ ì´ë™
                    if has_alert_events and events:
                        # ì„¤ì •ëœ ë ˆë²¨ ì´ìƒì˜ severityë§Œ ì§‘ê³„
                        alert_severities = {}
                        for evt in events:
                            sev = evt.get('severity', 'UNKNOWN').upper()
                            event_priority = get_severity_priority(sev)
                            if event_priority <= alert_threshold_priority:
                                alert_severities[sev] = alert_severities.get(sev, 0) + 1
                        
                        # severity ìš°ì„ ìˆœìœ„ ìˆœì„œëŒ€ë¡œ ì •ë ¬ (CRITICAL -> HIGH -> MEDIUM -> LOW -> INFO)
                        severity_order = ["CRITICAL", "HIGH", "MEDIUM", "LOW", "INFO"]
                        sorted_severities = []
                        for sev in severity_order:
                            if sev in alert_severities:
                                sorted_severities.append((sev, alert_severities[sev]))
                        
                        msg_lines.append(f"ğŸ“Š Alert Events Summary ({sum(alert_severities.values())} total):")
                        for sev, count in sorted_severities:
                            msg_lines.append(f"  â€¢ {sev}: {count}")
                        msg_lines.append("")
                    
                    # ìš”ì•½ (ì„±ê³µí•œ ê²½ìš°ì—ë§Œ) - ìƒˆë¡œìš´ í˜•ì‹
                    if not has_failure:
                        summary = enriched_data.get("summary", "No summary")
                        msg_lines.append("ğŸ“‹ Summary")
                        msg_lines.append(f"  â¤ {summary}")
                        msg_lines.append("")
                    
                    # ì•Œë¦¼ ì´ë²¤íŠ¸ë“¤ë§Œ í‘œì‹œ (ì´ë²¤íŠ¸ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ) - ìƒˆë¡œìš´ í˜•ì‹
                    if has_alert_events and events:
                        # ê°€ì¥ ë†’ì€ severity ë ˆë²¨ì˜ ì´ë²¤íŠ¸ ì¤‘ 1ê°œ ì„ íƒ
                        # ì›ë³¸ JSONì˜ highest_severity ì‚¬ìš©
                        highest_severity = enriched_data.get("highest_severity", "UNKNOWN")
                        
                        # highest_severityì™€ ë™ì¼í•œ ë ˆë²¨ì˜ ì´ë²¤íŠ¸ë“¤ ì¤‘ ì²« ë²ˆì§¸ ì„ íƒ
                        highest_severity_events = [evt for evt in alert_events 
                                                 if str(evt.get('severity', '')).upper() == str(highest_severity).upper()]
                        
                        # í•´ë‹¹ ë ˆë²¨ì˜ ì´ë²¤íŠ¸ê°€ ì—†ìœ¼ë©´ ì•Œë¦¼ ì´ë²¤íŠ¸ ì¤‘ ì²« ë²ˆì§¸ ì„ íƒ
                        if not highest_severity_events:
                            highest_severity_events = alert_events[:1]
                        
                        displayed_events = highest_severity_events[:1]
                        
                        for i, evt in enumerate(displayed_events, 1):
                            msg_lines.append(f"ğŸ”¥ Event-{i}")
                            msg_lines.append(f"  â€¢ Severity: {evt.get('severity', 'Unknown')}")
                            msg_lines.append(f"  â€¢ Event Type: {evt.get('event_type', 'Unknown')}")
                            msg_lines.append(f"  â€¢ Description: {evt.get('description', 'No description')}")
                            msg_lines.append(f"  â€¢ Confidence: {evt.get('confidence_score', 'N/A')}")

                            # Source IPs ì²˜ë¦¬ (ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ ê°’)
                            source_ips = evt.get('source_ips')
                            if source_ips:
                                if isinstance(source_ips, list):
                                    ip_str = ', '.join(str(ip) for ip in source_ips[:5])  # ìµœëŒ€ 5ê°œê¹Œì§€ë§Œ
                                    if len(source_ips) > 5:
                                        ip_str += f" (and {len(source_ips) - 5} more)"
                                else:
                                    ip_str = str(source_ips)
                                msg_lines.append(f"  â€¢ Source IPs: {ip_str}")

                            msg_lines.append(f"  â€¢ Human Review: {'Required' if evt.get('requires_human_review', False) else 'Not Required'}")

                            # Related Logs ì¶”ê°€ (ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ)
                            related_logs = evt.get('related_logs')
                            if related_logs:
                                msg_lines.append(f"  â€¢ Related Logs:")
                                if isinstance(related_logs, list):
                                    displayed_logs = related_logs[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€ë§Œ
                                    for j, log_line in enumerate(displayed_logs, 1):
                                        # ë¡œê·¸ ë¼ì¸ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ë‚´ê¸° (100ì ì œí•œ)
                                        truncated_log = str(log_line)[:100]
                                        if len(str(log_line)) > 100:
                                            truncated_log += "..."
                                        msg_lines.append(f"      {j}. {truncated_log}")
                                    if len(related_logs) > 3:
                                        msg_lines.append(f"      ... and {len(related_logs) - 3} more log entries")
                                else:
                                    # ë‹¨ì¼ ë¡œê·¸ì¸ ê²½ìš°
                                    truncated_log = str(related_logs)[:100]
                                    if len(str(related_logs)) > 100:
                                        truncated_log += "..."
                                    msg_lines.append(f"      1. {truncated_log}")

                            if evt.get('recommended_actions'):
                                msg_lines.append(f"  â€¢ Recommended Actions:")
                                actions = evt.get('recommended_actions')[:3]  # ì•¡ì…˜ì€ 3ê°œê¹Œì§€ë§Œ
                                for action in actions:
                                    msg_lines.append(f"      â¤ {action}")
                            msg_lines.append("")  # ì•Œë¦¼ ì´ë²¤íŠ¸ ê°„ êµ¬ë¶„ì„ ìœ„í•œ ë¹ˆ ì¤„
                        
                        # 1ê°œ ì´ˆê³¼ ì‹œ ìƒëµ ì•ˆë‚´ ë©”ì‹œì§€
                        if len(alert_events) > 1:
                            omitted_count = len(alert_events) - 1
                            msg_lines.append(f"   ... and {omitted_count} more {TELEGRAM_ALERT_LEVEL}+ event(s) omitted (check ES/Kibana for full details)")
                            msg_lines.append("")
                    
                    # í†µê³„ (ì•Œë¦¼ ì´ë²¤íŠ¸ì™€ ê´€ê³„ì—†ì´ í•­ìƒ í‘œì‹œ)
                    stats = enriched_data.get("statistics", {})
                    if stats:
                        msg_lines.append("ğŸ“Š Statistics:")
                        for key, value in list(stats.items())[:5]:  # ìµœëŒ€ 5ê°œ í†µê³„
                            msg_lines.append(f"  â€¢ {key}: {value}")
                        msg_lines.append("")
                    
                    # ES/Kibana ì¡°íšŒë¥¼ ìœ„í•œ ë©”íƒ€ë°ì´í„° ì •ë³´ (í•­ìƒ í‘œì‹œ)
                    msg_lines.append("ğŸ” ES/Kibana Metadata:")
                    msg_lines.append(f"  â€¢ Index: {ELASTICSEARCH_INDEX}")
                    for key, value in enriched_data.items():
                        if key.startswith("@"):  # ëª¨ë“  @ ë©”íƒ€ë°ì´í„° í‘œì‹œ
                            # @host ê°™ì€ dictëŠ” íŠ¹ë³„ ì²˜ë¦¬
                            if isinstance(value, dict):
                                msg_lines.append(f"  â€¢ {key}: {json.dumps(value, separators=(',', ':'))}")
                            # ë¦¬ìŠ¤íŠ¸ëŠ” ê°„ë‹¨í•˜ê²Œ í‘œì‹œ
                            elif isinstance(value, list):
                                msg_lines.append(f"  â€¢ {key}: {json.dumps(value, separators=(',', ':'))}")
                            else:
                                msg_lines.append(f"  â€¢ {key}: {value}")
                    
                    # ë©”ì‹œì§€ êµ¬ì„± ì™„ë£Œ
                    msg = "\n".join(msg_lines)
                    
                    # í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ê¸¸ì´ ì œí•œ (4096ì) ì²´í¬
                    if len(msg) > 4000:
                        msg = msg[:3990] + "\n...(truncated)"
                    
                    try:
                        send_telegram_alert(msg)
                        if has_alert_events and has_failure:
                            logger.info(f"[TELEGRAM] Alert sent successfully: {alert_type} for chunk {chunk_id}")
                        elif has_alert_events:
                            logger.info(f"[TELEGRAM] Alert sent successfully: {alert_type} for chunk {chunk_id} ({len(alert_events)} events)")
                        else:
                            logger.info(f"[TELEGRAM] Alert sent successfully: {alert_type} for chunk {chunk_id}")
                        print(f"[TELEGRAM][DEBUG] âœ… Alert sent: {alert_type}")
                    except Exception as e:
                        logger.error(f"[TELEGRAM] Failed to send alert for chunk {chunk_id}: {e}")
                        print(f"[TELEGRAM][ERROR] âŒ Failed to send alert: {e}")
                else:
                    logger.debug(f"[TELEGRAM] No alert conditions met for chunk {chunk_id} (no {TELEGRAM_ALERT_LEVEL}+ events and processing_result={processing_result})")
                    print(f"[TELEGRAM][DEBUG] No alert conditions met (no {TELEGRAM_ALERT_LEVEL}+ events, processing_result={processing_result})")
            except ImportError:
                print("[TELEGRAM][ERROR] telegram_alert import failed!")
                pass
        else:
            print("[TELEGRAM][DEBUG] Telegram alerts disabled in config - skipping all processing")
        # --- END Telegram Alert ---

        # Print final ES input data (ì½˜ì†”)
        print("\nâœ… [Final ES Input JSON]")
        print("-" * 30)
        print_json(json.dumps(enriched_data, ensure_ascii=False, indent=2))
        print()
        
        # DEBUG ë ˆë²¨ì—ì„œ ES ì „ì†¡ ì§ì „ ìµœì¢… JSON ë¡œê¹… (ë” ìƒì„¸í•œ ì •ë³´ í¬í•¨)
        logger.debug(f"ES transmission for chunk {chunk_id} - Document ID: {doc_id}")
        logger.debug(f"Final ES JSON data (chunk {chunk_id}):\n{json.dumps(enriched_data, ensure_ascii=False, indent=2)}")

        # Get Elasticsearch client
        client = get_elasticsearch_client()
        if not client:
            logger.error(f"Elasticsearch client not available.")
            return False

        # Index document in Elasticsearch
        response = client.index(
            index=ELASTICSEARCH_INDEX,
            id=doc_id,
            document=enriched_data
        )

        # Check response status (ì½˜ì†”)
        print(f"âœ… Sending data to Elasticsearch index '{ELASTICSEARCH_INDEX}' with ID '{doc_id}'")
        if response.get('result') in ['created', 'updated']:
            print(f"âœ… Elasticsearch transmission successful: {doc_id}")
            logger.info(f"Elasticsearch transmission successful: {doc_id}")
            return True
        else:
            print(f"âŒ Elasticsearch transmission failed: {response}")
            logger.error(f"Elasticsearch transmission failed: {response}")
            return False

    except RequestError as e:
        print(f"âŒ Elasticsearch request error: {e}")
        logger.error(f"Elasticsearch request error: {e}")
        return False
    except Exception as e:
        print(f"âŒ Error occurred during Elasticsearch transmission: {e}")
        logger.exception(f"Error occurred during Elasticsearch transmission: {e}")
        return False
