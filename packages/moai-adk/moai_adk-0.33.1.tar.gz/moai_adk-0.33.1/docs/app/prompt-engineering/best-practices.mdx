---
title: "í”„ë¡¬í”„íŠ¸ ëª¨ë²” ì‚¬ë¡€"
description: "Claude 4.5 ìµœì í™”, í† í° íš¨ìœ¨ì„±, ì„±ëŠ¥ ì¸¡ì • ë° ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•"
---

# í”„ë¡¬í”„íŠ¸ ëª¨ë²” ì‚¬ë¡€

ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê¸°ë²•ê³¼ Claude 4.5 ìµœì í™” ë°©ë²•ì„ í•™ìŠµí•©ë‹ˆë‹¤. ì‹¤ì œ ì‚¬ë¡€ì™€ ì¸¡ì • ê°€ëŠ¥í•œ ê²°ê³¼ë¬¼ì„ í†µí•´ íš¨ìœ¨ì„±ì„ ê·¹ëŒ€í™”í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## ğŸ¯ Claude 4.5 ìµœì í™”

### 1. Claude 4.5 íŠ¹ì„± í™œìš©

```python
# Claude 4.5 ìµœì í™” ê°€ì´ë“œ
CLAUDE_45_OPTIMIZATION_GUIDE = """
# Claude 4.5 íŠ¹ì„± ì´í•´ ë° í™œìš©

## ê°•ì  í™œìš© ì „ëµ
- **í–¥ìƒëœ ì½”ë”© ëŠ¥ë ¥**: ë³µì¡í•œ ì•Œê³ ë¦¬ì¦˜ê³¼ ì•„í‚¤í…ì²˜ ì„¤ê³„
- **ë” ë‚˜ì€ ì¶”ë¡ **: ë‹¨ê³„ë³„ ë¬¸ì œ í•´ê²° ë° ë…¼ë¦¬ì  ë¶„ì„
- **ê°œì„ ëœ ëª¨ë¸ë§**: ë°ì´í„° êµ¬ì¡° ë° ì‹œìŠ¤í…œ ì„¤ê³„
- **í–¥ìƒëœ ì•ˆì •ì„±**: ì¼ê´€ëœ ê²°ê³¼ë¬¼ ìƒì„±

## ìµœì í™” íŒ¨í„´

### 1. ì¶”ë¡  ëŠ¥ë ¥ ê·¹ëŒ€í™”
Claude 4.5ì˜ í–¥ìƒëœ ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•˜ëŠ” íŒ¨í„´:

```python
# ì¶”ë¡  ì¤‘ì‹¬ í”„ë¡¬í”„íŠ¸
REASONING_FOCUSED_PROMPT = """
# ì—­í• 
ë‹¹ì‹ ì€ {domain} ë¶„ì•¼ì˜ ìˆ˜ì„ ì „ë¬¸ê°€ë¡œì„œ, ì²´ê³„ì ì¸ ì¶”ë¡  ëŠ¥ë ¥ì„ ê°–ì¶”ê³  ìˆìŠµë‹ˆë‹¤.

# ë¬¸ì œ ë¶„ì„ ìš”ì²­
ë‹¤ìŒ ë¬¸ì œì— ëŒ€í•´ ë‹¨ê³„ë³„ ì¶”ë¡  ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”:
{problem_description}

# ì¶”ë¡  í”„ë ˆì„ì›Œí¬
1. **ë¬¸ì œ ì •ì˜**
   - í•µì‹¬ ì§ˆë¬¸ ëª…í™•í™”
   - ê°€ì •ê³¼ ì œì•½ì‚¬í•­ ì‹ë³„
   - ì„±ê³µ ê¸°ì¤€ ì •ì˜

2. **ì •ë³´ ë¶„ì„**
   - ê´€ë ¨ ì •ë³´ ìˆ˜ì§‘ ë° ë¶„ë¥˜
   - íŒ¨í„´ ë° ê´€ê³„ ì‹ë³„
   - ì ì¬ì  ë³€ìˆ˜ ê³ ë ¤

3. **ê°€ì„¤ ìˆ˜ë¦½**
   - ê°€ëŠ¥í•œ í•´ê²°ì±… ë¸Œë ˆì¸ìŠ¤í† ë°
   - ê° ê°€ì„¤ì˜ ê°•ì /ì•½ì  ë¶„ì„
   - ìš°ì„ ìˆœìœ„ ì„¤ì •

4. **ë…¼ë¦¬ì  ë„ì¶œ**
   - ë‹¨ê³„ë³„ ê²°ë¡  ë„ì¶œ
   - ê° ë‹¨ê³„ì˜ ê·¼ê±° ì œì‹œ
   - ì ì¬ì  í•¨ì • ê³ ë ¤

5. **ê²€ì¦ ë° ê°œì„ **
   - ê²°ê³¼ì˜ ì¼ê´€ì„± ê²€í† 
   - ë°˜ë¡€ íƒìƒ‰
   - ëŒ€ì•ˆì  ì ‘ê·¼ë²• ê²€í† 

# ì¶œë ¥ í˜•ì‹
ê° ë‹¨ê³„ì˜ ê²°ê³¼ë¥¼ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì œì‹œí•˜ê³ ,
ì¶”ë¡  ê³¼ì •ì—ì„œ ë‚´ë¦° ê²°ì •ì˜ ê·¼ê±°ë¥¼ ìƒì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
"""
```

### 2. ì½”ë”© ëŠ¥ë ¥ ìµœì í™”
Claude 4.5ì˜ í–¥ìƒëœ ì½”ë”© ëŠ¥ë ¥ì„ ê·¹ëŒ€í™”:

```python
# ë³µì¡í•œ ì½”ë”© ê³¼ì œ ìµœì í™”
ADVANCED_CODING_PATTERN = """
# ë³µì¡í•œ ì‹œìŠ¤í…œ ê°œë°œì„ ìœ„í•œ Claude 4.5 ìµœì í™”

# ì—­í•  ì •ì˜ (ìµœì í™”ëœ ì—­í• )
ë‹¹ì‹ ì€ 15ë…„ ê²½ë ¥ì˜ {domain} ì•„í‚¤í…íŠ¸ ê²¸ ì‹œë‹ˆì–´ ê°œë°œìì…ë‹ˆë‹¤.
- ëŒ€ê·œëª¨ ì‹œìŠ¤í…œ ì„¤ê³„ ë° êµ¬í˜„ ê²½í—˜
- {technologies} ì „ë¬¸ê°€
- í´ë¦° ì•„í‚¤í…ì²˜ ë° ì„¤ê³„ ì›ì¹™ ìˆ™ë‹¬
- íŒ€ ë¦¬ë”© ë° ì½”ë“œ ë¦¬ë·° ê²½í—˜

# ë³µì¡í•œ ê³¼ì—… ë¶„í•´
ë‹¤ìŒ ë³µì¡í•œ ì‹œìŠ¤í…œì„ ê°œë°œí•´ì£¼ì„¸ìš”:

## ì‹œìŠ¤í…œ ê°œìš”
{system_overview}

## ì•„í‚¤í…ì²˜ ìš”êµ¬ì‚¬í•­
{architecture_requirements}

# ë‹¨ê³„ë³„ ì ‘ê·¼ë²• (Claude 4.5 ì¶”ë¡  ëŠ¥ë ¥ í™œìš©)
1. **ì‹œìŠ¤í…œ ê²½ê³„ ì •ì˜**
   - ë¹„ì¦ˆë‹ˆìŠ¤ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„
   - ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ë¶„ë¦¬ ì „ëµ
   - ë°ì´í„° ì†ŒìŠ¤ì™€ ì†Œë¹„ì ì‹ë³„

2. **ì•„í‚¤í…ì²˜ íŒ¨í„´ ì„ íƒ**
   - ì í•©í•œ íŒ¨í„´ ë¶„ì„ (MSA, ì´ë²¤íŠ¸ ê¸°ë°˜, CQRS ë“±)
   - ê° íŒ¨í„´ì˜ ì¥ë‹¨ì  ë¹„êµ
   - í”„ë¡œì íŠ¸ íŠ¹ì„±ì— ë§ëŠ” íŒ¨í„´ ê²°ì •

3. **ìƒì„¸ ì„¤ê³„**
   - ì»´í¬ë„ŒíŠ¸ ìƒí˜¸ì‘ìš© ì •ì˜
   - ë°ì´í„° íë¦„ ì„¤ê³„
   - API ê³„ì•½ ì •ì˜

4. **êµ¬í˜„ ì „ëµ**
   - ê°œë°œ ìš°ì„ ìˆœìœ„ ì„¤ì •
   - ìœ„í—˜ ê´€ë¦¬ ì „ëµ
   - í…ŒìŠ¤íŠ¸ ì „ëµ ìˆ˜ë¦½

5. **ì½”ë“œ êµ¬í˜„**
   - ê° ì»´í¬ë„ŒíŠ¸ì˜ ìƒì„¸ ì½”ë“œ
   - í†µí•© í…ŒìŠ¤íŠ¸
   - ë°°í¬ ì „ëµ

# Claude 4.5 ìµœì í™” ì§€ì‹œ
- ê° ë‹¨ê³„ì—ì„œ ì¶”ë¡  ê³¼ì •ì„ ëª…í™•íˆ í‘œì‹œ
- ì„¤ê³„ ê²°ì •ì˜ ê·¼ê±°ë¥¼ ìƒì„¸íˆ ì œì‹œ
- ëŒ€ì•ˆì  ì ‘ê·¼ë²•ê³¼ ì„ íƒ ì´ìœ  ë¹„êµ
- ì ì¬ì  ë¦¬ìŠ¤í¬ì™€ ì™„í™” ë°©ì•ˆ ì œì‹œ
- êµ¬í˜„ ì½”ë“œì— ëŒ€í•œ ìƒì„¸í•œ ì£¼ì„ í¬í•¨
"""
```

### 3. ë‹¤ì¤‘ ì „ë¬¸ê°€ ì—­í•  í™œìš©

```python
# ë‹¤ì¤‘ ì „ë¬¸ê°€ ì‹œë®¬ë ˆì´ì…˜
MULTI_EXPERT_PATTERN = """
# ë‹¤ì¤‘ ì „ë¬¸ê°€ ì—­í•  í™œìš© (Claude 4.5 ìµœì í™”)

# ì‹œë‚˜ë¦¬ì˜¤
{complex_scenario}

# ì „ë¬¸ê°€ íŒ¨ë„ êµ¬ì„±
ë‹¹ì‹ ì€ ë‹¤ìŒ ì„¸ ì „ë¬¸ê°€ì˜ í†µí•©ëœ ì „ë¬¸ì„±ì„ ë°œíœ˜í•´ì•¼ í•©ë‹ˆë‹¤:

## 1. {expert_1_role}
- ì „ë¬¸ ë¶„ì•¼: {expert_1_domain}
- í•µì‹¬ ê´€ì‹¬ì‚¬: {expert_1_concerns}
- ì˜ê²¬ ì œì‹œ ë°©ì‹: {expert_1_style}

## 2. {expert_2_role}
- ì „ë¬¸ ë¶„ì•¼: {expert_2_domain}
- í•µì‹¬ ê´€ì‹¬ì‚¬: {expert_2_concerns}
- ì˜ê²¬ ì œì‹œ ë°©ì‹: {expert_2_style}

## 3. {expert_3_role}
- ì „ë¬¸ ë¶„ì•¼: {expert_3_domain}
- í•µì‹¬ ê´€ì‹¬ì‚¬: {expert_3_concerns}
- ì˜ê²¬ ì œì‹œ ë°©ì‹: {expert_3_style}

# í† ë¡  ë° ë¶„ì„ í”„ë¡œì„¸ìŠ¤
1. **ê° ì „ë¬¸ê°€ì˜ ì´ˆê¸° ë¶„ì„**
   - ê°ìì˜ ì „ë¬¸ ë¶„ì•¼ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ë¶„ì„
   - ì£¼ìš” ê´€ì‹¬ì‚¬ì™€ ìš°ë ¤ì  ì‹ë³„

2. **ì „ë¬¸ê°€ ê°„ í† ë¡ **
   - ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì˜ ë¹„êµ ë° ëŒ€ì¡°
   - ì ì¬ì  ì¶©ëŒ ì§€ì  ì‹ë³„
   - ê³µí†µ ê¸°ë°˜ ì°¾ê¸°

3. **í†µí•© ì†”ë£¨ì…˜ ë„ì¶œ**
   - ëª¨ë“  ì „ë¬¸ê°€ì˜ ê´€ì ì„ í†µí•©
   - ê· í˜• ì¡íŒ í•´ê²°ì±… ì œì‹œ
   - ì‹¤í–‰ ê°€ëŠ¥í•œ ê¶Œê³ ì‚¬í•­

# ì¶œë ¥ í˜•ì‹
## ì „ë¬¸ê°€ë³„ ë¶„ì„
### {expert_1_role} ê´€ì 
### {expert_2_role} ê´€ì 
### {expert_3_role} ê´€ì 

## í†µí•© ë¶„ì„
### í•µì‹¬ ë°œê²¬ì‚¬í•­
### ì£¼ìš” ê°ˆë“±ì  ë° í•´ê²°ì±…
### ì¢…í•© ê¶Œê³ ì‚¬í•­
### ì‹¤í–‰ ê³„íš

ê° ì „ë¬¸ê°€ì˜ ëª©ì†Œë¦¬ê°€ ëšœë ·íˆ êµ¬ë¶„ë˜ë„ë¡ ì‘ì„±í•˜ê³ ,
ìµœì¢… ê²°ë¡ ì´ ëª¨ë“  ê´€ì ì„ ê³ ë ¤í•œ ê· í˜• ì¡íŒ ê²°ê³¼ê°€ ë˜ë„ë¡ í•´ì£¼ì„¸ìš”.
"""
```

## ğŸ’° í† í° íš¨ìœ¨ì„± ê·¹ëŒ€í™”

### 1. í† í° ìµœì í™” ì „ëµ

```python
# í† í° íš¨ìœ¨ì„± ìµœì í™” ì‹œìŠ¤í…œ
class TokenOptimizationSystem:
    def __init__(self):
        self.optimization_strategies = {
            "concise_language": "ê°„ê²°í•œ ì–¸ì–´ ì‚¬ìš©",
            "structured_templates": "êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ í™œìš©",
            "variable_replacement": "ë³€ìˆ˜ ì¹˜í™˜ ì‹œìŠ¤í…œ",
            "context_compression": "ì»¨í…ìŠ¤íŠ¸ ì••ì¶•",
            "hierarchical_prompts": "ê³„ì¸µì  í”„ë¡¬í”„íŠ¸ ì„¤ê³„"
        }

    def optimize_for_efficiency(self, original_prompt, context=None):
        """í† í° íš¨ìœ¨ì„± ìµœì í™”"""
        optimizations = []

        # 1. ê°„ê²°í•œ ì–¸ì–´ë¡œ ë³€í™˜
        concise_prompt = self.make_concise(original_prompt)
        if self.count_tokens(concise_prompt) < self.count_tokens(original_prompt):
            optimizations.append({
                "strategy": "concise_language",
                "original_tokens": self.count_tokens(original_prompt),
                "optimized_tokens": self.count_tokens(concise_prompt),
                "saving": self.count_tokens(original_prompt) - self.count_tokens(concise_prompt)
            })
            original_prompt = concise_prompt

        # 2. êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜
        if self.can_use_template(original_prompt):
            template_prompt = self.apply_template(original_prompt, context)
            if self.count_tokens(template_prompt) < self.count_tokens(original_prompt):
                optimizations.append({
                    "strategy": "structured_templates",
                    "original_tokens": self.count_tokens(original_prompt),
                    "optimized_tokens": self.count_tokens(template_prompt),
                    "saving": self.count_tokens(original_prompt) - self.count_tokens(template_prompt)
                })
                original_prompt = template_prompt

        # 3. ë³€ìˆ˜ ì¹˜í™˜ ì‹œìŠ¤í…œ ì ìš©
        if context:
            variable_prompt = self.replace_with_variables(original_prompt, context)
            if self.count_tokens(variable_prompt) < self.count_tokens(original_prompt):
                optimizations.append({
                    "strategy": "variable_replacement",
                    "original_tokens": self.count_tokens(original_prompt),
                    "optimized_tokens": self.count_tokens(variable_prompt),
                    "saving": self.count_tokens(original_prompt) - self.count_tokens(variable_prompt)
                })
                original_prompt = variable_prompt

        return {
            "optimized_prompt": original_prompt,
            "optimizations": optimizations,
            "total_savings": sum(opt["saving"] for opt in optimizations),
            "efficiency_improvement": self.calculate_efficiency_improvement(optimizations)
        }

    def make_concise(self, prompt):
        """ê°„ê²°í•œ ì–¸ì–´ë¡œ ë³€í™˜"""
        # ê¸¸ê³ å†—é•·í•œ í‘œí˜„ì„ ê°„ê²°í•œ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        replacements = {
            "ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì„¸ìš”": "ë‹¤ìŒ ì‘ì—… ìˆ˜í–‰:",
            "ì•„ë˜ì— ëª…ì‹œëœ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±ì‹œí‚¤ëŠ”": "ìš”êµ¬ì‚¬í•­ ì¶©ì¡±:",
            "ë§¤ìš° ì¤‘ìš”í•œ ì ì€": "ì¤‘ìš”:",
            "ì‹ ì¤‘í•˜ê²Œ ê³ ë ¤í•˜ì—¬": "ê³ ë ¤:",
            "ê°€ì¥ íš¨ê³¼ì ì¸ ë°©ë²•ìœ¼ë¡œ": "ìµœì ì˜ ë°©ë²•ìœ¼ë¡œ:",
            "ìƒì„¸í•œ ì„¤ëª…ê³¼ í•¨ê»˜": "ìƒì„¸ ì„¤ëª…:",
        }

        for long_form, short_form in replacements.items():
            prompt = prompt.replace(long_form, short_form)

        return prompt

    def apply_template(self, prompt, context):
        """í…œí”Œë¦¿ ì ìš©"""
        # ë°˜ë³µì ì¸ êµ¬ì¡°ë¥¼ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜
        template_patterns = {
            "list_requirements": r"ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±í•´ì•¼ í•©ë‹ˆë‹¤:(.*?)(?=\n\n|\n#|$)",
            "define_constraints": r"ì œì•½ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:(.*?)(?=\n\n|\n#|$)",
            "specify_format": r"ì¶œë ¥ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:(.*?)(?=\n\n|\n#|$)"
        }

        for pattern_name, pattern in template_patterns.items():
            matches = re.search(pattern, prompt, re.DOTALL)
            if matches:
                content = matches.group(1).strip()
                template_content = self.convert_to_template_format(content, pattern_name)
                prompt = prompt.replace(matches.group(0), f"{pattern_name}:\n{template_content}")

        return prompt

    def replace_with_variables(self, prompt, context):
        """ë³€ìˆ˜ë¡œ ì¹˜í™˜"""
        # ë°˜ë³µë˜ëŠ” ë‚´ìš©ì„ ë³€ìˆ˜ë¡œ ì¹˜í™˜
        if "tech_stack" in context:
            tech_stack_str = ", ".join(context["tech_stack"])
            prompt = prompt.replace(tech_stack_str, "{TECH_STACK}")

        if "project_name" in context:
            prompt = prompt.replace(context["project_name"], "{PROJECT_NAME}")

        return prompt

# í† í° íš¨ìœ¨ì„± ë¶„ì„ ì˜ˆì‹œ
optimizer = TokenOptimizationSystem()

original_prompt = """
ì €ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‘ì—…ì„ ìˆ˜í–‰í•´ ì£¼ì‹œê¸¸ ë°”ëë‹ˆë‹¤.
í”„ë¡œì íŠ¸ ì´ë¦„ì€ MoAI-ADKì´ê³ , ê¸°ìˆ  ìŠ¤íƒì€ Python, FastAPI, PostgreSQL, Redisë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ì¶©ì¡±ì‹œí‚¤ëŠ” ì‚¬ìš©ì ì¸ì¦ ì‹œìŠ¤í…œì„ ê°œë°œí•´ ì£¼ì„¸ìš”:
1. JWT ê¸°ë°˜ ì¸ì¦
2. ë¹„ë°€ë²ˆí˜¸ ì•”í˜¸í™”
3. ë¦¬í”„ë ˆì‹œ í† í°
4. ì†ë„ ì œí•œ
ì œì•½ì‚¬í•­ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- ë°˜ë“œì‹œ í…ŒìŠ¤íŠ¸ ì½”ë“œë¥¼ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- ì„±ëŠ¥ì„ ìµœì í™”í•´ì•¼ í•©ë‹ˆë‹¤
ì¶œë ¥ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:
- ì½”ë“œì™€ ì„¤ëª…ì„ í•¨ê»˜ ì œê³µí•´ ì£¼ì„¸ìš”
"""

context = {
    "project_name": "MoAI-ADK",
    "tech_stack": ["Python", "FastAPI", "PostgreSQL", "Redis"]
}

optimization_result = optimizer.optimize_for_efficiency(original_prompt, context)
print(f"í† í° ì ˆì•½: {optimization_result['total_savings']} í† í°")
print(f"íš¨ìœ¨ì„± ê°œì„ : {optimization_result['efficiency_improvement']:.1%}")
```

### 2. íš¨ìœ¨ì ì¸ ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬

```python
# ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ ìµœì í™”
class ContextManager:
    def __init__(self):
        self.context_cache = {}
        self.compression_history = []

    def compress_context(self, context, priority_weights=None):
        """ì»¨í…ìŠ¤íŠ¸ ì••ì¶•"""
        if not priority_weights:
            priority_weights = {
                "critical": 1.0,
                "important": 0.7,
                "useful": 0.4,
                "optional": 0.1
            }

        compressed_context = {}
        context_importance = {}

        for key, value in context.items():
            importance = self.assess_context_importance(key, value, priority_weights)
            context_importance[key] = importance

            # ì¤‘ìš”ë„ì— ë”°ë¼ ì••ì¶• ë ˆë²¨ ê²°ì •
            if importance >= 0.8:
                compressed_context[key] = value  # ì™„ì „ ë³´ì¡´
            elif importance >= 0.5:
                compressed_context[key] = self.summarize_content(value)  # ìš”ì•½
            elif importance >= 0.2:
                compressed_context[key] = self.extract_keywords(value)  # í‚¤ì›Œë“œ
            # importance < 0.2: ì œì™¸

        return {
            "compressed_context": compressed_context,
            "original_size": self.calculate_context_size(context),
            "compressed_size": self.calculate_context_size(compressed_context),
            "compression_ratio": self.calculate_compression_ratio(context, compressed_context),
            "importance_scores": context_importance
        }

    def assess_context_importance(self, key, value, weights):
        """ì»¨í…ìŠ¤íŠ¸ ì¤‘ìš”ë„ í‰ê°€"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ì¤‘ìš”ë„ í‰ê°€
        critical_keywords = ["security", "authentication", "database", "api", "critical"]
        important_keywords = ["requirements", "constraints", "format", "output"]
        useful_keywords = ["examples", "background", "context"]
        optional_keywords = ["nice_to_have", "optional", "additional"]

        content_lower = str(value).lower()

        critical_count = sum(1 for kw in critical_keywords if kw in content_lower)
        important_count = sum(1 for kw in important_keywords if kw in content_lower)
        useful_count = sum(1 for kw in useful_keywords if kw in content_lower)
        optional_count = sum(1 for kw in optional_keywords if kw in content_lower)

        # ê°€ì¤‘ í‰ê·  ê³„ì‚°
        importance = (
            critical_count * weights["critical"] +
            important_count * weights["important"] +
            useful_count * weights["useful"] +
            optional_count * weights["optional"]
        )

        return min(1.0, importance / 5)  # ìµœëŒ€ê°’ 1.0ìœ¼ë¡œ ì œí•œ

    def summarize_content(self, content):
        """ë‚´ìš© ìš”ì•½"""
        if isinstance(content, str):
            sentences = content.split('.')
            # ì²« ë¬¸ì¥ê³¼ ë§ˆì§€ë§‰ ë¬¸ì¥ ìœ ì§€ (ê°€ì¥ ì¤‘ìš”í•œ ë‚´ìš©)
            if len(sentences) > 3:
                return sentences[0] + " ... " + sentences[-1]
            else:
                return content
        return content

    def extract_keywords(self, content):
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        if isinstance(content, str):
            # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ
            words = content.split()
            # ì£¼ìš” ëª…ì‚¬ì™€ ê¸°ìˆ  ìš©ì–´ í•„í„°ë§
            keywords = [word for word in words if len(word) > 4 and word.isalnum()]
            return ", ".join(keywords[:5])  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
        return content
```

## ğŸ“Š ì„±ëŠ¥ ì¸¡ì • ë° ìµœì í™”

### 1. í”„ë¡¬í”„íŠ¸ ì„±ëŠ¥ ë¶„ì„

```python
# ê³ ê¸‰ ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œ
class AdvancedPerformanceAnalyzer:
    def __init__(self):
        self.benchmark_data = {}
        self.performance_history = []

    def comprehensive_analysis(self, prompt, response, expected_outcome=None, context=None):
        """ì¢…í•© ì„±ëŠ¥ ë¶„ì„"""
        analysis = {
            "prompt_analysis": self.analyze_prompt(prompt),
            "response_analysis": self.analyze_response(response),
            "efficiency_metrics": self.calculate_efficiency_metrics(prompt, response),
            "quality_assessment": self.assess_quality(prompt, response, expected_outcome),
            "optimization_suggestions": self.generate_optimization_suggestions(prompt, response)
        }

        # ê¸°ë¡ ì €ì¥
        self.record_analysis(analysis, context)

        return analysis

    def analyze_prompt(self, prompt):
        """í”„ë¡¬í”„íŠ¸ ë¶„ì„"""
        return {
            "complexity": self.calculate_prompt_complexity(prompt),
            "clarity": self.assess_prompt_clarity(prompt),
            "structure": self.analyze_prompt_structure(prompt),
            "completeness": self.check_prompt_completeness(prompt),
            "specificity": self.measure_specificity(prompt)
        }

    def calculate_prompt_complexity(self, prompt):
        """í”„ë¡¬í”„íŠ¸ ë³µì¡ë„ ê³„ì‚°"""
        complexity_factors = {
            "length": len(prompt.split()),
            "nested_conditions": prompt.count("if") + prompt.count("when"),
            "multiple_requirements": len(re.findall(r'\d+\.', prompt)),
            "technical_terms": len(re.findall(r'\b[A-Z]{2,}\b', prompt)),
            "ambiguity_indicators": len(re.findall(r'\b(ì¢‹ì€|íš¨ìœ¨ì ì¸|ì ì ˆí•œ)\b', prompt))
        }

        # ì •ê·œí™”ëœ ë³µì¡ë„ ì ìˆ˜
        normalized_complexity = {
            "length_score": min(complexity_factors["length"] / 200, 1.0),
            "conditional_score": min(complexity_factors["nested_conditions"] / 5, 1.0),
            "requirements_score": min(complexity_factors["multiple_requirements"] / 10, 1.0),
            "technical_score": min(complexity_factors["technical_terms"] / 10, 1.0),
            "ambiguity_score": complexity_factors["ambiguity_indicators"] / 5
        }

        overall_complexity = sum(normalized_complexity.values()) / len(normalized_complexity)

        return {
            "factors": complexity_factors,
            "normalized_scores": normalized_complexity,
            "overall_complexity": overall_complexity,
            "complexity_level": self.categorize_complexity(overall_complexity)
        }

    def categorize_complexity(self, score):
        """ë³µì¡ë„ ìˆ˜ì¤€ ë¶„ë¥˜"""
        if score < 0.3:
            return "ê°„ë‹¨í•¨"
        elif score < 0.6:
            return "ì¤‘ê°„"
        elif score < 0.8:
            return "ë³µì¡í•¨"
        else:
            return "ë§¤ìš° ë³µì¡í•¨"

    def generate_optimization_suggestions(self, prompt, response):
        """ìµœì í™” ì œì•ˆ ìƒì„±"""
        suggestions = []

        # í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ìµœì í™” ì œì•ˆ
        prompt_analysis = self.analyze_prompt(prompt)

        if prompt_analysis["clarity"]["score"] < 0.7:
            suggestions.append({
                "area": "clarity",
                "priority": "high",
                "suggestion": "í”„ë¡¬í”„íŠ¸ë¥¼ ë” ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”. êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ê³¼ ê¸°ëŒ€ ê²°ê³¼ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.",
                "example": self.get_clarity_improvement_example(prompt)
            })

        if prompt_analysis["specificity"]["score"] < 0.6:
            suggestions.append({
                "area": "specificity",
                "priority": "medium",
                "suggestion": "ë” êµ¬ì²´ì ì¸ ì§€ì‹œë¥¼ ì œê³µí•˜ì„¸ìš”. ìˆ˜ëŸ‰, í˜•ì‹, ê¸°ì¤€ ë“±ì„ ëª…í™•íˆ ì§€ì •í•˜ì„¸ìš”.",
                "example": self.get_specificity_improvement_example(prompt)
            })

        # íš¨ìœ¨ì„± ê¸°ë°˜ ìµœì í™” ì œì•ˆ
        efficiency = self.calculate_efficiency_metrics(prompt, response)

        if efficiency["token_efficiency"]["score"] < 0.5:
            suggestions.append({
                "area": "efficiency",
                "priority": "medium",
                "suggestion": "í† í° íš¨ìœ¨ì„±ì„ ê°œì„ í•˜ì„¸ìš”. ê°„ê²°í•œ í‘œí˜„ê³¼ ë³€ìˆ˜ ì¹˜í™˜ì„ í™œìš©í•˜ì„¸ìš”.",
                "example": self.get_efficiency_improvement_example(prompt)
            })

        return suggestions

    def get_clarity_improvement_example(self, prompt):
        """ëª…í™•ì„± ê°œì„  ì˜ˆì‹œ"""
        return {
            "before": "ì¢‹ì€ APIë¥¼ ë§Œë“¤ì–´ì¤˜",
            "after": """ë‹¤ìŒ ìš”êµ¬ì‚¬í•­ì„ ë§Œì¡±í•˜ëŠ” REST APIë¥¼ ì„¤ê³„í•˜ê³  êµ¬í˜„í•´ì£¼ì„¸ìš”:

ê¸°ëŠ¥: ì‚¬ìš©ì ê´€ë¦¬
ê¸°ìˆ  ìŠ¤íƒ: FastAPI, PostgreSQL
ìš”êµ¬ì‚¬í•­:
- JWT ì¸ì¦
- CRUD ì˜¤í¼ë ˆì´ì…˜
- ì…ë ¥ ìœ íš¨ì„± ê²€ì‚¬
- ì˜ˆì™¸ ì²˜ë¦¬

ì¶œë ¥ í˜•ì‹:
- Python ì½”ë“œ
- API ì—”ë“œí¬ì¸íŠ¸ ëª…ì„¸"""
        }

    def track_performance_trends(self, days=30):
        """ì„±ëŠ¥ íŠ¸ë Œë“œ ì¶”ì """
        cutoff_date = datetime.now() - timedelta(days=days)
        recent_analyses = [
            analysis for analysis in self.performance_history
            if analysis["timestamp"] > cutoff_date
        ]

        if len(recent_analyses) < 2:
            return "ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ íŠ¸ë Œë“œ ë¶„ì„ì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        # íŠ¸ë Œë“œ ë¶„ì„
        quality_trend = self.calculate_trend(
            [a["quality_assessment"]["overall_score"] for a in recent_analyses]
        )
        efficiency_trend = self.calculate_trend(
            [a["efficiency_metrics"]["overall_efficiency"] for a in recent_analyses]
        )

        return {
            "period": f"ìµœê·¼ {days}ì¼",
            "total_analyses": len(recent_analyses),
            "quality_trend": quality_trend,
            "efficiency_trend": efficiency_trend,
            "recommendations": self.get_trend_based_recommendations(quality_trend, efficiency_trend)
        }
```

### 2. ìë™ ìµœì í™” ì‹œìŠ¤í…œ

```python
# ìë™ ìµœì í™” ì‹œìŠ¤í…œ
class AutoOptimizationSystem:
    def __init__(self):
        self.optimizer = TokenOptimizationSystem()
        self.analyzer = AdvancedPerformanceAnalyzer()
        self.optimization_rules = self.load_optimization_rules()

    def auto_optimize(self, prompt, context=None, target_metrics=None):
        """ìë™ ìµœì í™”"""
        # 1. ì´ˆê¸° ë¶„ì„
        initial_analysis = self.analyzer.comprehensive_analysis(prompt, "", context=context)

        # 2. ìµœì í™” ì „ëµ ì„ íƒ
        strategies = self.select_optimization_strategies(initial_analysis, target_metrics)

        # 3. ìˆœì°¨ì  ìµœì í™” ì ìš©
        optimized_prompt = prompt
        optimization_log = []

        for strategy in strategies:
            result = self.apply_optimization_strategy(optimized_prompt, strategy, context)
            if result["improvement"] > 0.05:  # 5% ì´ìƒ ê°œì„  ì‹œ ì ìš©
                optimized_prompt = result["optimized_prompt"]
                optimization_log.append(result)

        # 4. ìµœì¢… ê²€ì¦
        final_analysis = self.analyzer.comprehensive_analysis(optimized_prompt, "", context=context)
        improvement = self.calculate_improvement(initial_analysis, final_analysis)

        return {
            "original_prompt": prompt,
            "optimized_prompt": optimized_prompt,
            "improvement": improvement,
            "optimization_log": optimization_log,
            "validation": self.validate_optimization(optimized_prompt)
        }

    def select_optimization_strategies(self, analysis, target_metrics):
        """ìµœì í™” ì „ëµ ì„ íƒ"""
        strategies = []

        # í’ˆì§ˆ ê¸°ë°˜ ì „ëµ ì„ íƒ
        if analysis["prompt_analysis"]["clarity"]["score"] < 0.7:
            strategies.append("improve_clarity")

        if analysis["prompt_analysis"]["specificity"]["score"] < 0.6:
            strategies.append("increase_specificity")

        # íš¨ìœ¨ì„± ê¸°ë°˜ ì „ëµ ì„ íƒ
        if analysis["efficiency_metrics"]["token_efficiency"]["score"] < 0.6:
            strategies.append("optimize_tokens")

        if analysis["efficiency_metrics"]["response_time"]["estimated"] > 5.0:
            strategies.append("reduce_complexity")

        # ëª©í‘œ ë©”íŠ¸ë¦­ ê¸°ë°˜ ì „ëµ ì„ íƒ
        if target_metrics:
            for metric, target in target_metrics.items():
                current_value = self.extract_metric_value(analysis, metric)
                if current_value < target:
                    strategies.extend(self.get_metric_specific_strategies(metric))

        return strategies

    def apply_optimization_strategy(self, prompt, strategy, context=None):
        """ìµœì í™” ì „ëµ ì ìš©"""
        strategy_implementations = {
            "improve_clarity": self.improve_clarity,
            "increase_specificity": self.increase_specificity,
            "optimize_tokens": self.optimize_tokens,
            "reduce_complexity": self.reduce_complexity
        }

        if strategy in strategy_implementations:
            return strategy_implementations[strategy](prompt, context)

        return {"optimized_prompt": prompt, "improvement": 0.0, "applied_changes": []}

    def improve_clarity(self, prompt, context):
        """ëª…í™•ì„± ê°œì„ """
        # ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì ì¸ í‘œí˜„ìœ¼ë¡œ ë³€í™˜
        clarity_improvements = {
            "ì¢‹ì€": "ë‹¤ìŒ ê¸°ì¤€ì„ ë§Œì¡±í•˜ëŠ”",
            "íš¨ìœ¨ì ì¸": "ì„±ëŠ¥ ëª©í‘œ(ì‘ë‹µ ì‹œê°„ 200ms ì´í•˜)ë¥¼ ë§Œì¡±í•˜ëŠ”",
            "ì ì ˆí•œ": "ìš”êµ¬ì‚¬í•­ì— ë¶€í•©í•˜ëŠ”",
            "ê°„ë‹¨í•œ": "ìœ ì§€ë³´ìˆ˜ê°€ ìš©ì´í•œ"
        }

        improved_prompt = prompt
        applied_changes = []

        for vague_term, clear_term in clarity_improvements.items():
            if vague_term in improved_prompt:
                improved_prompt = improved_prompt.replace(vague_term, clear_term)
                applied_changes.append(f"'{vague_term}' â†’ '{clear_term}'")

        # êµ¬ì¡° ê°œì„ 
        if not self.has_clear_structure(improved_prompt):
            improved_prompt = self.add_clear_structure(improved_prompt)
            applied_changes.append("ëª…í™•í•œ êµ¬ì¡° ì¶”ê°€")

        improvement = self.estimate_improvement(prompt, improved_prompt, "clarity")

        return {
            "optimized_prompt": improved_prompt,
            "improvement": improvement,
            "applied_changes": applied_changes
        }

    def has_clear_structure(self, prompt):
        """ëª…í™•í•œ êµ¬ì¡° í™•ì¸"""
        structure_indicators = ["#", "##", "1.", "2.", "- ìš”êµ¬ì‚¬í•­:", "ê¸°ëŠ¥:"]
        return any(indicator in prompt for indicator in structure_indicators)

    def add_clear_structure(self, prompt):
        """ëª…í™•í•œ êµ¬ì¡° ì¶”ê°€"""
        return f"""
# ì—­í•  ì •ì˜
[ì „ë¬¸ê°€ ì—­í• ì„ ëª…ì‹œí•˜ì„¸ìš”]

# ìš”êµ¬ì‚¬í•­
[êµ¬ì²´ì ì¸ ìš”êµ¬ì‚¬í•­ì„ ë‚˜ì—´í•˜ì„¸ìš”]

# ì œì•½ì‚¬í•­
[ê¸°ìˆ ì  ì œì•½ì‚¬í•­ì„ ëª…ì‹œí•˜ì„¸ìš”]

# ì¶œë ¥ í˜•ì‹
[ì›í•˜ëŠ” ì¶œë ¥ í˜•ì‹ì„ ì§€ì •í•˜ì„¸ìš”]

{prompt}
        """
```

## ğŸ¯ ì „ë¬¸ê°€ ìˆ˜ì¤€ì˜ íŒê³¼ ê¸°ë²•

### 1. ê³ ê¸‰ íŒ¨í„´ ë§ˆìŠ¤í„°ë¦¬

```python
# ì „ë¬¸ê°€ ìˆ˜ì¤€ í”„ë¡¬í”„íŠ¸ íŒ¨í„´
EXPERT_LEVEL_PATTERNS = {
    "meta_cognition": """
    # ë©”íƒ€ì¸ì§€ íŒ¨í„´
    ë‹¹ì‹ ì€ ìŠ¤ìŠ¤ë¡œì˜ ì‚¬ê³  ê³¼ì •ì„ ì¸ì§€í•˜ê³  ì¡°ì ˆí•  ìˆ˜ ìˆëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒ ì‘ì—…ì„ ìˆ˜í–‰í•  ë•Œ:
    1. **ë¬¸ì œ ì¬ì •ì˜**: ì£¼ì–´ì§„ ë¬¸ì œë¥¼ ë” ëª…í™•í•˜ê²Œ ì¬ì •ì˜
    2. **ì „ëµ ìˆ˜ë¦½**: ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ìµœì ì˜ ì „ëµ ì„ íƒ
    3. **ì‹¤í–‰ ëª¨ë‹ˆí„°ë§**: ê³¼ì •ì—ì„œ ì „ëµì˜ íš¨ê³¼ì„± ì§€ì†ì  í‰ê°€
    4. **ê²°ê³¼ í‰ê°€**: ìµœì¢… ê²°ê³¼ì˜ í’ˆì§ˆ ê°ê´€ì  í‰ê°€
    5. **ê³¼ì • ë°˜ì„±**: ì „ì²´ ê³¼ì •ì—ì„œ í•™ìŠµí•  ì  ì¶”ì¶œ

    ê° ë‹¨ê³„ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í‘œí˜„í•˜ê³ , ì™œ íŠ¹ì • ê²°ì •ì„ ë‚´ë ¸ëŠ”ì§€ ì„¤ëª…í•˜ì„¸ìš”.
    """,

    "socratic_method": """
    # ì†Œí¬ë¼í…ŒìŠ¤ì‹ ë¬¸ë‹µ íŒ¨í„´
    ë‹¹ì‹ ì€ ì†Œí¬ë¼í…ŒìŠ¤ì‹ ì§ˆë¬¸ì„ í†µí•´ ë¬¸ì œì˜ ë³¸ì§ˆì„ íƒêµ¬í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒ ì£¼ì œì— ëŒ€í•´ ì‹¬ì¸µì ìœ¼ë¡œ íƒêµ¬í•˜ê¸° ìœ„í•´:
    1. **ê¸°ë³¸ ê°€ì • ì§ˆë¬¸**: "ì™œ ê·¸ë ‡ê²Œ ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"
    2. **ì •ì˜ ëª…í™•í™”**: "Xì˜ ì •í™•í•œ ì˜ë¯¸ëŠ” ë¬´ì—‡ì…ë‹ˆê¹Œ?"
    3. **ì˜ˆì‹œ ìš”ì²­**: "êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
    4. **ëŒ€ì•ˆ íƒìƒ‰**: "ë‹¤ë¥¸ ê°€ëŠ¥ì„±ì€ ì—†ì„ê¹Œìš”?"
    5. **í•¨ì • ì§ˆë¬¸**: "ë§Œì•½ Yê°€ ì‚¬ì‹¤ì´ ì•„ë‹ˆë¼ë©´ ì–´ë–»ê²Œ ë˜ê² ìŠµë‹ˆê¹Œ?"

    ê° ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ í†µí•´ ì ì§„ì ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ì´í•´ë¥¼ ë„ì¶œí•˜ì„¸ìš”.
    """,

    "first_principles": """
    # ì œ1ì›ë¦¬ ì‚¬ê³  íŒ¨í„´
    ë‹¹ì‹ ì€ ë³µì¡í•œ ë¬¸ì œë¥¼ ê°€ì¥ ê¸°ë³¸ì ì¸ ì›ë¦¬ë¶€í„° ë¶„ì„í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

    ë‹¤ìŒ ë¬¸ì œë¥¼ ì œ1ì›ë¦¬ì—ì„œë¶€í„° ì ‘ê·¼í•˜ì—¬:
    1. **ë³¸ì§ˆì  ìš”ì†Œ ì‹ë³„**: ë¬¸ì œì˜ ê°€ì¥ ê¸°ë³¸ì´ ë˜ëŠ” ìš”ì†Œë“¤ ì¶”ì¶œ
    2. **ê°€ì • ë¶„í•´**: ê¸°ì¡´ì˜ ëª¨ë“  ê°€ì •ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ê²€í† 
    3. **ì›ë¦¬ ì¬êµ¬ì„±**: ê²€ì¦ëœ ì›ë¦¬ë“¤ì„ ìƒˆë¡œìš´ ë°©ì‹ìœ¼ë¡œ ì¡°í•©
    4. **ì°½ì˜ì  í•´ê²°ì±…**: ì „í†µì ì¸ ì ‘ê·¼ì„ ë„˜ì–´ì„  í˜ì‹ ì  í•´ê²°ì±…
    5. **í˜„ì‹¤ì„± ê²€ì¦**: í˜„ì‹¤ì  ì œì•½ ì•ˆì—ì„œì˜ ì‹¤í˜„ ê°€ëŠ¥ì„± í‰ê°€

    ê° ë‹¨ê³„ì˜ ë…¼ë¦¬ì  íë¦„ì„ ìƒì„¸íˆ ì„¤ëª…í•˜ì„¸ìš”.
    """
}
```

### 2. ë„ë©”ì¸ íŠ¹í™” ìµœì í™”

```python
# ë„ë©”ì¸ë³„ ìµœì í™” ê°€ì´ë“œ
DOMAIN_SPECIFIC_OPTIMIZATION = {
    "software_engineering": {
        "focus_areas": ["ì½”ë“œ í’ˆì§ˆ", "ì•„í‚¤í…ì²˜", "í…ŒìŠ¤íŠ¸", "ì„±ëŠ¥"],
        "optimal_patterns": [
            "TDD ì ‘ê·¼ë²•",
            "CLEAN ì½”ë“œ ì›ì¹™",
            "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ íŒ¨í„´",
            "SOLID ì›ì¹™ ì ìš©"
        ],
        "evaluation_criteria": [
            "ì½”ë“œ ê°€ë…ì„±",
            "ìœ ì§€ë³´ìˆ˜ì„±",
            "í™•ì¥ì„±",
            "í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€"
        ]
    },

    "data_science": {
        "focus_areas": ["ë°ì´í„° ì²˜ë¦¬", "ëª¨ë¸ë§", "ê²€ì¦", "í•´ì„"],
        "optimal_patterns": [
            "ê³¼í•™ì  ë°©ë²•ë¡ ",
            "í†µê³„ì  ê²€ì¦",
            "êµì°¨ ê²€ì¦",
            "íŠ¹ì„± ê³µí•™"
        ],
        "evaluation_criteria": [
            "ëª¨ë¸ ì •í™•ë„",
            "ì¬í˜„ì„±",
            "í•´ì„ ê°€ëŠ¥ì„±",
            "ì¼ë°˜í™” ì„±ëŠ¥"
        ]
    },

    "system_design": {
        "focus_areas": ["í™•ì¥ì„±", "ì•ˆì •ì„±", "ì„±ëŠ¥", "ë³´ì•ˆ"],
        "optimal_patterns": [
            "C4 ëª¨ë¸ë§",
            "ë¶€í•˜ ë¶„ì‚°",
            "ì¥ì•  ê²©ë¦¬",
            "CAP ì´ë¡  ì ìš©"
        ],
        "evaluation_criteria": [
            "ê°€ìš©ì„±",
            "ì²˜ë¦¬ëŸ‰",
            "ì‘ë‹µ ì‹œê°„",
            "ë¹„ìš© íš¨ìœ¨ì„±"
        ]
    }
}
```

## ğŸ“ˆ ì‹¤ì œ ì‚¬ë¡€ ì—°êµ¬

### 1. ì„±ê³µì ì¸ ìµœì í™” ì‚¬ë¡€

```python
# ì‹¤ì œ ìµœì í™” ì‚¬ë¡€
OPTIMIZATION_CASE_STUDIES = {
    "case_1": {
        "problem": "ë³µì¡í•œ API ê°œë°œ í”„ë¡¬í”„íŠ¸ê°€ ë„ˆë¬´ ê¸¸ê³  ëª¨í˜¸í•¨",
        "original_prompt_length": 850,
        "original_response_quality": 0.65,
        "optimization_applied": [
            "êµ¬ì¡°í™”ëœ í…œí”Œë¦¿ ì ìš©",
            "ë³€ìˆ˜ ì¹˜í™˜ ì‹œìŠ¤í…œ ë„ì…",
            "ë‹¨ê³„ë³„ ì ‘ê·¼ë²• ëª…ì‹œí™”"
        ],
        "optimized_prompt_length": 420,
        "optimized_response_quality": 0.89,
        "improvement": "51% í† í° ì ˆì•½, 37% í’ˆì§ˆ í–¥ìƒ"
    },

    "case_2": {
        "problem": "ë°ì´í„° ë¶„ì„ ìš”ì²­ì˜ ê²°ê³¼ë¬¼ì´ ì¼ê´€ì„±ì´ ì—†ìŒ",
        "original_response_consistency": 0.45,
        "optimization_applied": [
            "ì¶œë ¥ í˜•ì‹ í‘œì¤€í™”",
            "í‰ê°€ ê¸°ì¤€ ëª…ì‹œ",
            "ì˜ˆì‹œ ê¸°ë°˜ í•™ìŠµ íŒ¨í„´ ì¶”ê°€"
        ],
        "optimized_response_consistency": 0.92,
        "improvement": "104% ì¼ê´€ì„± í–¥ìƒ"
    }
}
```

## ğŸ“– ê²°ë¡  ë° ë‹¤ìŒ ë‹¨ê³„

í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ì€ ì§€ì†ì ì¸ ê°œì„ ê³¼ í•™ìŠµì´ í•„ìš”í•œ ê¸°ìˆ ì…ë‹ˆë‹¤. ì´ ê°€ì´ë“œì—ì„œ í•™ìŠµí•œ ê¸°ë²•ë“¤ì„ ì‹¤ì œ í”„ë¡œì íŠ¸ì— ì ìš©í•˜ê³ , ì„±ëŠ¥ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ì§€ì†ì ìœ¼ë¡œ ìµœì í™”í•˜ì„¸ìš”.

### í•µì‹¬ ìš”ì•½

1. **Claude 4.5 ìµœì í™”**: ëª¨ë¸ì˜ ê°•ì ì„ ìµœëŒ€í•œ í™œìš©í•˜ëŠ” êµ¬ì¡°í™”ëœ ì ‘ê·¼
2. **í† í° íš¨ìœ¨ì„±**: ê°„ê²°í•¨ê³¼ ëª…í™•ì„±ì˜ ê· í˜•ì„ í†µí•œ ë¹„ìš© íš¨ìœ¨ì„± ê·¹ëŒ€í™”
3. **ì„±ëŠ¥ ì¸¡ì •**: ë°ì´í„° ê¸°ë°˜ì˜ ê°ê´€ì ì¸ í‰ê°€ì™€ ê°œì„ 
4. **ì§€ì†ì  ìµœì í™”**: ìë™í™”ëœ ì‹œìŠ¤í…œì„ í†µí•œ ë°˜ë³µì  ê°œì„ 

### ì‹¤ì²œè¡ŒåŠ¨è®¡åˆ’

1. **ê¸°ì¡´ í”„ë¡¬í”„íŠ¸ ë¶„ì„**: í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í”„ë¡¬í”„íŠ¸ë“¤ì˜ í’ˆì§ˆ í‰ê°€
2. **ì ì§„ì  ê°œì„ **: ìš°ì„ ìˆœìœ„ê°€ ë†’ì€ í”„ë¡¬í”„íŠ¸ë¶€í„° ìµœì í™” ì ìš©
3. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§**: ì§€ì†ì ì¸ ì¸¡ì •ê³¼ ì¶”ì  ì‹œìŠ¤í…œ êµ¬ì¶•
4. **ì§€ì‹ ê³µìœ **: íŒ€ ë‚´ ë² ìŠ¤íŠ¸ í”„ë™í‹°ìŠ¤ ê³µìœ  ë° í‘œì¤€í™”

---

## ğŸ”— ê´€ë ¨ ìë£Œ

- [Anthropic Claude ìµœì‹  ê°€ì´ë“œ](https://docs.anthropic.com/claude/docs)
- [MoAI-ADK ì›Œí¬í”Œë¡œìš°](../core-concepts/workflow)
- [í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì»¤ë®¤ë‹ˆí‹°](https://github.com/dair-ai/Prompt-Engineering-Guide)
- [ê³ ê¸‰ íŒ¨í„´ ë¼ì´ë¸ŒëŸ¬ë¦¬](https://github.com/openai/openai-cookbook)