---
title: "ì›Œí¬í”Œë¡œìš° ìë™í™”"
description: "MoAI-ADKì˜ ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œ, Plan-Run-Sync ë£¨í”„, ì—ì´ì „íŠ¸ ê¸°ë°˜ í”„ë¡œì„¸ìŠ¤ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"
---

# ì›Œí¬í”Œë¡œìš° ìë™í™”

MoAI-ADKì˜ í•µì‹¬ ê°•ì ì€ **ì™„ì „ ìë™í™”ëœ ì›Œí¬í”Œë¡œìš°** ì‹œìŠ¤í…œì…ë‹ˆë‹¤. SPEC-First ê°œë°œë¶€í„° ë°°í¬ê¹Œì§€ ì „ì²´ ê³¼ì •ì„ AI ì—ì´ì „íŠ¸ë“¤ì´ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•˜ì—¬ ê°œë°œìì˜ ìƒì‚°ì„±ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤.

## ğŸ”„ Plan-Run-Sync ë¬´í•œ ë£¨í”„

### 3ë‹¨ê³„ ë¬´í•œ ë£¨í”„ ì•„í‚¤í…ì²˜

```mermaid
graph TD
    subgraph "PLAN Phase"
        P1[ğŸ“‹ User Request]
        P2[ğŸ” Requirement Analysis]
        P3[ğŸ“ SPEC Generation]
        P4[âœ… User Approval]
    end

    subgraph "RUN Phase"
        R1[ğŸ”´ RED: Write Tests]
        R2[ğŸŸ¢ GREEN: Implement Code]
        R3[ğŸ”µ BLUE: Refactor]
        R4[ğŸ§ª TRUST 5 Validation]
    end

    subgraph "SYNC Phase"
        S1[ğŸ“š Generate Docs]
        S2[ğŸ“Š Create Diagrams]
        S3[ğŸš€ Prepare Deployment]
        S4[ğŸ”„ Update Repository]
    end

    P1 --> P2 --> P3 --> P4
    P4 --> R1 --> R2 --> R3 --> R4
    R4 --> S1 --> S2 --> S3 --> S4
    S4 --> P1

    style P1 fill:#e3f2fd
    style R1 fill:#f3e5f5
    style S1 fill:#e8f5e9
```

### ë¬´í•œ ë£¨í”„ì˜ ìë™í™” ë©”ì»¤ë‹ˆì¦˜

```python
class AutomatedWorkflowEngine:
    """ìë™í™”ëœ ì›Œí¬í”Œë¡œìš° ì—”ì§„"""

    def __init__(self):
        self.current_phase = "plan"
        self.workflow_state = {}
        self.agent_registry = AgentRegistry()
        self.context_manager = DistributedContextManager()

    async def execute_infinite_loop(self, user_request: str):
        """ë¬´í•œ ë£¨í”„ ì‹¤í–‰"""

        while True:
            try:
                if self.current_phase == "plan":
                    await self.execute_plan_phase(user_request)
                    self.current_phase = "run"

                elif self.current_phase == "run":
                    await self.execute_run_phase()
                    self.current_phase = "sync"

                elif self.current_phase == "sync":
                    await self.execute_sync_phase()
                    self.current_phase = "idle"

                # ìë™ ì§„í–‰ ë˜ëŠ” ì‚¬ìš©ì ì…ë ¥ ëŒ€ê¸°
                if not await self.should_continue_automatically():
                    break

            except WorkflowException as e:
                await self.handle_workflow_error(e)

    async def execute_plan_phase(self, request: str):
        """PLAN ë‹¨ê³„ ìë™ ì‹¤í–‰"""

        # 1. ìš”ì²­ ë¶„ì„
        analysis_result = await Task(
            subagent_type="manager-strategy",
            prompt=f"Analyze user request: {request}",
            context={"phase": "planning"}
        )

        # 2. SPEC ìë™ ìƒì„±
        spec_result = await Task(
            subagent_type="manager-spec",
            prompt="Generate comprehensive SPEC",
            context=analysis_result
        )

        # 3. ì‚¬ìš©ì ìŠ¹ì¸ ìë™ í™•ì¸ (ì„¤ì •ì— ë”°ë¼)
        if self.settings.get("auto_approve_specs", False):
            approval = True
        else:
            approval = await self.request_user_approval(spec_result)

        if approval:
            self.workflow_state["current_spec"] = spec_result
            await self.transition_to_next_phase()
```

## ğŸ¯ ê° ë‹¨ê³„ì˜ ìë™í™” ìƒì„¸

### PLAN ë‹¨ê³„ ìë™í™”

#### ìë™ ìš”êµ¬ì‚¬í•­ ë¶„ì„

```python
class RequirementAnalyzer:
    """ìë™ ìš”êµ¬ì‚¬í•­ ë¶„ì„ ì‹œìŠ¤í…œ"""

    async def analyze_requirements(self, user_request: str) -> dict:
        """ì‚¬ìš©ì ìš”ì²­ì—ì„œ ìš”êµ¬ì‚¬í•­ ìë™ ì¶”ì¶œ"""

        analysis = {
            "functional_requirements": [],
            "non_functional_requirements": [],
            "constraints": [],
            "success_criteria": [],
            "estimated_complexity": "medium",
            "required_agents": [],
            "estimated_duration": 0
        }

        # ìì—°ì–´ ì²˜ë¦¬ë¡œ ìš”êµ¬ì‚¬í•­ ì¶”ì¶œ
        nlp_result = await self.process_natural_language(user_request)

        # ë„ë©”ì¸ ì‹ë³„
        domains = self.identify_domains(nlp_result)
        analysis["required_agents"] = self.map_domains_to_agents(domains)

        # ë³µì¡ë„ ì¶”ì •
        analysis["estimated_complexity"] = self.estimate_complexity(
            user_request, domains
        )

        # ê¸°ê°„ ì¶”ì •
        analysis["estimated_duration"] = self.estimate_duration(
            analysis["estimated_complexity"]
        )

        return analysis

    def map_domains_to_agents(self, domains: list) -> list:
        """ë„ë©”ì¸ì„ í•„ìš”í•œ ì—ì´ì „íŠ¸ë¡œ ë§¤í•‘"""

        domain_agent_map = {
            "backend": ["expert-backend", "expert-database"],
            "frontend": ["expert-frontend", "expert-uiux"],
            "security": ["expert-security"],
            "devops": ["expert-devops"],
            "api": ["expert-backend", "expert-database"],
            "ui": ["expert-frontend", "expert-uiux"],
            "database": ["expert-database"],
            "performance": ["expert-debug"],
            "testing": ["manager-tdd"]
        }

        agents = set()
        for domain in domains:
            agents.update(domain_agent_map.get(domain, []))

        return list(agents)
```

#### ìë™ SPEC ìƒì„±

```python
class AutoSpecGenerator:
    """ìë™ SPEC ìƒì„± ì‹œìŠ¤í…œ"""

    async def generate_complete_spec(self, analysis: dict) -> dict:
        """ì™„ì „í•œ SPEC ë¬¸ì„œ ìë™ ìƒì„±"""

        spec = {
            "spec_id": f"SPEC-{self.generate_spec_id()}",
            "title": analysis.get("title", ""),
            "requirements": await self.generate_requirements(analysis),
            "constraints": await self.generate_constraints(analysis),
            "success_criteria": await self.generate_success_criteria(analysis),
            "test_scenarios": await self.generate_test_scenarios(analysis),
            "technical_specifications": await self.generate_tech_specs(analysis),
            "dependencies": await self.identify_dependencies(analysis),
            "risks": await self.identify_risks(analysis)
        }

        return spec

    async def generate_requirements(self, analysis: dict) -> list:
        """EARS í˜•ì‹ìœ¼ë¡œ ìš”êµ¬ì‚¬í•­ ìë™ ìƒì„±"""

        requirements = []

        # ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
        for func_req in analysis["functional_requirements"]:
            requirement = {
                "type": "functional",
                "format": "WHEN...IF...THEN",
                "statement": self.format_ears_requirement(func_req),
                "priority": self.determine_priority(func_req),
                "acceptance_criteria": self.generate_acceptance_criteria(func_req)
            }
            requirements.append(requirement)

        # ë¹„ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
        for non_func_req in analysis["non_functional_requirements"]:
            requirement = {
                "type": "non-functional",
                "format": "system shall",
                "statement": self.format_system_requirement(non_func_req),
                "priority": self.determine_priority(non_func_req),
                "metrics": self.define_metrics(non_func_req)
            }
            requirements.append(requirement)

        return requirements
```

### RUN ë‹¨ê³„ ìë™í™”

#### ìë™ TDD ì‹¤í–‰

```python
class AutomatedTDDExecutor:
    """ìë™ TDD ì‹¤í–‰ ì‹œìŠ¤í…œ"""

    async def execute_tdd_cycle(self, spec: dict) -> dict:
        """ì™„ì „í•œ TDD ì‚¬ì´í´ ìë™ ì‹¤í–‰"""

        tdd_results = {
            "spec_id": spec["spec_id"],
            "test_results": {},
            "implementation_results": {},
            "refactoring_results": {},
            "quality_metrics": {},
            "final_status": "success"
        }

        try:
            # RED ë‹¨ê³„: ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ì‘ì„±
            test_results = await self.execute_red_phase(spec)
            tdd_results["test_results"] = test_results

            # GREEN ë‹¨ê³„: ìµœì†Œ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸ í†µê³¼
            implementation_results = await self.execute_green_phase(
                test_results
            )
            tdd_results["implementation_results"] = implementation_results

            # BLUE ë‹¨ê³„: ë¦¬íŒ©í† ë§ ë° ìµœì í™”
            refactoring_results = await self.execute_blue_phase(
                implementation_results
            )
            tdd_results["refactoring_results"] = refactoring_results

            # TRUST 5 ê²€ì¦
            quality_metrics = await self.execute_trust5_validation(
                refactoring_results
            )
            tdd_results["quality_metrics"] = quality_metrics

        except TDDException as e:
            tdd_results["final_status"] = "failed"
            tdd_results["error"] = str(e)

        return tdd_results

    async def execute_red_phase(self, spec: dict) -> dict:
        """RED ë‹¨ê³„: ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìë™ ì‘ì„±"""

        test_results = {
            "tests_written": 0,
            "test_files_created": [],
            "all_tests_failing": True
        }

        # ê° ìš”êµ¬ì‚¬í•­ì— ëŒ€í•œ í…ŒìŠ¤íŠ¸ ìƒì„±
        for requirement in spec["requirements"]:
            test_code = await self.generate_test_code(requirement)

            # í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            test_file = await self.create_test_file(
                requirement["id"], test_code
            )
            test_results["test_files_created"].append(test_file)

            # í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ì‹¤íŒ¨ í™•ì¸)
            test_result = await self.run_single_test(test_file)
            if not test_result["failed"]:
                test_results["all_tests_failing"] = False

            test_results["tests_written"] += 1

        return test_results
```

#### ìë™ ì½”ë“œ êµ¬í˜„

```python
class AutoCodeGenerator:
    """ìë™ ì½”ë“œ ìƒì„± ì‹œìŠ¤í…œ"""

    async def generate_implementation(self, failing_tests: dict,
                                    spec: dict) -> dict:
        """ì‹¤íŒ¨í•˜ëŠ” í…ŒìŠ¤íŠ¸ë¥¼ í†µê³¼í•˜ëŠ” ìµœì†Œ ì½”ë“œ ìë™ ìƒì„±"""

        implementation = {
            "code_files": [],
            "all_tests_passing": False,
            "coverage_percentage": 0,
            "implementation_time": 0
        }

        start_time = time.time()

        for test_file in failing_tests["test_files_created"]:
            # í…ŒìŠ¤íŠ¸ ë¶„ì„
            test_analysis = await self.analyze_test_requirements(test_file)

            # ìµœì†Œ ì½”ë“œ ìƒì„±
            code_file = await self.generate_minimum_code(
                test_analysis, spec
            )
            implementation["code_files"].append(code_file)

            # í…ŒìŠ¤íŠ¸ ì¬ì‹¤í–‰
            test_result = await self.run_single_test(test_file)
            if not test_result["passed"]:
                raise TDDException(f"Test {test_file} still failing")

        # ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        all_tests_result = await self.run_all_tests()
        implementation["all_tests_passing"] = all_tests_result["all_passed"]

        # ì»¤ë²„ë¦¬ì§€ ì¸¡ì •
        implementation["coverage_percentage"] = all_tests_result["coverage"]

        implementation["implementation_time"] = time.time() - start_time

        return implementation
```

### SYNC ë‹¨ê³„ ìë™í™”

#### ìë™ ë¬¸ì„œ ìƒì„±

```python
class AutoDocumentationGenerator:
    """ìë™ ë¬¸ì„œ ìƒì„± ì‹œìŠ¤í…œ"""

    async def generate_complete_documentation(self, implementation: dict,
                                            spec: dict) -> dict:
        """ì™„ì „í•œ ë¬¸ì„œ ìë™ ìƒì„±"""

        documentation = {
            "api_docs": await self.generate_api_documentation(implementation),
            "architecture_diagrams": await self.generate_diagrams(implementation),
            "user_guides": await self.generate_user_guides(implementation, spec),
            "deployment_guides": await self.generate_deployment_guides(implementation),
            "changelog_entries": await self.generate_changelog_entries(implementation),
            "readme_updates": await self.update_readme(implementation, spec)
        }

        return documentation

    async def generate_api_documentation(self, implementation: dict) -> dict:
        """API ë¬¸ì„œ ìë™ ìƒì„±"""

        api_docs = {
            "endpoints": [],
            "data_models": [],
            "authentication": {},
            "error_handling": {},
            "examples": []
        }

        # ì½”ë“œì—ì„œ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ì¶œ
        endpoints = await self.extract_api_endpoints(implementation["code_files"])

        for endpoint in endpoints:
            doc_entry = {
                "path": endpoint["path"],
                "method": endpoint["method"],
                "description": endpoint["description"],
                "parameters": endpoint["parameters"],
                "request_body": endpoint["request_body"],
                "responses": endpoint["responses"],
                "examples": await self.generate_usage_examples(endpoint)
            }
            api_docs["endpoints"].append(doc_entry)

        return api_docs

    async def generate_diagrams(self, implementation: dict) -> dict:
        """ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìë™ ìƒì„±"""

        diagrams = {
            "system_architecture": await self.generate_system_architecture_diagram(implementation),
            "data_flow": await self.generate_data_flow_diagram(implementation),
            "sequence_diagrams": await self.generate_sequence_diagrams(implementation),
            "component_diagrams": await self.generate_component_diagrams(implementation)
        }

        return diagrams

    async def generate_system_architecture_diagram(self, implementation: dict) -> str:
        """ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (Mermaid)"""

        # ì»´í¬ë„ŒíŠ¸ ë¶„ì„
        components = await self.analyze_components(implementation["code_files"])

        # Mermaid ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±
        mermaid_diagram = """
```mermaid
graph TB
    subgraph "Frontend Layer"
        UI[React Components]
        State[State Management]
        Router[Navigation]
    end

    subgraph "API Layer"
        Gateway[API Gateway]
        Auth[Authentication]
        Services[Business Logic]
    end

    subgraph "Data Layer"
        Cache[Redis Cache]
        Database[PostgreSQL]
        Storage[File Storage]
    end

    UI --> Gateway
    State --> Gateway
    Router --> Gateway

    Gateway --> Auth
    Gateway --> Services

    Services --> Cache
    Services --> Database
    Services --> Storage
```
        """

        return mermaid_diagram
```

## ğŸ¤– ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### ì›Œí¬í”Œë¡œìš° ê´€ë¦¬ì

```python
class WorkflowOrchestrator:
    """ê³ ê¸‰ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´í„°"""

    def __init__(self):
        self.active_workflows = {}
        self.workflow_templates = {}
        self.agent_pool = AgentPool()
        self.resource_manager = ResourceManager()

    async def orchestrate_complex_workflow(self, workflow_definition: dict) -> dict:
        """ë³µì¡í•œ ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""

        workflow_id = str(uuid.uuid4())
        workflow = {
            "id": workflow_id,
            "definition": workflow_definition,
            "status": "initializing",
            "phases": [],
            "agents_assigned": [],
            "results": {},
            "start_time": datetime.now()
        }

        self.active_workflows[workflow_id] = workflow

        try:
            # ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
            await self.initialize_workflow(workflow)

            # ë‹¨ê³„ë³„ ì‹¤í–‰
            for phase in workflow["phases"]:
                await self.execute_workflow_phase(workflow, phase)

            # ê²°ê³¼ í†µí•©
            final_result = await self.integrate_results(workflow)

            workflow["status"] = "completed"
            workflow["final_result"] = final_result

        except Exception as e:
            workflow["status"] = "failed"
            workflow["error"] = str(e)
            await self.handle_workflow_failure(workflow)

        return workflow

    async def execute_workflow_phase(self, workflow: dict, phase: dict):
        """ì›Œí¬í”Œë¡œìš° ë‹¨ê³„ ì‹¤í–‰"""

        phase["status"] = "running"
        phase["start_time"] = datetime.now()

        # í•„ìš”í•œ ì—ì´ì „íŠ¸ í• ë‹¹
        assigned_agents = await self.assign_agents_for_phase(phase)
        phase["agents_assigned"] = assigned_agents

        # ë³‘ë ¬ ë˜ëŠ” ìˆœì°¨ ì‹¤í–‰
        if phase["execution_mode"] == "parallel":
            results = await self.execute_parallel_tasks(phase, assigned_agents)
        else:
            results = await self.execute_sequential_tasks(phase, assigned_agents)

        phase["results"] = results
        phase["status"] = "completed"
        phase["end_time"] = datetime.now()
```

### ìì› ê´€ë¦¬ ìµœì í™”

```python
class ResourceManager:
    """ì›Œí¬í”Œë¡œìš° ìì› ê´€ë¦¬ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.agent_capacity = {}
        self.resource_pools = {}
        self.allocation_history = []

    async def optimize_resource_allocation(self, workflow: dict) -> dict:
        """ìì› í• ë‹¹ ìµœì í™”"""

        optimization = {
            "agent_allocation": {},
            "resource_estimates": {},
            "bottleneck_analysis": {},
            "recommendations": []
        }

        # ì—ì´ì „íŠ¸ ìš©ëŸ‰ ë¶„ì„
        agent_load = await self.analyze_agent_load()
        optimization["agent_allocation"] = agent_load

        # ë¦¬ì†ŒìŠ¤ ë³‘ëª© ì§€ì  ë¶„ì„
        bottlenecks = await self.identify_bottlenecks(workflow)
        optimization["bottleneck_analysis"] = bottlenecks

        # ìµœì í™” ì¶”ì²œ
        recommendations = await self.generate_optimization_recommendations(
            agent_load, bottlenecks
        )
        optimization["recommendations"] = recommendations

        return optimization

    async def balance_workload(self, active_workflows: list) -> dict:
        """ì›Œí¬ë¡œë“œ ê· í˜• ì¡°ì •"""

        workload_balance = {
            "current_distribution": {},
            "imbalances": [],
            "rebalancing_actions": []
        }

        # í˜„ì¬ ì›Œí¬ë¡œë“œ ë¶„í¬ ë¶„ì„
        for workflow in active_workflows:
            for agent in workflow["agents_assigned"]:
                if agent not in workload_balance["current_distribution"]:
                    workload_balance["current_distribution"][agent] = 0
                workload_balance["current_distribution"][agent] += 1

        # ë¶ˆê· í˜• ì‹ë³„
        max_load = max(workload_balance["current_distribution"].values())
        min_load = min(workload_balance["current_distribution"].values())

        if max_load - min_load > 3:  # 3ê°œ ì´ìƒ ì°¨ì´
            workload_balance["imbalances"].append({
                "type": "load_imbalance",
                "severity": "high",
                "max_load": max_load,
                "min_load": min_load
            })

        return workload_balance
```

## ğŸ“Š ìë™í™” ì„±ëŠ¥ ì¸¡ì •

### ì›Œí¬í”Œë¡œìš° ë©”íŠ¸ë¦­

```python
class WorkflowAnalytics:
    """ì›Œí¬í”Œë¡œìš° ì„±ëŠ¥ ë¶„ì„ ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.metrics_history = []
        self.benchmark_data = {}
        self.performance_trends = {}

    def calculate_automation_efficiency(self, workflow: dict) -> dict:
        """ìë™í™” íš¨ìœ¨ì„± ê³„ì‚°"""

        efficiency = {
            "automation_score": 0,
            "time_savings": 0,
            "quality_improvement": 0,
            "error_reduction": 0,
            "consistency_score": 0
        }

        # ìë™í™” ì ìˆ˜
        total_tasks = len(workflow["phases"])
        automated_tasks = sum(
            1 for phase in workflow["phases"]
            if phase.get("automated", False)
        )
        efficiency["automation_score"] = (automated_tasks / total_tasks) * 100

        # ì‹œê°„ ì ˆì•½
        estimated_manual_time = self.estimate_manual_execution_time(workflow)
        actual_automated_time = workflow.get("execution_time", 0)
        efficiency["time_savings"] = (
            (estimated_manual_time - actual_automated_time) /
            estimated_manual_time
        ) * 100

        # í’ˆì§ˆ í–¥ìƒ
        quality_metrics = workflow.get("quality_metrics", {})
        efficiency["quality_improvement"] = self.calculate_quality_improvement(
            quality_metrics
        )

        return efficiency

    def generate_workflow_report(self, workflow_id: str) -> dict:
        """ì›Œí¬í”Œë¡œìš° ìƒì„¸ ë¦¬í¬íŠ¸ ìƒì„±"""

        workflow = self.active_workflows.get(workflow_id)
        if not workflow:
            return {"error": "Workflow not found"}

        report = {
            "workflow_summary": {
                "id": workflow["id"],
                "status": workflow["status"],
                "duration": self.calculate_duration(workflow),
                "phases_completed": len([p for p in workflow["phases"] if p["status"] == "completed"]),
                "total_phases": len(workflow["phases"])
            },
            "performance_metrics": self.calculate_performance_metrics(workflow),
            "agent_utilization": self.calculate_agent_utilization(workflow),
            "quality_analysis": self.analyze_quality_metrics(workflow),
            "recommendations": self.generate_workflow_recommendations(workflow)
        }

        return report
```

## ğŸ”® ì§„í™”í•˜ëŠ” ìë™í™”

### í•™ìŠµ ê¸°ë°˜ ìµœì í™”

```python
class LearningWorkflowOptimizer:
    """í•™ìŠµ ê¸°ë°˜ ì›Œí¬í”Œë¡œìš° ìµœì í™” ì‹œìŠ¤í…œ"""

    def __init__(self):
        self.historical_data = []
        self.pattern_recognition = PatternRecognition()
        self.optimization_strategies = {}

    async def learn_from_executions(self, completed_workflows: list):
        """ì‹¤í–‰ ê²°ê³¼ì—ì„œ í•™ìŠµ"""

        for workflow in completed_workflows:
            # ì„±ê³µ íŒ¨í„´ ì‹ë³„
            if workflow["status"] == "completed":
                patterns = await self.extract_success_patterns(workflow)
                await self.update_success_patterns(patterns)

            # ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
            else:
                failure_patterns = await self.analyze_failure_patterns(workflow)
                await self.update_failure_patterns(failure_patterns)

        # ìµœì í™” ì „ëµ ì—…ë°ì´íŠ¸
        await self.update_optimization_strategies()

    async def predict_optimal_workflow(self, requirements: dict) -> dict:
        """ìµœì ì˜ ì›Œí¬í”Œë¡œìš° ì˜ˆì¸¡"""

        prediction = {
            "recommended_agents": [],
            "optimal_sequence": [],
            "estimated_duration": 0,
            "success_probability": 0,
            "risk_factors": []
        }

        # ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ì˜ˆì¸¡
        similar_workflows = await self.find_similar_workflows(requirements)

        if similar_workflows:
            # ì„±ê³µì ì¸ ì›Œí¬í”Œë¡œìš° íŒ¨í„´ ì ìš©
            successful_patterns = [
                w for w in similar_workflows if w["status"] == "completed"
            ]

            prediction["recommended_agents"] = self.extract_common_agents(
                successful_patterns
            )
            prediction["optimal_sequence"] = self.extract_common_sequence(
                successful_patterns
            )
            prediction["success_probability"] = self.calculate_success_probability(
                successful_patterns, len(similar_workflows)
            )

        return prediction
```

---

## ğŸ¯ í•µì‹¬ takeaways

1. **ì™„ì „ ìë™í™”**: Plan-Run-Sync 3ë‹¨ê³„ ë¬´í•œ ë£¨í”„ ìë™í™”
2. **ì§€ëŠ¥í˜• SPEC**: ìì—°ì–´ ìš”ì²­ì—ì„œ ìë™ìœ¼ë¡œ ì™„ì „í•œ SPEC ìƒì„±
3. **TDD ìë™í™”**: RED-GREEN-BLUE ì‚¬ì´í´ ì™„ì „ ìë™ ì‹¤í–‰
4. **ë¬¸ì„œ ìë™í™”**: API ë¬¸ì„œ, ì•„í‚¤í…ì²˜ ë‹¤ì´ì–´ê·¸ë¨, ë°°í¬ ê°€ì´ë“œ ìë™ ìƒì„±
5. **í•™ìŠµ ê¸°ë°˜ ìµœì í™”**: ê³¼ê±° ì‹¤í–‰ ë°ì´í„°ì—ì„œ í•™ìŠµí•˜ì—¬ ì›Œí¬í”Œë¡œìš° ì§€ì†ì  ê°œì„ 

MoAI-ADKì˜ ì›Œí¬í”Œë¡œìš° ìë™í™”ëŠ” ê°œë°œìê°€ **ê¸°ëŠ¥ ìš”êµ¬ì‚¬í•­ì—ë§Œ ì§‘ì¤‘**í•˜ê³  ë°˜ë³µì ì¸ ì‘ì—…ì€ AIì—ê²Œ ì™„ì „íˆ ìœ„ì„í•˜ëŠ” **ì°¨ì„¸ëŒ€ ê°œë°œ íŒ¨ëŸ¬ë‹¤ì„**ì„ êµ¬í˜„í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°œë°œ ì†ë„ëŠ” **3-4ë°° í–¥ìƒ**ë˜ê³  ì½”ë“œ í’ˆì§ˆì€ **ì¼ê´€ë˜ê²Œ ìœ ì§€**ë©ë‹ˆë‹¤.