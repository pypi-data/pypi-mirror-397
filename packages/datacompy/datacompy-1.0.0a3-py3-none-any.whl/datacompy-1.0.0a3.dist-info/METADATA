Metadata-Version: 2.4
Name: datacompy
Version: 1.0.0a3
Summary: Dataframe comparisons in Python
Author-email: Faisal Dosani <faisal.dosani@capitalone.com>, Raymond Haffar <raymond.haffar@capitalone.com>, Jacob Dawang <jacob.dawang@capitalone.com>
Maintainer-email: Faisal Dosani <faisal.dosani@capitalone.com>, Jacob Dawang <jacob.dawang@capitalone.com>, Raymond Haffar <raymond.haffar@capitalone.com>
Project-URL: Bug Tracker, https://github.com/capitalone/datacompy/issues
Project-URL: Documentation, https://capitalone.github.io/datacompy/
Project-URL: Homepage, https://github.com/capitalone/datacompy
Project-URL: Repository, https://github.com/capitalone/datacompy.git
Project-URL: Source Code, https://github.com/capitalone/datacompy
Classifier: Intended Audience :: Developers
Classifier: Natural Language :: English
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3 :: Only
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Programming Language :: Python :: 3.13
Requires-Python: >=3.10.0
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: jinja2>=3
Requires-Dist: numpy<=2.3.4,>=1.26.4
Requires-Dist: ordered-set<=4.1,>=4.0.2
Requires-Dist: pandas<=2.3.3,>=2.2
Requires-Dist: polars[pandas]<=1.36.1,>=0.20.4
Provides-Extra: build
Requires-Dist: build; extra == "build"
Requires-Dist: twine; extra == "build"
Requires-Dist: wheel; extra == "build"
Provides-Extra: dev
Requires-Dist: datacompy[build]; extra == "dev"
Requires-Dist: datacompy[docs]; extra == "dev"
Requires-Dist: datacompy[qa]; extra == "dev"
Requires-Dist: datacompy[snowflake]; extra == "dev"
Requires-Dist: datacompy[spark]; extra == "dev"
Requires-Dist: datacompy[tests-spark]; extra == "dev"
Requires-Dist: datacompy[tests]; extra == "dev"
Provides-Extra: docs
Requires-Dist: furo; extra == "docs"
Requires-Dist: myst-parser; extra == "docs"
Requires-Dist: sphinx; extra == "docs"
Provides-Extra: edgetest
Requires-Dist: edgetest; extra == "edgetest"
Requires-Dist: edgetest-conda; extra == "edgetest"
Provides-Extra: qa
Requires-Dist: mypy; extra == "qa"
Requires-Dist: pandas-stubs; extra == "qa"
Requires-Dist: pre-commit; extra == "qa"
Requires-Dist: ruff; extra == "qa"
Provides-Extra: snowflake
Requires-Dist: snowflake-snowpark-python<=1.33,>=1.26; extra == "snowflake"
Provides-Extra: spark
Requires-Dist: pyspark[connect]<4,>=3.5; python_version <= "3.11" and extra == "spark"
Requires-Dist: pyspark[connect]>=4; python_version >= "3.12" and extra == "spark"
Provides-Extra: tests
Requires-Dist: pytest; extra == "tests"
Requires-Dist: pytest-cov; extra == "tests"
Provides-Extra: tests-spark
Requires-Dist: pytest-spark; extra == "tests-spark"
Dynamic: license-file

# DataComPy

![PyPI - Python Version](https://img.shields.io/pypi/pyversions/datacompy)
[![Ruff](https://img.shields.io/endpoint?url=https://raw.githubusercontent.com/astral-sh/ruff/main/assets/badge/v2.json)](https://github.com/astral-sh/ruff)
[![PyPI version](https://badge.fury.io/py/datacompy.svg)](https://badge.fury.io/py/datacompy)
[![Anaconda-Server Badge](https://anaconda.org/conda-forge/datacompy/badges/version.svg)](https://anaconda.org/conda-forge/datacompy)
![PyPI - Downloads](https://img.shields.io/pypi/dm/datacompy)


DataComPy is a package to compare two DataFrames (or tables) such as Pandas, Spark, Polars, and
even Snowflake. Originally it was created to be something of a replacement
for SAS's ``PROC COMPARE`` for Pandas DataFrames with some more functionality than
just ``Pandas.DataFrame.equals(Pandas.DataFrame)`` (in that it prints out some stats,
and lets you tweak how accurate matches have to be). Supported types include:

- Pandas
- Polars
- Spark
- Snowflake

> [!IMPORTANT]
> datacompy is progressing towards a `v1` release. During this transition, a `support/0.19.x` branch will be maintained solely for `v0.19.x` users.
> This branch will only receive dependency updates and critical bug fixes; no new features will be added.
> All new feature development should target the `v1` branches (`develop` and eventually `main`).


## Quick Installation

```shell
pip install datacompy
```

or

```shell
conda install datacompy
```

### Installing extras

If you would like to use Spark or any other backends please make sure you install via extras:

```shell
pip install datacompy[spark]
pip install datacompy[snowflake]

```


## Supported backends

- Pandas: ([See documentation](https://capitalone.github.io/datacompy/pandas_usage.html))
- Spark: ([See documentation](https://capitalone.github.io/datacompy/spark_usage.html))
- Polars: ([See documentation](https://capitalone.github.io/datacompy/polars_usage.html))
- Snowflake/Snowpark: ([See documentation](https://capitalone.github.io/datacompy/snowflake_usage.html))


## Contributors

We welcome and appreciate your contributions! Before we can accept any contributions, we ask that you please be sure to
sign the [Contributor License Agreement (CLA)](https://cla-assistant.io/capitalone/datacompy).

This project adheres to the [Open Source Code of Conduct](https://developer.capitalone.com/resources/code-of-conduct/).
By participating, you are expected to honor this code.


## Roadmap

Roadmap details can be found [here](https://github.com/capitalone/datacompy/blob/develop/ROADMAP.rst)
