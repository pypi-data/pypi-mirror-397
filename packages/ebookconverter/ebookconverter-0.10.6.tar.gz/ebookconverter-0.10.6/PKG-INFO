Metadata-Version: 2.1
Name: ebookconverter
Version: 0.10.6
Summary: The Project Gutenberg tool to orchestrate ebook generation.
Home-page: https://github.com/gutenbergtools/ebookconverter/
Author: Eric Hellman
Author-email: eric@hellman.org
License: GPL v3
Platform: OS-independent
Classifier: License :: OSI Approved :: GNU General Public License (GPL)
Classifier: Environment :: Console
Classifier: Operating System :: OS Independent
Classifier: Intended Audience :: Other Audience
Classifier: Development Status :: 4 - Beta
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3.9
License-File: LICENSE
Requires-Dist: ebookmaker>=0.13.7
Requires-Dist: setproctitle==1.1.10
Requires-Dist: requests_oauthlib>=1.2.0
Requires-Dist: rdflib>=4.2.2
Requires-Dist: qrcode>=6.1
Requires-Dist: libgutenberg[postgres]>=0.10.33
Requires-Dist: pymarc>=5.2.3

# ebookconverter
code that orchestrates ebook conversion for project gutenberg


EbookConverter manages the creation and update of ebook assets for Project Gutenberg. It uses a postgres database to keep track of both ebook metadata and ebook files. the postgress database is managed by the libgutenberg package.

The cron-rebuild-files.sh script runs as a cron job, rebuilding 2100 books per day, so as to rebuild every book roughly once a month.

ebookconverter talks to the gutenberg database to build a list of ebookmaker jobs. These jobs require some metadata about the book, and a target file to process.

ebookconverter expects source files to be in numbered directories in a 'files' directory. The location of the files directory is given by the FILESDIR config parameter.

Config parameters should be set in a file at /etc/ebookconverter.conf or ~/.ebookconverter

ebookconverter has been tested on Python 3.9.

## Installing

`pipenv install ebookconverter`

The following directories should exist:
    - $PRIVATE/logs
    - $PRIVATE/logs/json
    - $PRIVATE/logs/json/backup
    - $PRIVATE/logs/notifications
    - $PRIVATE/logs/dopush
    - $PRIVATE/logs/dopush/backup

## Using the EbookConverter Scripts

you can run these commands either by first entering a `pipenv shell` or on a single line using `pipenv run <command> <args>`

Rebuild one or more books
`ebookconverter --range=<start>-<finish> --build=all`
`ebookconverter --range=<booknumber>  --build=all`
`ebookconverter --range=<booknumber>  --build=all --validate`

Reload metadata from a workflow json file (use with care, it will overwrite any metadata in the DB)
`reload_workflow <booknumber>`

Regenerate the csv file
`make_csv`

Look for any ebooks with changed files in the last X days and then check if any of the previously known files of that ebook have been deleted.

`autodelete`
