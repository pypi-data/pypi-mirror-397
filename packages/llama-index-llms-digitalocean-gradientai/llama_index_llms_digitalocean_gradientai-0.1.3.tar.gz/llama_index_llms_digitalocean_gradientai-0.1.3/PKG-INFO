Metadata-Version: 2.4
Name: llama-index-llms-digitalocean-gradientai
Version: 0.1.3
Summary: LlamaIndex integration for DigitalOcean Gradient AI
Home-page: https://github.com/bnarasimha21/llamaindex-digitalocean-gradientai
Author: Narasimha Badrinath
Author-email: Narasimha Badrinath <bnarasimha21@gmail.com>
License-Expression: MIT
Project-URL: Homepage, https://github.com/bnarasimha21/llamaindex-digitalocean-gradientai
Project-URL: Documentation, https://github.com/bnarasimha21/llamaindex-digitalocean-gradientai#readme
Project-URL: Repository, https://github.com/bnarasimha21/llamaindex-digitalocean-gradientai
Project-URL: Issues, https://github.com/bnarasimha21/llamaindex-digitalocean-gradientai/issues
Keywords: llamaindex,gradient,gradientai,llm,rag,digitalocean
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: llama-index-core>=0.10.0
Requires-Dist: gradient>=3.8.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-asyncio>=0.21.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: ruff>=0.1.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Requires-Dist: pre-commit>=3.0.0; extra == "dev"
Requires-Dist: python-dotenv>=1.0.0; extra == "dev"
Dynamic: author
Dynamic: home-page
Dynamic: license-file
Dynamic: requires-python

# llama-index-llms-digitalocean-gradientai

LlamaIndex integration for DigitalOcean Gradient AI.

## Installation

```bash
pip install llama-index-llms-digitalocean-gradientai
```

This package uses the official [gradient](https://github.com/digitalocean/gradient-python) SDK (PyPI package: `gradient`) under the hood; it is installed automatically as a dependency.

## Usage

### Basic Usage

```python
from llama_index.llms.digitalocean.gradientai import DigitalOceanGradientAILLM

llm = DigitalOceanGradientAILLM(
    model="openai-gpt-oss-120b",
    api_key="your-api-key",
    workspace_id="your-workspace-id"
)

response = llm.complete("What is DigitalOcean Gradient?")
print(response)
```

### Chat Interface

```python
from llama_index.core.llms import ChatMessage
from llama_index.llms.digitalocean.gradientai import DigitalOceanGradientAILLM

llm = DigitalOceanGradientAILLM(
    model="openai-gpt-oss-120b",
    api_key="your-api-key",
    workspace_id="your-workspace-id"
)

messages = [
    ChatMessage(role="system", content="You are a helpful assistant."),
    ChatMessage(role="user", content="What is the capital of France?")
]

response = llm.chat(messages)
print(response.message.content)
```

### Streaming

```python
from llama_index.llms.digitalocean.gradientai import DigitalOceanGradientAILLM

llm = DigitalOceanGradientAILLM(
    model="meta-llama-3-70b-instruct",
    api_key="your-api-key",
    workspace_id="your-workspace-id"
)

response_gen = llm.stream_complete("Tell me a story about AI:")
for delta in response_gen:
    print(delta.delta, end="", flush=True)
```

### Async Usage

```python
import asyncio
from llama_index.llms.gradient import DigitalOceanGradientAILLM

async def main():
llm = DigitalOceanGradientAILLM(
        model="meta-llama-3-70b-instruct",
        api_key="your-api-key",
        workspace_id="your-workspace-id"
    )
    response = await llm.acomplete("What is Gradient?")
    print(response)

asyncio.run(main())
```

### With RAG Pipeline

```python
from llama_index.core import VectorStoreIndex, Document
from llama_index.llms.digitalocean.gradientai import DigitalOceanGradientAILLM

llm = DigitalOceanGradientAILLM(
    model="meta-llama-3-70b-instruct",
    api_key="your-api-key",
    workspace_id="your-workspace-id"
)

documents = [Document(text="DigitalOcean Gradient is a managed LLM API service...")]
index = VectorStoreIndex.from_documents(documents)
query_engine = index.as_query_engine(llm=llm)
response = query_engine.query("What is Gradient?")
print(response)
```

## Package Structure

```
llama-index-llms-digitalocean-gradientai/
├── llama_index/
│   └── llms/
│       └── digitalocean/
│           └── gradientai/
│               ├── __init__.py
│               └── base.py
├── setup.py
├── pyproject.toml
├── README.md
└── requirements.txt
```

## License

MIT
