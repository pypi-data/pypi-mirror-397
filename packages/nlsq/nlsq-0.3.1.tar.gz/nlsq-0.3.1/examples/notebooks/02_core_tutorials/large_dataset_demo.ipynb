{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò Large Dataset Fitting: Handle Millions of Data Points> Master NLSQ's strategies for fitting curves to datasets too large for memory‚è±Ô∏è **20-30 minutes** | üìä **Level: ‚óè‚óè‚óã Intermediate** | üè∑Ô∏è **Memory Management** | **Performance** | **Scalability**[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/imewei/NLSQ/blob/main/examples/notebooks/02_core_tutorials/large_dataset_demo.ipynb)---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üó∫Ô∏è Learning Path**You are here:** Core Tutorials > **Large Dataset Fitting**```Getting Started ‚Üí Quickstart ‚Üí [Large Dataset Demo] ‚Üê You are here ‚Üí GPU Optimization```**Prerequisites:**- ‚úì Completed [NLSQ Quickstart](../01_getting_started/nlsq_quickstart.ipynb)- ‚úì Familiar with NumPy arrays and JAX basics- ‚úì Understand basic curve fitting concepts- ‚úì Knowledge of memory constraints in data processing**Recommended flow:**- ‚Üê **Previous:** [NLSQ Quickstart](../01_getting_started/nlsq_quickstart.ipynb)- ‚Üí **Next (Recommended):** [GPU Optimization Deep Dive](../03_advanced/gpu_optimization_deep_dive.ipynb)- ‚Üí **Alternative:** [Performance Optimization](performance_optimization_demo.ipynb)---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ What You'll LearnAfter completing this tutorial, you will be able to:- ‚úì **Estimate memory requirements** before fitting to avoid out-of-memory errors- ‚úì **Use automatic chunking** for datasets larger than available memory- ‚úì **Implement streaming optimization** for unlimited dataset sizes (100M+ points)- ‚úì **Choose between chunking vs streaming** approaches based on dataset characteristics- ‚úì **Configure memory limits** and use context managers for temporary settings- ‚úì **Monitor and troubleshoot** large dataset fits with progress reporting---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Why This Matters**The problem:** SciPy's `curve_fit` loads entire datasets into memory, failing on large datasets or becoming prohibitively slow. For datasets >1M points, traditional approaches either crash or require excessive computation time.**NLSQ's solution:**- **Automatic memory management** - Detects available memory and optimizes strategy- **GPU acceleration** - 150-270x faster than CPU-only approaches- **Intelligent chunking** - Achieves <1% error for well-conditioned problems- **Streaming optimization** - Handles unlimited dataset sizes with zero accuracy loss- **Progress reporting** - Track long-running fits in real-time**Real-world use cases:**- üî¨ **High-throughput screening** - Millions of measurements from automated experiments- üì° **Sensor calibration** - Continuous data streams from IoT devices- üß¨ **Genomics data fitting** - Large-scale biological datasets- üå°Ô∏è **Climate model parameter estimation** - Decades of environmental measurements- üìä **Financial time series** - Years of high-frequency trading data**When to use this approach:**- ‚úÖ **Good for:** Datasets >100K points, memory-constrained environments, production systems- ‚ùå **Not needed for:** Small datasets (<10K points) ‚Üí Use [Quickstart](../01_getting_started/nlsq_quickstart.ipynb) instead**Performance characteristics:**- **Speed:** GPU acceleration provides 150-270x speedup vs SciPy- **Memory:** Processes datasets 10-100x larger than available RAM- **Accuracy:** <1% error with chunking, zero loss with streaming---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö° Quick StartFit a 1 million point dataset in 3 steps:```pythonfrom nlsq import fit_large_datasetimport numpy as np# 1. Generate datax = np.linspace(0, 5, 1_000_000)y = 5.0 * np.exp(-1.2 * x) + 0.5 + np.random.normal(0, 0.05, 1_000_000)# 2. Define modeldef exponential_decay(x, a, b, c):    return a * jnp.exp(-b * x) + c# 3. Fit automaticallyresult = fit_large_dataset(exponential_decay, x, y, p0=[4.0, 1.0, 0.4])print(f\"Parameters: {result.popt}\")```**Expected output:**```‚úÖ Fit completed in 0.8 secondsParameters: [5.001, 1.199, 0.500]Relative errors: <0.1%```---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìñ Setup and ImportsFirst, let's import the necessary modules and verify the Python version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.099514Z",
     "iopub.status.busy": "2025-12-18T06:32:30.099219Z",
     "iopub.status.idle": "2025-12-18T06:32:30.398174Z",
     "shell.execute_reply": "2025-12-18T06:32:30.397763Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.400304Z",
     "iopub.status.busy": "2025-12-18T06:32:30.400105Z",
     "iopub.status.idle": "2025-12-18T06:32:30.760968Z",
     "shell.execute_reply": "2025-12-18T06:32:30.760197Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Python 3.13 meets requirements\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:2025-12-18 00:32:30,757:jax._src.xla_bridge:850: An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:jax._src.xla_bridge:An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  GPU ACCELERATION AVAILABLE\n",
      "‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
      "NVIDIA GPU detected: NVIDIA GeForce RTX 4090 Laptop GPU\n",
      "JAX is currently using: CPU-only\n",
      "\n",
      "Enable 150-270x speedup with GPU acceleration:\n",
      "  make install-jax-gpu\n",
      "\n",
      "Or manually:\n",
      "  pip uninstall -y jax jaxlib\n",
      "  pip install \"jax[cuda12-local]>=0.6.0\"\n",
      "\n",
      "See README.md GPU Installation section for details.\n",
      "\n",
      "NLSQ version: 0.3.0.post9\n",
      "NLSQ Large Dataset Demo - Enhanced Version\n"
     ]
    }
   ],
   "source": [
    "# Check Python version\n",
    "import sys\n",
    "\n",
    "print(f\"‚úÖ Python {sys.version_info.major}.{sys.version_info.minor} meets requirements\")\n",
    "\n",
    "import time\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "\n",
    "from nlsq import (\n",
    "    AlgorithmSelector,\n",
    "    CurveFit,\n",
    "    LargeDatasetConfig,\n",
    "    LargeDatasetFitter,\n",
    "    LDMemoryConfig,\n",
    "    MemoryConfig,\n",
    "    __version__,\n",
    "    auto_select_algorithm,\n",
    "    configure_for_large_datasets,\n",
    "    curve_fit_large,\n",
    "    estimate_memory_requirements,\n",
    "    fit_large_dataset,\n",
    "    get_memory_config,\n",
    "    large_dataset_context,\n",
    "    memory_context,\n",
    "    set_memory_limits,\n",
    ")\n",
    "\n",
    "print(f\"NLSQ version: {__version__}\")\n",
    "print(\"NLSQ Large Dataset Demo - Enhanced Version\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Model FunctionsWe'll use several model functions throughout this tutorial to demonstrate different aspects of large dataset fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.762926Z",
     "iopub.status.busy": "2025-12-18T06:32:30.762678Z",
     "iopub.status.idle": "2025-12-18T06:32:30.765986Z",
     "shell.execute_reply": "2025-12-18T06:32:30.765464Z"
    }
   },
   "outputs": [],
   "source": [
    "def exponential_decay(x, a, b, c):\n",
    "    \"\"\"Exponential decay model with offset: y = a * exp(-b * x) + c\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c\n",
    "\n",
    "\n",
    "def polynomial_model(x, a, b, c, d):\n",
    "    \"\"\"Polynomial model: y = a*x^3 + b*x^2 + c*x + d\"\"\"\n",
    "    return a * x**3 + b * x**2 + c * x + d\n",
    "\n",
    "\n",
    "def gaussian(x, a, mu, sigma, offset):\n",
    "    \"\"\"Gaussian model: y = a * exp(-((x - mu)^2) / (2*sigma^2)) + offset\"\"\"\n",
    "    return a * jnp.exp(-((x - mu) ** 2) / (2 * sigma**2)) + offset\n",
    "\n",
    "\n",
    "def complex_model(x, a, b, c, d, e, f):\n",
    "    \"\"\"Complex model with many parameters for algorithm selection testing\"\"\"\n",
    "    return a * jnp.exp(-b * x) + c * jnp.sin(d * x) + e * x**2 + f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Memory Estimation**Key concept:** Before fitting large datasets, use `estimate_memory_requirements()` to predict memory usage and determine the optimal processing strategy.**Why it matters:** Prevents out-of-memory errors and helps you choose between single-pass, chunked, or streaming approaches.**How it works:**1. Calculates memory needed for data arrays (x, y)2. Estimates Jacobian matrix size (n_points √ó n_params)3. Accounts for JAX compilation overhead4. Recommends chunk count based on available memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.767528Z",
     "iopub.status.busy": "2025-12-18T06:32:30.767408Z",
     "iopub.status.idle": "2025-12-18T06:32:30.771313Z",
     "shell.execute_reply": "2025-12-18T06:32:30.770887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "MEMORY ESTIMATION DEMO\n",
      "============================================================\n",
      "\n",
      "Small dataset (100,000 points, 3 parameters):\n",
      "  Total memory estimate: 0.014 GB\n",
      "  Number of chunks: 1\n",
      "  Strategy: Single pass (fits in memory)\n",
      "\n",
      "Medium dataset (1,000,000 points, 3 parameters):\n",
      "  Total memory estimate: 0.136 GB\n",
      "  Number of chunks: 1\n",
      "  Strategy: Single pass (fits in memory)\n",
      "\n",
      "Large dataset (10,000,000 points, 3 parameters):\n",
      "  Total memory estimate: 1.360 GB\n",
      "  Number of chunks: 10\n",
      "  Strategy: Chunked processing (10 chunks)\n",
      "\n",
      "Very large dataset (50,000,000 points, 3 parameters):\n",
      "  Total memory estimate: 6.799 GB\n",
      "  Number of chunks: 50\n",
      "  Strategy: Chunked processing (50 chunks)\n",
      "\n",
      "Extremely large dataset (100,000,000 points, 3 parameters):\n",
      "  Total memory estimate: 13.597 GB\n",
      "  Number of chunks: 100\n",
      "  Strategy: Chunked processing (100 chunks)\n",
      "  üí° Consider: Streaming optimization for zero accuracy loss\n"
     ]
    }
   ],
   "source": [
    "def demo_memory_estimation():\n",
    "    \"\"\"Demonstrate memory estimation capabilities.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"MEMORY ESTIMATION DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Estimate requirements for different dataset sizes\n",
    "    test_cases = [\n",
    "        (100_000, 3, \"Small dataset\"),\n",
    "        (1_000_000, 3, \"Medium dataset\"),\n",
    "        (10_000_000, 3, \"Large dataset\"),\n",
    "        (50_000_000, 3, \"Very large dataset\"),\n",
    "        (100_000_000, 3, \"Extremely large dataset\"),\n",
    "    ]\n",
    "\n",
    "    for n_points, n_params, description in test_cases:\n",
    "        stats = estimate_memory_requirements(n_points, n_params)\n",
    "        print(f\"\\n{description} ({n_points:,} points, {n_params} parameters):\")\n",
    "        print(f\"  Total memory estimate: {stats.total_memory_estimate_gb:.3f} GB\")\n",
    "        print(f\"  Number of chunks: {stats.n_chunks}\")\n",
    "\n",
    "        # Determine strategy description\n",
    "        if stats.n_chunks == 1:\n",
    "            print(\"  Strategy: Single pass (fits in memory)\")\n",
    "        elif stats.n_chunks > 1:\n",
    "            print(f\"  Strategy: Chunked processing ({stats.n_chunks} chunks)\")\n",
    "\n",
    "        # For very large datasets, suggest streaming\n",
    "        if n_points > 50_000_000:\n",
    "            print(\"  üí° Consider: Streaming optimization for zero accuracy loss\")\n",
    "\n",
    "demo_memory_estimation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Configuration & Algorithm Selection**Key concept:** NLSQ provides sophisticated configuration management and automatic algorithm selection for optimal performance.**Features:**- **`get_memory_config()`** - View current memory settings- **`configure_for_large_datasets()`** - Optimize settings for large data- **`auto_select_algorithm()`** - Automatically choose best optimization algorithm- **Context managers** - Temporarily change settings for specific operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.772533Z",
     "iopub.status.busy": "2025-12-18T06:32:30.772431Z",
     "iopub.status.idle": "2025-12-18T06:32:30.899757Z",
     "shell.execute_reply": "2025-12-18T06:32:30.899145Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ADVANCED CONFIGURATION & ALGORITHM SELECTION DEMO\n",
      "============================================================\n",
      "Current memory configuration:\n",
      "  Memory limit: 8.0 GB\n",
      "  Mixed precision fallback: True\n",
      "\n",
      "Configuring for large dataset processing...\n",
      "Updated memory limit: 8.0 GB\n",
      "\n",
      "=== Algorithm Selection Demo ===\n",
      "\n",
      "Simple exponential (3 parameters):\n",
      "  Recommended algorithm: trf\n",
      "  Recommended tolerance: 1e-08\n",
      "  Problem complexity: Unknown\n",
      "  Memory for 1M points: 0.136 GB\n",
      "  Chunking strategy: Not needed\n",
      "\n",
      "Polynomial (4 parameters):\n",
      "  Recommended algorithm: trf\n",
      "  Recommended tolerance: 1e-08\n",
      "  Problem complexity: Unknown\n",
      "  Memory for 1M points: 0.158 GB\n",
      "  Chunking strategy: Not needed\n",
      "\n",
      "Complex multi-param (6 parameters):\n",
      "  Recommended algorithm: trf\n",
      "  Recommended tolerance: 1e-08\n",
      "  Problem complexity: Unknown\n",
      "  Memory for 1M points: 0.203 GB\n",
      "  Chunking strategy: Not needed\n"
     ]
    }
   ],
   "source": [
    "def demo_advanced_configuration():\n",
    "    \"\"\"Demonstrate advanced configuration and algorithm selection.\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    print(\"ADVANCED CONFIGURATION & ALGORITHM SELECTION DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Current memory configuration\n",
    "    current_config = get_memory_config()\n",
    "    print(\"Current memory configuration:\")\n",
    "    print(f\"  Memory limit: {current_config.memory_limit_gb} GB\")\n",
    "    print(f\"  Mixed precision fallback: {current_config.enable_mixed_precision_fallback}\")\n",
    "\n",
    "    # Automatically configure for large datasets\n",
    "    print(\"\\nConfiguring for large dataset processing...\")\n",
    "    configure_for_large_datasets(memory_limit_gb=8.0, enable_chunking=True)\n",
    "\n",
    "    # Show updated configuration\n",
    "    new_config = get_memory_config()\n",
    "    print(f\"Updated memory limit: {new_config.memory_limit_gb} GB\")\n",
    "\n",
    "    # Generate test dataset for algorithm selection\n",
    "    print(\"\\n=== Algorithm Selection Demo ===\")\n",
    "    np.random.seed(42)\n",
    "\n",
    "    # Test different model complexities\n",
    "    test_cases = [\n",
    "        (\"Simple exponential\", exponential_decay, 3, [5.0, 1.2, 0.5]),\n",
    "        (\"Polynomial\", polynomial_model, 4, [0.1, -0.5, 2.0, 1.0]),\n",
    "        (\"Complex multi-param\", complex_model, 6, [3.0, 0.8, 1.5, 2.0, 0.1, 0.2]),\n",
    "    ]\n",
    "\n",
    "    for model_name, model_func, n_params, true_params in test_cases:\n",
    "        print(f\"\\n{model_name} ({n_params} parameters):\")\n",
    "\n",
    "        # Generate sample data\n",
    "        n_sample = 10000  # Smaller sample for algorithm analysis\n",
    "        x_sample = np.linspace(0, 5, n_sample)\n",
    "        y_sample = model_func(x_sample, *true_params) + np.random.normal(\n",
    "            0, 0.05, n_sample\n",
    "        )\n",
    "\n",
    "        # Get algorithm recommendation\n",
    "        try:\n",
    "            recommendations = auto_select_algorithm(model_func, x_sample, y_sample)\n",
    "            print(f\"  Recommended algorithm: {recommendations['algorithm']}\")\n",
    "            print(f\"  Recommended tolerance: {recommendations['ftol']}\")\n",
    "            print(f\"  Problem complexity: {recommendations.get('complexity', 'Unknown')}\")\n",
    "\n",
    "            # Estimate memory for full dataset\n",
    "            large_n = 1_000_000  # 1M points\n",
    "            stats = estimate_memory_requirements(large_n, n_params)\n",
    "            print(f\"  Memory for 1M points: {stats.total_memory_estimate_gb:.3f} GB\")\n",
    "            print(f\"  Chunking strategy: {'Required' if stats.n_chunks > 1 else 'Not needed'}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Algorithm selection failed: {e}\")\n",
    "            print(f\"  Using default settings for {model_name}\")\n",
    "\n",
    "# Run the demo\n",
    "demo_advanced_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Large Dataset Fitting**Key function:** `fit_large_dataset()` - Convenience function for automatic large dataset handling**Features:**- Automatic memory management- Progress reporting for long-running fits- Intelligent strategy selection (single-pass, chunked, or streaming)- Returns standard `OptimizeResult` with fitted parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:30.901534Z",
     "iopub.status.busy": "2025-12-18T06:32:30.901423Z",
     "iopub.status.idle": "2025-12-18T06:32:33.186130Z",
     "shell.execute_reply": "2025-12-18T06:32:33.185765Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 1,000,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.14 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 1,000,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 1000000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "BASIC LARGE DATASET FITTING DEMO\n",
      "============================================================\n",
      "Generating 1M point exponential decay dataset...\n",
      "Dataset: 1,000,000 points\n",
      "True parameters: a=5.0, b=1.2, c=0.5\n",
      "\n",
      "Fitting with automatic memory management...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 1000000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=3.338895e+04 | ‚Äñ‚àáf‚Äñ=1.365785e+05 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.451362e+03 | ‚Äñ‚àáf‚Äñ=1.161946e+04 | step=4.142463e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.250606e+03 | ‚Äñ‚àáf‚Äñ=4.699238e+02 | step=4.142463e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.250468e+03 | ‚Äñ‚àáf‚Äñ=1.148351e-01 | step=4.142463e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.624568s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=1.250468e+03 | time=1.625s | final_gradient_norm=5.634469823230651e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 2.104662s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 2.1046621550049167, 'final_cost': 2500.9361998064796, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Fit completed in 2.24 seconds\n",
      "Fitted parameters: [5.000, 1.200, 0.500]\n",
      "Absolute errors: [0.0002, 0.0000, 0.0001]\n",
      "Relative errors: [0.00%, 0.00%, 0.03%]\n"
     ]
    }
   ],
   "source": [
    "def demo_basic_large_dataset_fitting():\n",
    "    \"\"\"Demonstrate basic large dataset fitting.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"BASIC LARGE DATASET FITTING DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Generate synthetic large dataset (1M points)\n",
    "    print(\"Generating 1M point exponential decay dataset...\")\n",
    "    np.random.seed(42)\n",
    "    n_points = 1_000_000\n",
    "    x_data = np.linspace(0, 5, n_points, dtype=np.float64)\n",
    "    true_params = [5.0, 1.2, 0.5]\n",
    "    noise_level = 0.05\n",
    "    y_true = true_params[0] * np.exp(-true_params[1] * x_data) + true_params[2]\n",
    "    y_data = y_true + np.random.normal(0, noise_level, n_points)\n",
    "\n",
    "    print(f\"Dataset: {n_points:,} points\")\n",
    "    print(\n",
    "        f\"True parameters: a={true_params[0]}, b={true_params[1]}, c={true_params[2]}\"\n",
    "    )\n",
    "\n",
    "    # Fit using convenience function\n",
    "    print(\"\\nFitting with automatic memory management...\")\n",
    "    start_time = time.time()\n",
    "    result = fit_large_dataset(\n",
    "        exponential_decay,\n",
    "        x_data,\n",
    "        y_data,\n",
    "        p0=[4.0, 1.0, 0.4],\n",
    "        memory_limit_gb=2.0,  # 2GB limit\n",
    "        show_progress=True,\n",
    "    )\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    if result.success:\n",
    "        fitted_params = np.array(result.popt)\n",
    "        errors = np.abs(fitted_params - np.array(true_params))\n",
    "        rel_errors = errors / np.array(true_params) * 100\n",
    "        print(f\"\\n‚úÖ Fit completed in {fit_time:.2f} seconds\")\n",
    "        print(\n",
    "            f\"Fitted parameters: [{fitted_params[0]:.3f}, {fitted_params[1]:.3f}, {fitted_params[2]:.3f}]\"\n",
    "        )\n",
    "        print(f\"Absolute errors: [{errors[0]:.4f}, {errors[1]:.4f}, {errors[2]:.4f}]\")\n",
    "        print(\n",
    "            f\"Relative errors: [{rel_errors[0]:.2f}%, {rel_errors[1]:.2f}%, {rel_errors[2]:.2f}%]\"\n",
    "        )\n",
    "    else:\n",
    "        print(f\"‚ùå Fit failed: {result.message}\")\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "demo_basic_large_dataset_fitting()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Context Managers for Temporary Configuration**Key concept:** Use context managers to temporarily change settings without affecting global state**Available contexts:**- **`memory_context(MemoryConfig)`** - Temporarily change memory settings- **`large_dataset_context(LargeDatasetConfig)`** - Optimize for large dataset processing**Why use context managers:**- Settings automatically restore after the context exits- Safe for nested operations- Allows experiment with different configurations- No risk of forgetting to restore settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:33.191544Z",
     "iopub.status.busy": "2025-12-18T06:32:33.191394Z",
     "iopub.status.idle": "2025-12-18T06:32:35.489355Z",
     "shell.execute_reply": "2025-12-18T06:32:35.488900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 500,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.07 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 500,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 500000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CONTEXT MANAGERS DEMO\n",
      "============================================================\n",
      "Original memory limit: 8.0 GB\n",
      "Test dataset: 500,000 points\n",
      "\n",
      "--- Test 1: Memory-constrained fitting ---\n",
      "Inside context memory limit: 0.5 GB\n",
      "Mixed precision enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 500000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=3.381814e+03 | ‚Äñ‚àáf‚Äñ=2.268377e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=6.368694e+02 | ‚Äñ‚àáf‚Äñ=6.263187e+02 | step=3.741991e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=6.277287e+02 | ‚Äñ‚àáf‚Äñ=9.639740e+00 | step=3.741991e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=6.277286e+02 | ‚Äñ‚àáf‚Äñ=2.729460e-04 | step=3.741991e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.817833s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=4 | final_cost=6.277286e+02 | time=0.818s | final_gradient_norm=0.00027294598707158866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 1.017864s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 1.0178643229883164, 'final_cost': 1255.4571180396572, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 500,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.07 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 500,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 500000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Constrained fit completed: 1.120s\n",
      "   Parameters: [4.00017172 1.49998995 0.29995423]\n",
      "After context memory limit: 8.0 GB\n",
      "\n",
      "--- Test 2: Large dataset optimization ---\n",
      "Inside large dataset context - chunking optimized\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 500000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=3.381814e+03 | ‚Äñ‚àáf‚Äñ=2.268377e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=6.368694e+02 | ‚Äñ‚àáf‚Äñ=6.263187e+02 | step=3.741991e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=6.277287e+02 | ‚Äñ‚àáf‚Äñ=9.639740e+00 | step=3.741991e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=6.277286e+02 | ‚Äñ‚àáf‚Äñ=2.729460e-04 | step=3.741991e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.798413s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=4 | final_cost=6.277286e+02 | time=0.798s | final_gradient_norm=0.00027294598707158866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.979008s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.9790079209778924, 'final_cost': 1255.4571180396572, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Optimized fit completed: 1.055s\n",
      "   Parameters: [4.00017172 1.49998995 0.29995423]\n",
      "\n",
      "‚úì Context managers allow flexible, temporary configuration changes!\n"
     ]
    }
   ],
   "source": [
    "def demo_context_managers():\n",
    "    \"\"\"Demonstrate context managers for temporary configuration.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CONTEXT MANAGERS DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Show current configuration\n",
    "    original_mem_config = get_memory_config()\n",
    "    print(f\"Original memory limit: {original_mem_config.memory_limit_gb} GB\")\n",
    "\n",
    "    # Generate test data\n",
    "    np.random.seed(555)\n",
    "    n_points = 500_000\n",
    "    x_data = np.linspace(0, 5, n_points)\n",
    "    y_data = exponential_decay(x_data, 4.0, 1.5, 0.3) + np.random.normal(\n",
    "        0, 0.05, n_points\n",
    "    )\n",
    "    print(f\"Test dataset: {n_points:,} points\")\n",
    "\n",
    "    # Test 1: Memory context for memory-constrained fitting\n",
    "    print(\"\\n--- Test 1: Memory-constrained fitting ---\")\n",
    "    constrained_config = MemoryConfig(\n",
    "        memory_limit_gb=0.5,  # Very low limit\n",
    "        enable_mixed_precision_fallback=True,\n",
    "    )\n",
    "\n",
    "    with memory_context(constrained_config):\n",
    "        temp_config = get_memory_config()\n",
    "        print(f\"Inside context memory limit: {temp_config.memory_limit_gb} GB\")\n",
    "        print(f\"Mixed precision enabled: {temp_config.enable_mixed_precision_fallback}\")\n",
    "\n",
    "        start_time = time.time()\n",
    "        result1 = fit_large_dataset(\n",
    "            exponential_decay, x_data, y_data, p0=[3.5, 1.3, 0.25], show_progress=False\n",
    "        )\n",
    "        time1 = time.time() - start_time\n",
    "\n",
    "        if result1.success:\n",
    "            print(f\"‚úÖ Constrained fit completed: {time1:.3f}s\")\n",
    "            print(f\"   Parameters: {result1.popt}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Constrained fit failed: {result1.message}\")\n",
    "\n",
    "    # Check that configuration is restored\n",
    "    restored_config = get_memory_config()\n",
    "    print(f\"After context memory limit: {restored_config.memory_limit_gb} GB\")\n",
    "\n",
    "    # Test 2: Large dataset context for optimized processing\n",
    "    print(\"\\n--- Test 2: Large dataset optimization ---\")\n",
    "    ld_config = LargeDatasetConfig()\n",
    "\n",
    "    with large_dataset_context(ld_config):\n",
    "        print(\"Inside large dataset context - chunking optimized\")\n",
    "        start_time = time.time()\n",
    "        result2 = fit_large_dataset(\n",
    "            exponential_decay, x_data, y_data, p0=[3.5, 1.3, 0.25], show_progress=False\n",
    "        )\n",
    "        time2 = time.time() - start_time\n",
    "\n",
    "        if result2.success:\n",
    "            print(f\"‚úÖ Optimized fit completed: {time2:.3f}s\")\n",
    "            print(f\"   Parameters: {result2.popt}\")\n",
    "        else:\n",
    "            print(f\"‚ùå Optimized fit failed: {result2.message}\")\n",
    "\n",
    "    print(\"\\n‚úì Context managers allow flexible, temporary configuration changes!\")\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "demo_context_managers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Chunked Processing**Key concept:** For datasets that don't fit in memory, NLSQ automatically chunks the data and processes it in batches using an advanced exponential moving average algorithm.**How it works:**1. Dataset divided into manageable chunks based on memory limit2. Each chunk processed separately to compute partial gradient3. Gradients combined using exponential moving average4. Achieves <1% error for well-conditioned problems**When to use:**- Dataset larger than available RAM- Memory-constrained environments- Well-conditioned optimization problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:35.491085Z",
     "iopub.status.busy": "2025-12-18T06:32:35.490942Z",
     "iopub.status.idle": "2025-12-18T06:32:38.303011Z",
     "shell.execute_reply": "2025-12-18T06:32:38.302144Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 2,000,000 points, 4 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 170.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.32 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 1,000,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 2,000,000 points, 4 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 170.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.32 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 1,000,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Auto-enabled mixed precision for chunked processing (50% additional memory savings)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Mixed precision optimization enabled (float32 ‚Üí float64 fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset using 2 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 1000000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CHUNKED PROCESSING DEMO\n",
      "============================================================\n",
      "Generating 2M point polynomial dataset...\n",
      "Dataset: 2,000,000 points\n",
      "True parameters: [0.5, -1.2, 2.0, 1.5]\n",
      "\n",
      "Processing strategy: chunked\n",
      "Chunk size: 1,000,000\n",
      "Number of chunks: 2\n",
      "Memory estimate: 0.32 GB\n",
      "\n",
      "Fitting with chunked processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 1000000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=2.369915e+05 | ‚Äñ‚àáf‚Äñ=2.020638e+06 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=5.002569e+03 | ‚Äñ‚àáf‚Äñ=7.134165e-08 | step=2.416609e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.269870s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=2 | final_cost=5.002569e+03 | time=1.270s | final_gradient_norm=7.134165337360007e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 1.633725s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 1.6337245420145337, 'final_cost': 10005.13793956109, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 1/2 chunks (50.0%) - ETA: 1.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 1000000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 1000000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=5.017499e+03 | ‚Äñ‚àáf‚Äñ=1.463448e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=5.004831e+03 | ‚Äñ‚àáf‚Äñ=2.756541e-07 | step=2.818770e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.645427s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=2 | final_cost=5.004831e+03 | time=0.645s | final_gradient_norm=2.756541217230346e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.759410s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.7594098330009729, 'final_cost': 10009.661564310247, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 2/2 chunks (100.0%) - ETA: 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Chunked fit completed with 100.0% success rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Chunked fit completed in 2.72 seconds\n",
      "Used 2 chunks with 100.0% success rate\n",
      "Fitted parameters: [ 0.49954434 -1.1991878   2.00000184  1.49975205]\n",
      "Absolute errors: [4.55663678e-04 8.12197994e-04 1.84414704e-06 2.47951876e-04]\n",
      "Relative errors: [9.11327356e-02 6.76831662e-02 9.22073520e-05 1.65301251e-02]%\n"
     ]
    }
   ],
   "source": [
    "def demo_chunked_processing():\n",
    "    \"\"\"Demonstrate chunked processing with progress reporting.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CHUNKED PROCESSING DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Generate a dataset that will require chunking\n",
    "    print(\"Generating 2M point polynomial dataset...\")\n",
    "    np.random.seed(123)\n",
    "    n_points = 2_000_000\n",
    "    x_data = np.linspace(-2, 2, n_points, dtype=np.float64)\n",
    "    true_params = [0.5, -1.2, 2.0, 1.5]\n",
    "    noise_level = 0.1\n",
    "    y_true = (\n",
    "        true_params[0] * x_data**3\n",
    "        + true_params[1] * x_data**2\n",
    "        + true_params[2] * x_data\n",
    "        + true_params[3]\n",
    "    )\n",
    "    y_data = y_true + np.random.normal(0, noise_level, n_points)\n",
    "\n",
    "    print(f\"Dataset: {n_points:,} points\")\n",
    "    print(f\"True parameters: {true_params}\")\n",
    "\n",
    "    # Create fitter with limited memory to force chunking\n",
    "    fitter = LargeDatasetFitter(memory_limit_gb=0.5)  # Small limit to force chunking\n",
    "\n",
    "    # Get processing recommendations\n",
    "    recs = fitter.get_memory_recommendations(n_points, 4)\n",
    "    print(f\"\\nProcessing strategy: {recs['processing_strategy']}\")\n",
    "    print(f\"Chunk size: {recs['recommendations']['chunk_size']:,}\")\n",
    "    print(f\"Number of chunks: {recs['recommendations']['n_chunks']}\")\n",
    "    print(\n",
    "        f\"Memory estimate: {recs['recommendations']['total_memory_estimate_gb']:.2f} GB\"\n",
    "    )\n",
    "\n",
    "    # Fit with progress reporting\n",
    "    print(\"\\nFitting with chunked processing...\")\n",
    "    start_time = time.time()\n",
    "    result = fitter.fit_with_progress(\n",
    "        polynomial_model, x_data, y_data, p0=[0.4, -1.0, 1.8, 1.2]\n",
    "    )\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    if result.success:\n",
    "        fitted_params = np.array(result.popt)\n",
    "        errors = np.abs(fitted_params - np.array(true_params))\n",
    "        rel_errors = errors / np.abs(np.array(true_params)) * 100\n",
    "        print(f\"\\n‚úÖ Chunked fit completed in {fit_time:.2f} seconds\")\n",
    "\n",
    "        if hasattr(result, \"n_chunks\"):\n",
    "            print(\n",
    "                f\"Used {result.n_chunks} chunks with {result.success_rate:.1%} success rate\"\n",
    "            )\n",
    "\n",
    "        print(f\"Fitted parameters: {fitted_params}\")\n",
    "        print(f\"Absolute errors: {errors}\")\n",
    "        print(f\"Relative errors: {rel_errors}%\")\n",
    "    else:\n",
    "        print(f\"‚ùå Chunked fit failed: {result.message}\")\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "demo_chunked_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Streaming Optimization for Unlimited Datasets**Key concept:** For datasets too large to fit in memory, NLSQ uses streaming optimization with mini-batch gradient descent. Unlike subsampling (deprecated), streaming processes **100% of data with zero accuracy loss**.**‚ö†Ô∏è Deprecation Notice:**- **Removed:** Subsampling (which caused data loss)- **Added:** Streaming optimization (processes all data)- **Deprecated:** `enable_sampling`, `sampling_threshold`, `max_sampled_size` parameters now emit warnings**How streaming works:**1. Processes data in sequential batches2. Uses mini-batch gradient descent3. No data is skipped or discarded4. Zero accuracy loss compared to full dataset processing**When to use:**- Dataset > available RAM- Unlimited or continuously generated data- When accuracy is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:38.306086Z",
     "iopub.status.busy": "2025-12-18T06:32:38.305824Z",
     "iopub.status.idle": "2025-12-18T06:32:40.009168Z",
     "shell.execute_reply": "2025-12-18T06:32:40.008787Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 1,000,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.14 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 1,000,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 1000000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "STREAMING OPTIMIZATION DEMO\n",
      "============================================================\n",
      "Simulating extremely large dataset (100M points)...\n",
      "Using streaming optimization for zero data loss\n",
      "\n",
      "Generating representative dataset for demo...\n",
      "\n",
      "Full dataset memory estimate: 13.6 GB\n",
      "Number of chunks required: 100\n",
      "\n",
      "Configuring streaming optimization...\n",
      "\n",
      "Fitting with streaming optimization...\n",
      "(Processing 100% of data in batches)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 1000000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.016660e+04 | ‚Äñ‚àáf‚Äñ=1.717303e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=5.168709e+03 | ‚Äñ‚àáf‚Äñ=1.378554e+04 | step=2.575364e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=5.001172e+03 | ‚Äñ‚àáf‚Äñ=4.158581e+01 | step=2.575364e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=5.001170e+03 | ‚Äñ‚àáf‚Äñ=5.681019e-03 | step=2.575364e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.298944s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=5.001170e+03 | time=1.299s | final_gradient_norm=9.318468014930417e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 1.486662s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 1.486661811999511, 'final_cost': 10002.33959164098, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Streaming fit completed in 1.55 seconds\n",
      "\n",
      "Fitted parameters: [3.00009638 0.80008703 0.20011093]\n",
      "True parameters:    [3.0, 0.8, 0.2]\n",
      "Relative errors:    ['0.00%', '0.01%', '0.06%']\n",
      "\n",
      "‚ÑπÔ∏è Streaming processed 100% of data (zero accuracy loss)\n"
     ]
    }
   ],
   "source": [
    "def demo_streaming_optimization():\n",
    "    \"\"\"Demonstrate streaming optimization for unlimited datasets.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"STREAMING OPTIMIZATION DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Simulate a very large dataset scenario\n",
    "    print(\"Simulating extremely large dataset (100M points)...\")\n",
    "    print(\"Using streaming optimization for zero data loss\\n\")\n",
    "\n",
    "    n_points_full = 100_000_000  # 100M points\n",
    "    true_params = [3.0, 0.8, 0.2]\n",
    "\n",
    "    # For demo purposes, generate a representative dataset\n",
    "    # In production, streaming would process full dataset in batches\n",
    "    print(\"Generating representative dataset for demo...\")\n",
    "    np.random.seed(777)\n",
    "    n_demo = 1_000_000  # 1M points for demo\n",
    "    x_data = np.linspace(0, 10, n_demo)\n",
    "    y_data = exponential_decay(x_data, *true_params) + np.random.normal(0, 0.1, n_demo)\n",
    "\n",
    "    # Memory estimation\n",
    "    stats = estimate_memory_requirements(n_points_full, len(true_params))\n",
    "    print(f\"\\nFull dataset memory estimate: {stats.total_memory_estimate_gb:.1f} GB\")\n",
    "    print(f\"Number of chunks required: {stats.n_chunks}\")\n",
    "\n",
    "    # Configure streaming optimization\n",
    "    print(\"\\nConfiguring streaming optimization...\")\n",
    "    config = LDMemoryConfig(\n",
    "        memory_limit_gb=4.0,\n",
    "        use_streaming=True,  # Enable streaming\n",
    "        streaming_batch_size=50000,  # Process 50K points per batch\n",
    "    )\n",
    "    fitter = LargeDatasetFitter(config=config)\n",
    "\n",
    "    print(\"\\nFitting with streaming optimization...\")\n",
    "    print(\"(Processing 100% of data in batches)\\n\")\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        result = fitter.fit(exponential_decay, x_data, y_data, p0=[2.5, 0.6, 0.15])\n",
    "        fit_time = time.time() - start_time\n",
    "\n",
    "        if result.success:\n",
    "            print(f\"\\n‚úÖ Streaming fit completed in {fit_time:.2f} seconds\")\n",
    "            print(f\"\\nFitted parameters: {result.x}\")\n",
    "            print(f\"True parameters:    {true_params}\")\n",
    "\n",
    "            errors = np.abs(result.x - np.array(true_params))\n",
    "            rel_errors = errors / np.abs(np.array(true_params)) * 100\n",
    "            print(f\"Relative errors:    {[f'{e:.2f}%' for e in rel_errors]}\")\n",
    "            print(\"\\n‚ÑπÔ∏è Streaming processed 100% of data (zero accuracy loss)\")\n",
    "        else:\n",
    "            print(f\"‚ùå Streaming fit failed: {result.message}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error during streaming fit: {e}\")\n",
    "\n",
    "\n",
    "demo_streaming_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. curve_fit_large Convenience Function**Key function:** `curve_fit_large()` provides automatic detection and handling of large datasets**Features:**- Automatic dataset size detection- Intelligent processing strategy selection- SciPy-compatible API (drop-in replacement)- Returns standard `(popt, pcov)` tuple**When to use:**- You want automatic handling of both small and large datasets- Migrating from SciPy's `curve_fit`- Don't want to manually configure chunking/streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:40.013285Z",
     "iopub.status.busy": "2025-12-18T06:32:40.011663Z",
     "iopub.status.idle": "2025-12-18T06:32:52.367687Z",
     "shell.execute_reply": "2025-12-18T06:32:52.367173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CURVE_FIT_LARGE CONVENIENCE FUNCTION DEMO\n",
      "============================================================\n",
      "Generating 3M point dataset for curve_fit_large demo...\n",
      "Dataset: 3,000,000 points\n",
      "True parameters: a=5.00, mu=5.00, sigma=1.50, offset=0.50\n",
      "\n",
      "Using curve_fit_large with automatic optimization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 3,000,000 points, 4 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 170.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.47 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 300,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Auto-enabled mixed precision for chunked processing (50% additional memory savings)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Mixed precision optimization enabled (float32 ‚Üí float64 fallback)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset using 10 chunks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=4.504638e+03 | ‚Äñ‚àáf‚Äñ=4.208710e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.505687e+03 | ‚Äñ‚àáf‚Äñ=1.162010e+03 | step=1.343726e+01 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.500917e+03 | ‚Äñ‚àáf‚Äñ=4.103601e+01 | step=1.679658e+00 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.500866e+03 | ‚Äñ‚àáf‚Äñ=6.588770e+00 | step=8.398289e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.500866e+03 | ‚Äñ‚àáf‚Äñ=3.218177e+00 | step=2.099572e-01 | nfev=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.500866e+03 | ‚Äñ‚àáf‚Äñ=1.969996e-01 | step=1.049786e-01 | nfev=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.206126s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=6 | final_cost=1.500866e+03 | time=1.206s | final_gradient_norm=0.00010405903990121135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 1.487923s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 1.4879227060009725, 'final_cost': 3001.7313031497965, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 1/10 chunks (10.0%) - ETA: 13.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.515877e+03 | ‚Äñ‚àáf‚Äñ=3.864338e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.499842e+03 | ‚Äñ‚àáf‚Äñ=3.724024e+02 | step=2.741981e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.499684e+03 | ‚Äñ‚àáf‚Äñ=1.182533e+02 | step=1.370990e+00 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.499674e+03 | ‚Äñ‚àáf‚Äñ=5.024230e+01 | step=6.854952e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.499673e+03 | ‚Äñ‚àáf‚Äñ=1.306833e+01 | step=3.427476e-01 | nfev=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.499673e+03 | ‚Äñ‚àáf‚Äñ=3.185367e+00 | step=1.713738e-01 | nfev=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.499673e+03 | ‚Äñ‚àáf‚Äñ=7.843249e-01 | step=8.568690e-02 | nfev=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.568221s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=7 | final_cost=1.499673e+03 | time=0.568s | final_gradient_norm=0.00040090993140461524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.630890s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.6308898339921143, 'final_cost': 2999.3450993779734, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 2/10 chunks (20.0%) - ETA: 9.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.983811e+03 | ‚Äñ‚àáf‚Äñ=4.456732e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.592875e+03 | ‚Äñ‚àáf‚Äñ=2.086582e+04 | step=1.794686e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.504039e+03 | ‚Äñ‚àáf‚Äñ=2.487611e+03 | step=3.589372e+00 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.503454e+03 | ‚Äñ‚àáf‚Äñ=1.850015e+03 | step=8.973430e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.502736e+03 | ‚Äñ‚àáf‚Äñ=9.674301e+01 | step=4.486715e-01 | nfev=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.502731e+03 | ‚Äñ‚àáf‚Äñ=2.944025e+01 | step=2.243358e-01 | nfev=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.502726e+03 | ‚Äñ‚àáf‚Äñ=1.220107e+02 | step=2.243358e-01 | nfev=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.502718e+03 | ‚Äñ‚àáf‚Äñ=1.235331e+02 | step=2.243358e-01 | nfev=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=8 | cost=1.502709e+03 | ‚Äñ‚àáf‚Äñ=1.262086e+02 | step=2.243358e-01 | nfev=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=9 | cost=1.502701e+03 | ‚Äñ‚àáf‚Äñ=1.289558e+02 | step=2.243358e-01 | nfev=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=10 | cost=1.502692e+03 | ‚Äñ‚àáf‚Äñ=1.317774e+02 | step=2.243358e-01 | nfev=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=11 | cost=1.502683e+03 | ‚Äñ‚àáf‚Äñ=1.346723e+02 | step=2.243358e-01 | nfev=17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=12 | cost=1.502673e+03 | ‚Äñ‚àáf‚Äñ=1.376498e+02 | step=2.243358e-01 | nfev=18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=13 | cost=1.502663e+03 | ‚Äñ‚àáf‚Äñ=1.407032e+02 | step=2.243358e-01 | nfev=19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=14 | cost=1.502653e+03 | ‚Äñ‚àáf‚Äñ=1.438361e+02 | step=2.243358e-01 | nfev=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=15 | cost=1.502643e+03 | ‚Äñ‚àáf‚Äñ=1.470513e+02 | step=2.243358e-01 | nfev=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=16 | cost=1.502632e+03 | ‚Äñ‚àáf‚Äñ=1.503435e+02 | step=2.243358e-01 | nfev=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=17 | cost=1.502620e+03 | ‚Äñ‚àáf‚Äñ=1.537163e+02 | step=2.243358e-01 | nfev=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=18 | cost=1.502609e+03 | ‚Äñ‚àáf‚Äñ=1.571676e+02 | step=2.243358e-01 | nfev=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=19 | cost=1.502596e+03 | ‚Äñ‚àáf‚Äñ=1.606953e+02 | step=2.243358e-01 | nfev=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=20 | cost=1.502584e+03 | ‚Äñ‚àáf‚Äñ=1.642971e+02 | step=2.243358e-01 | nfev=26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=21 | cost=1.502571e+03 | ‚Äñ‚àáf‚Äñ=1.679702e+02 | step=2.243358e-01 | nfev=27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=22 | cost=1.502557e+03 | ‚Äñ‚àáf‚Äñ=1.717104e+02 | step=2.243358e-01 | nfev=28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=23 | cost=1.502543e+03 | ‚Äñ‚àáf‚Äñ=1.755095e+02 | step=2.243358e-01 | nfev=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=24 | cost=1.502528e+03 | ‚Äñ‚àáf‚Äñ=1.793669e+02 | step=2.243358e-01 | nfev=30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=25 | cost=1.502513e+03 | ‚Äñ‚àáf‚Äñ=1.832635e+02 | step=2.243358e-01 | nfev=31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=26 | cost=1.502497e+03 | ‚Äñ‚àáf‚Äñ=1.871994e+02 | step=2.243358e-01 | nfev=32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=27 | cost=1.502481e+03 | ‚Äñ‚àáf‚Äñ=1.911531e+02 | step=2.243358e-01 | nfev=33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=28 | cost=1.502476e+03 | ‚Äñ‚àáf‚Äñ=1.349850e+01 | step=1.121679e-01 | nfev=35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=29 | cost=1.502468e+03 | ‚Äñ‚àáf‚Äñ=4.920472e+01 | step=2.243358e-01 | nfev=36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=30 | cost=1.502460e+03 | ‚Äñ‚àáf‚Äñ=2.000017e+02 | step=2.243358e-01 | nfev=37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=31 | cost=1.502442e+03 | ‚Äñ‚àáf‚Äñ=1.999893e+02 | step=2.243358e-01 | nfev=38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=32 | cost=1.502424e+03 | ‚Äñ‚àáf‚Äñ=2.039443e+02 | step=2.243358e-01 | nfev=39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=33 | cost=1.502406e+03 | ‚Äñ‚àáf‚Äñ=2.077764e+02 | step=2.243358e-01 | nfev=40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=34 | cost=1.502387e+03 | ‚Äñ‚àáf‚Äñ=2.115021e+02 | step=2.243358e-01 | nfev=41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=35 | cost=1.502367e+03 | ‚Äñ‚àáf‚Äñ=2.150899e+02 | step=2.243358e-01 | nfev=42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=36 | cost=1.502348e+03 | ‚Äñ‚àáf‚Äñ=2.184947e+02 | step=2.243358e-01 | nfev=43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=37 | cost=1.502328e+03 | ‚Äñ‚àáf‚Äñ=2.216612e+02 | step=2.243358e-01 | nfev=44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=38 | cost=1.502309e+03 | ‚Äñ‚àáf‚Äñ=2.245327e+02 | step=2.243358e-01 | nfev=45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=39 | cost=1.502291e+03 | ‚Äñ‚àáf‚Äñ=2.270394e+02 | step=2.243358e-01 | nfev=46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=40 | cost=1.502278e+03 | ‚Äñ‚àáf‚Äñ=1.719635e+01 | step=1.121679e-01 | nfev=48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=41 | cost=1.502278e+03 | ‚Äñ‚àáf‚Äñ=7.814525e-02 | step=8.763116e-04 | nfev=53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=42 | cost=1.502278e+03 | ‚Äñ‚àáf‚Äñ=7.819946e-02 | step=1.752623e-03 | nfev=54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=43 | cost=1.502278e+03 | ‚Äñ‚àáf‚Äñ=7.694818e-02 | step=3.505246e-03 | nfev=55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=44 | cost=1.502277e+03 | ‚Äñ‚àáf‚Äñ=7.211441e-02 | step=7.010492e-03 | nfev=56\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=45 | cost=1.502277e+03 | ‚Äñ‚àáf‚Äñ=2.163297e-01 | step=1.402098e-02 | nfev=57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=46 | cost=1.502276e+03 | ‚Äñ‚àáf‚Äñ=9.003138e-01 | step=2.804197e-02 | nfev=58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=47 | cost=1.502273e+03 | ‚Äñ‚àáf‚Äñ=3.640243e+00 | step=5.608394e-02 | nfev=59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=48 | cost=1.502269e+03 | ‚Äñ‚àáf‚Äñ=1.463904e+01 | step=1.121679e-01 | nfev=60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=49 | cost=1.502269e+03 | ‚Äñ‚àáf‚Äñ=7.536637e-02 | step=8.763116e-04 | nfev=65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=50 | cost=1.502269e+03 | ‚Äñ‚àáf‚Äñ=7.541718e-02 | step=1.752623e-03 | nfev=66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=51 | cost=1.502268e+03 | ‚Äñ‚àáf‚Äñ=7.412779e-02 | step=3.505246e-03 | nfev=67\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=52 | cost=1.502268e+03 | ‚Äñ‚àáf‚Äñ=6.914997e-02 | step=7.010492e-03 | nfev=68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=53 | cost=1.502268e+03 | ‚Äñ‚àáf‚Äñ=2.176185e-01 | step=1.402098e-02 | nfev=69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=54 | cost=1.502266e+03 | ‚Äñ‚àáf‚Äñ=9.049072e-01 | step=2.804197e-02 | nfev=70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 3.997887s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=55 | final_cost=1.502266e+03 | time=3.998s | final_gradient_norm=0.07263952986002722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 4.056812s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 4.056811579997884, 'final_cost': 3004.5329009755446, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 3/10 chunks (30.0%) - ETA: 14.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.747480e+03 | ‚Äñ‚àáf‚Äñ=1.951850e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.528122e+03 | ‚Äñ‚àáf‚Äñ=7.697044e+03 | step=7.715910e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.495482e+03 | ‚Äñ‚àáf‚Äñ=1.898824e+02 | step=7.715910e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.495464e+03 | ‚Äñ‚àáf‚Äñ=3.485164e-02 | step=7.715910e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.291684s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=1.495464e+03 | time=0.292s | final_gradient_norm=0.0010745892616174791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.350399s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.3503990859899204, 'final_cost': 2990.9277526141077, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 4/10 chunks (40.0%) - ETA: 10.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.547779e+03 | ‚Äñ‚àáf‚Äñ=4.038795e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.500998e+03 | ‚Äñ‚àáf‚Äñ=7.926353e+01 | step=7.140808e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.500961e+03 | ‚Äñ‚àáf‚Äñ=9.595912e+01 | step=7.140808e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.500959e+03 | ‚Äñ‚àáf‚Äñ=4.438229e+01 | step=7.140808e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.500950e+03 | ‚Äñ‚àáf‚Äñ=4.933224e+01 | step=7.140808e+00 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.500950e+03 | ‚Äñ‚àáf‚Äñ=7.360353e+00 | step=7.140808e+00 | nfev=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.500947e+03 | ‚Äñ‚àáf‚Äñ=4.312866e+01 | step=2.886015e-01 | nfev=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.500945e+03 | ‚Äñ‚àáf‚Äñ=3.039498e+00 | step=1.443008e-01 | nfev=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.609016s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=8 | final_cost=1.500945e+03 | time=0.609s | final_gradient_norm=0.008116869983024997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.665180s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.6651797550148331, 'final_cost': 3001.8902133338443, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 5/10 chunks (50.0%) - ETA: 7.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.511575e+03 | ‚Äñ‚àáf‚Äñ=2.731462e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.501759e+03 | ‚Äñ‚àáf‚Äñ=2.100632e+02 | step=7.591641e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.501666e+03 | ‚Äñ‚àáf‚Äñ=5.215399e+01 | step=7.018877e-01 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.501650e+03 | ‚Äñ‚àáf‚Äñ=1.455645e+01 | step=3.509439e-01 | nfev=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.501637e+03 | ‚Äñ‚àáf‚Äñ=6.530244e+01 | step=3.509439e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.501630e+03 | ‚Äñ‚àáf‚Äñ=6.916341e+01 | step=3.509439e-01 | nfev=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.501623e+03 | ‚Äñ‚àáf‚Äñ=4.012981e+00 | step=1.754719e-01 | nfev=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.501623e+03 | ‚Äñ‚àáf‚Äñ=1.193881e+00 | step=8.773597e-02 | nfev=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=8 | cost=1.501623e+03 | ‚Äñ‚àáf‚Äñ=2.941029e-01 | step=4.386798e-02 | nfev=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.705992s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=9 | final_cost=1.501623e+03 | time=0.706s | final_gradient_norm=0.004621263174111847\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.765025s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.7650254239852075, 'final_cost': 3003.245161879139, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 6/10 chunks (60.0%) - ETA: 5.6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.515432e+03 | ‚Äñ‚àáf‚Äñ=5.118795e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.502846e+03 | ‚Äñ‚àáf‚Äñ=1.523709e+02 | step=7.297091e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.502834e+03 | ‚Äñ‚àáf‚Äñ=9.967319e-02 | step=7.297091e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.502834e+03 | ‚Äñ‚àáf‚Äñ=7.636084e-03 | step=7.297091e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.502834e+03 | ‚Äñ‚àáf‚Äñ=1.985037e-03 | step=7.297091e+00 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.406622s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=5 | final_cost=1.502834e+03 | time=0.407s | final_gradient_norm=0.0019850367290136076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.460346s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.4603461680235341, 'final_cost': 3005.668646951994, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 7/10 chunks (70.0%) - ETA: 3.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.509340e+03 | ‚Äñ‚àáf‚Äñ=3.934424e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.502307e+03 | ‚Äñ‚àáf‚Äñ=2.260018e+03 | step=7.208600e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.500491e+03 | ‚Äñ‚àáf‚Äñ=7.604882e+02 | step=9.462839e-01 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.500207e+03 | ‚Äñ‚àáf‚Äñ=2.829953e+02 | step=4.473411e-01 | nfev=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.500157e+03 | ‚Äñ‚àáf‚Äñ=1.511071e+02 | step=4.473411e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.500138e+03 | ‚Äñ‚àáf‚Äñ=6.244807e+01 | step=2.236706e-01 | nfev=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.500137e+03 | ‚Äñ‚àáf‚Äñ=6.339673e-01 | step=2.795882e-02 | nfev=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.500135e+03 | ‚Äñ‚àáf‚Äñ=3.615109e+00 | step=5.591764e-02 | nfev=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.626741s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=8 | final_cost=1.500135e+03 | time=0.627s | final_gradient_norm=0.06765444120422937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.680487s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.6804866629827302, 'final_cost': 3000.2706589469944, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 8/10 chunks (80.0%) - ETA: 2.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.519561e+03 | ‚Äñ‚àáf‚Äñ=2.630843e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.503848e+03 | ‚Äñ‚àáf‚Äñ=1.019268e+03 | step=8.795354e-01 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.502519e+03 | ‚Äñ‚àáf‚Äñ=8.333492e+01 | step=4.397677e-01 | nfev=6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.502509e+03 | ‚Äñ‚àáf‚Äñ=3.241116e+01 | step=2.198839e-01 | nfev=8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.502507e+03 | ‚Äñ‚àáf‚Äñ=7.782415e+00 | step=1.099419e-01 | nfev=10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.502505e+03 | ‚Äñ‚àáf‚Äñ=2.951415e+01 | step=1.099419e-01 | nfev=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.502503e+03 | ‚Äñ‚àáf‚Äñ=2.893905e+01 | step=1.099419e-01 | nfev=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.502501e+03 | ‚Äñ‚àáf‚Äñ=2.804753e+01 | step=1.099419e-01 | nfev=13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=8 | cost=1.502501e+03 | ‚Äñ‚àáf‚Äñ=1.607552e+00 | step=5.497096e-02 | nfev=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=9 | cost=1.502500e+03 | ‚Äñ‚àáf‚Äñ=6.817874e+00 | step=1.099419e-01 | nfev=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=10 | cost=1.502500e+03 | ‚Äñ‚àáf‚Äñ=1.532108e-02 | step=3.435685e-03 | nfev=20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=11 | cost=1.502500e+03 | ‚Äñ‚àáf‚Äñ=2.794534e-02 | step=6.871371e-03 | nfev=21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=12 | cost=1.502500e+03 | ‚Äñ‚àáf‚Äñ=1.070840e-01 | step=1.374274e-02 | nfev=22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=13 | cost=1.502500e+03 | ‚Äñ‚àáf‚Äñ=4.225126e-01 | step=2.748548e-02 | nfev=23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=14 | cost=1.502499e+03 | ‚Äñ‚àáf‚Äñ=1.675841e+00 | step=5.497096e-02 | nfev=24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=15 | cost=1.502498e+03 | ‚Äñ‚àáf‚Äñ=6.625853e+00 | step=1.099419e-01 | nfev=25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=16 | cost=1.502498e+03 | ‚Äñ‚àáf‚Äñ=1.427495e-02 | step=3.435685e-03 | nfev=29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.305447s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`xtol` termination condition is satisfied. | iterations=17 | final_cost=1.502498e+03 | time=1.305s | final_gradient_norm=0.014274952487834737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 1.374187s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 1.3741870319936424, 'final_cost': 3004.9968016709586, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 9/10 chunks (90.0%) - ETA: 1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 4, 'n_data_points': 300000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 4, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 4, 'n_residuals': 300000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.506212e+03 | ‚Äñ‚àáf‚Äñ=1.753549e+02 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.506135e+03 | ‚Äñ‚àáf‚Äñ=1.143091e+02 | step=4.360346e-01 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.506124e+03 | ‚Äñ‚àáf‚Äñ=9.220214e+01 | step=4.360346e-01 | nfev=5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=7.071608e+00 | step=2.180173e-01 | nfev=7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=4 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=1.602918e+00 | step=1.090087e-01 | nfev=9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=5 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=3.884941e-01 | step=5.450433e-02 | nfev=11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=6 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=1.524383e+00 | step=1.090087e-01 | nfev=12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=7 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=3.769809e-01 | step=5.450433e-02 | nfev=14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=8 | cost=1.506105e+03 | ‚Äñ‚àáf‚Äñ=1.467635e+00 | step=1.090087e-01 | nfev=15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.713316s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=9 | final_cost=1.506105e+03 | time=0.713s | final_gradient_norm=0.36181172700519915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.769135s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.7691353890113533, 'final_cost': 3012.2104099514495, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Progress: 10/10 chunks (100.0%) - ETA: 0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Chunked fit completed with 100.0% success rate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ curve_fit_large completed in 12.17 seconds\n",
      "Fitted parameters: [3.90589708 5.26354232 1.45371549 0.49963011]\n",
      "Absolute errors: [1.09410292e+00 2.63542317e-01 4.62845149e-02 3.69892047e-04]\n",
      "Relative errors: [21.88205833  5.27084633  3.08563433  0.07397841]%\n",
      "Parameter uncertainties (std): [2.99903735 0.47499195 0.13092359 0.16116546]\n"
     ]
    }
   ],
   "source": [
    "def demo_curve_fit_large():\n",
    "    \"\"\"Demonstrate the curve_fit_large convenience function.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"CURVE_FIT_LARGE CONVENIENCE FUNCTION DEMO\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Generate test dataset\n",
    "    print(\"Generating 3M point dataset for curve_fit_large demo...\")\n",
    "    np.random.seed(789)\n",
    "    n_points = 3_000_000\n",
    "    x_data = np.linspace(0, 10, n_points, dtype=np.float64)\n",
    "    true_params = [5.0, 5.0, 1.5, 0.5]\n",
    "    y_true = gaussian(x_data, *true_params)\n",
    "    y_data = y_true + np.random.normal(0, 0.1, n_points)\n",
    "\n",
    "    print(f\"Dataset: {n_points:,} points\")\n",
    "    print(\n",
    "        f\"True parameters: a={true_params[0]:.2f}, mu={true_params[1]:.2f}, sigma={true_params[2]:.2f}, offset={true_params[3]:.2f}\"\n",
    "    )\n",
    "\n",
    "    # Use curve_fit_large - automatic large dataset handling\n",
    "    print(\"\\nUsing curve_fit_large with automatic optimization...\")\n",
    "    start_time = time.time()\n",
    "    popt, pcov = curve_fit_large(\n",
    "        gaussian,\n",
    "        x_data,\n",
    "        y_data,\n",
    "        p0=[4.5, 4.8, 1.3, 0.4],\n",
    "        memory_limit_gb=1.0,  # Force chunking with low memory limit\n",
    "        show_progress=True,\n",
    "        auto_size_detection=True,  # Automatically detect large dataset\n",
    "    )\n",
    "    fit_time = time.time() - start_time\n",
    "\n",
    "    errors = np.abs(popt - np.array(true_params))\n",
    "    rel_errors = errors / np.array(true_params) * 100\n",
    "    print(f\"\\n‚úÖ curve_fit_large completed in {fit_time:.2f} seconds\")\n",
    "    print(f\"Fitted parameters: {popt}\")\n",
    "    print(f\"Absolute errors: {errors}\")\n",
    "    print(f\"Relative errors: {rel_errors}%\")\n",
    "\n",
    "    # Show parameter uncertainties from covariance matrix\n",
    "    param_std = np.sqrt(np.diag(pcov))\n",
    "    print(f\"Parameter uncertainties (std): {param_std}\")\n",
    "\n",
    "\n",
    "# Run the demo\n",
    "demo_curve_fit_large()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Performance ComparisonLet's compare different fitting approaches across various dataset sizes to understand when each strategy is most effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T06:32:52.369967Z",
     "iopub.status.busy": "2025-12-18T06:32:52.369814Z",
     "iopub.status.idle": "2025-12-18T06:32:54.276885Z",
     "shell.execute_reply": "2025-12-18T06:32:54.276443Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 10,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.00 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 10,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 10000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PERFORMANCE COMPARISON\n",
      "============================================================\n",
      "\n",
      "      Size     Time (s)  Memory (GB)             Strategy\n",
      "-------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 10000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.021853e+02 | ‚Äñ‚àáf‚Äñ=8.154136e+02 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.299780e+01 | ‚Äñ‚àáf‚Äñ=6.470948e+01 | step=2.578759e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.258256e+01 | ‚Äñ‚àáf‚Äñ=2.461242e+00 | step=2.578759e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.258219e+01 | ‚Äñ‚àáf‚Äñ=1.556516e-03 | step=2.578759e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.153462s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=1.258219e+01 | time=0.153s | final_gradient_norm=9.389295275661184e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.329701s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.3297011510003358, 'final_cost': 25.164388103806253, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 100,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.01 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 100,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 100000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    10,000        0.382        0.001         Single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 100000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=1.028850e+03 | ‚Äñ‚àáf‚Äñ=8.171703e+03 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=1.294961e+02 | ‚Äñ‚àáf‚Äñ=6.602263e+02 | step=2.578759e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=1.252290e+02 | ‚Äñ‚àáf‚Äñ=2.620611e+01 | step=2.578759e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=1.252250e+02 | ‚Äñ‚àáf‚Äñ=5.504848e-03 | step=2.578759e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.196226s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=1.252250e+02 | time=0.196s | final_gradient_norm=7.840626886474322e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.414408s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.4144076020165812, 'final_cost': 250.45007909077088, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Dataset analysis for 500,000 points, 3 parameters:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Estimated memory per point: 146.0 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Total memory estimate: 0.07 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Recommended chunk size: 500,000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:  Number of chunks: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.nlsq.large_dataset:Fitting dataset in single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 500000, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': False, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   100,000        0.471        0.014         Single chunk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.optimizer.trf:Starting TRF optimization (no bounds) | {'n_params': 3, 'n_residuals': 500000, 'max_nfev': None}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=0 | cost=5.138772e+03 | ‚Äñ‚àáf‚Äñ=4.080610e+04 | nfev=1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=1 | cost=6.470026e+02 | ‚Äñ‚àáf‚Äñ=3.300621e+03 | step=2.578759e+00 | nfev=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=2 | cost=6.256043e+02 | ‚Äñ‚àáf‚Äñ=1.312255e+02 | step=2.578759e+00 | nfev=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.optimizer.trf:Optimization: iter=3 | cost=6.255845e+02 | ‚Äñ‚àáf‚Äñ=2.715484e-02 | step=2.578759e+00 | nfev=4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 0.800430s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=6.255845e+02 | time=0.800s | final_gradient_norm=3.558968074353765e-08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 0.975217s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 0.975216843013186, 'final_cost': 1251.1690277573123, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   500,000        1.034        0.068         Single chunk\n"
     ]
    }
   ],
   "source": [
    "def compare_approaches():\n",
    "    \"\"\"Compare different fitting approaches.\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"PERFORMANCE COMPARISON\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Test different dataset sizes\n",
    "    sizes = [10_000, 100_000, 500_000]\n",
    "    print(f\"\\n{'Size':>10} {'Time (s)':>12} {'Memory (GB)':>12} {'Strategy':>20}\")\n",
    "    print(\"-\" * 55)\n",
    "\n",
    "    for n in sizes:\n",
    "        # Generate data\n",
    "        np.random.seed(42)\n",
    "        x = np.linspace(0, 10, n)\n",
    "        y = 2.0 * np.exp(-0.5 * x) + 0.3 + np.random.normal(0, 0.05, n)\n",
    "\n",
    "        # Get memory estimate\n",
    "        stats = estimate_memory_requirements(n, 3)\n",
    "\n",
    "        # Determine strategy\n",
    "        if stats.n_chunks == 1:\n",
    "            strategy = \"Single chunk\"\n",
    "        else:\n",
    "            strategy = f\"Chunked ({stats.n_chunks} chunks)\"\n",
    "\n",
    "        # Time the fit\n",
    "        start = time.time()\n",
    "        result = fit_large_dataset(\n",
    "            exponential_decay,\n",
    "            x,\n",
    "            y,\n",
    "            p0=[2.5, 0.6, 0.2],\n",
    "            memory_limit_gb=0.5,  # Small limit to test chunking\n",
    "            show_progress=False,\n",
    "        )\n",
    "        elapsed = time.time() - start\n",
    "\n",
    "        print(\n",
    "            f\"{n:10,} {elapsed:12.3f} {stats.total_memory_estimate_gb:12.3f} {strategy:>20}\"\n",
    "        )\n",
    "\n",
    "\n",
    "# Run comparison\n",
    "compare_approaches()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîë Key Takeaways1. **Memory estimation first:** Always use `estimate_memory_requirements()` before fitting large datasets to predict memory usage and avoid crashes.2. **Automatic is best:** Use `curve_fit_large()` for automatic optimization - it intelligently selects the best strategy (single-pass, chunked, or streaming).3. **Chunking for large data:** Chunked processing works well when dataset is larger than RAM but can be processed in batches. Achieves <1% error for well-conditioned problems.4. **Streaming for unlimited:** Use streaming optimization when dataset exceeds available memory or is continuously generated. Processes 100% of data with zero accuracy loss.5. **Context managers for flexibility:** Use `memory_context()` and `large_dataset_context()` for temporary configuration changes without affecting global settings.6. **Monitor progress:** Enable `show_progress=True` for long-running fits to track optimization progress in real-time.7. **Algorithm selection matters:** Use `auto_select_algorithm()` to automatically choose the best optimization algorithm for your specific problem.---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Common Pitfalls**Pitfall 1: Not checking memory requirements**- **Symptom:** Out of memory errors, system crashes, or extremely slow performance- **Cause:** Dataset too large for available RAM, not using chunking/streaming- **Solution:** Always call `estimate_memory_requirements()` first to understand memory needs```python# ‚úÖ Correct approachstats = estimate_memory_requirements(n_points, n_params)if stats.n_chunks > 1:    # Use chunking or streaming    result = fit_large_dataset(func, x, y, memory_limit_gb=2.0)```**Pitfall 2: Using streaming when chunking is sufficient**- **Symptom:** Slower performance than necessary- **Cause:** Streaming uses mini-batch gradient descent which is slower than direct optimization- **Solution:** Chunking is faster when data fits in memory (even if split into chunks)```python# Choose based on memory requirementsstats = estimate_memory_requirements(n_points, n_params)if stats.total_memory_estimate_gb < available_ram_gb:    # Use chunking (faster)    result = fit_large_dataset(func, x, y, memory_limit_gb=available_ram_gb)else:    # Use streaming (handles unlimited data)    config = LDMemoryConfig(use_streaming=True)    fitter = LargeDatasetFitter(config=config)```**Pitfall 3: Forgetting to restore configuration**- **Symptom:** Global settings changed unexpectedly, affecting subsequent fits- **Cause:** Manually changing config without restoring- **Solution:** Use context managers to automatically restore settings```python# ‚ùå Wrong approachconfigure_for_large_datasets(memory_limit_gb=1.0)# ... do work ...# (forgot to restore original settings)# ‚úÖ Correct approachwith memory_context(MemoryConfig(memory_limit_gb=1.0)):    # ... do work ...# Settings automatically restored here```**Pitfall 4: Not monitoring long-running fits**- **Symptom:** Fits appear frozen, no feedback on progress- **Cause:** Not enabling progress reporting- **Solution:** Use `show_progress=True` for datasets >100K points```python# ‚úÖ Always use progress reporting for large datasetsresult = fit_large_dataset(    func, x, y,     p0=initial_guess,    show_progress=True  # Get real-time updates)```---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Best Practices1. **Start with memory estimation**   - Call `estimate_memory_requirements()` before fitting   - Plan your strategy based on the results   - Set appropriate `memory_limit_gb` for your system2. **Use automatic functions when possible**   - `curve_fit_large()` handles most cases automatically   - `fit_large_dataset()` provides explicit control when needed   - Let NLSQ choose the optimal strategy3. **Enable progress reporting**   - Use `show_progress=True` for datasets >100K points   - Monitor optimization progress for long-running fits   - Helps identify convergence issues early4. **Choose the right approach**   - **Small (<100K):** Regular `curve_fit()` is sufficient   - **Medium (100K-10M):** Use `curve_fit_large()` with chunking   - **Large (>10M):** Consider streaming optimization   - **Unlimited:** Always use streaming5. **Use context managers**   - Temporary configuration changes with automatic restoration   - Safe for nested operations   - Prevents global state pollution6. **Leverage algorithm selection**   - Use `auto_select_algorithm()` for complex models   - Let NLSQ choose optimal tolerance and algorithm   - Improves convergence for difficult problems7. **Monitor memory usage**   - Check system memory before starting   - Leave headroom (20-30%) for other processes   - Use mixed precision fallback for memory-constrained systems---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Performance Considerations**Memory usage:**- **Single-pass:** Requires `n_points √ó n_params √ó 8 bytes` for Jacobian- **Chunked:** Memory divided by number of chunks- **Streaming:** Constant memory regardless of dataset size- **Trade-off:** Memory vs accuracy (chunking has <1% error, streaming has 0% error)**Computational cost:**- **Time complexity:** O(n √ó m) where n = points, m = parameters- **JAX compilation:** First fit is slow (~1-5s), subsequent fits are fast- **GPU acceleration:** 150-270x speedup for large datasets (>1M points)- **Chunking overhead:** Minimal (<5%) for well-conditioned problems**Scaling behavior:**- **Linear scaling:** Fit time scales linearly with dataset size- **GPU advantage:** Increases with dataset size (more parallelism)- **Memory scaling:** O(n √ó m) for Jacobian matrix- **Chunking efficiency:** >95% accuracy retention for most problems**Trade-offs:**| Approach | Speed | Memory | Accuracy | Best For ||----------|-------|--------|----------|----------|| Single-pass | Fastest | High | 100% | Fits in RAM || Chunked | Fast | Medium | >99% | Larger than RAM || Streaming | Moderate | Low | 100% | Unlimited size |**Optimization tips:**1. Use GPU when available (automatic in JAX)2. Set `memory_limit_gb` to 70-80% of available RAM3. Enable mixed precision fallback for memory-constrained systems4. Use `auto_select_algorithm()` for complex models5. Reuse `CurveFit` objects to avoid recompilation---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚ùì Common Questions**Q: How do I know if I need chunking vs streaming?**A: Use `estimate_memory_requirements()`. If `n_chunks > 1` but the total memory estimate is less than your available RAM, use chunking (faster). If dataset exceeds available memory, use streaming (handles unlimited data).**Q: What's the accuracy trade-off with chunking?**A: NLSQ's advanced chunking algorithm (exponential moving average) achieves <1% error for well-conditioned problems. For ill-conditioned problems or when accuracy is critical, use streaming for zero accuracy loss.**Q: Why is my first fit slow?**A: JAX compiles functions on first use (JIT compilation). Subsequent fits with the same function signature reuse the compiled code and run 100-300x faster.**Q: Can I use large dataset features on a GPU?**A: Yes! JAX automatically uses GPU when available. Large dataset features work seamlessly on both CPU and GPU, with GPU providing additional 2-5x speedup.**Q: What if my dataset doesn't fit in RAM at all?**A: Use streaming optimization with `LDMemoryConfig(use_streaming=True)`. Streaming processes data in batches and can handle unlimited dataset sizes with zero accuracy loss.**Q: How do I monitor long-running fits?**A: Set `show_progress=True` when calling `fit_large_dataset()` or `curve_fit_large()`. This provides real-time progress updates showing iteration count and current objective value.**Q: Should I always use `curve_fit_large()` instead of `curve_fit()`?**A: For small datasets (<100K points), regular `curve_fit()` is simpler and equally fast. Use `curve_fit_large()` when you have >100K points or want automatic dataset size detection.[Complete FAQ](../../docs/faq.md)---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Related Resources**Build on this knowledge:**- [GPU Optimization Deep Dive](../03_advanced/gpu_optimization_deep_dive.ipynb) - Maximize GPU performance- [Performance Optimization Demo](performance_optimization_demo.ipynb) - General optimization strategies- [Streaming Tutorials](../06_streaming/) - Production streaming workflows**Alternative approaches:**- [NLSQ Quickstart](../01_getting_started/nlsq_quickstart.ipynb) - For small datasets (<100K points)- [Custom Algorithms Advanced](../03_advanced/custom_algorithms_advanced.ipynb) - When standard algorithms don't converge**Feature demos:**- [Callbacks Demo](../05_feature_demos/callbacks_demo.ipynb) - Monitor optimization progress- [Enhanced Error Messages](../05_feature_demos/enhanced_error_messages_demo.ipynb) - Debug fitting issues**References:**- [API Documentation - Large Dataset Functions](https://nlsq.readthedocs.io/en/latest/api.html#large-dataset-fitting)- [Memory Management Guide](https://nlsq.readthedocs.io/en/latest/guides/memory.html)- [Performance Benchmarks](https://nlsq.readthedocs.io/en/latest/benchmarks.html)---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Technical Glossary**Chunking:** Dividing a large dataset into smaller batches that fit in memory, processing each batch separately, and combining results using an exponential moving average algorithm.**Streaming optimization:** Processing data in sequential batches using mini-batch gradient descent. Handles unlimited dataset sizes with zero accuracy loss.**Memory estimation:** Predicting memory requirements before fitting by calculating data array sizes, Jacobian matrix size, and JAX compilation overhead.**Exponential moving average (EMA):** Algorithm used in chunking to combine gradients from different chunks with decaying weights, achieving <1% error for well-conditioned problems.**JIT compilation:** Just-In-Time compilation by JAX that converts Python functions to optimized machine code on first use. Subsequent calls reuse the compiled code for 100-300x speedup.**Context manager:** Python construct (`with` statement) that automatically manages resource setup and cleanup, used for temporary configuration changes.**Well-conditioned problem:** Optimization problem where the objective function is smooth, has a clear minimum, and small parameter changes lead to proportional objective changes.**Ill-conditioned problem:** Optimization problem with steep gradients, multiple local minima, or high sensitivity to parameter changes. Benefits from streaming (zero accuracy loss) over chunking.**Auto-detection:** NLSQ feature that automatically detects dataset size and chooses optimal processing strategy (single-pass, chunked, or streaming).**Mixed precision fallback:** Memory optimization technique that uses float32 instead of float64 when memory is constrained, trading slight accuracy for 50% memory reduction.[Complete glossary](../../docs/glossary.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
