{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    return a * jnp.exp(-b * x)\ndef main():\n    print(\"=\" * 70)\n    print(\"Streaming Optimizer: Basic Fault Tolerance Example\")\n    print(\"=\" * 70)\n    print()\n    np.random.seed(42)\n    n_samples = 10000\n    x_data = np.linspace(0, 10, n_samples)\n    true_a, true_b = 2.5, 0.3\n    y_true = exponential_decay(x_data, true_a, true_b)\n    y_data = y_true + 0.1 * np.random.randn(n_samples)\n    print(f\"Dataset: {n_samples} samples\")\n    print(f\"True parameters: a={true_a}, b={true_b}\")\n    print()\n    config = StreamingConfig(\n        batch_size=100,\n        max_epochs=10,\n        learning_rate=0.001,\n        enable_fault_tolerance=True,  # Enable fault tolerance features\n        validate_numerics=True,  # Check for NaN/Inf\n        min_success_rate=0.5,  # Require 50% batch success\n        max_retries_per_batch=2,  # Max 2 retry attempts\n        checkpoint_dir=\"checkpoints\",\n        checkpoint_frequency=100,  # Save every 100 iterations\n        enable_checkpoints=True,\n    )\n    print(\"Configuration:\")\n    print(f\"  Batch size: {config.batch_size}\")\n    print(f\"  Max epochs: {config.max_epochs}\")\n    print(f\"  Learning rate: {config.learning_rate}\")\n    print(f\"  Fault tolerance: {config.enable_fault_tolerance}\")\n    print(f\"  Validate numerics: {config.validate_numerics}\")\n    print(f\"  Min success rate: {config.min_success_rate:.0%}\")\n    print(f\"  Max retries per batch: {config.max_retries_per_batch}\")\n    print()\n    optimizer = StreamingOptimizer(config)\n    p0 = np.array([1.0, 0.1])\n    print(f\"Initial guess: a={p0[0]}, b={p0[1]}\")\n    print()\n    print(\"Starting optimization...\")\n    print(\"-\" * 70)\n    result = optimizer.fit(\n        (x_data, y_data),  # Data as tuple\n        exponential_decay,  # Model function\n        p0,  # Initial parameters\n        verbose=1,  # Show progress\n    )\n    print(\"-\" * 70)\n    print()\n    best_params = result[\"x\"]\n    success = result[\"success\"]\n    message = result[\"message\"]\n    best_loss = result[\"best_loss\"]\n    diagnostics = result[\"streaming_diagnostics\"]\n    print(\"RESULTS\")\n    print(\"=\" * 70)\n    print(f\"Success: {success}\")\n    print(f\"Message: {message}\")\n    print()\n    print(\"Best parameters found:\")\n    print(f\"  a = {best_params[0]:.6f} (true: {true_a})\")\n    print(f\"  b = {best_params[1]:.6f} (true: {true_b})\")\n    print(f\"  Best loss = {best_loss:.6e}\")\n    print()\n    print(\"DIAGNOSTICS\")\n    print(\"=\" * 70)\n    print(f\"Batch success rate: {diagnostics['batch_success_rate']:.1%}\")\n    print(f\"Total batches attempted: {diagnostics['total_batches_attempted']}\")\n    print(f\"Total retries: {diagnostics['total_retries']}\")\n    print(f\"Convergence achieved: {diagnostics['convergence_achieved']}\")\n    print(f\"Final epoch: {diagnostics['final_epoch']}\")\n    print(f\"Elapsed time: {diagnostics['elapsed_time']:.2f}s\")\n    print()\n    if diagnostics[\"failed_batches\"]:\n        print(f\"Failed batches ({len(diagnostics['failed_batches'])}):\")\n        print(f\"  Indices: {diagnostics['failed_batches']}\")\n        print(f\"  Error types: {diagnostics['error_types']}\")\n        print()\n    agg = diagnostics[\"aggregate_stats\"]\n    print(\"Aggregate Statistics (from batch buffer):\")\n    print(f\"  Mean loss: {agg['mean_loss']:.6e}\")\n    print(f\"  Std loss: {agg['std_loss']:.6e}\")\n    print(f\"  Mean gradient norm: {agg['mean_grad_norm']:.6f}\")\n    print(f\"  Mean batch time: {agg['mean_batch_time'] * 1000:.2f}ms\")\n    print()\n    recent_stats = diagnostics[\"recent_batch_stats\"]\n    if recent_stats:\n        print(f\"Recent batch statistics (last {len(recent_stats)} batches):\")\n        for i, stats in enumerate(recent_stats[-5:], 1):\n            status = \"SUCCESS\" if stats[\"success\"] else \"FAILED\"\n            retry_info = (\n                f\" (retries: {stats['retry_count']})\"\n                if stats[\"retry_count\"] > 0\n                else \"\"\n            )\n            print(\n                f\"  Batch {stats['batch_idx']}: {status}, loss={stats['loss']:.6e}{retry_info}\"\n            )\n        print()\n    if diagnostics[\"checkpoint_info\"]:\n        cp = diagnostics[\"checkpoint_info\"]\n        print(\"Checkpoint Information:\")\n        print(f\"  Path: {cp['path']}\")\n        print(f\"  Saved at: {cp['saved_at']}\")\n        print(f\"  Batch index: {cp['batch_idx']}\")\n        print()\n    print(\"=\" * 70)\n    print(\"Example complete!\")\n    print()\n    print(\"Key takeaways:\")\n    print(\"  - Fault tolerance enabled by default (no configuration needed)\")\n    print(\"  - Best parameters always returned (never initial p0)\")\n    print(\"  - NaN/Inf detection at three validation points\")\n    print(\"  - Adaptive retry strategies for failed batches\")\n    print(\"  - Comprehensive diagnostics for analysis\")\n    print(\"  - Checkpoints saved automatically for recovery\")\nif __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
