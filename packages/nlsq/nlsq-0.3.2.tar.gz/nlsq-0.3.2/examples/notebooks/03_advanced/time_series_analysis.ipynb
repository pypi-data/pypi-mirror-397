{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b752e499",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:01.094904Z",
     "iopub.status.busy": "2025-12-18T21:07:01.094609Z",
     "iopub.status.idle": "2025-12-18T21:07:01.385389Z",
     "shell.execute_reply": "2025-12-18T21:07:01.384850Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib for inline plotting in VS Code/Jupyter\n",
    "# MUST come before importing matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5df3bd82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:01.387466Z",
     "iopub.status.busy": "2025-12-18T21:07:01.387318Z",
     "iopub.status.idle": "2025-12-18T21:07:02.061413Z",
     "shell.execute_reply": "2025-12-18T21:07:02.060865Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Imports and test data ready for time series analysis\n"
     ]
    }
   ],
   "source": [
    "# Standard library imports\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party imports\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# NLSQ imports\n",
    "from nlsq import CurveFit\n",
    "\n",
    "# Initialize\n",
    "np.random.seed(42)\n",
    "cf = CurveFit()\n",
    "\n",
    "\n",
    "# Model functions for time series\n",
    "def logistic_growth(t, L, k, t0):\n",
    "    \"\"\"Logistic growth model.\n",
    "\n",
    "    Common in population dynamics, product adoption, epidemic spread.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array_like\n",
    "        Time\n",
    "    L : float\n",
    "        Carrying capacity (asymptotic maximum)\n",
    "    k : float\n",
    "        Growth rate\n",
    "    t0 : float\n",
    "        Inflection point (time of maximum growth rate)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array_like\n",
    "        Population/quantity at time t\n",
    "    \"\"\"\n",
    "    return L / (1.0 + jnp.exp(-k * (t - t0)))\n",
    "\n",
    "\n",
    "# Generate test data\n",
    "t_data = np.linspace(0, 100, 80)\n",
    "L_true = 1000.0\n",
    "k_true = 0.08\n",
    "t0_true = 50.0\n",
    "\n",
    "print(\"✓ Imports and test data ready for time series analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d9d7a2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:02.063102Z",
     "iopub.status.busy": "2025-12-18T21:07:02.062845Z",
     "iopub.status.idle": "2025-12-18T21:07:05.158034Z",
     "shell.execute_reply": "2025-12-18T21:07:05.157444Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated logistic growth data\n",
      "  Time range: 0 - 100 days\n",
      "  True parameters: L=1000.0, k=0.08, t0=50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 3, 'n_data_points': 80, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': True, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 3, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.662999s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=3.156466e+04 | time=1.663s | final_gradient_norm=1.5572458544945291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 2.097597s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 2.0975965170000563, 'final_cost': 63129.329240049825, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Parameters:\n",
      "  Carrying capacity (L): 998.3 ± 9.7 (true: 1000.0)\n",
      "  Growth rate (k): 0.082 ± 0.002 (true: 0.08)\n",
      "  Inflection point (t0): 50.4 ± 0.4 days (true: 50.0)\n",
      "\n",
      "Derived:\n",
      "  Maximum growth rate: 20.5 units/day\n",
      "  Doubling time (early phase): 8.4 days\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Growth trend analysis complete\n"
     ]
    }
   ],
   "source": [
    "y_true = logistic_growth(t_data, L_true, k_true, t0_true)\n",
    "np.random.seed(42)\n",
    "noise = np.random.normal(0, 30, len(t_data))\n",
    "y_observed = y_true + noise\n",
    "print(\"✓ Generated logistic growth data\")\n",
    "print(f\"  Time range: {t_data.min():.0f} - {t_data.max():.0f} days\")\n",
    "print(f\"  True parameters: L={L_true}, k={k_true}, t0={t0_true}\")\n",
    "cf = CurveFit()\n",
    "p0 = [900.0, 0.1, 45.0]  # L, k, t0\n",
    "bounds = ([0, 0, 0], [2000, 1.0, 100])  # L, k, t0 must be positive\n",
    "popt, pcov = cf.curve_fit(\n",
    "    logistic_growth, jnp.array(t_data), jnp.array(y_observed), p0=p0, bounds=bounds\n",
    ")\n",
    "L_fit, k_fit, t0_fit = popt\n",
    "L_err, k_err, t0_err = np.sqrt(np.diag(pcov))\n",
    "print(\"Fitted Parameters:\")\n",
    "print(f\"  Carrying capacity (L): {L_fit:.1f} ± {L_err:.1f} (true: {L_true})\")\n",
    "print(f\"  Growth rate (k): {k_fit:.3f} ± {k_err:.3f} (true: {k_true})\")\n",
    "print(f\"  Inflection point (t0): {t0_fit:.1f} ± {t0_err:.1f} days (true: {t0_true})\")\n",
    "max_growth_rate = k_fit * L_fit / 4  # dN/dt at t0\n",
    "print(\"\\nDerived:\")\n",
    "print(f\"  Maximum growth rate: {max_growth_rate:.1f} units/day\")\n",
    "print(f\"  Doubling time (early phase): {np.log(2) / k_fit:.1f} days\")\n",
    "t_extended = np.linspace(0, 150, 300)\n",
    "y_fit = logistic_growth(jnp.array(t_extended), L_fit, k_fit, t0_fit)\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "ax1.plot(t_data, y_observed, \"o\", alpha=0.5, label=\"Observed data\", ms=4)\n",
    "ax1.plot(t_extended, y_fit, \"r-\", lw=2, label=\"Fitted logistic model\")\n",
    "ax1.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1, label=\"Forecast boundary\")\n",
    "ax1.axhline(\n",
    "    L_fit, color=\"green\", ls=\":\", lw=1.5, label=f\"Carrying capacity: {L_fit:.0f}\"\n",
    ")\n",
    "ax1.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=f\"Inflection: {t0_fit:.0f} d\")\n",
    "ax1.set_xlabel(\"Time (days)\")\n",
    "ax1.set_ylabel(\"Population / Quantity\")\n",
    "ax1.set_title(\"Logistic Growth Fitting and Forecasting\")\n",
    "ax1.legend()\n",
    "ax1.grid(alpha=0.3)\n",
    "growth_rate = k_fit * y_fit * (1 - y_fit / L_fit)  # dN/dt\n",
    "ax2.plot(t_extended, growth_rate, \"b-\", lw=2)\n",
    "ax2.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=\"Maximum growth rate\")\n",
    "ax2.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1)\n",
    "ax2.set_xlabel(\"Time (days)\")\n",
    "ax2.set_ylabel(\"Growth Rate (dN/dt)\")\n",
    "ax2.set_title(\"Instantaneous Growth Rate\")\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig_dir = Path(\"figures\") / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_01.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"✓ Growth trend analysis complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55f6932",
   "metadata": {},
   "source": [
    "Part 2: Seasonal Decomposition with Fourier Series\n",
    "\n",
    "Many time series exhibit periodic patterns (daily, weekly, annual cycles). We can model these using Fourier series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "278407be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:05.159606Z",
     "iopub.status.busy": "2025-12-18T21:07:05.159462Z",
     "iopub.status.idle": "2025-12-18T21:07:07.953682Z",
     "shell.execute_reply": "2025-12-18T21:07:07.953013Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Starting curve fit | {'n_params': 5, 'n_data_points': 1095, 'method': 'trf', 'solver': 'auto', 'batch_size': None, 'has_bounds': True, 'dynamic_sizing': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Starting least squares optimization | {'method': 'trf', 'n_params': 5, 'loss': 'linear', 'ftol': 1e-08, 'xtol': 1e-08, 'gtol': 1e-08}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated seasonal temperature data\n",
      "  Duration: 1095 days (3.0 years)\n",
      "  True parameters: mean=15.0°C, amplitude=10.0°C\n",
      "  Warming trend: 3.65°C/year\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.least_squares:Timer: optimization took 1.235572s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.least_squares:Convergence: reason=`ftol` termination condition is satisfied. | iterations=4 | final_cost=2.168455e+03 | time=1.236s | final_gradient_norm=0.006387870804850552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PERFORMANCE:nlsq.curve_fit:Timer: curve_fit took 2.082202s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:nlsq.curve_fit:Curve fit completed | {'total_time': 2.0822015599987935, 'final_cost': 4336.909714941169, 'covariance_warning': False}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitted Seasonal Parameters:\n",
      "  Baseline: 15.00 ± 0.12 °C\n",
      "  Trend: 0.0099 ± 0.0002 °C/day = 3.60 °C/year\n",
      "  Amplitude: 10.01 ± 0.09 °C\n",
      "  Period: 364.9 ± 0.6 days\n",
      "  Phase: -0.013 ± 0.017 rad\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Seasonal decomposition complete\n"
     ]
    }
   ],
   "source": [
    "days = np.linspace(0, 3 * 365, 3 * 365)\n",
    "annual_mean = 15.0  # °C\n",
    "annual_amplitude = 10.0  # °C\n",
    "annual_period = 365.25  # days\n",
    "trend_slope = 0.01  # °C/day (climate warming)\n",
    "trend_component = annual_mean + trend_slope * days\n",
    "seasonal_component = annual_amplitude * np.sin(2 * np.pi * days / annual_period)\n",
    "temp_true = trend_component + seasonal_component\n",
    "np.random.seed(123)\n",
    "temp_observed = temp_true + np.random.normal(0, 2.0, len(days))\n",
    "print(\"✓ Generated seasonal temperature data\")\n",
    "print(f\"  Duration: {len(days)} days ({len(days) / 365:.1f} years)\")\n",
    "print(f\"  True parameters: mean={annual_mean}°C, amplitude={annual_amplitude}°C\")\n",
    "print(f\"  Warming trend: {trend_slope * 365:.2f}°C/year\")\n",
    "\n",
    "\n",
    "def trend_seasonal_model(t, mean, trend, amplitude, period, phase):\n",
    "    \"\"\"Combined linear trend and sinusoidal seasonal component.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    t : array_like\n",
    "        Time (days)\n",
    "    mean : float\n",
    "        Baseline level\n",
    "    trend : float\n",
    "        Linear trend (units per day)\n",
    "    amplitude : float\n",
    "        Seasonal amplitude\n",
    "    period : float\n",
    "        Seasonal period (days)\n",
    "    phase : float\n",
    "        Phase shift (radians)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    y : array_like\n",
    "        Modeled values\n",
    "    \"\"\"\n",
    "    trend_part = mean + trend * t\n",
    "    seasonal_part = amplitude * jnp.sin(2 * jnp.pi * t / period + phase)\n",
    "    return trend_part + seasonal_part\n",
    "\n",
    "\n",
    "p0_seasonal = [15.0, 0.0, 8.0, 365.0, 0.0]  # mean, trend, amplitude, period, phase\n",
    "bounds_seasonal = (\n",
    "    [-50, -0.1, 0, 300, -2 * np.pi],  # Lower\n",
    "    [50, 0.1, 20, 400, 2 * np.pi],  # Upper\n",
    ")\n",
    "popt_seasonal, pcov_seasonal = cf.curve_fit(\n",
    "    trend_seasonal_model,\n",
    "    jnp.array(days),\n",
    "    jnp.array(temp_observed),\n",
    "    p0=p0_seasonal,\n",
    "    bounds=bounds_seasonal,\n",
    ")\n",
    "mean_fit, trend_fit, amp_fit, period_fit, phase_fit = popt_seasonal\n",
    "errors = np.sqrt(np.diag(pcov_seasonal))\n",
    "print(\"Fitted Seasonal Parameters:\")\n",
    "print(f\"  Baseline: {mean_fit:.2f} ± {errors[0]:.2f} °C\")\n",
    "print(\n",
    "    f\"  Trend: {trend_fit:.4f} ± {errors[1]:.4f} °C/day = {trend_fit * 365:.2f} °C/year\"\n",
    ")\n",
    "print(f\"  Amplitude: {amp_fit:.2f} ± {errors[2]:.2f} °C\")\n",
    "print(f\"  Period: {period_fit:.1f} ± {errors[3]:.1f} days\")\n",
    "print(f\"  Phase: {phase_fit:.3f} ± {errors[4]:.3f} rad\")\n",
    "trend_fitted = mean_fit + trend_fit * days\n",
    "seasonal_fitted = amp_fit * np.sin(2 * np.pi * days / period_fit + phase_fit)\n",
    "total_fitted = trend_fitted + seasonal_fitted\n",
    "residuals = temp_observed - total_fitted\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\n",
    "axes[0].plot(days / 365, temp_observed, \"o\", alpha=0.3, ms=2, label=\"Observed\")\n",
    "axes[0].plot(days / 365, total_fitted, \"r-\", lw=1.5, label=\"Fitted model\")\n",
    "axes[0].set_ylabel(\"Temperature (°C)\")\n",
    "axes[0].set_title(\"Original Time Series\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[1].plot(days / 365, trend_fitted, \"b-\", lw=2)\n",
    "axes[1].set_ylabel(\"Trend (°C)\")\n",
    "axes[1].set_title(f\"Trend Component (slope: {trend_fit * 365:.3f} °C/year)\")\n",
    "axes[1].grid(alpha=0.3)\n",
    "axes[2].plot(days / 365, seasonal_fitted, \"g-\", lw=1.5)\n",
    "axes[2].set_ylabel(\"Seasonal (°C)\")\n",
    "axes[2].set_title(\n",
    "    f\"Seasonal Component (period: {period_fit:.1f} days, amplitude: {amp_fit:.1f} °C)\"\n",
    ")\n",
    "axes[2].grid(alpha=0.3)\n",
    "axes[3].plot(days / 365, residuals, \"o\", alpha=0.4, ms=2, color=\"gray\")\n",
    "axes[3].axhline(0, color=\"k\", ls=\"--\", lw=1)\n",
    "axes[3].set_ylabel(\"Residual (°C)\")\n",
    "axes[3].set_xlabel(\"Time (years)\")\n",
    "axes[3].set_title(f\"Residuals (std: {np.std(residuals):.2f} °C, should be white noise)\")\n",
    "axes[3].grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig_dir = Path(\"figures\") / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_02.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"✓ Seasonal decomposition complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3732728c",
   "metadata": {},
   "source": [
    "Part 3: Forecasting with Uncertainty\n",
    "\n",
    "Extrapolate the fitted model into the future with prediction intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "051c3b09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:07.955177Z",
     "iopub.status.busy": "2025-12-18T21:07:07.955023Z",
     "iopub.status.idle": "2025-12-18T21:07:08.695326Z",
     "shell.execute_reply": "2025-12-18T21:07:08.694779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Generated 365 day forecast\n",
      "  Forecast period: 3.0 - 4.0 years\n",
      "  Prediction interval width: 4.0 °C (±1σ residuals)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Forecast visualization complete\n"
     ]
    }
   ],
   "source": [
    "days_forecast = np.linspace(0, 4 * 365, 4 * 365)\n",
    "forecast_boundary = 3 * 365\n",
    "temp_forecast = trend_seasonal_model(jnp.array(days_forecast), *popt_seasonal)\n",
    "n_samples = 200\n",
    "param_samples = np.random.multivariate_normal(\n",
    "    popt_seasonal, pcov_seasonal, size=n_samples\n",
    ")\n",
    "forecast_samples = np.array(\n",
    "    [\n",
    "        trend_seasonal_model(jnp.array(days_forecast), *params)\n",
    "        for params in param_samples\n",
    "    ]\n",
    ")\n",
    "forecast_mean = np.mean(forecast_samples, axis=0)\n",
    "forecast_std = np.std(forecast_samples, axis=0)\n",
    "forecast_lower = np.percentile(forecast_samples, 2.5, axis=0)  # 95% PI\n",
    "forecast_upper = np.percentile(forecast_samples, 97.5, axis=0)\n",
    "residual_std = np.std(residuals)\n",
    "forecast_lower_total = forecast_lower - 2 * residual_std\n",
    "forecast_upper_total = forecast_upper + 2 * residual_std\n",
    "print(f\"✓ Generated {len(days_forecast) - len(days)} day forecast\")\n",
    "print(\n",
    "    f\"  Forecast period: {len(days) / 365:.1f} - {len(days_forecast) / 365:.1f} years\"\n",
    ")\n",
    "print(f\"  Prediction interval width: {2 * residual_std:.1f} °C (±1σ residuals)\")\n",
    "fig, ax = plt.subplots(figsize=(14, 6))\n",
    "ax.plot(\n",
    "    days / 365, temp_observed, \"o\", alpha=0.3, ms=2, color=\"steelblue\", label=\"Observed\"\n",
    ")\n",
    "ax.plot(\n",
    "    days / 365,\n",
    "    total_fitted,\n",
    "    \"r-\",\n",
    "    lw=2,\n",
    "    label=\"Fitted model\",\n",
    "    alpha=0.8,\n",
    ")\n",
    "forecast_mask = days_forecast > forecast_boundary\n",
    "ax.plot(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_mean[forecast_mask],\n",
    "    \"r--\",\n",
    "    lw=2,\n",
    "    label=\"Forecast\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_lower[forecast_mask],\n",
    "    forecast_upper[forecast_mask],\n",
    "    alpha=0.3,\n",
    "    color=\"red\",\n",
    "    label=\"95% PI (parameter)\",\n",
    ")\n",
    "ax.fill_between(\n",
    "    days_forecast[forecast_mask] / 365,\n",
    "    forecast_lower_total[forecast_mask],\n",
    "    forecast_upper_total[forecast_mask],\n",
    "    alpha=0.15,\n",
    "    color=\"orange\",\n",
    "    label=\"95% PI (total)\",\n",
    ")\n",
    "ax.axvline(forecast_boundary / 365, color=\"gray\", ls=\"--\", lw=2, label=\"Forecast start\")\n",
    "ax.set_xlabel(\"Time (years)\", fontsize=12)\n",
    "ax.set_ylabel(\"Temperature (°C)\", fontsize=12)\n",
    "ax.set_title(\"Time Series Forecast with Uncertainty Quantification\", fontsize=14)\n",
    "ax.legend(loc=\"upper left\")\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig_dir = Path(\"figures\") / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_03.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(\"✓ Forecast visualization complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aabb0a66",
   "metadata": {},
   "source": [
    "Part 4: Residual Diagnostics (Autocorrelation)\n",
    "\n",
    "For valid inference, residuals should be uncorrelated (white noise). We check this with autocorrelation analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09137657",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-18T21:07:08.697099Z",
     "iopub.status.busy": "2025-12-18T21:07:08.696996Z",
     "iopub.status.idle": "2025-12-18T21:07:08.913034Z",
     "shell.execute_reply": "2025-12-18T21:07:08.912582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Autocorrelation analysis complete\n",
      "  Significant lags (95% level): 2 / 60 (3.3%)\n",
      "  ✓ Residuals consistent with white noise (good fit)\n"
     ]
    }
   ],
   "source": [
    "def autocorrelation(x, max_lag=50):\n",
    "    \"\"\"Calculate autocorrelation function (ACF).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        Time series (residuals)\n",
    "    max_lag : int\n",
    "        Maximum lag to compute\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lags : array\n",
    "        Lag values\n",
    "    acf : array\n",
    "        Autocorrelation values\n",
    "    \"\"\"\n",
    "    x_centered = x - np.mean(x)\n",
    "    c0 = np.dot(x_centered, x_centered) / len(x)\n",
    "    lags = np.arange(0, max_lag + 1)\n",
    "    acf = np.zeros(len(lags))\n",
    "    for i, lag in enumerate(lags):\n",
    "        if lag == 0:\n",
    "            acf[i] = 1.0\n",
    "        else:\n",
    "            c_lag = np.dot(x_centered[:-lag], x_centered[lag:]) / len(x)\n",
    "            acf[i] = c_lag / c0\n",
    "    return lags, acf\n",
    "\n",
    "\n",
    "lags, acf_values = autocorrelation(residuals, max_lag=60)\n",
    "conf_bound = 1.96 / np.sqrt(len(residuals))\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.stem(lags, acf_values, basefmt=\" \", linefmt=\"C0-\", markerfmt=\"C0o\")\n",
    "ax.axhline(0, color=\"k\", lw=1)\n",
    "ax.axhline(conf_bound, color=\"r\", ls=\"--\", lw=1.5, label=\"95% confidence\")\n",
    "ax.axhline(-conf_bound, color=\"r\", ls=\"--\", lw=1.5)\n",
    "ax.fill_between(\n",
    "    lags, -conf_bound, conf_bound, alpha=0.2, color=\"red\", label=\"White noise region\"\n",
    ")\n",
    "ax.set_xlabel(\"Lag (days)\")\n",
    "ax.set_ylabel(\"Autocorrelation\")\n",
    "ax.set_title(\"Autocorrelation Function (ACF) of Residuals\")\n",
    "ax.set_xlim(-1, max(lags) + 1)\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "fig_dir = Path(\"figures\") / \"time_series_analysis\"\n",
    "fig_dir.mkdir(parents=True, exist_ok=True)\n",
    "plt.savefig(fig_dir / \"fig_04.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "significant_lags = np.sum(np.abs(acf_values[1:]) > conf_bound)  # Exclude lag 0\n",
    "print(\"✓ Autocorrelation analysis complete\")\n",
    "print(\n",
    "    f\"  Significant lags (95% level): {significant_lags} / {len(lags) - 1} ({significant_lags / (len(lags) - 1) * 100:.1f}%)\"\n",
    ")\n",
    "if significant_lags / (len(lags) - 1) < 0.05:\n",
    "    print(\"  ✓ Residuals consistent with white noise (good fit)\")\n",
    "else:\n",
    "    print(\n",
    "        \"  ⚠ Significant autocorrelation detected: consider more complex model or autoregressive errors\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d7f476",
   "metadata": {},
   "source": [
    "Summary and Best Practices\n",
    "\n",
    "When to Use NLSQ for Time Series\n",
    "\n",
    "| **Use Case** | **NLSQ Strength** | **Alternative** |\n",
    "|--------------|-------------------|------------------|\n",
    "| Physical growth models (exponential, logistic) | ✅ Excellent (interpretable parameters) | ARIMA (less interpretable) |\n",
    "| Periodic data with known/unknown period | ✅ Good (Fourier series) | Seasonal decomposition (STL, Prophet) |\n",
    "| Trend + seasonality | ✅ Good (combined parametric model) | Prophet, TBATS |\n",
    "| Autoregressive processes (ARMA) | ❌ Poor (not designed for this) | ARIMA, SARIMA |\n",
    "| Irregular sampling | ✅ Excellent (handles any time grid) | Interpolation + ARIMA |\n",
    "| Large datasets (millions of points) | ✅ Excellent (JAX GPU acceleration) | Dask + statsmodels |\n",
    "\n",
    "Key Takeaways\n",
    "\n",
    "1. **Model Selection**: Choose parametric forms based on domain knowledge\n",
    "- Growth: Exponential, logistic, Gompertz\n",
    "- Decay: Exponential, power-law\n",
    "- Periodic: Fourier series (sum of sines/cosines)\n",
    "\n",
    "2. **Forecasting Uncertainty**\n",
    "- **Parameter uncertainty**: From covariance matrix (Monte Carlo sampling)\n",
    "- **Model uncertainty**: Residual standard deviation\n",
    "- **Total**: Combine both sources for realistic prediction intervals\n",
    "\n",
    "3. **Diagnostics**\n",
    "- **Residuals**: Should be centered at zero, no trend\n",
    "- **Autocorrelation**: Should be within confidence bounds (white noise)\n",
    "- **Heteroscedasticity**: Check if residual variance changes over time\n",
    "\n",
    "4. **Multi-Seasonal Data**\n",
    "- Use multiple sinusoids: `amp1 * sin(2π t / P1) + amp2 * sin(2π t / P2)`\n",
    "- Example: Daily + weekly cycles in energy consumption\n",
    "\n",
    "Production Code Template\n",
    "\n",
    "```python\n",
    "from nlsq import CurveFit\n",
    "import jax.numpy as jnp\n",
    "\n",
    "def forecast_time_series(t, y, forecast_days=30):\n",
    "\"\"\"Fit trend+seasonal model and forecast.\"\"\"\n",
    "\n",
    "Model\n",
    "def model(t, mean, trend, amp, period, phase):\n",
    "return mean + trend * t + amp * jnp.sin(2 * jnp.pi * t / period + phase)\n",
    "\n",
    "Fit\n",
    "cf = CurveFit()\n",
    "p0 = [jnp.mean(y), 0.0, jnp.std(y) / 2, 365.0, 0.0]\n",
    "popt, pcov = cf.curve_fit(model, jnp.array(t), jnp.array(y), p0=p0)\n",
    "\n",
    "Forecast\n",
    "t_future = jnp.arange(t[-1] + 1, t[-1] + 1 + forecast_days)\n",
    "y_forecast = model(t_future, *popt)\n",
    "\n",
    "Uncertainty (simplified)\n",
    "residual_std = jnp.std(y - model(jnp.array(t), *popt))\n",
    "forecast_uncertainty = residual_std\n",
    "\n",
    "return t_future, y_forecast, forecast_uncertainty\n",
    "```\n",
    "\n",
    "Next Steps\n",
    "\n",
    "- **Advanced Seasonality**: Multi-frequency Fourier series for complex cycles\n",
    "- **State-Space Models**: Kalman filtering with NLSQ parameter estimation\n",
    "- **Batch Processing**: Fit thousands of time series in parallel with `jax.vmap`\n",
    "- **Hybrid Models**: Combine NLSQ (trend/seasonal) with ARIMA (residual modeling)\n",
    "\n",
    "References\n",
    "\n",
    "1. **Time Series Analysis**: Chatfield, *The Analysis of Time Series* (2004)\n",
    "2. **Forecasting**: Hyndman & Athanasopoulos, *Forecasting: Principles and Practice* (2021)\n",
    "3. **Related Examples**:\n",
    "- `gallery/biology/growth_curves.py` - Bacterial growth fitting\n",
    "- `gallery/physics/damped_oscillation.py` - Oscillatory time series\n",
    "- `advanced_features_demo.ipynb` - Robustness for outliers in time series\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
