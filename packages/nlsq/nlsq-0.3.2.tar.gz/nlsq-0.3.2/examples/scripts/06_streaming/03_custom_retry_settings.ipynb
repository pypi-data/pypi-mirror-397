{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    return a * jnp.exp(-b * x)\ndef inject_noise_into_data(x_data, y_data, noise_rate=0.1):\n    \"\"\"Inject NaN values into data to simulate noisy sensors\"\"\"\n    n_samples = len(y_data)\n    n_corrupted = int(n_samples * noise_rate)\n    corrupt_indices = np.random.choice(n_samples, n_corrupted, replace=False)\n    y_corrupted = np.array(y_data, copy=True)\n    y_corrupted[corrupt_indices] = np.nan\n    return y_corrupted\ndef main():\n    print(\"=\" * 70)\n    print(\"Streaming Optimizer: Custom Retry Settings Example\")\n    print(\"=\" * 70)\n    print()\n    np.random.seed(42)\n    n_samples = 10000\n    x_data = np.linspace(0, 10, n_samples)\n    true_a, true_b = 2.5, 0.3\n    y_true = noisy_exponential(x_data, true_a, true_b)\n    y_data = y_true + 0.1 * np.random.randn(n_samples)\n    noise_rate = 0.10\n    y_corrupted = inject_noise_into_data(x_data, y_data, noise_rate)\n    n_corrupted = np.sum(np.isnan(y_corrupted))\n    print(f\"Dataset: {n_samples} samples\")\n    print(f\"Corrupted samples: {n_corrupted} ({n_corrupted / n_samples:.1%})\")\n    print(f\"True parameters: a={true_a}, b={true_b}\")\n    print()\n    print(\"PART 1: Standard Settings (min_success_rate=0.5)\")\n    print(\"=\" * 70)\n    config_standard = StreamingConfig(\n        batch_size=100,\n        max_epochs=5,\n        learning_rate=0.001,\n        enable_fault_tolerance=True,\n        validate_numerics=True,\n        min_success_rate=0.5,  # Require 50% success (standard)\n        max_retries_per_batch=2,  # Standard retry limit\n    )\n    print(\"Configuration:\")\n    print(f\"  Min success rate: {config_standard.min_success_rate:.0%}\")\n    print(f\"  Max retries per batch: {config_standard.max_retries_per_batch}\")\n    print()\n    optimizer1 = StreamingOptimizer(config_standard)\n    p0 = np.array([1.0, 0.1])\n    print(\"Starting optimization with standard settings...\")\n    result1 = optimizer1.fit(\n        (x_data, y_corrupted),\n        noisy_exponential,\n        p0,\n        verbose=0,  # Silent mode\n    )\n    diag1 = result1[\"streaming_diagnostics\"]\n    print(f\"Result: {'SUCCESS' if result1['success'] else 'FAILED'}\")\n    print(f\"Message: {result1['message']}\")\n    print(f\"Batch success rate: {diag1['batch_success_rate']:.1%}\")\n    print(\n        f\"Failed batches: {len(diag1['failed_batches'])}/{diag1['total_batches_attempted']}\"\n    )\n    print(f\"Total retries: {diag1['total_retries']}\")\n    print()\n    print(\"PART 2: Permissive Settings (min_success_rate=0.3)\")\n    print(\"=\" * 70)\n    config_permissive = StreamingConfig(\n        batch_size=100,\n        max_epochs=10,\n        learning_rate=0.001,\n        enable_fault_tolerance=True,\n        validate_numerics=True,\n        min_success_rate=0.3,  # Allow 70% failures (very permissive)\n        max_retries_per_batch=2,  # Standard retry limit\n    )\n    print(\"Configuration:\")\n    print(f\"  Min success rate: {config_permissive.min_success_rate:.0%} (permissive)\")\n    print(f\"  Max retries per batch: {config_permissive.max_retries_per_batch}\")\n    print()\n    optimizer2 = StreamingOptimizer(config_permissive)\n    print(\"Starting optimization with permissive settings...\")\n    result2 = optimizer2.fit(\n        (x_data, y_corrupted),\n        noisy_exponential,\n        p0,\n        verbose=1,\n    )\n    print()\n    diag2 = result2[\"streaming_diagnostics\"]\n    print(f\"Result: {'SUCCESS' if result2['success'] else 'FAILED'}\")\n    print(f\"Message: {result2['message']}\")\n    print(f\"Batch success rate: {diag2['batch_success_rate']:.1%}\")\n    print(\n        f\"Failed batches: {len(diag2['failed_batches'])}/{diag2['total_batches_attempted']}\"\n    )\n    print(f\"Total retries: {diag2['total_retries']}\")\n    print()\n    print(\"PART 3: Error Analysis\")\n    print(\"=\" * 70)\n    print(\"Error Type Distribution:\")\n    for error_type, count in diag2[\"error_types\"].items():\n        pct = count / sum(diag2[\"error_types\"].values()) * 100\n        print(f\"  {error_type}: {count} ({pct:.1f}%)\")\n    print()\n    print(\"Retry Statistics:\")\n    if diag2[\"retry_counts\"]:\n        retry_counts_list = list(diag2[\"retry_counts\"].values())\n        print(f\"  Batches with retries: {len(retry_counts_list)}\")\n        print(f\"  Average retries per failed batch: {np.mean(retry_counts_list):.2f}\")\n        print(f\"  Max retries for single batch: {max(retry_counts_list)}\")\n    else:\n        print(\"  No retries attempted\")\n    print()\n    print(\"FINAL RESULTS\")\n    print(\"=\" * 70)\n    if result2[\"success\"]:\n        best_params = result2[\"x\"]\n        print(\"Best parameters:\")\n        print(f\"  a = {best_params[0]:.6f} (true: {true_a})\")\n        print(f\"  b = {best_params[1]:.6f} (true: {true_b})\")\n        print(f\"  Best loss = {result2['best_loss']:.6e}\")\n        print()\n        param_errors = np.abs(best_params - np.array([true_a, true_b]))\n        rel_errors = param_errors / np.array([true_a, true_b]) * 100\n        print(\"Parameter errors:\")\n        print(f\"  a error: {param_errors[0]:.6f} ({rel_errors[0]:.2f}%)\")\n        print(f\"  b error: {param_errors[1]:.6f} ({rel_errors[1]:.2f}%)\")\n    else:\n        print(\"Optimization failed - success rate too low\")\n        print(f\"Best parameters found (may be suboptimal): {result2['x']}\")\n    print()\n    agg = diag2[\"aggregate_stats\"]\n    print(\"Aggregate Statistics (successful batches only):\")\n    print(f\"  Mean loss: {agg['mean_loss']:.6e}\")\n    print(f\"  Std loss: {agg['std_loss']:.6e}\")\n    print(f\"  Mean gradient norm: {agg['mean_grad_norm']:.6f}\")\n    print()\n    print(\"=\" * 70)\n    print(\"Example complete!\")\n    print()\n    print(\"Key takeaways:\")\n    print(\"  - min_success_rate controls acceptable failure rate\")\n    print(\"  - Permissive settings (0.3-0.5) good for noisy data\")\n    print(\"  - Strict settings (0.7-0.9) good for clean data\")\n    print(\"  - Retry strategies adapt to error types automatically\")\n    print(\"  - Best parameters returned even when success rate fails\")\n    print(\"  - Error type distribution helps diagnose data issues\")\nif __name__ == \"__main__\":\n    main()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
