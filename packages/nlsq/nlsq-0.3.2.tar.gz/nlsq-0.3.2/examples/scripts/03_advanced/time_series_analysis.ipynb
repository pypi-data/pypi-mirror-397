{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "    Common in population dynamics, product adoption, epidemic spread.\n    Parameters\n    ----------\n    t : array_like\n        Time\n    L : float\n        Carrying capacity (asymptotic maximum)\n    k : float\n        Growth rate\n    t0 : float\n        Inflection point (time of maximum growth rate)\n    Returns\n    -------\n    y : array_like\n        Population/quantity at time t\n    \"\"\"\n    return L / (1.0 + jnp.exp(-k * (t - t0)))\ny_true = logistic_growth(t_data, L_true, k_true, t0_true)\nnp.random.seed(42)\nnoise = np.random.normal(0, 30, len(t_data))\ny_observed = y_true + noise\nprint(\"\u2713 Generated logistic growth data\")\nprint(f\"  Time range: {t_data.min():.0f} - {t_data.max():.0f} days\")\nprint(f\"  True parameters: L={L_true}, k={k_true}, t0={t0_true}\")\ncf = CurveFit()\np0 = [900.0, 0.1, 45.0]  # L, k, t0\nbounds = ([0, 0, 0], [2000, 1.0, 100])  # L, k, t0 must be positive\npopt, pcov = cf.curve_fit(\n    logistic_growth, jnp.array(t_data), jnp.array(y_observed), p0=p0, bounds=bounds\n)\nL_fit, k_fit, t0_fit = popt\nL_err, k_err, t0_err = np.sqrt(np.diag(pcov))\nprint(\"Fitted Parameters:\")\nprint(f\"  Carrying capacity (L): {L_fit:.1f} \u00b1 {L_err:.1f} (true: {L_true})\")\nprint(f\"  Growth rate (k): {k_fit:.3f} \u00b1 {k_err:.3f} (true: {k_true})\")\nprint(f\"  Inflection point (t0): {t0_fit:.1f} \u00b1 {t0_err:.1f} days (true: {t0_true})\")\nmax_growth_rate = k_fit * L_fit / 4  # dN/dt at t0\nprint(\"\\nDerived:\")\nprint(f\"  Maximum growth rate: {max_growth_rate:.1f} units/day\")\nprint(f\"  Doubling time (early phase): {np.log(2) / k_fit:.1f} days\")\nt_extended = np.linspace(0, 150, 300)\ny_fit = logistic_growth(jnp.array(t_extended), L_fit, k_fit, t0_fit)\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\nax1.plot(t_data, y_observed, \"o\", alpha=0.5, label=\"Observed data\", ms=4)\nax1.plot(t_extended, y_fit, \"r-\", lw=2, label=\"Fitted logistic model\")\nax1.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1, label=\"Forecast boundary\")\nax1.axhline(\n    L_fit, color=\"green\", ls=\":\", lw=1.5, label=f\"Carrying capacity: {L_fit:.0f}\"\n)\nax1.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=f\"Inflection: {t0_fit:.0f} d\")\nax1.set_xlabel(\"Time (days)\")\nax1.set_ylabel(\"Population / Quantity\")\nax1.set_title(\"Logistic Growth Fitting and Forecasting\")\nax1.legend()\nax1.grid(alpha=0.3)\ngrowth_rate = k_fit * y_fit * (1 - y_fit / L_fit)  # dN/dt\nax2.plot(t_extended, growth_rate, \"b-\", lw=2)\nax2.axvline(t0_fit, color=\"orange\", ls=\":\", lw=1.5, label=\"Maximum growth rate\")\nax2.axvline(t_data.max(), color=\"gray\", ls=\"--\", lw=1)\nax2.set_xlabel(\"Time (days)\")\nax2.set_ylabel(\"Growth Rate (dN/dt)\")\nax2.set_title(\"Instantaneous Growth Rate\")\nax2.legend()\nax2.grid(alpha=0.3)\nplt.tight_layout()\nfig_dir = Path(__file__).parent / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_01.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(\"\u2713 Growth trend analysis complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 2: Seasonal Decomposition with Fourier Series\n",
        "\n",
        "Many time series exhibit periodic patterns (daily, weekly, annual cycles). We can model these using Fourier series.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "days = np.linspace(0, 3 * 365, 3 * 365)\nannual_mean = 15.0  # \u00b0C\nannual_amplitude = 10.0  # \u00b0C\nannual_period = 365.25  # days\ntrend_slope = 0.01  # \u00b0C/day (climate warming)\ntrend_component = annual_mean + trend_slope * days\nseasonal_component = annual_amplitude * np.sin(2 * np.pi * days / annual_period)\ntemp_true = trend_component + seasonal_component\nnp.random.seed(123)\ntemp_observed = temp_true + np.random.normal(0, 2.0, len(days))\nprint(\"\u2713 Generated seasonal temperature data\")\nprint(f\"  Duration: {len(days)} days ({len(days) / 365:.1f} years)\")\nprint(f\"  True parameters: mean={annual_mean}\u00b0C, amplitude={annual_amplitude}\u00b0C\")\nprint(f\"  Warming trend: {trend_slope * 365:.2f}\u00b0C/year\")\ndef trend_seasonal_model(t, mean, trend, amplitude, period, phase):\n    \"\"\"Combined linear trend and sinusoidal seasonal component.\n    Parameters\n    ----------\n    t : array_like\n        Time (days)\n    mean : float\n        Baseline level\n    trend : float\n        Linear trend (units per day)\n    amplitude : float\n        Seasonal amplitude\n    period : float\n        Seasonal period (days)\n    phase : float\n        Phase shift (radians)\n    Returns\n    -------\n    y : array_like\n        Modeled values\n    \"\"\"\n    trend_part = mean + trend * t\n    seasonal_part = amplitude * jnp.sin(2 * jnp.pi * t / period + phase)\n    return trend_part + seasonal_part\np0_seasonal = [15.0, 0.0, 8.0, 365.0, 0.0]  # mean, trend, amplitude, period, phase\nbounds_seasonal = (\n    [-50, -0.1, 0, 300, -2 * np.pi],  # Lower\n    [50, 0.1, 20, 400, 2 * np.pi],  # Upper\n)\npopt_seasonal, pcov_seasonal = cf.curve_fit(\n    trend_seasonal_model,\n    jnp.array(days),\n    jnp.array(temp_observed),\n    p0=p0_seasonal,\n    bounds=bounds_seasonal,\n)\nmean_fit, trend_fit, amp_fit, period_fit, phase_fit = popt_seasonal\nerrors = np.sqrt(np.diag(pcov_seasonal))\nprint(\"Fitted Seasonal Parameters:\")\nprint(f\"  Baseline: {mean_fit:.2f} \u00b1 {errors[0]:.2f} \u00b0C\")\nprint(\n    f\"  Trend: {trend_fit:.4f} \u00b1 {errors[1]:.4f} \u00b0C/day = {trend_fit * 365:.2f} \u00b0C/year\"\n)\nprint(f\"  Amplitude: {amp_fit:.2f} \u00b1 {errors[2]:.2f} \u00b0C\")\nprint(f\"  Period: {period_fit:.1f} \u00b1 {errors[3]:.1f} days\")\nprint(f\"  Phase: {phase_fit:.3f} \u00b1 {errors[4]:.3f} rad\")\ntrend_fitted = mean_fit + trend_fit * days\nseasonal_fitted = amp_fit * np.sin(2 * np.pi * days / period_fit + phase_fit)\ntotal_fitted = trend_fitted + seasonal_fitted\nresiduals = temp_observed - total_fitted\nfig, axes = plt.subplots(4, 1, figsize=(12, 10), sharex=True)\naxes[0].plot(days / 365, temp_observed, \"o\", alpha=0.3, ms=2, label=\"Observed\")\naxes[0].plot(days / 365, total_fitted, \"r-\", lw=1.5, label=\"Fitted model\")\naxes[0].set_ylabel(\"Temperature (\u00b0C)\")\naxes[0].set_title(\"Original Time Series\")\naxes[0].legend()\naxes[0].grid(alpha=0.3)\naxes[1].plot(days / 365, trend_fitted, \"b-\", lw=2)\naxes[1].set_ylabel(\"Trend (\u00b0C)\")\naxes[1].set_title(f\"Trend Component (slope: {trend_fit * 365:.3f} \u00b0C/year)\")\naxes[1].grid(alpha=0.3)\naxes[2].plot(days / 365, seasonal_fitted, \"g-\", lw=1.5)\naxes[2].set_ylabel(\"Seasonal (\u00b0C)\")\naxes[2].set_title(\n    f\"Seasonal Component (period: {period_fit:.1f} days, amplitude: {amp_fit:.1f} \u00b0C)\"\n)\naxes[2].grid(alpha=0.3)\naxes[3].plot(days / 365, residuals, \"o\", alpha=0.4, ms=2, color=\"gray\")\naxes[3].axhline(0, color=\"k\", ls=\"--\", lw=1)\naxes[3].set_ylabel(\"Residual (\u00b0C)\")\naxes[3].set_xlabel(\"Time (years)\")\naxes[3].set_title(f\"Residuals (std: {np.std(residuals):.2f} \u00b0C, should be white noise)\")\naxes[3].grid(alpha=0.3)\nplt.tight_layout()\nfig_dir = Path(__file__).parent / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_02.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(\"\u2713 Seasonal decomposition complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 3: Forecasting with Uncertainty\n",
        "\n",
        "Extrapolate the fitted model into the future with prediction intervals.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "days_forecast = np.linspace(0, 4 * 365, 4 * 365)\nforecast_boundary = 3 * 365\ntemp_forecast = trend_seasonal_model(jnp.array(days_forecast), *popt_seasonal)\nn_samples = 200\nparam_samples = np.random.multivariate_normal(\n    popt_seasonal, pcov_seasonal, size=n_samples\n)\nforecast_samples = np.array(\n    [\n        trend_seasonal_model(jnp.array(days_forecast), *params)\n        for params in param_samples\n    ]\n)\nforecast_mean = np.mean(forecast_samples, axis=0)\nforecast_std = np.std(forecast_samples, axis=0)\nforecast_lower = np.percentile(forecast_samples, 2.5, axis=0)  # 95% PI\nforecast_upper = np.percentile(forecast_samples, 97.5, axis=0)\nresidual_std = np.std(residuals)\nforecast_lower_total = forecast_lower - 2 * residual_std\nforecast_upper_total = forecast_upper + 2 * residual_std\nprint(f\"\u2713 Generated {len(days_forecast) - len(days)} day forecast\")\nprint(\n    f\"  Forecast period: {len(days) / 365:.1f} - {len(days_forecast) / 365:.1f} years\"\n)\nprint(f\"  Prediction interval width: {2 * residual_std:.1f} \u00b0C (\u00b11\u03c3 residuals)\")\nfig, ax = plt.subplots(figsize=(14, 6))\nax.plot(\n    days / 365, temp_observed, \"o\", alpha=0.3, ms=2, color=\"steelblue\", label=\"Observed\"\n)\nax.plot(\n    days / 365,\n    total_fitted,\n    \"r-\",\n    lw=2,\n    label=\"Fitted model\",\n    alpha=0.8,\n)\nforecast_mask = days_forecast > forecast_boundary\nax.plot(\n    days_forecast[forecast_mask] / 365,\n    forecast_mean[forecast_mask],\n    \"r--\",\n    lw=2,\n    label=\"Forecast\",\n)\nax.fill_between(\n    days_forecast[forecast_mask] / 365,\n    forecast_lower[forecast_mask],\n    forecast_upper[forecast_mask],\n    alpha=0.3,\n    color=\"red\",\n    label=\"95% PI (parameter)\",\n)\nax.fill_between(\n    days_forecast[forecast_mask] / 365,\n    forecast_lower_total[forecast_mask],\n    forecast_upper_total[forecast_mask],\n    alpha=0.15,\n    color=\"orange\",\n    label=\"95% PI (total)\",\n)\nax.axvline(forecast_boundary / 365, color=\"gray\", ls=\"--\", lw=2, label=\"Forecast start\")\nax.set_xlabel(\"Time (years)\", fontsize=12)\nax.set_ylabel(\"Temperature (\u00b0C)\", fontsize=12)\nax.set_title(\"Time Series Forecast with Uncertainty Quantification\", fontsize=14)\nax.legend(loc=\"upper left\")\nax.grid(alpha=0.3)\nplt.tight_layout()\nfig_dir = Path(__file__).parent / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_03.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nprint(\"\u2713 Forecast visualization complete\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Part 4: Residual Diagnostics (Autocorrelation)\n",
        "\n",
        "For valid inference, residuals should be uncorrelated (white noise). We check this with autocorrelation analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def autocorrelation(x, max_lag=50):\n    \"\"\"Calculate autocorrelation function (ACF).\n    Parameters\n    ----------\n    x : array_like\n        Time series (residuals)\n    max_lag : int\n        Maximum lag to compute\n    Returns\n    -------\n    lags : array\n        Lag values\n    acf : array\n        Autocorrelation values\n    \"\"\"\n    x_centered = x - np.mean(x)\n    c0 = np.dot(x_centered, x_centered) / len(x)\n    lags = np.arange(0, max_lag + 1)\n    acf = np.zeros(len(lags))\n    for i, lag in enumerate(lags):\n        if lag == 0:\n            acf[i] = 1.0\n        else:\n            c_lag = np.dot(x_centered[:-lag], x_centered[lag:]) / len(x)\n            acf[i] = c_lag / c0\n    return lags, acf\nlags, acf_values = autocorrelation(residuals, max_lag=60)\nconf_bound = 1.96 / np.sqrt(len(residuals))\nfig, ax = plt.subplots(figsize=(10, 5))\nax.stem(lags, acf_values, basefmt=\" \", linefmt=\"C0-\", markerfmt=\"C0o\")\nax.axhline(0, color=\"k\", lw=1)\nax.axhline(conf_bound, color=\"r\", ls=\"--\", lw=1.5, label=\"95% confidence\")\nax.axhline(-conf_bound, color=\"r\", ls=\"--\", lw=1.5)\nax.fill_between(\n    lags, -conf_bound, conf_bound, alpha=0.2, color=\"red\", label=\"White noise region\"\n)\nax.set_xlabel(\"Lag (days)\")\nax.set_ylabel(\"Autocorrelation\")\nax.set_title(\"Autocorrelation Function (ACF) of Residuals\")\nax.set_xlim(-1, max(lags) + 1)\nax.legend()\nax.grid(alpha=0.3)\nplt.tight_layout()\nfig_dir = Path(__file__).parent / \"figures\" / \"time_series_analysis\"\nfig_dir.mkdir(parents=True, exist_ok=True)\nplt.savefig(fig_dir / \"fig_04.png\", dpi=300, bbox_inches=\"tight\")\nplt.close()\nsignificant_lags = np.sum(np.abs(acf_values[1:]) > conf_bound)  # Exclude lag 0\nprint(\"\u2713 Autocorrelation analysis complete\")\nprint(\n    f\"  Significant lags (95% level): {significant_lags} / {len(lags) - 1} ({significant_lags / (len(lags) - 1) * 100:.1f}%)\"\n)\nif significant_lags / (len(lags) - 1) < 0.05:\n    print(\"  \u2713 Residuals consistent with white noise (good fit)\")\nelse:\n    print(\n        \"  \u26a0 Significant autocorrelation detected: consider more complex model or autoregressive errors\"\n    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Summary and Best Practices\n",
        "\n",
        "When to Use NLSQ for Time Series\n",
        "\n",
        "| **Use Case** | **NLSQ Strength** | **Alternative** |\n",
        "|--------------|-------------------|------------------|\n",
        "| Physical growth models (exponential, logistic) | \u2705 Excellent (interpretable parameters) | ARIMA (less interpretable) |\n",
        "| Periodic data with known/unknown period | \u2705 Good (Fourier series) | Seasonal decomposition (STL, Prophet) |\n",
        "| Trend + seasonality | \u2705 Good (combined parametric model) | Prophet, TBATS |\n",
        "| Autoregressive processes (ARMA) | \u274c Poor (not designed for this) | ARIMA, SARIMA |\n",
        "| Irregular sampling | \u2705 Excellent (handles any time grid) | Interpolation + ARIMA |\n",
        "| Large datasets (millions of points) | \u2705 Excellent (JAX GPU acceleration) | Dask + statsmodels |\n",
        "\n",
        "Key Takeaways\n",
        "\n",
        "1. **Model Selection**: Choose parametric forms based on domain knowledge\n",
        "- Growth: Exponential, logistic, Gompertz\n",
        "- Decay: Exponential, power-law\n",
        "- Periodic: Fourier series (sum of sines/cosines)\n",
        "\n",
        "2. **Forecasting Uncertainty**\n",
        "- **Parameter uncertainty**: From covariance matrix (Monte Carlo sampling)\n",
        "- **Model uncertainty**: Residual standard deviation\n",
        "- **Total**: Combine both sources for realistic prediction intervals\n",
        "\n",
        "3. **Diagnostics**\n",
        "- **Residuals**: Should be centered at zero, no trend\n",
        "- **Autocorrelation**: Should be within confidence bounds (white noise)\n",
        "- **Heteroscedasticity**: Check if residual variance changes over time\n",
        "\n",
        "4. **Multi-Seasonal Data**\n",
        "- Use multiple sinusoids: `amp1 * sin(2\u03c0 t / P1) + amp2 * sin(2\u03c0 t / P2)`\n",
        "- Example: Daily + weekly cycles in energy consumption\n",
        "\n",
        "Production Code Template\n",
        "\n",
        "```python\n",
        "from nlsq import CurveFit\n",
        "import jax.numpy as jnp\n",
        "\n",
        "def forecast_time_series(t, y, forecast_days=30):\n",
        "\"\"\"Fit trend+seasonal model and forecast.\"\"\"\n",
        "\n",
        "Model\n",
        "def model(t, mean, trend, amp, period, phase):\n",
        "return mean + trend * t + amp * jnp.sin(2 * jnp.pi * t / period + phase)\n",
        "\n",
        "Fit\n",
        "cf = CurveFit()\n",
        "p0 = [jnp.mean(y), 0.0, jnp.std(y) / 2, 365.0, 0.0]\n",
        "popt, pcov = cf.curve_fit(model, jnp.array(t), jnp.array(y), p0=p0)\n",
        "\n",
        "Forecast\n",
        "t_future = jnp.arange(t[-1] + 1, t[-1] + 1 + forecast_days)\n",
        "y_forecast = model(t_future, *popt)\n",
        "\n",
        "Uncertainty (simplified)\n",
        "residual_std = jnp.std(y - model(jnp.array(t), *popt))\n",
        "forecast_uncertainty = residual_std\n",
        "\n",
        "return t_future, y_forecast, forecast_uncertainty\n",
        "```\n",
        "\n",
        "Next Steps\n",
        "\n",
        "- **Advanced Seasonality**: Multi-frequency Fourier series for complex cycles\n",
        "- **State-Space Models**: Kalman filtering with NLSQ parameter estimation\n",
        "- **Batch Processing**: Fit thousands of time series in parallel with `jax.vmap`\n",
        "- **Hybrid Models**: Combine NLSQ (trend/seasonal) with ARIMA (residual modeling)\n",
        "\n",
        "References\n",
        "\n",
        "1. **Time Series Analysis**: Chatfield, *The Analysis of Time Series* (2004)\n",
        "2. **Forecasting**: Hyndman & Athanasopoulos, *Forecasting: Principles and Practice* (2021)\n",
        "3. **Related Examples**:\n",
        "- `gallery/biology/growth_curves.py` - Bacterial growth fitting\n",
        "- `gallery/physics/damped_oscillation.py` - Oscillatory time series\n",
        "- `advanced_features_demo.ipynb` - Robustness for outliers in time series\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
