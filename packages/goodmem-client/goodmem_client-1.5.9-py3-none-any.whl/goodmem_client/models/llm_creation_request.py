# coding: utf-8

"""
    GoodMem API

    API for interacting with the GoodMem service, providing vector-based memory storage and retrieval with multiple embedder support. The service enables creation of memory spaces, storing memories with vector representations, and efficient similarity-based retrieval.

    The version of the OpenAPI document: v1
    Contact: support@goodmem.io
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictInt, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from goodmem_client.models.endpoint_authentication import EndpointAuthentication
from goodmem_client.models.llm_capabilities import LLMCapabilities
from goodmem_client.models.llm_provider_type import LLMProviderType
from goodmem_client.models.llm_sampling_params import LLMSamplingParams
from goodmem_client.models.modality import Modality
from typing import Optional, Set
from typing_extensions import Self

class LLMCreationRequest(BaseModel):
    """
    Request body for creating a new LLM. An LLM represents a configuration for text generation services.
    """ # noqa: E501
    validate: Optional[Dict[str, Any]] = None
    display_name: StrictStr = Field(description="User-facing name of the LLM", alias="displayName")
    description: Optional[StrictStr] = Field(default=None, description="Description of the LLM")
    provider_type: LLMProviderType = Field(alias="providerType")
    endpoint_url: StrictStr = Field(description="API endpoint URL", alias="endpointUrl")
    api_path: Optional[StrictStr] = Field(default=None, description="API path for chat/completions request (defaults to /v1/chat/completions if not provided)", alias="apiPath")
    model_identifier: StrictStr = Field(description="Model identifier", alias="modelIdentifier")
    supported_modalities: Optional[List[Modality]] = Field(default=None, description="Supported content modalities (defaults to TEXT if not provided)", alias="supportedModalities")
    credentials: Optional[EndpointAuthentication] = None
    labels: Optional[Dict[str, StrictStr]] = Field(default=None, description="User-defined labels for categorization")
    version: Optional[StrictStr] = Field(default=None, description="Version information")
    monitoring_endpoint: Optional[StrictStr] = Field(default=None, description="Monitoring endpoint URL", alias="monitoringEndpoint")
    capabilities: Optional[LLMCapabilities] = None
    default_sampling_params: Optional[LLMSamplingParams] = Field(default=None, alias="defaultSamplingParams")
    max_context_length: Optional[StrictInt] = Field(default=None, description="Maximum context window size in tokens", alias="maxContextLength")
    client_config: Optional[Dict[str, Dict[str, Any]]] = Field(default=None, description="Provider-specific client configuration as flexible JSON structure", alias="clientConfig")
    owner_id: Optional[StrictStr] = Field(default=None, description="Optional owner ID. If not provided, derived from the authentication context. Requires CREATE_LLM_ANY permission if specified.", alias="ownerId")
    llm_id: Optional[StrictStr] = Field(default=None, description="Optional client-provided UUID for idempotent creation. If not provided, server generates a new UUID. Returns ALREADY_EXISTS if ID is already in use.", alias="llmId")
    __properties: ClassVar[List[str]] = ["validate", "displayName", "description", "providerType", "endpointUrl", "apiPath", "modelIdentifier", "supportedModalities", "credentials", "labels", "version", "monitoringEndpoint", "capabilities", "defaultSamplingParams", "maxContextLength", "clientConfig", "ownerId", "llmId"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of LLMCreationRequest from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    def to_dict(self) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.
        """
        excluded_fields: Set[str] = set([
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of credentials
        if self.credentials:
            _dict['credentials'] = self.credentials.to_dict()
        # override the default output from pydantic by calling `to_dict()` of capabilities
        if self.capabilities:
            _dict['capabilities'] = self.capabilities.to_dict()
        # override the default output from pydantic by calling `to_dict()` of default_sampling_params
        if self.default_sampling_params:
            _dict['defaultSamplingParams'] = self.default_sampling_params.to_dict()
        # set to None if description (nullable) is None
        # and model_fields_set contains the field
        if self.description is None and "description" in self.model_fields_set:
            _dict['description'] = None

        # set to None if api_path (nullable) is None
        # and model_fields_set contains the field
        if self.api_path is None and "api_path" in self.model_fields_set:
            _dict['apiPath'] = None

        # set to None if supported_modalities (nullable) is None
        # and model_fields_set contains the field
        if self.supported_modalities is None and "supported_modalities" in self.model_fields_set:
            _dict['supportedModalities'] = None

        # set to None if labels (nullable) is None
        # and model_fields_set contains the field
        if self.labels is None and "labels" in self.model_fields_set:
            _dict['labels'] = None

        # set to None if version (nullable) is None
        # and model_fields_set contains the field
        if self.version is None and "version" in self.model_fields_set:
            _dict['version'] = None

        # set to None if monitoring_endpoint (nullable) is None
        # and model_fields_set contains the field
        if self.monitoring_endpoint is None and "monitoring_endpoint" in self.model_fields_set:
            _dict['monitoringEndpoint'] = None

        # set to None if max_context_length (nullable) is None
        # and model_fields_set contains the field
        if self.max_context_length is None and "max_context_length" in self.model_fields_set:
            _dict['maxContextLength'] = None

        # set to None if client_config (nullable) is None
        # and model_fields_set contains the field
        if self.client_config is None and "client_config" in self.model_fields_set:
            _dict['clientConfig'] = None

        # set to None if owner_id (nullable) is None
        # and model_fields_set contains the field
        if self.owner_id is None and "owner_id" in self.model_fields_set:
            _dict['ownerId'] = None

        # set to None if llm_id (nullable) is None
        # and model_fields_set contains the field
        if self.llm_id is None and "llm_id" in self.model_fields_set:
            _dict['llmId'] = None

        return _dict

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of LLMCreationRequest from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_validate({
            "validate": obj.get("validate"),
            "displayName": obj.get("displayName"),
            "description": obj.get("description"),
            "providerType": obj.get("providerType"),
            "endpointUrl": obj.get("endpointUrl"),
            "apiPath": obj.get("apiPath"),
            "modelIdentifier": obj.get("modelIdentifier"),
            "supportedModalities": obj.get("supportedModalities"),
            "credentials": EndpointAuthentication.from_dict(obj["credentials"]) if obj.get("credentials") is not None else None,
            "labels": obj.get("labels"),
            "version": obj.get("version"),
            "monitoringEndpoint": obj.get("monitoringEndpoint"),
            "capabilities": LLMCapabilities.from_dict(obj["capabilities"]) if obj.get("capabilities") is not None else None,
            "defaultSamplingParams": LLMSamplingParams.from_dict(obj["defaultSamplingParams"]) if obj.get("defaultSamplingParams") is not None else None,
            "maxContextLength": obj.get("maxContextLength"),
            "clientConfig": obj.get("clientConfig"),
            "ownerId": obj.get("ownerId"),
            "llmId": obj.get("llmId")
        })
        return _obj


