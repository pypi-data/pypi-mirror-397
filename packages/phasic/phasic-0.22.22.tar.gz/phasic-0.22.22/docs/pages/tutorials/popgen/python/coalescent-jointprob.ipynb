{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Always import phasic first to set jax backend correctly\n",
        "import phasic\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('retina', 'png')\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (5, 3.7)\n",
        "sns.set_context('paper', font_scale=0.9)\n",
        "# import warnings\n",
        "# warnings.filterwarnings(action='ignore', category=Warning, module='seaborn')\n",
        "phasic.set_theme('dark')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4caa0a8-ba4d-4aa3-a390-4c4ae1dcdadd",
      "metadata": {},
      "source": [
        "# Joint probability experiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b58d1ea-e893-4b13-813f-17969e07fead",
      "metadata": {},
      "source": [
        "R header:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# remove.packages(\"ptdalgorithms\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# # GNUMPLIB\n",
        "# ./configure --prefix=$CONDA_PREFIX --enable-cxx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# !export LIBS=\"-L/Users/kmt/miniconda3/envs/phasetype/lib\"\n",
        "# !export CPPFLAGS=\"-I/Users/kmt/miniconda3/envs/phasetype/include\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "source(\"plot_functions.R\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# # p <- ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) +\n",
        "# #       geom_point(aes(color=Species, shape=Species)) + despine\n",
        "\n",
        "# # ggplotly(width=600, height=400)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# theme_set(theme_bw())\n",
        "\n",
        "# despine <- theme(panel.border = element_blank(), panel.grid.major = element_blank(),\n",
        "#     panel.grid.minor = element_blank(), axis.line = element_line(colour = \"black\"),\n",
        "#                 text=element_text(size=17)) \n",
        "\n",
        "# options(repr.plot.width=7, repr.plot.height=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdc25d9-56af-4656-ac11-ff3b909362aa",
      "metadata": {},
      "source": [
        "## Make discrete"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def make_discrete(mutation_graph, mutation_rate):\n",
        "    # Takes a graph for a continuous distribution and turns\n",
        "    # it into a descrete one (inplace). Returns a matrix of\n",
        "    # rewards for computing marginal moments\n",
        "\n",
        "    # current nr of states in graph\n",
        "    vlength = mutation_graph.vertices_length()\n",
        "\n",
        "    # number of fields in state vector (assumes all are the same length)\n",
        "    state_vector_length = len(mutation_graph.vertex_at(0)$state)\n",
        "\n",
        "    # list state vector fields to reward at each auxiliary node\n",
        "    rewarded_state_vector_indexes = vector(mode = \"list\", length = state_vector_length)\n",
        "\n",
        "    # loop all but starting node\n",
        "    for i in range(2, vlength + 1):\n",
        "        vertex = mutation_graph.vertex_at(i - 1)\n",
        "        if vertex.rate > 0: # not absorbing\n",
        "            for (j in 1:len(vertex.state)) {\n",
        "                val = vertex.state[j]\n",
        "                if val > 0: # only ones we may reward\n",
        "                    # add auxilliary node\n",
        "                    mutation_vertex = mutation_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "                    mutation_vertex.add_edge(vertex, 1)\n",
        "                    vertex.add_edge(mutation_vertex, mutation_rate*val)\n",
        "\n",
        "                    rewarded_state_vector_indexes[[mutation_vertex.index]] = c(rewarded_state_vector_indexes[[j]], j)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # normalize graph\n",
        "    weights_were_multiplied_with = normalize_graph(mutation_graph)\n",
        "\n",
        "    # build reward matrix\n",
        "    rewards = matrix(nrow=mutation_graph.vertices_length(),ncol=state_vector_length, 0)\n",
        "    for (state in range(len(rewarded_state_vector_indexes))) {\n",
        "        for (i in rewarded_state_vector_indexes[[state]]) {\n",
        "            rewards[state, i] = 1\n",
        "\n",
        "\n",
        "    rewards = t(rewards)\n",
        "    return rewards\n",
        "\n",
        "# # self-transition rate:\n",
        "# mutation_rate = 1e-8\n",
        "\n",
        "# # clone graph to get one to modify:\n",
        "# mutation_graph = clone_graph(graph)\n",
        "\n",
        "# # add auxilliary states, normalize and return reward matrix:\n",
        "# rewards = make_discrete(mutation_graph, mutation_rate)\n",
        "\n",
        "# # for plotting the new graph\n",
        "# gam = graph_as_matrix(mutation_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27dff722-3e7c-4a76-b950-6eea2f981b78",
      "metadata": {},
      "source": [
        "# Trash-state approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# def discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=Inf, return_graph=False):\n",
        "\n",
        "#     if is.list(reward_limits):\n",
        "#         assert is.infinite(tot_reward_limit)) # don't use tot_reward_limit with list of all allowed rewards\n",
        "#         reward_dims = len(reward_limits[[1]])\n",
        "#         possible_rewards = reward_limits\n",
        "#     else:\n",
        "#         reward_dims = len(reward_limits)\n",
        "    \n",
        "#         # get all possible reward combinations respecting the reward_limits\n",
        "#         possible_rewards = unname(as.list(as.data.frame(t(\n",
        "#             expand.grid(\n",
        "#                 sapply(reward_limits, function(x) list(0:x))\n",
        "#                        ) \n",
        "#                     ))) \n",
        "#                 )\n",
        "#     }\n",
        "\n",
        "#     ############\n",
        "#     # remove reward combinations not respecting the tot_reward_limit                                \n",
        "#     possible_rewards = possible_rewards[sapply(possible_rewards, function(x) sum(x)<=tot_reward_limit)]\n",
        "#     ############\n",
        "\n",
        "#     # print(possible_rewards)\n",
        "                                                \n",
        "#     # m = matrix(0, nrow = reward_dims, ncol = reward_dims)\n",
        "#     # diag(m) = 1                                                \n",
        "#     # # only use reward increments where we want tons at all (where reward limits are non-zero)                                            \n",
        "#     # # diag(m) = rowSums(as.data.frame(possible_rewards))\n",
        "#     # reward_increments = as.list(as.data.frame(m))\n",
        "        \n",
        "#     # new graph\n",
        "#     state_vector_length = len(graph.vertex_at(0)$state) + reward_dims\n",
        "#     state_reward_indices = (state_vector_length-reward_dims+1):state_vector_length\n",
        "#     new_graph = phasic.Graph(state_length=state_vector_length)\n",
        "    \n",
        "#     # add vertices to new graph\n",
        "#     t_vertex_indices = c()\n",
        "#     for (vertex in vertices(graph)) {\n",
        "#         for (p in possible_rewards) {\n",
        "            \n",
        "#           ############# # HOW DO I MAKE THIS WORK FOR OTHER THAN THE COALESCENCE STATE SPACE\n",
        "#           # for all non-abs states, skip state/reward combinations with rewards that cannot be earned at state\n",
        "#           if (len(edges(vertex)) > 0 and !reward_possible(vertex.state, p)) next            \n",
        "#           # if (len(edges(vertex)) > 0 and highest_nonzero_index(p) > highest_nonzero_index(vertex.state)) next\n",
        "#           #############\n",
        "\n",
        "#           state = c(vertex.state, p)\n",
        "\n",
        "#           new_vertex = new_graph.find_or_create_vertex(state) # if I use create_vertex here, I cannot find it again with find_vertex...\n",
        "#           if len(edges(vertex)) == 0:\n",
        "#             t_vertex_indices = c(t_vertex_indices, new_vertex.index) \n",
        "#           }\n",
        "#         }\n",
        "#     }\n",
        "#     # trash states\n",
        "#     trash_vertex = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#     trash_loop_vertex = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#     trash_vertex.add_edge(trash_loop_vertex, 1)\n",
        "#     trash_loop_vertex.add_edge(trash_vertex, 1)\n",
        "    \n",
        "#     # add edges to new graph\n",
        "#     for (vertex in vertices(graph)) {\n",
        "        \n",
        "#         if (vertex.index == 1)\n",
        "#             next\n",
        "        \n",
        "#         state = vertex.state\n",
        "#         for (p in possible_rewards) {\n",
        "#             new_vertex = find_vertex(new_graph, c(state, p))\n",
        "\n",
        "#             #############\n",
        "#             if (is.null(new_vertex)) next\n",
        "#             #############\n",
        "\n",
        "#             # coalescence edges\n",
        "#             for (edge in edges(vertex)) {            \n",
        "#                 child_state = edge.child$state\n",
        "#                 new_child_vertex = find_vertex(new_graph, c(child_state, p))\n",
        "\n",
        "#                 #############\n",
        "#                 if (is.null(new_vertex) or is.null(new_child_vertex)) next\n",
        "#                 #############\n",
        "\n",
        "#                 new_vertex.add_edge(#                          new_child_vertex, \n",
        "#                          edge.weight)\n",
        "#             }\n",
        "\n",
        "#             # mutation edges\n",
        "#             new_vertex_rewards = tail(new_vertex.state, reward_dims)\n",
        "#             trash_rate = 0\n",
        "#             for i in range(1, reward_dims + 1):\n",
        "#                 r = np.zeros(reward_dims, dtype=int)\n",
        "#                 r[i] = 1\n",
        "#                 rate = state[i] * mutation_rate \n",
        "#                 new_child_vertex = find_vertex(new_graph, c(state, new_vertex_rewards + r))\n",
        "                \n",
        "#                 # if  all(sapply(reward_limits, function(x) all(new_vertex_rewards + r <= x))) :\n",
        "#                 if  all(new_vertex_rewards + r <= reward_limits) & sum(new_vertex_rewards + r) <= tot_reward_limit:\n",
        "                    \n",
        "#                     #############\n",
        "#                     if (is.null(new_vertex) or is.null(new_child_vertex)) next\n",
        "#                     #############\n",
        "                    \n",
        "#                     new_vertex.add_edge(#                              new_child_vertex, \n",
        "#                              rate)\n",
        "                \n",
        "#                 else:\n",
        "#                     trash_rate = trash_rate + rate\n",
        "#                 }\n",
        "#             }\n",
        "#             new_vertex.add_edge(trash_vertex, trash_rate) \n",
        "#         }\n",
        "#     }\n",
        "#     # add edges from t-states to new final absorbing\n",
        "#     new_absorbing = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#     for (i in t_vertex_indices) {\n",
        "#         add_edge(new_graph.vertex_at(i - 1), new_absorbing, 1)\n",
        "#     }\n",
        "    \n",
        "#     # add edges from starting vertex (IPV)\n",
        "#     starting_vertex = graph.vertex_at(0)\n",
        "#     new_starting_vertex = new_graph.vertex_at(0)\n",
        "#     for (edge in edges(starting_vertex)) {\n",
        "#         new_starting_vertex.add_edge(find_vertex(new_graph, c(edge.child$state, np.zeros(reward_dims, dtype=int))), 1)\n",
        "#     }\n",
        "    \n",
        "#     # normalize graph                            \n",
        "#     weights_were_multiplied_with = normalize_graph(new_graph)\n",
        "\n",
        "#     if (return_graph)                           \n",
        "#         return new_graph                                             \n",
        "\n",
        "#     start = proc.time()[3]\n",
        "\n",
        "#     # time spent in each of the the t-states after some appropriately large time (these are the joint probs)\n",
        "#     # (maybe I can somehow figure out to stop at the 0.999 quantile)\n",
        "#     accum_time = accumulated_visiting_time(new_graph, 100)[t_vertex_indices]\n",
        "\n",
        "#     # I can test if the graph is acyclic and if so, use accumulated_residence_time instead?\n",
        "                                                \n",
        "#     proc.time()[3] - start\n",
        "    \n",
        "#     # data frame with joint probs\n",
        "#     states = states(new_graph)\n",
        "#     state_reward_matrix = as.data.frame(states[t_vertex_indices, state_reward_indices])\n",
        "#     joint_probs = cbind(state_reward_matrix, accum_time)\n",
        "\n",
        "#     print(c(graph.vertices_length(), new_graph.vertices_length(), new_graph.vertices_length()/graph.vertices_length()))                                \n",
        "#     return joint_probs   \n",
        "# } "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# sample_size = 4\n",
        "# graph = standard_coalescent(sample_size)\n",
        "# state_length = len(graph.vertex_at(0)$state)\n",
        "\n",
        "# # last state index is absorbing where no rewards can be earned\n",
        "# # reward_limits = c(rep(20, state_length-1), 0)\n",
        "# reward_limits = c(rep(1, state_length-1), 0)\n",
        "\n",
        "# tot_reward_limit = Inf\n",
        "\n",
        "# # mutation_rate = 20000 * 31 * 5e-10 # 0.00031\n",
        "# mutation_rate = 1\n",
        "\n",
        "# def reward_possible(state, rewards):\n",
        "#     def highest_nonzero_index(a):\n",
        "#        idx = a != 0\n",
        "#        ifelse(any(idx), max(which(idx)), 0)\n",
        "#     }\n",
        "#     return (highest_nonzero_index(rewards) <= highest_nonzero_index(state))\n",
        "# }\n",
        "                                   \n",
        "# start = proc.time()[3]\n",
        "# joint_probs = discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit)\n",
        "# proc.time()[3] - start\n",
        "\n",
        "# new_graph = discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit, return_graph=True)\n",
        "# plot_graph(graph_as_matrix(new_graph), size=np.array([10, 10], dtype=int), align=True, #rainbow=True,\n",
        "#                fontsize=16, ranksep=2, nodesep=0.5, rankdir=\"LR\",\n",
        "#               subgraphs=True, subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"),\n",
        "#            splines='line'\n",
        "#           )  \n",
        "                                                \n",
        "# joint_probs                               "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def discrete_joint_prob(graph, reward_rates, precision=1e-15, return_graph=False):\n",
        "\n",
        "    starting_vertex = graph.starting_vertex()\n",
        "    reward_dims = len(reward_rates(starting_vertex.state, current_rewards=None)) - 1 # a bit of a hack. -1 to not count trash rate...\n",
        "\n",
        "    orig_state_vector_length = len(graph.vertex_at(0)$state)\n",
        "    state_vector_length = orig_state_vector_length + reward_dims\n",
        "\n",
        "    state_indices = 1:orig_state_vector_length\n",
        "    reward_indices = (orig_state_vector_length+1):state_vector_length\n",
        "\n",
        "    new_graph = phasic.Graph(state_length=state_vector_length)\n",
        "    new_starting_vertex = new_graph.vertex_at(0)\n",
        "\n",
        "    null_rewards = np.zeros(reward_dims, dtype=int)\n",
        "\n",
        "    index = 1\n",
        "    # add edges from starting vertex (IPV)\n",
        "    for (edge in edges(starting_vertex)) {        \n",
        "        new_starting_vertex.add_edge(new_graph.find_or_create_vertex(c(edge.child$state, null_rewards)),\n",
        "          1\n",
        "        )\n",
        "\n",
        "    index = index + 1\n",
        "    \n",
        "    trash_rates = list()\n",
        "    t_vertex_indices = c()\n",
        "    while index <= new_graph.vertices_length():\n",
        "\n",
        "        new_vertex = new_graph.vertex_at(index - 1)\n",
        "        new_state = new_vertex.state.copy()\n",
        "        state = new_vertex.state[state_indices]\n",
        "        vertex = find_vertex(graph, state)\n",
        "\n",
        "        # non-mutation transitions (coalescence)\n",
        "        for (edge in edges(vertex)) {\n",
        "            new_child_state = c(edge.child$state, new_state[reward_indices])\n",
        "\n",
        "            if (all(new_state == new_child_state)) next\n",
        "                \n",
        "            new_child_vertex = new_graph.find_or_create_vertex(new_child_state)\n",
        "            # cat(new_child_vertex.state, \"\\n\")\n",
        "            new_vertex.add_edge(new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n",
        "                edge.weight\n",
        "            )\n",
        "\n",
        "            # if new child was absorbing, record at \"t-states\":\n",
        "            if len(edges(find_vertex(graph, new_child_state[state_indices]))) == 0:\n",
        "                t_vertex_indices = c(t_vertex_indices, new_child_vertex.index) \n",
        "\n",
        "\n",
        "        # mutation transitions\n",
        "        current_state = new_state[state_indices]\n",
        "        current_rewards = new_state[reward_indices]\n",
        "        rates = reward_rates(current_state, current_rewards) # list of all allowed mutation transition rates with trash rate appended\n",
        "\n",
        "        trash_rates[[index]] = rates[reward_dims+1]\n",
        "        for i in range(1, reward_dims + 1):\n",
        "            rate = rates[i]\n",
        "            if rate > 0:\n",
        "                new_rewards = current_rewards\n",
        "                new_rewards[i] = new_rewards[i] + 1\n",
        "                new_child_vertex = new_graph.find_or_create_vertex(c(current_state, new_rewards))\n",
        "                # assert sum(new_child_vertex.state) > 4)\n",
        "                # cat(new_child_vertex.state, \"\\n\")\n",
        "                new_vertex.add_edge(new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n",
        "                    rate\n",
        "                    )\n",
        "                \n",
        "                # # if new child was absorbing, record at \"t-states\":                \n",
        "                # if len(edges(find_vertex(graph, new_child_state[state_indices]))) == 0:\n",
        "                #     t_vertex_indices = c(t_vertex_indices, new_child_vertex.index) \n",
        "                # }                 \n",
        "\n",
        "\n",
        "        index = index + 1 \n",
        "\n",
        "        if index %% 1000 == 0:\n",
        "            cat(index, new_graph.vertices_length(), \"\\n\")\n",
        "            flush.console()\n",
        "\n",
        "        # assert index < 100000)\n",
        "\n",
        "    # trash states\n",
        "    trash_vertex = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "    trash_loop_vertex = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "    trash_vertex.add_edge(trash_loop_vertex, 1)\n",
        "    trash_loop_vertex.add_edge(trash_vertex, 1)\n",
        "\n",
        "    # add trash edges\n",
        "    for (i in 1:len(trash_rates)) {\n",
        "        rate = trash_rates[[i]]\n",
        "        if !is.null(rate):\n",
        "            add_edge(new_graph.vertex_at(i - 1), trash_vertex, rate) \n",
        "\n",
        "\n",
        "    # add edges from t-states to new final absorbing\n",
        "    new_absorbing = new_graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "\n",
        "    t_vertex_indices = unique(t_vertex_indices)\n",
        "    \n",
        "    for (i in t_vertex_indices) {\n",
        "        add_edge(new_graph.vertex_at(i - 1), new_absorbing, 1)\n",
        "\n",
        "    # normalize graph                            \n",
        "    weights_were_multiplied_with = normalize_graph(new_graph)\n",
        "\n",
        "    if (return_graph)                           \n",
        "        return new_graph                                             \n",
        "\n",
        "    # time spent in each of the the t-states after some appropriately large time (these are the joint probs)\n",
        "    prev = 0\n",
        "    for decade in range(1, 100 + 1):\n",
        "        # cat(decade, \"\\n\")\n",
        "        # flush.console()\n",
        "        accum_time = accumulated_visiting_time(new_graph, decade*10)[t_vertex_indices]\n",
        "        if (all(abs(accum_time-prev) < precision)) break\n",
        "        prev = accum_time\n",
        "\n",
        "    assert decade < 100)\n",
        "    \n",
        "    # I can test if the graph is acyclic and if so, use accumulated_residence_time instead?\n",
        "                                                    \n",
        "    # data frame with joint probs\n",
        "    states = states(new_graph)\n",
        "    state_reward_matrix = as.data.frame(states[t_vertex_indices, reward_indices])\n",
        "    joint_probs = cbind(state_reward_matrix, accum_time)\n",
        "\n",
        "    print(c(graph.vertices_length(), new_graph.vertices_length(), new_graph.vertices_length()/graph.vertices_length()))                                \n",
        "    return joint_probs  \n",
        "\n",
        "def partial(f, ...):\n",
        "    l = list(...)\n",
        "    function(...) {\n",
        "        do.call(f, c(l, list(...)))\n",
        "\n",
        "\n",
        "# sample_size = 2\n",
        "# graph = two_locus_arg(sample_size, 1, 1)\n",
        "# graph.vertices_length()\n",
        "\n",
        "# reward_rates = partial(arg_reward_rates, mutation_rate=1, reward_limit=1, locus_ton_reward_limit=1)\n",
        "\n",
        "# joint_probs = discrete_joint_prob(graph, reward_rates)\n",
        "# head(joint_probs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b26747c1-6147-4a76-9771-43fe53279a16",
      "metadata": {},
      "source": [
        "## Coalescent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def standard_coalescent(n):\n",
        "    \n",
        "    # n = 4\n",
        "      \n",
        "    # state_vector_length = n + 1    ## + 1 needed to keep it from dumping ##################\n",
        "    state_vector_length = n \n",
        "\n",
        "    graph = phasic.Graph(state_length=state_vector_length)\n",
        "    starting_vertex = graph.vertex_at(0)\n",
        "\n",
        "    # initial_state = c(np.zeros(n, dtype=int), 0)\n",
        "    initial_state = np.zeros(state_vector_length, dtype=int)\n",
        "\n",
        "    initial_state[1] = n\n",
        "    \n",
        "    starting_vertex.add_edge(graph.find_or_create_vertex(initial_state),\n",
        "      1\n",
        "    )\n",
        "    index = 2\n",
        "    \n",
        "    while index <= graph.vertices_length():\n",
        "      vertex = graph.vertex_at(index - 1)\n",
        "      \n",
        "      # loop over all classes of lineages\n",
        "      for i in range(1, n + 1):\n",
        "        for j in range(i, n + 1):\n",
        "          state = vertex.state\n",
        "          \n",
        "          # if same class, there need to be at least two to coalesce\n",
        "          if i == j:\n",
        "            if state[i] < 2:\n",
        "              continue\n",
        "\n",
        "            # coal rate\n",
        "            rate = state[i] * (state[i] - 1) / 2\n",
        "          else:\n",
        "            # else at least one in each class to coalesce\n",
        "            if state[i] < 1 or state[j] < 1:\n",
        "              continue\n",
        "\n",
        "            # number of combinations\n",
        "            rate = state[i] * state[j]\n",
        "\n",
        "          # copy state\n",
        "          child_state = state.copy()\n",
        "          # update child state\n",
        "          child_state[i] = child_state[i] - 1\n",
        "          child_state[j] = child_state[j] - 1\n",
        "          child_state[i+j] = child_state[i+j] + 1\n",
        "\n",
        "          vertex.add_edge(graph.find_or_create_vertex(child_state),\n",
        "              rate, [rate]\n",
        "            )\n",
        "\n",
        "\n",
        "      index = index + 1\n",
        "\n",
        "    return graph\n",
        "\n",
        "# sample_size = 4\n",
        "# graph = standard_coalescent(sample_size)\n",
        "\n",
        "# for (i in 1:graph.vertices_length()) {\n",
        "#     state = graph.vertex_at(i - 1)$state\n",
        "#     print(state)\n",
        "#     print(find_vertex(graph, state))\n",
        "# }\n",
        "\n",
        "# expectation(graph)\n",
        "\n",
        "# states = t(sapply(1:graph.vertices_length(), function(index) graph.vertex_at(index - 1)$state ))\n",
        "# ipv = graph_as_matrix(graph)$IPV\n",
        "# sim = graph_as_matrix(graph)$SIM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "sample_size = 4\n",
        "graph = standard_coalescent(sample_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "gam = graph_as_matrix(graph)\n",
        "gam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "if graph.vertices_length() < 30:    \n",
        "    plot_graph(gam, size=np.array([10, 10], dtype=int), align=True, #rainbow=True,\n",
        "               fontsize=16, ranksep=2, nodesep=0.5, rankdir=\"LR\",\n",
        "               subgraphs=True, subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"),\n",
        "               splines='line'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def coalescent_reward_rates(new_state, current_rewards, mutation_rate, reward_limit, tot_reward_limit):    \n",
        "    reward_limits = c(rep(reward_limit, len(new_state)-1), 0)\n",
        "    \n",
        "    reward_dims = len(reward_limits)\n",
        "    if (is.null(current_rewards))\n",
        "        current_rewards = np.zeros(reward_dims, dtype=int)\n",
        "\n",
        "    result = np.zeros(reward_dims, dtype=int)\n",
        "    trash_rate = 0\n",
        "    \n",
        "    for i in range(1, reward_dims + 1):\n",
        "        rate = new_state[i] * mutation_rate \n",
        "        r = np.zeros(reward_dims, dtype=int)\n",
        "        r[i] = 1\n",
        "        if  all(current_rewards + r <= reward_limits) and sum(current_rewards + r) <= tot_reward_limit:\n",
        "            result[i] = rate\n",
        "        else:\n",
        "            trash_rate = trash_rate + rate\n",
        "\n",
        "\n",
        "    return c(result, trash_rate)\n",
        "\n",
        "reward_rates = partial(coalescent_reward_rates, mutation_rate=1, reward_limit=1, tot_reward_limit=2)\n",
        "# reward_rates = partial(coalescent_reward_rates, mutation_rate=1, reward_limit=20, tot_reward_limit=Inf)\n",
        "\n",
        "start = proc.time()[3]\n",
        "joint_probs = discrete_joint_prob(graph, reward_rates)\n",
        "proc.time()[3] - start\n",
        "\n",
        "head(joint_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "with_deficit = c(sum(joint_probs.V1 * joint_probs.accum_time), \n",
        "  sum(joint_probs.V2 * joint_probs.accum_time), \n",
        "  sum(joint_probs.V3 * joint_probs.accum_time))\n",
        "with_deficit\n",
        "(c(2, 1, 2/3) - with_deficit) / c(2, 1, 2/3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "new_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)\n",
        "new_gam = graph_as_matrix(new_graph)\n",
        "\n",
        "if new_graph.vertices_length() < 30:    \n",
        "    plot_graph(new_gam, size=np.array([10, 10], dtype=int), align=True, #rainbow=True,\n",
        "               fontsize=16, ranksep=2, nodesep=0.5, rankdir=\"LR\",\n",
        "               subgraphs=True, subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"),\n",
        "               splines='line'\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# new_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)\n",
        "# start = proc.time()[3]\n",
        "# prev = 0\n",
        "# for i in range(1, 10 + 1):\n",
        "#     accum_time = accumulated_visiting_time(new_graph, 10*i)\n",
        "    \n",
        "#     if (all(abs(accum_time-prev)[1:10] < 10e-15))\n",
        "#         break\n",
        "\n",
        "#     prev = accum_time\n",
        "# }\n",
        "# proc.time()[3] - start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "joint_probs %>% filter(V1==1, V2==0, V3==1) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f09039-4ea5-4def-9d87-53aeaadd55cf",
      "metadata": {},
      "source": [
        "With `sample_size <- 4`, `mutation_rate <- 1`, `reward_limits <- rep(20, sample_size-1)`, and `tot_reward_limit <- Inf`, tothe marginal probabilities match the SFS:\n",
        "\n",
        "```\n",
        "c(sum(joint_probs$V1 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V2 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V3 * joint_probs$accum_time))\n",
        "```\n",
        "\n",
        "```\n",
        "1.99981743759578 0.998152771395828 0.666638375487117\n",
        "```\n",
        "\n",
        "and the joint prob of a singleton and a trippleton is:\n",
        "\n",
        "```\n",
        "1\t0\t1\t0.03111111\n",
        "```\n",
        "\n",
        "which is exactly what we also get with `reward_limits <- rep(1, sample_size-1)`.\n",
        "\n",
        "Setting `tot_reward_limit <- 2` also produces `0.03111111`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "joint_probs %>% rename_with(gsub, pattern=\"V\", replacement=\"ton\") %>% group_by(ton1, ton2) %>% summarize(prob=sum(accum_time), .groups=\"keep\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# plot_df <- joint_probs %>% \n",
        "#     rename_with(gsub, pattern=\"V\", replacement=\"ton\") %>% \n",
        "#     group_by(ton1, ton2) %>% \n",
        "#     summarize(prob=sum(accum_time), .groups=\"keep\")\n",
        "\n",
        "# for (colname in colnames(plot_df)) {\n",
        "#     if (startsWith(colname, 'ton')) {\n",
        "#         plot_df[[colname]] <- as.factor(plot_df[[colname]])\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# ggplot(plot_df, aes(x=ton1, y=ton2)) +\n",
        "#     geom_tile(aes(fill = prob)) + \n",
        "#     geom_text(aes(label = round(prob, 3))) +\n",
        "#     scale_fill_viridis() +\n",
        "#     # scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "#     #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n",
        "#     #                 ) +\n",
        "#     theme_minimal() +\n",
        "#      theme(panel.grid.major = element_blank(), \n",
        "#             panel.grid.minor = element_blank(), \n",
        "#             text=element_text(size=17))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# def map_state(state):\n",
        "#         lumped_state = c(sum(state[1:sample_size]), head(state, sample_size) * (reward_limits - tail(state, sample_size)))\n",
        "#         lumped_state = int(lumped_state)\n",
        "#         return lumped_state\n",
        "# }\n",
        "# def label_fun(state, index):\n",
        "#     return paste(map_state(state, collapse=\"\"))\n",
        "# }\n",
        "\n",
        "# if graph.vertices_length() < 30:    \n",
        "#     new_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)\n",
        "\n",
        "#     plot_graph(graph_as_matrix(new_graph), size=np.array([10, 10], dtype=int), align=True, #rainbow=True,\n",
        "#                    fontsize=26, ranksep=4, nodesep=0.9, rankdir=\"LR\",\n",
        "#               subgraphs=True, subgraphfun=label_fun,\n",
        "#               # subgraphs=True, subgraphfun=function(state, index) sum(head(state, sample_size)),\n",
        "#             splines='line'\n",
        "#               )  \n",
        "# }           "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "graph_vec = c()\n",
        "new_graph_vec = c()\n",
        "sample_sizes = 4:15\n",
        "for (sample_size in sample_sizes) {\n",
        "    graph = standard_coalescent(sample_size)\n",
        "    graph_vec = c(graph_vec, graph.vertices_length())\n",
        "    reward_limits = c(rep(1, sample_size-1), 0)\n",
        "    tot_reward_limit = Inf\n",
        "    new_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)\n",
        "    # new_graph = discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit, return_graph=True)\n",
        "    new_graph_vec = c(new_graph_vec, new_graph.vertices_length())\n",
        "    # new_graph_vec = c(new_graph_vec, len(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# theme_set(theme_bw() + theme(axis.line = element_line(colour = \"black\"),\n",
        "#                  text=element_text(size=17),\n",
        "#                  axis.text = element_text(size=15),\n",
        "#                  plot.margin = unit(c(0.3,0.1,0.1,0.1), \"inch\")))\n",
        "# palette <- c(\"#888888\", \"#E69F00\", \"#56B4E9\", \"#009E73\", \"#F0E442\", \"#0072B2\", \"#D55E00\", \"#CC79A7\")\n",
        "# opt <- options(repr.plot.width=7, repr.plot.height=5,\n",
        "#                ggplot2.discrete.colour=palette, ggplot2.discrete.fill=palette) ;\n",
        "# despine <-  theme(panel.border = element_blank(), \n",
        "#                  panel.grid.major = element_blank(),\n",
        "#                  panel.grid.minor = element_blank())\n",
        "\n",
        "# library(gridExtra)\n",
        "# df <- data.frame(\n",
        "#   samples = sample_sizes,\n",
        "#   graph_states = graph_vec,\n",
        "#   new_graph_states =new_graph_vec\n",
        "# )\n",
        "# df_long <- pivot_longer(df, c(graph_states, new_graph_states))\n",
        "# p1 <- ggplot(df_long, aes(x=samples, y=value, color=name)) +\n",
        "#     geom_line(linewidth=1) + geom_point(size=3) + \n",
        "#     despine +\n",
        "#     xlim(0, NA) + ylim(0, NA) +\n",
        "#     labs(x=\"Sample size\", y=\"Vertices\", color=\"Graph\") +\n",
        "#     scale_color_discrete(labels = c(\"Original\", \"Augmented\"))\n",
        "# p2 <- ggplot(df, aes(x=samples, y=new_graph_vec / graph_vec)) + \n",
        "#     geom_line(linewidth=1) + geom_point(size=3) + \n",
        "#     geom_abline(slope=1, intercept=0) +\n",
        "#     # geom_abline(slope=0.25, intercept=1.5) +\n",
        "#     despine +\n",
        "#     xlim(0, NA) + ylim(0, NA) +\n",
        "#     labs(x=\"Sample size\", y=\"Augmented / original vertices\", color=\"Graph\")\n",
        "\n",
        "# opt <- options(repr.plot.width=12, repr.plot.height=5.5)\n",
        "# grid.arrange(p1, p2, nrow = 1, widths = 3:2)\n",
        "# options(opt) ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# # nr_states_vec <- c()\n",
        "# # nr_lumped_states_vec <- c()\n",
        "# # sample_sizes <- 4:10\n",
        "# # for (sample_size in sample_sizes) {\n",
        "# #     graph <- standard_coalescent(sample_size)\n",
        "# #     state_length <- length(vertex_at(graph, 1)$state)\n",
        "# #     # last state index is absorbing where no rewards can be earned\n",
        "# #     reward_limits <- c(rep(1, state_length-1), 0)    \n",
        "# #     new_graph <- discrete_joint_prob(graph, reward_rates, return_graph=TRUE)\n",
        "# #     # new_graph <- discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, return_graph=TRUE)\n",
        "# #     nr_states_vec <- c(nr_states_vec, vertices_length(new_graph))\n",
        "# #     nr_lumped_states_vec <- c(nr_lumped_states_vec, length(unique(apply(apply(states(new_graph), 1, map_state), 2, paste, collapse=\"\"))))\n",
        "# # }\n",
        "# # df <- data.frame(\n",
        "# #   samples = sample_sizes,\n",
        "# #   nr_states = nr_states_vec,\n",
        "# #   nr_lumped_states =nr_lumped_states_vec\n",
        "# # )\n",
        "# # df_long <- pivot_longer(df, c(nr_states, nr_lumped_states))\n",
        "# # ggplot(df_long, aes(x=samples, y=value, hue=name)) + geom_line() + geom_point()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb87dcc-9f5f-4d4e-acac-93e1cadc501c",
      "metadata": {},
      "source": [
        "## Two-locus ARG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def arg_reward_rates(new_state, current_rewards, mutation_rate, reward_limit, locus_ton_reward_limit):    \n",
        "    reward_limits = c(rep(reward_limit, len(new_state)-1), 0)\n",
        "    reward_limits = c(reward_limits, reward_limits) # duplicate to account for separate mutations at each locus\n",
        "\n",
        "    reward_dims = len(reward_limits)\n",
        "    if (is.null(current_rewards))\n",
        "        current_rewards = np.zeros(reward_dims, dtype=int)\n",
        "\n",
        "# allowed_l1 = sapply(1:(reward_dims %/% 2), function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 > 0)\n",
        "# allowed_l2 = sapply((reward_dims %/% 2 + 1):reward_dims, function(i) index_to_props_two_locus(sample_size, i)$descendants_l2 > 0)                   \n",
        "# allowed_mask = int(c(allowed_l1, allowed_l2))\n",
        "    \n",
        "    result = np.zeros(reward_dims, dtype=int)\n",
        "    trash_rate = 0\n",
        "                           \n",
        "    for i in range(1, reward_dims + 1):\n",
        "        rate = new_state[(i-1) %% (reward_dims %/% 2) + 1] * mutation_rate # fancy index to map state index to duplicted reward index\n",
        "        r = np.zeros(reward_dims, dtype=int)\n",
        "        r[i] = 1\n",
        "        proposed_rewards = current_rewards + r\n",
        "        \n",
        "        if ( all(proposed_rewards <= reward_limits) and \n",
        "            sum(head(proposed_rewards, reward_dims %/% 2)) <= locus_ton_reward_limit and \n",
        "            sum(tail(proposed_rewards, reward_dims %/% 2)) <= locus_ton_reward_limit ) {\n",
        "            result[i] = rate\n",
        "        else:\n",
        "            trash_rate = trash_rate + rate\n",
        "\n",
        "\n",
        "    return c(result, trash_rate)\n",
        "\n",
        "sample_size = 4\n",
        "graph = two_locus_arg(sample_size, 1, 1)\n",
        "graph.vertices_length()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "reward_rates = partial(arg_reward_rates, mutation_rate=1, reward_limit=1, locus_ton_reward_limit=1)\n",
        "\n",
        "start = proc.time()[3]\n",
        "joint_probs = discrete_joint_prob(graph, reward_rates)\n",
        "proc.time()[3] - start\n",
        "\n",
        "tail(joint_probs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# sample_size = 3\n",
        "# graph = two_locus_arg(sample_size, 1, 1)\n",
        "\n",
        "# # plot_graph(graph_as_matrix(graph), size=np.array([10, 10], dtype=int), align=True, rainbow=True,\n",
        "# #                fontsize=16, ranksep=2, nodesep=0.5,\n",
        "# #           subgraphs=True,         \n",
        "# #            subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))  \n",
        "\n",
        "# state_length = len(graph.vertex_at(0)$state)\n",
        "# reward_limits = list()\n",
        "# for i in range(1, state_length + 1):\n",
        "#     prop_i = index_to_props_two_locus(sample_size, i)\n",
        "#     if prop_i.descendants_l1 == sample_size and prop_i.descendants_l2 == sample_size:\n",
        "#         # absorbing state has no reward\n",
        "#         next\n",
        "#     }\n",
        "#     if prop_i.descendants_l1 > 0 and prop_i.descendants_l2 > 0:\n",
        "#         r = np.zeros(state_length, dtype=int)\n",
        "#         r[i] = 1\n",
        "#         # cat(prop_i.descendants_l1, \" \", prop_i.descendants_l2, \" \", r, \"\\n\")\n",
        "#         reward_limits = c(reward_limits,  list(r))\n",
        "#         next\n",
        "#     }\n",
        "#     for j in range(i, state_length + 1):\n",
        "#         prop_j = index_to_props_two_locus(sample_size, j)\n",
        "#         if prop_j.descendants_l1 > 0 and prop_j.descendants_l2 > 0:\n",
        "#             next\n",
        "#         }        \n",
        "#         r = np.zeros(state_length, dtype=int)\n",
        "#         if (prop_i.descendants_l1 > 0 and prop_j.descendants_l2 > 0) or (prop_j.descendants_l1 > 0 and prop_i.descendants_l2 > 0):\n",
        "#             r[i] = 1\n",
        "#             r[j] = 1\n",
        "#             reward_limits = c(reward_limits, list(r))\n",
        "#             # cat(prop_i.descendants_l1, \" \", prop_i.descendants_l2, \" \", prop_j.descendants_l1, \" \", prop_j.descendants_l2, \" \", r, \"\\n\")            \n",
        "#         }\n",
        "#     }\n",
        "# }\n",
        "\n",
        "# tot_reward_limit = Inf\n",
        "\n",
        "# mutation_rate = 1\n",
        "\n",
        "# def reward_possible(state, rewards):\n",
        "#     def max_nrs_descendants(state):\n",
        "#        l1 = 0\n",
        "#        l2 = 0\n",
        "#        for (i in 1:len(state)) {\n",
        "#            if state[i] > 0:\n",
        "#                props = index_to_props_two_locus(sample_size, i) # SAMPLE SIZE SHOULD NOT BE A GLOBAL HERE...\n",
        "#                l1 = max(c(l1, props.descendants_l1))\n",
        "#                l2 = max(c(l2, props.descendants_l2))\n",
        "#            }\n",
        "#         }\n",
        "#        return c(l1, l2)\n",
        "#     }\n",
        "#     return (all(max_nrs_descendants(rewards) <= max_nrs_descendants(state)))\n",
        "# }\n",
        "\n",
        "\n",
        "# #reward_limits\n",
        "# #reward_limits = reward_limits[[1]]\n",
        "# state_length = len(graph.vertex_at(0)$state)\n",
        "# # last state index is absorbing where no rewards can be earned\n",
        "# reward_limits = c(rep(1, state_length-1), 0)\n",
        "\n",
        "# start = proc.time()[3]\n",
        "# joint_probs = discrete_joint_prob(graph, reward_limits, mutation_rate, reward_possible, tot_reward_limit=tot_reward_limit)\n",
        "# proc.time()[3] - start\n",
        "# tail(joint_probs)                                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "state_length = ncol(joint_probs) - 1\n",
        "\n",
        "mat = joint_probs %>% select(starts_with('V')) %>% as.matrix\n",
        "\n",
        "def fun(x, marg_ton, sample_size):\n",
        "     any(sapply((1:state_length)[which(x==1)], function(i) index_to_props_two_locus(sample_size, i)$descendants_l1 == marg_ton))\n",
        "\n",
        "for marg_ton in range(1, sample_size + 1):               \n",
        "    mask = apply(mat, 1, fun, marg_ton=marg_ton, sample_size=sample_size)\n",
        "    print( sum(joint_probs.accum_time[mask]) )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def fun(name, sample_size):\n",
        "     def f(name, sample_size):\n",
        "        if (!startsWith(name, \"V\"))\n",
        "            return name\n",
        "        idx = int(gsub('V', '', name))\n",
        "        props = index_to_props_two_locus(sample_size, idx)\n",
        "        # new_name = paste(c(\"(\", props.descendants_l1, \", \", props.descendants_l2, \")\"), collapse=\"\")\n",
        "        new_name = paste(c(\"ton\", props.descendants_l1, \"x\", props.descendants_l2, \"_\", props.population, props.population), collapse=\"\")\n",
        "        return new_name\n",
        "\n",
        "    sapply(name, f, sample_size=sample_size)\n",
        "\n",
        "df = joint_probs %>% \n",
        "    # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %>% \n",
        "    rename_with(fun, sample_size=sample_size)\n",
        "\n",
        "head(df)\n",
        "\n",
        "tonnames = df %>% select(!accum_time) %>% names() %>% str_extract(\"^ton[:digit:]x[:digit:]\") %>% unique()\n",
        "l = map(tonnames, function (n) rowSums(select(df, ends_with(n))))\n",
        "plot_df = as.data.frame(do.call(cbind, l))\n",
        "colnames(plot_df) = tonnames\n",
        "plot_df['accum_time'] = df['accum_time']\n",
        "head(plot_df)         "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# plot_df = joint_probs %>% \n",
        "#     # rename_with(gsub, pattern=\"V\", replacement=\"ton\") %>% \n",
        "#     rename_with(fun, sample_size=sample_size) %>%\n",
        "#     group_by(ton0x1, ton1x0) %>% \n",
        "#     summarize(prob=sum(accum_time), .groups=\"keep\")\n",
        "\n",
        "# for (colname in colnames(plot_df)) {\n",
        "#     # if startsWith(colname, 'ton'):\n",
        "#     if colname != 'prob':\n",
        "#         plot_df[[colname]] = as.factor(plot_df[[colname]])\n",
        "#     }\n",
        "# }\n",
        "# plot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ggplot(plot_df, aes(x=ton0x1, y=ton1x0)) +\n",
        "#     geom_tile(aes(fill = accum_time)) + \n",
        "#     geom_text(aes(label = round(accum_time, 3))) +\n",
        "#     scale_fill_viridis() +\n",
        "#     # scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "#     #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n",
        "#     #                 ) +\n",
        "#     theme_minimal() +\n",
        "#      theme(panel.grid.major = element_blank(), \n",
        "#             panel.grid.minor = element_blank(), \n",
        "#             text=element_text(size=17))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# get_exp_mat <- function(graph, rewards, s) \n",
        "# {\n",
        "#     exp_mat <- matrix(nrow=s+1,ncol=s+1)\n",
        "#     for (i in 0:s) {\n",
        "#       for (j in 0:s) {\n",
        "#         exp_mat[i+1,j+1] <- expectation(graph, rewards[props_to_index_two_locus(s, i, j), ])\n",
        "#       }\n",
        "#     } \n",
        "#     return(exp_mat)\n",
        "# }\n",
        "                 \n",
        "# plot_exp_mat <- function(exp_mat, title=\"Expectations\") \n",
        "# {  \n",
        "#     df <- as.data.frame(exp_mat) #%>% gather()\n",
        "#     df <- df %>% rownames_to_column('ton1') %>% gather('ton2', 'value', -c(ton1))\n",
        "\n",
        "#     limit <- max(abs(df$value)) * c(-1, 1)\n",
        "    \n",
        "#     ggplot(df, aes(ton1, ton2)) +\n",
        "#         geom_tile(aes(fill = value)) + \n",
        "#         geom_text(aes(label = round(value, 2)), size=5) +\n",
        "#         ggtitle(title) +\n",
        "#     scale_x_discrete(labels= seq(0, nrow(exp_mat))) + \n",
        "#     scale_y_discrete(labels= seq(0, nrow(exp_mat))) + \n",
        "#     scale_fill_distiller(palette = 'PiYG',direction = 1, limit=limit) +\n",
        "#     theme_minimal() +\n",
        "#      theme(panel.grid.major = element_blank(), \n",
        "#             panel.grid.minor = element_blank(), \n",
        "#             text=element_text(size=17))\n",
        "\n",
        "# } \n",
        "\n",
        "# exp_mat <- get_exp_mat(graph, reward_matrix, sample_size)\n",
        "# new_exp_mat <- get_exp_mat(new_graph, rbind(0, new_reward_matrix, 0), sample_size)\n",
        "\n",
        "# options(repr.plot.width = 20, repr.plot.height = 5, repr.plot.res = 100)\n",
        "\n",
        "# p1 <- plot_exp_mat(exp_mat, \"Original graph\")    \n",
        "# p2 <- plot_exp_mat(new_exp_mat, \"Lumped graph\")    \n",
        "# p3 <- plot_exp_mat(exp_mat - new_exp_mat, \"Absolute difference\")    \n",
        "# rel_diff <- (exp_mat - new_exp_mat)/exp_mat\n",
        "# rel_diff[is.na(rel_diff)] <- 0\n",
        "# p4 <- plot_exp_mat(rel_diff, \"Relative difference\")    \n",
        "# grid.arrange(p1, p2, p3, p4, nrow = 1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59025cf2-796a-461e-bd46-b1850fa5345d",
      "metadata": {},
      "source": [
        "# Base-n approach\n",
        "\n",
        "## State space for joint proability computation\n",
        "\n",
        "Generate coalescent state space like normal with the following modifications\n",
        "\n",
        "- Change state space from (4, 0, 0, 0) to (4, 0, 0, 0, t1, t2, t3, t4). The last extra \"ton\" states keep track of the number accumulated mutations of each kind. We simply double the state vector so we keep track of the counts lineages with descendants, but also the counts of mutations happened on such lineages.\n",
        "- Each state can mutate to accumulate a \"ton\" in accordance with its state vector. E.g., a `(4, 0, 0, 0, 0, 0, 0, 0)` state can only make singletons,  a `(2, 1, 0, 0, 0, 0, 0, 0)` state can only make singletons and doubletons.\n",
        "- A mutation event is a transition to a siter state E.g., `(4, 0, 0, 0, 0, 0, 0, 0) -> (4, 0, 0, 0, 1, 0, 0, 0)`\n",
        "- The ton counts have a maximum value (base-1). If this value is reached, the mutation transition instead leads to a trash state with an infinite self loop. The transitions to trash represents the part of the deficient PDF not covered because we only run up to a max nr of tons."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e531025-71c8-4ffe-a658-a5e751c9956c",
      "metadata": {},
      "source": [
        "## Reward transform\n",
        "\n",
        "- Convert the last half of each state (with ton counts) to numbers in some base.\n",
        "- Use these for reward transformation.\n",
        "- Compute PDF for t <- 1:sample_size^(base-1)\n",
        "- Convert each time t back to the corresponding ton vector and associate it with the probability\n",
        "- group by two tons and sum probs in groups to get all pairwise combinations for a joint probability matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f6f252-ef42-41a8-95a4-4e295e858b58",
      "metadata": {},
      "source": [
        "## Figure out why you get NAs in multi_rewards with max_tons <- 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfd5180-27f1-4920-a148-662e38288df7",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# def joint_prob_coalescent(n, mutation_rate, max_tons, total_tons=Inf):\n",
        "    \n",
        "#     state_vector_length = n + n + 1\n",
        "#     graph = phasic.Graph(state_length=state_vector_length)\n",
        "#     starting_vertex = graph.vertex_at(0)\n",
        "#     initial_state = c(np.zeros(n, dtype=int), 0)\n",
        "#     initial_state[1] = n\n",
        "    \n",
        "#     add_edge(\n",
        "#       starting_vertex,\n",
        "#       graph.find_or_create_vertex(initial_state),\n",
        "#       1\n",
        "#     )\n",
        "#     index = 2\n",
        "\n",
        "#     while index <= graph.vertices_length():\n",
        "#       vertex = graph.vertex_at(index - 1)\n",
        "\n",
        "#       # skip if we only have one lineage left or if this is a trash state\n",
        "#       if sum(vertex.state[1:n]) <= 1:\n",
        "#         index = index + 1\n",
        "#         next\n",
        "#       }\n",
        "\n",
        "#       # mutations\n",
        "#       trash_rate = 0 \n",
        "#       for i in range(1, n + 1):\n",
        "#         state = vertex.state          \n",
        "#         rate = vertex.state[i] * mutation_rate\n",
        "#         nr_tons = state[n+i]\n",
        "#         if rate > 0:\n",
        "#             if nr_tons < max_tons and sum(vertex.state[(n+1):(2*n)]) < total_tons:\n",
        "#               child_state = state.copy()\n",
        "#               mutation_vertex = graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#               vertex.add_edge(mutation_vertex, rate)\n",
        "#               child_state[n+i] = child_state[i+n] + 1\n",
        "#               mutation_vertex.add_edge(graph.find_or_create_vertex(child_state), 1)\n",
        "                \n",
        "#               # child_state[n+i] = child_state[i+n] + 1\n",
        "#               # vertex.add_edge(graph.find_or_create_vertex(child_state), rate)\n",
        "#             else:\n",
        "#               trash_rate = trash_rate + rate\n",
        "#             }\n",
        "#         }          \n",
        "#       }\n",
        "#       if trash_rate > 0:\n",
        "#         vertex.add_edge(graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int)), trash_rate)\n",
        "#       }\n",
        "\n",
        "#       # loop over all classes of lineages\n",
        "#       for i in range(1, n + 1):\n",
        "#         for j in range(i, n + 1):\n",
        "#           state = vertex.state\n",
        "          \n",
        "#           # if same class, there need to be at least two to coalesce\n",
        "#           if i == j:\n",
        "#             if state[i] < 2:\n",
        "#               continue\n",
        "#             }\n",
        "#             # coal rate\n",
        "#             rate = state[i] * (state[i] - 1) / 2\n",
        "#           else:\n",
        "#             # else at least one in each class to coalesce\n",
        "#             if state[i] < 1 or state[j] < 1:\n",
        "#               continue\n",
        "#             }\n",
        "#             # number of combinations\n",
        "#             rate = state[i] * state[j]\n",
        "#           }\n",
        "          \n",
        "#           # copy state\n",
        "#           child_state = state.copy()\n",
        "#           # update child state\n",
        "#           child_state[i] = child_state[i] - 1\n",
        "#           child_state[j] = child_state[j] - 1\n",
        "#           child_state[i+j] = child_state[i+j] + 1\n",
        "\n",
        "#           add_edge(\n",
        "#               vertex,\n",
        "#               graph.find_or_create_vertex(child_state),\n",
        "#               rate\n",
        "#             )\n",
        "#         }\n",
        "#       }\n",
        "\n",
        "#       index = index + 1\n",
        "#     }\n",
        "#     trash_vertex = graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#     trash_loop_vertex = graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "#     trash_vertex.add_edge(trash_loop_vertex, 1)\n",
        "#     trash_loop_vertex.add_edge(trash_vertex, 1)\n",
        "    \n",
        "#     return graph\n",
        "# }\n",
        "# # states = t(sapply(1:graph.vertices_length(), function(index) graph.vertex_at(index - 1)$state ))\n",
        "# # ipv = graph_as_matrix(graph)$IPV\n",
        "# # sim = graph_as_matrix(graph)$SIM\n",
        "\n",
        "# # sample_size = 4\n",
        "# # # mutation_rate = 20000 * 31 * 5e-10 # 0.00031\n",
        "# # mutation_rate = 1\n",
        "# # max_tons = 3\n",
        "# # base = max_tons + 1\n",
        "# # # graph = joint_prob_coalescent(sample_size, mutation_rate, max_tons)\n",
        "# # # gam = graph_as_matrix(graph)\n",
        "# # # #gam\n",
        "\n",
        "# # graph = joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons)\n",
        "# # gam = graph_as_matrix(graph)\n",
        "# # plot_graph(gam, #subgraphs=True, \n",
        "# #            rainbow=True,\n",
        "# #            size=np.array([10, 8], dtype=int), \n",
        "# #            align=True,\n",
        "# #            fontsize=16, ranksep=1, nodesep=0.25,          \n",
        "# #            # subgraphfun=function(state) paste(state[-len(state)], collapse=\"\")\n",
        "# #            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "def joint_prob_coalescent(n, mutation_rate, max_tons, total_tons=Inf):\n",
        "\n",
        "    assert total_tons == Inf)\n",
        "    \n",
        "    state_vector_length = n + n + 1\n",
        "    graph = phasic.Graph(state_length=state_vector_length)\n",
        "    starting_vertex = graph.vertex_at(0)\n",
        "    initial_state = c(np.zeros(n, dtype=int), 0)\n",
        "    initial_state[1] = n\n",
        "    \n",
        "    starting_vertex.add_edge(graph.find_or_create_vertex(initial_state),\n",
        "      1\n",
        "    )\n",
        "    index = 2\n",
        "\n",
        "    while index <= graph.vertices_length():\n",
        "      vertex = graph.vertex_at(index - 1)\n",
        "\n",
        "      # skip if we only have one lineage left or if this is a trash state\n",
        "      if sum(vertex.state[1:n]) <= 1:\n",
        "        index = index + 1\n",
        "        next\n",
        "\n",
        "      # loop over all classes of lineages\n",
        "      for i in range(1, n + 1):\n",
        "        for j in range(i, n + 1):\n",
        "          state = vertex.state\n",
        "          \n",
        "          # if same class, there need to be at least two to coalesce\n",
        "          if i == j:\n",
        "            if state[i] < 2:\n",
        "              continue\n",
        "\n",
        "            # coal rate\n",
        "            rate = state[i] * (state[i] - 1) / 2\n",
        "          else:\n",
        "            # else at least one in each class to coalesce\n",
        "            if state[i] < 1 or state[j] < 1:\n",
        "              continue\n",
        "\n",
        "            # number of combinations\n",
        "            rate = state[i] * state[j]\n",
        "\n",
        "          # copy state\n",
        "          child_state = state.copy()\n",
        "          # update child state\n",
        "          child_state[i] = child_state[i] - 1\n",
        "          child_state[j] = child_state[j] - 1\n",
        "          child_state[i+j] = child_state[i+j] + 1\n",
        "\n",
        "          vertex.add_edge(graph.find_or_create_vertex(child_state),\n",
        "              rate\n",
        "            )\n",
        "\n",
        "\n",
        "      # mutations\n",
        "      trash_rate = 0 \n",
        "      for i in range(1, n + 1):\n",
        "        rate = vertex.state[i] * mutation_rate\n",
        "        nr_tons = child_state[n+i]\n",
        "        if rate > 0:\n",
        "            if nr_tons < max_tons and sum(vertex.state[(n+1):(2*n)]) < total_tons:\n",
        "              child_state = state.copy()\n",
        "              child_state[n+i] = child_state[i+n] + 1\n",
        "              vertex.add_edge(graph.find_or_create_vertex(child_state), rate)\n",
        "            else:\n",
        "              trash_rate = trash_rate + rate\n",
        "\n",
        "\n",
        "\n",
        "      if trash_rate > 0:\n",
        "        vertex.add_edge(graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int)), trash_rate)\n",
        "\n",
        "      index = index + 1\n",
        "\n",
        "    trash_vertex = graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "    trash_loop_vertex = graph.find_or_create_vertex(np.zeros(state_vector_length, dtype=int))\n",
        "    trash_vertex.add_edge(trash_loop_vertex, 1)\n",
        "    trash_loop_vertex.add_edge(trash_vertex, 1)\n",
        "    \n",
        "    return graph\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "def ndigits(x):\n",
        "  y = floor(abs(x))\n",
        "  if y != 0:\n",
        "    floor(log10(y)) + 1\n",
        "  else:\n",
        "    1\n",
        "\n",
        "\n",
        "def rev_number(n):\n",
        "    m=int(rev(strsplit(as.character(n),\"\")))\n",
        "    if (m==rev(m)) print(\"reversed number\")\n",
        "\n",
        "def forth(vec, base):\n",
        "    # return  int( c(vec %*%  (base ^ rev(range(len(vec)) / base)) ) )\n",
        "    # return  int( c(vec %*%  (base ^ (range(len(vec)) / base)) ) )\n",
        "    # return  c(vec %*%  (base ^ (rev(range(len(vec))) / base)) ) \n",
        "    return  c(vec %*%  (base ^ (range(len(vec)) / base)) ) \n",
        "\n",
        "def back(x, base, state_length):\n",
        "    # x = int(rev(paste(x, collapse='')))\n",
        "    # x = floor(as.numeric(rev(paste(x, collapse=''))))\n",
        "    vec = c()\n",
        "\n",
        "    for i in range(1, state_length + 1):\n",
        "        # if x > 0:\n",
        "            vec = c(x %% (base), vec)\n",
        "            x = x %/% (base)\n",
        "        # }\n",
        "\n",
        "    # while x > 0:\n",
        "    #     vec = c(x %% (base), vec)\n",
        "    #     x = x %/% (base)\n",
        "    # }\n",
        "    \n",
        "    # for (i in 1:ndigits(x)) {\n",
        "    #     if x > 0:\n",
        "    #         vec = c(x %% (base), vec)\n",
        "    #         x = x %/% (base)\n",
        "    #     }\n",
        "    # }\n",
        "    vec = int(vec)\n",
        "    return  rev(c(rep(0, state_length-len(vec), vec) ))\n",
        "    # return  c(rep(0, state_length-len(vec), vec) )\n",
        "\n",
        "# vec = np.array([1, 2, 0], dtype=int)\n",
        "# base = max(vec)+1\n",
        "# state_length = len(vec)\n",
        "# print(vec)\n",
        "# f = forth(vec, base)\n",
        "# print(f)\n",
        "# b = back(f, base, state_length)\n",
        "# print(b)\n",
        "# b = c(rep(0, len(vec)-len(b)), b)\n",
        "# print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "graph = standard_coalescent(sample_size)\n",
        "graph_as_matrix(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "plot_graph(graph_as_matrix(graph), size=np.array([10, 8], dtype=int), align=True, # rainbow=True,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "expectation(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "rewards = make_discrete(graph, 1)\n",
        "graph_as_matrix(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "plot_graph(graph_as_matrix(graph), #rainbow=True, \n",
        "           size=np.array([10, 8], dtype=int), #align=True,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25,\n",
        "             # subgraph=True, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "apply(rewards[1:3,], 1, function(x) expectation(graph, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "rev_graph = reward_transform(graph, rewards[1,])\n",
        "plot_graph(graph_as_matrix(rev_graph), #rainbow=True, \n",
        "           size=np.array([10, 8], dtype=int), #align=True,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25,\n",
        "             # subgraph=True, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "pdph(1:10, rev_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3381999-d744-465c-b6be-b2572c5110ab",
      "metadata": {},
      "source": [
        "## Compute joint prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec3aa7d-855a-4682-872a-688f18072d38",
      "metadata": {},
      "source": [
        "> **Constraining the total number of mutations does not work**\n",
        "> \n",
        "> The deficit is computed correctly as long as all max rewards so that all r scalar values in the CDF represents a reward combination in the MDF\n",
        "> \n",
        "> Just like we can limit the number of each king of tons in the state space contruction, we might also limit the total number of mutations so that we, for example, can have at most one instance of two different tons (`total_tons=2`). E.g., a singleton and a tripleton.\n",
        "> \n",
        "> However, this gives a a deficit problem I am not sure I can solve with this approach. In principle, the deficit should be taken care of, and I should just discard all joint probs for total numbers of tons larger than `total_tons` - but that does not seem to be the case..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04142edc-bfed-4fb8-b6ad-d70bd85ad345",
      "metadata": {},
      "source": [
        "**maybe I don't need loops if they are not selff-loops anyway. If aux->C has rate 1 then A->aux->C is the same as A->C. Below I just changed two things**\n",
        "\n",
        "1. normalize the graph\n",
        "2. use pdph instead of pph\n",
        "\n",
        "**BUT** if I normalize I need to represent the residual prob as reward, which means I need to reward transform, which I cannot if I want to do everying in one go with the scalar trick. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "sample_size = 4\n",
        "\n",
        "graph = standard_coalescent(sample_size)\n",
        "plot_graph(graph_as_matrix(graph), size=np.array([10, 8], dtype=int), align=True, rainbow=True,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25,\n",
        "            subgraphs=True,         \n",
        "           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# mutation_rate = 20000 * 31 * 5e-10 # 0.00031\n",
        "mutation_rate = 1\n",
        "max_tons = 20\n",
        "total_tons = Inf\n",
        "base = max_tons + 1\n",
        "graph = joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n",
        "\n",
        "weights_were_multiplied_with = normalize_graph(graph)\n",
        "\n",
        "# gam = graph_as_matrix(graph)\n",
        "#gam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "if (graph.vertices_length() < 50)\n",
        "    plot_graph(graph_as_matrix(graph), size=np.array([10, 8], dtype=int), align=True, rainbow=True,\n",
        "               fontsize=16, ranksep=2, nodesep=0.5,\n",
        "             subgraphs=True,         \n",
        "           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49855f7e-6066-4c38-8ae4-9ce979b0701d",
      "metadata": {},
      "source": [
        "Get last halves of states that server as mutation rewards:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "rewards = states(graph)[, (sample_size+1):(2*sample_size)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a1299d-b226-4122-97c2-50ca95759370",
      "metadata": {},
      "source": [
        "Turn reward vectors into scalars (with the appropriate base):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "multi_rewards = apply(rewards, 1, forth, base=base)\n",
        "multi_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967d8ea3-ecc9-46a9-98ec-f7789a60cc73",
      "metadata": {},
      "source": [
        "Loop over states except starting to find trash vertices and give them a reward so they won't dissapear in the reward transformation. They will not contribute this reward because they are dead ends:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "trash_states = c()\n",
        "for (i in 2:graph.vertices_length()) {\n",
        "  vertex = graph.vertex_at(i - 1)\n",
        "  if sum(vertex.state) == 0:\n",
        "    multi_rewards[i] = 1\n",
        "    trash_states = c(trash_states, i)\n",
        "\n",
        "\n",
        "trash_states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "multi_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aadd23ab-4f43-4f78-84bb-7e83ea91b808",
      "metadata": {},
      "source": [
        "Reward transform graph using scalar rewards:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "rew_graph = reward_transform(graph, multi_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "if (graph.vertices_length() < 50)\n",
        "    plot_graph(graph_as_matrix(rew_graph),\n",
        "           rainbow=True,\n",
        "           size=np.array([8, 8], dtype=int), \n",
        "           align=True,\n",
        "           fontsize=14, ranksep=1, nodesep=0.5, \n",
        "           # subgraphs=True, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8dd4a3b-88fb-4197-aab5-84d651419674",
      "metadata": {},
      "source": [
        "Compute CDF assming no mutation count exceeds `max_tons`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "cdf_df = data.frame(t=seq(0, base^(sample_size-1) - 1, 1))\n",
        "cdf_df['cdf'] = sapply(cdf_df.t, function (t) pdph(t, rew_graph))\n",
        "# cdf_df['cdf'] = sapply(cdf_df.t, function (t) pph(t, rew_graph))\n",
        "tail(cdf_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06996680-f800-4b0e-a59d-4a3451b7e5d4",
      "metadata": {},
      "source": [
        "Convert reward scalars back into state vectors representing ton counts:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "x = lapply(cdf_df.t, back, base=base, state_length=sample_size)\n",
        "m = do.call(rbind, x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# is_additional_deficit = int(rowSums(m) > total_tons)\n",
        "# p = df.cdf\n",
        "# pdf_from_cdf = c(p[1], p[2:len(p)] - p[-len(p)])\n",
        "# additional_deficit = cumsum(pdf_from_cdf * is_additional_deficit)\n",
        "# additional_deficit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "df = cbind(cdf_df, data.frame(m))\n",
        "tail(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6db536-1fdf-489a-b34d-d42b459e065e",
      "metadata": {},
      "source": [
        "The deficit is taken care of, so you should discard all joint probs for total numbers of tons larger than `total_tons`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df = df[!is_additional_deficit, ]\n",
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=cdf)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine + ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abffbee-02a9-4119-ae39-7fc059609100",
      "metadata": {},
      "source": [
        "Compute probability of standing in on of the trash states for each time t in our CDF. These represent the deficit of the computed CDF:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea43497d-429a-41a8-a3f7-eba09fbab7ef",
      "metadata": {},
      "source": [
        "> Make sure the stop_probability is the discrete version of that is what we are doing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "trash_prob = c()\n",
        "for (t in df.t) {\n",
        "    # s = stop_probability(graph, t)\n",
        "    s = dph_stop_probability(graph, t)\n",
        "    trash_prob = c(trash_prob, sum(s[trash_states]))\n",
        "\n",
        "df['cdf_deficit'] = trash_prob\n",
        "head(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f01b411-ceb7-4879-9a88-b82d5179504d",
      "metadata": {},
      "source": [
        "CDF deficit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=cdf_deficit)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine + ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe6364c4-9f95-4b62-90ec-bfbd288c2a82",
      "metadata": {},
      "source": [
        "Sanity check: adding CDF and deficit should produce a CDF that goes to 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "df['cdf_incl_deficit'] = df.cdf + df.cdf_deficit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=cdf_incl_deficit)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine + \n",
        "#     ylim(0, 1) + \n",
        "#     geom_hline(yintercept=1, linetype=\"dashed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90f9d697-f685-4952-8bec-50b9f6609095",
      "metadata": {},
      "source": [
        "I.e., and a PDF that sum to one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "p = df.cdf_incl_deficit\n",
        "df['pdf_from_cdf_incl_deficit'] = c(p[1], p[2:len(p)] - p[-len(p)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=pdf_from_cdf_incl_deficit)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "sum(df.pdf_from_cdf_incl_deficit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e85cf02-54de-4d02-a4d5-a5f8f56e6138",
      "metadata": {},
      "source": [
        "It **almost** does... Maybe a numerical issue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e689faea-c08a-4250-bc57-f1c18a44c666",
      "metadata": {},
      "source": [
        "Compute PDF from the CDF (**this is the one we are after**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "p = df.cdf\n",
        "df['pdf_from_cdf'] = c(p[1], p[2:len(p)] - p[-len(p)])\n",
        "df['prob'] = df.pdf_from_cdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=pdf_from_cdf)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c00f68d-df0d-4d8a-a0a0-9f5a4c794b52",
      "metadata": {},
      "source": [
        "The reason we need to go through the CDF to get the PDF is that the PDF function in PtD computes the distribution of times when the absorbing state is reached. It this cannot take the deficit in trash_states into account. The PDF commputed directly looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f796db8c-a992-4952-8f50-bac73e34044a",
      "metadata": {},
      "source": [
        "> Make sure I ues the discrete version here if I also use the dicscrete CDF above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df['pdf'] = sapply(df.t, function (t) dph(t, rew_graph))\n",
        "df['pdf'] = sapply(df.t, function (t) ddph(t, rew_graph))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df %>% ggplot(aes(x=t, y=pdf)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e327b443-4880-4963-905b-feb06bd9e954",
      "metadata": {},
      "source": [
        "## When we do the discrete version, we don't need to go through the CDF to get the PDF. We can just use the `ddph` directly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# df['diff'] <- df['pdf_from_cdf'] - df['pdf']\n",
        "# df %>% ggplot(aes(x=t, y=diff)) + \n",
        "#     geom_bar(stat=\"identity\") +\n",
        "#     labs(x='scaled time', y='probability') + \n",
        "#     despine "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c694718-7478-49b6-b342-da81fd79cf5b",
      "metadata": {},
      "source": [
        "\n",
        "The marginal expectations does not match the SFS proportions, because paths that accumulate more than `max_tons` singletons will end in the trash state and not have the opportunity to also accumulate doubletons etc. That reflects that the the joint prob of a singleton *and* a doubleton is be a subset of the singleton probability. That way the total marginal singleton prob will be roughly sfs expectation, but the total marginal doubleton prob will be much too small:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "sfs = c(1, 1/2, 1/3)\n",
        "sfs / sum(sfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "df[df.X1==1 & df.X2==0 & df.X3==1, ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "c(sum(joint_probs.V1 * joint_probs.accum_time), \n",
        "  sum(joint_probs.V2 * joint_probs.accum_time), \n",
        "  sum(joint_probs.V3 * joint_probs.accum_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "c(sum(df.X1 * df.prob), sum(df.X2 * df.prob), sum(df.X3 * df.prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "plot_df = df %>% group_by(X2, X3) %>% summarise(prob = sum(prob))\n",
        "plot_df[,-ncol(plot_df)] = lapply(plot_df[,-ncol(plot_df)], as.factor)\n",
        "head(plot_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ggplot(plot_df, aes(x=X2, y=X3)) +\n",
        "#     geom_tile(aes(fill = prob)) + \n",
        "#     geom_text(aes(label = round(prob, 3))) +\n",
        "#     scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "#                     limit=max(abs(plot_df$prob)) * c(-1, 1)\n",
        "#                     ) +\n",
        "#     theme_minimal() +\n",
        "#      theme(panel.grid.major = element_blank(), \n",
        "#             panel.grid.minor = element_blank(), \n",
        "#             text=element_text(size=17))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# ggplot(plot_df, aes(x=X2, y=X3)) +\n",
        "#     geom_tile(aes(fill = log10(prob))) + \n",
        "#     geom_text(aes(label = round(log10(prob), 2))) +\n",
        "#     scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "#                     limit=max(abs(log10(plot_df$prob))) * c(-1, 1)\n",
        "#                     ) +\n",
        "# theme_minimal() +\n",
        "#  theme(panel.grid.major = element_blank(), \n",
        "#         panel.grid.minor = element_blank(), \n",
        "#         text=element_text(size=17))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "# plot_graph = function(gam, constrained=True, \n",
        "#                        subgraphs=False, ranksep=2, nodesep=1,\n",
        "#                        subgraphfun=function(state, index) paste(state[-len(state)], collapse=\"\"), \n",
        "#                        size=np.array([6, 6], dtype=int), fontsize=10, rankdir=\"LR\", align=False, nodecolor='white', rainbow=False, penwidth=1) {\n",
        "\n",
        "\n",
        "#     def format_rate(rate):\n",
        "#         # tol = .Machine.double.eps^0.5\n",
        "#         # if min(abs(c(rate%%1, rate%%1-1))) < tol:\n",
        "#         if rate == round(rate):\n",
        "#             return rate\n",
        "#         else:\n",
        "#             return formatC(rate, format = \"e\", digits = 2)\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     def random_color():\n",
        "#         if rainbow:\n",
        "#             return paste(\"#\", paste0(sample(c(0:9, LETTERS[1:6], 6, T), collapse = ''), sep=''))\n",
        "#         else:\n",
        "#             return '#000000'\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     sub_graphs = list()\n",
        "#     state_classes = list()\n",
        "    \n",
        "#     if constrained:\n",
        "#         constrained = 'true'\n",
        "#     else:\n",
        "#         constrained = 'false'\n",
        "#     }\n",
        "\n",
        "#     states = c()\n",
        "#     for (i in 1:(nrow(gam.states))) {\n",
        "#         states = c(states, paste0(i, ' [label=\"', paste(gam.states[i,], collapse = \",\"), '\"];'))\n",
        "#     }\n",
        "    \n",
        "#     edge_templ = '\"FROM\" -> \"TO\" [constraint=true, label=\"LABEL\",labelfloat=false,color=\"COLOR\",fontcolor=\"COLOR\"];'\n",
        "\n",
        "#     subgraph_template = '\n",
        "#     subgraph cluster_FREQBIN {\n",
        "#         rank=same;\n",
        "#         style=filled;\n",
        "#         color=whitesmoke;\n",
        "#         node [style=filled];\n",
        "#         NODES;\n",
        "#         label = \"FREQBIN\";\n",
        "#     }\n",
        "#     '\n",
        "#     start_name = 'IPV'\n",
        "#     absorbing_name = 'Absorb'\n",
        "#     edges = c()\n",
        "#     # IPV edges\n",
        "#     for (i in 1:len(gam.IPV)) {\n",
        "#         if gam.IPV[i] > 0:\n",
        "#             edge = edge_templ\n",
        "#             edge = sub('FROM', start_name, edge)\n",
        "#             edge = sub('TO', i, edge)\n",
        "#             edge = sub('LABEL', gam.IPV[i], edge)\n",
        "#             edge = gsub('COLOR', random_color(), edge)                        \n",
        "#             edges = c(edges, edge)\n",
        "#         }\n",
        "#     }    \n",
        "#     # Matrix edges\n",
        "#     for (i in 1:(nrow(gam.states))) {\n",
        "#         for (j in 1:nrow(gam.states)) {\n",
        "#             if (i != j) and (gam.SIM[i, j] > 0):\n",
        "#                 edge = edge_templ\n",
        "#                 edge = sub('FROM', i, edge)\n",
        "#                 edge = sub('TO', j, edge)\n",
        "#                 edge = sub('LABEL', format_rate(gam.SIM[i, j]), edge)\n",
        "#                 edge = gsub('COLOR', random_color(), edge)\n",
        "#                 edges = c(edges, edge)\n",
        "#             }\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     absorb_rates = -rowSums(gam.SIM)\n",
        "#     for (i in 1:nrow(gam.states)) {\n",
        "\n",
        "#         # TODO: Avoid the hack below by changing the function to use the graph instead of the matrix\n",
        "#         if absorb_rates[i] > abs(1e-14):\n",
        "#         # if absorb_rates[i] > 0:\n",
        "#             edge = edge_templ\n",
        "#             edge = sub('FROM', i, edge)\n",
        "#             edge = sub('TO', absorbing_name, edge)\n",
        "#             edge = sub('LABEL', absorb_rates[i], edge)\n",
        "#             edge = gsub('COLOR', random_color(), edge)            \n",
        "#             edges = c(edges, edge)\n",
        "#         }\n",
        "#     }\n",
        "\n",
        "#     graph_spec = paste(c(states, edges), collapse = '\\n')\n",
        "\n",
        "#     rank_same = ''\n",
        "\n",
        "#     if subgraphs:        \n",
        "#         for (i in 1:(nrow(gam.states))) {\n",
        "#             sg = subgraphfun(gam.states[i,], index=i)\n",
        "#             sub_graphs[[sg]] = c(sub_graphs[[sg]], i)\n",
        "#         }\n",
        "#         for (sg in labels(sub_graphs)) {\n",
        "            \n",
        "#             nodes = sub_graphs[[sg]]\n",
        "#             tmpl = subgraph_template\n",
        "#             node_str = ''\n",
        "#             for (i in 1:len(nodes)) {\n",
        "#                 node_str = paste(node_str, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n",
        "#             }\n",
        "#             tmpl = sub('NODES', node_str, tmpl)\n",
        "#             tmpl = sub('FREQBIN', sg, tmpl)            \n",
        "#             tmpl = sub('FREQBIN', sg, tmpl)            \n",
        "#             graph_spec = paste(graph_spec, tmpl)\n",
        "#         }\n",
        "\n",
        "\n",
        "#         if align:\n",
        "#             for (i in 1:(nrow(gam.states))) {\n",
        "#                 sc = paste(head(gam.states[i,], -1), collapse = \",\")\n",
        "#                 state_classes[[sc]] = c(state_classes[[sc]], i)\n",
        "#             }\n",
        "#             for (sc in labels(state_classes)) {\n",
        "#                 rank_same = paste(rank_same, '{rank=same; ', sep='')\n",
        "#                 nodes = state_classes[[sc]]\n",
        "#                 for (i in 1:len(nodes)) {\n",
        "#                     rank_same = paste(rank_same, paste('\"', nodes[i], '\" ', sep=''), sep=' ')\n",
        "#                 }            \n",
        "#                 rank_same = paste(rank_same, ' }', sep='\\n')\n",
        "#             }\n",
        "#         }\n",
        "    \n",
        "#     }\n",
        "\n",
        "#     style_str = '\n",
        "#         graph [compound=true newrank=true pad=\"0.5\", ranksep=\"RANKSEP\", nodesep=\"NODESEP\"] \n",
        "#         rankdir=RANKDIR;\n",
        "#         size=\"SIZEX,SIZEY\";\n",
        "#         fontname=\"Helvetica,Arial,sans-serif\"\n",
        "#     \tnode [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, style=filled, fillcolor=\"NODECOLOR\"]\n",
        "#     \tedge [fontname=\"Helvetica,Arial,sans-serif\", fontsize=FONTSIZE, penwidth=PENWIDTH]\n",
        "#         Absorb [style=filled,color=\"lightgrey\"]\n",
        "#         IPV [style=filled,color=\"lightgrey\"]\n",
        "#         RANKSAME\n",
        "#     '\n",
        "#     style_str = sub('SIZEX', size[1], style_str)\n",
        "#     style_str = sub('SIZEY', size[2], style_str)\n",
        "#     style_str = gsub('FONTSIZE', fontsize, style_str)    \n",
        "#     style_str = gsub('RANKDIR', rankdir, style_str)    \n",
        "#     style_str = gsub('RANKSAME', rank_same, style_str)\n",
        "#     style_str = gsub('RANKSEP', ranksep, style_str)\n",
        "#     style_str = gsub('NODESEP', nodesep, style_str)\n",
        "#     graph_string = paste('digraph G {', style_str, graph_spec, '}', sep='\\n')\n",
        "#     graph_string = gsub('NODECOLOR', nodecolor, graph_string)  \n",
        "#     graph_string = gsub('PENWIDTH', penwidth, graph_string)  \n",
        "#     system(\"dot -Tsvg -o tmp.svg\", input=graph_string, intern=True)\n",
        "#     return display_svg(file=\"tmp.svg\")\n",
        "# }\n",
        "                  \n",
        "sample_size = 3\n",
        "mutation_rate = 1\n",
        "max_tons = 1\n",
        "total_tons = Inf\n",
        "base = max_tons + 1\n",
        "graph = joint_prob_coalescent(sample_size, mutation_rate, max_tons, total_tons=total_tons)\n",
        "\n",
        "plot_graph(graph_as_matrix(graph), rainbow=True, size=np.array([10, 8], dtype=int), align=True,\n",
        "           fontsize=16, ranksep=1, nodesep=0.25,\n",
        "           subgraphs=True,\n",
        "           # rankdir=\"TB\",\n",
        "           subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        "           # subgraphfun=function(state, index) paste(state[-len(state)], collapse=\"\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.4.1"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "state": {},
        "version_major": 2,
        "version_minor": 0
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
