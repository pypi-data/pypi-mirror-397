{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "062c05f1-d020-464b-9aac-a063140cb125",
      "metadata": {},
      "source": [
        "---\n",
        "title: Joint probability and FMC embedding\n",
        "--- "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Always import phasic first to set jax backend correctly\n",
        "import phasic\n",
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
        "set_matplotlib_formats('retina', 'png')\n",
        "import matplotlib\n",
        "matplotlib.rcParams['figure.figsize'] = (5, 3.7)\n",
        "sns.set_context('paper', font_scale=0.9)\n",
        "phasic.set_theme('dark')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1900373",
      "metadata": {},
      "source": [
        "## Example model: Coalescent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def coalescent(state, nr_samples=None):\n",
        "    if not state.size:\n",
        "        ipv = [([nr_samples]+[0]*nr_samples, 1)]\n",
        "        return ipv\n",
        "    else:\n",
        "        transitions = []\n",
        "        for i in range(nr_samples):\n",
        "            for j in range(i, nr_samples):            \n",
        "                same = int(i == j)\n",
        "                if same and state[i] < 2:\n",
        "                    continue\n",
        "                if not same and (state[i] < 1 or state[j] < 1):\n",
        "                    continue \n",
        "                new = state.copy()\n",
        "                new[i] -= 1\n",
        "                new[j] -= 1\n",
        "                new[i+j+1] += 1\n",
        "                transitions.append((new, state[i]*(state[j]-same)/(1+same)))\n",
        "        return transitions\n",
        "\n",
        "graph = Graph(callback=coalescent, nr_samples=4)\n",
        "\n",
        "graph.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.expectation()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards = graph.states().T\n",
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sfs = np.apply_along_axis(graph.expectation, 1, rewards)\n",
        "sns.barplot(sfs) ;"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cdc25d9-56af-4656-ac11-ff3b909362aa",
      "metadata": {},
      "source": [
        "## Make discrete\n",
        "\n",
        "Turn state space for a continuous PTD into one for a discrete."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def make_discrete(graph, mutation_rate, skip_states=[], skip_slots=[]):\n",
        "    \"\"\"\n",
        "    Takes a graph for a continuous distribution and turns\n",
        "    it into a descrete one (inplace). Returns a matrix of\n",
        "    rewards for computing marginal moments\n",
        "    \"\"\"\n",
        "\n",
        "    mutation_graph = graph.copy()\n",
        "\n",
        "    # save current nr of states in graph\n",
        "    vlength = mutation_graph.vertices_length()\n",
        "\n",
        "    # number of fields in state vector (assumes all are the same length)\n",
        "    state_vector_length = len(mutation_graph.vertex_at(1).state())\n",
        "\n",
        "    # list state vector fields to reward at each auxiliary node\n",
        "    # rewarded_state_vector_indexes = [[] for _ in range(state_vector_length)]\n",
        "    rewarded_state_vector_indexes = defaultdict(list)\n",
        "\n",
        "    # loop all but starting node\n",
        "    for i in range(1, vlength):\n",
        "        if i in skip_states:\n",
        "            continue\n",
        "        vertex = mutation_graph.vertex_at(i)\n",
        "        if vertex.rate() > 0: # not absorbing\n",
        "            for j in range(state_vector_length):\n",
        "                if j in skip_slots:\n",
        "                    continue\n",
        "                val = vertex.state()[j]\n",
        "                if val > 0: # only ones we may reward\n",
        "                    # add auxilliary node\n",
        "                    mutation_vertex = mutation_graph.create_vertex(np.repeat(0, state_vector_length))\n",
        "                    mutation_vertex.add_edge(vertex, 1)\n",
        "                    vertex.add_edge(mutation_vertex, mutation_rate*val)\n",
        "                    # print(mutation_vertex.index(), rewarded_state_vector_indexes[j], j)\n",
        "                    # rewarded_state_vector_indexes[mutation_vertex.index()] = rewarded_state_vector_indexes[j] + [j]\n",
        "                    rewarded_state_vector_indexes[mutation_vertex.index()].append(j)\n",
        "\n",
        "    # print(rewarded_state_vector_indexes)\n",
        "\n",
        "    # normalize graph\n",
        "    weights_were_multiplied_with = mutation_graph.normalize()\n",
        "\n",
        "    # build reward matrix\n",
        "    rewards = np.zeros((mutation_graph.vertices_length(), state_vector_length))\n",
        "    for state in rewarded_state_vector_indexes:\n",
        "        for i in rewarded_state_vector_indexes[state]:\n",
        "            rewards[state, i] = 1\n",
        "\n",
        "    rewards = np.transpose(rewards)\n",
        "    return mutation_graph, rewards\n",
        "\n",
        "\n",
        "\n",
        "graph = Graph(callback=coalescent, nr_samples=3)\n",
        "\n",
        "# self-transition rate:\n",
        "# mutation_rate = 1e-8\n",
        "mutation_rate = 0.1\n",
        "\n",
        "# # clone graph to get one to modify:\n",
        "# mutation_graph = graph.copy()\n",
        "\n",
        "# add auxilliary states, normalize and return reward matrix:\n",
        "mutation_graph, rewards = make_discrete(graph, mutation_rate)\n",
        "\n",
        "# print(mutation_graph.expectation())\n",
        "# print([mutation_graph.expectation(r) for r in rewards])\n",
        "\n",
        "# print(rewards)\n",
        "mutation_graph.plot()\n",
        "\n",
        "\n",
        "# from functools import wraps\n",
        "\n",
        "# def discrete(mutation_rate, skip_states=[], skip_slots=[]):\n",
        "#     def decorator(graph_constructor):\n",
        "#         @wraps(graph_constructor)\n",
        "#         def wrapper(*args, **kwargs):\n",
        "#             graph = graph_constructor(*args, **kwargs)\n",
        "#             rewards = make_discrete(graph, mutation_rate)\n",
        "#             return rewards\n",
        "#         return wrapper\n",
        "#     return decorator\n",
        "    \n",
        "# @discrete(mutation_rate=1)\n",
        "# def foo():    \n",
        "#     return coalescent(4)\n",
        "\n",
        "\n",
        "# rewards = foo()\n",
        "# rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discrete_graph, discrete_rewards= graph.discretize(reward_rate=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mutation_graph.states()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04ff0b20",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.expectation() * 0.1\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.expectation(np.sum(mutation_graph.states(), axis=0) * 0.1), \n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sfs = np.apply_along_axis(mutation_graph.expectation_discrete, 1, rewards)\n",
        "sns.barplot(sfs) ;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.barplot(mutation_graph.pdf(np.arange(10)))\n",
        "sns.despine()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64c4fbb6",
      "metadata": {},
      "source": [
        "## Discrete joint prob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def discrete_joint_prob(graph, reward_rates, precision=1e-15, return_fun=False, return_graph=False):\n",
        "\n",
        "    starting_vertex = graph.starting_vertex()\n",
        "    reward_dims = len(reward_rates(starting_vertex.state())) - 1 # a bit of a hack. -1 to not count trash rate...\n",
        "\n",
        "    orig_state_vector_length = len(graph.vertex_at(1).state())\n",
        "    state_vector_length = orig_state_vector_length + reward_dims\n",
        "\n",
        "    state_indices = np.arange(orig_state_vector_length)\n",
        "    reward_indices = np.arange(orig_state_vector_length, state_vector_length)\n",
        "\n",
        "    new_graph = Graph(state_vector_length)\n",
        "    # new_starting_vertex = new_graph.vertex_at(1)\n",
        "    new_starting_vertex = new_graph.starting_vertex()\n",
        "\n",
        "    null_rewards = np.zeros(reward_dims)\n",
        "\n",
        "    index = 0\n",
        "    # add edges from starting vertex (IPV)\n",
        "    for edge in starting_vertex.edges():\n",
        "        new_starting_vertex.add_edge(\n",
        "          new_graph.find_or_create_vertex(np.append(edge.to().state(), null_rewards).astype(int)), 1)\n",
        "\n",
        "    index = index + 1\n",
        "    \n",
        "    trash_rates = {}\n",
        "    t_vertex_indices = np.array([], dtype=int)\n",
        "    while index < new_graph.vertices_length():\n",
        "\n",
        "        new_vertex = new_graph.vertex_at(index)\n",
        "        new_state = new_vertex.state()\n",
        "        state = new_vertex.state()[state_indices]\n",
        "        vertex = graph.find_vertex(state)\n",
        "\n",
        "        # non-mutation transitions (coalescence)\n",
        "        for edge in vertex.edges():\n",
        "            new_child_state = np.append(edge.to().state(), new_state[reward_indices])\n",
        "\n",
        "            if np.all(new_state == new_child_state):\n",
        "                continue\n",
        "                \n",
        "            new_child_vertex = new_graph.find_or_create_vertex(new_child_state)\n",
        "            # cat(new_child_vertex$state, \"\\n\")\n",
        "            new_vertex.add_edge(new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n",
        "                edge.weight()\n",
        "            )\n",
        "\n",
        "            # if new child was absorbing, record at \"t-states\":\n",
        "            if not graph.find_vertex(new_child_state[state_indices]).edges():\n",
        "                t_vertex_indices = np.append(t_vertex_indices, new_child_vertex.index()) \n",
        "\n",
        "        # mutation transitions\n",
        "        current_state = new_state[state_indices]\n",
        "        current_rewards = new_state[reward_indices]\n",
        "        rates = reward_rates(current_state, current_rewards) # list of all allowed mutation transition rates with trash rate appended\n",
        "\n",
        "        trash_rates[index] = rates[reward_dims]\n",
        "        for i in range(reward_dims):\n",
        "            rate = rates[i]\n",
        "            if rate > 0:\n",
        "                new_rewards = current_rewards\n",
        "                new_rewards[i] = new_rewards[i] + 1\n",
        "                new_child_vertex = new_graph.find_or_create_vertex(np.append(current_state, new_rewards))\n",
        "                # stopifnot(sum(new_child_vertex$state) > 4)\n",
        "                # cat(new_child_vertex$state, \"\\n\")\n",
        "                new_vertex.add_edge(\n",
        "                    new_child_vertex, # if I use create_vertex here, I cannot find it again with find_vertex...\n",
        "                    rate\n",
        "                    )\n",
        "                \n",
        "                # # if new child was absorbing, record at \"t-states\":                \n",
        "                # if (length(edges(find_vertex(graph, new_child_state[state_indices]))) == 0) {\n",
        "                #     t_vertex_indices = c(t_vertex_indices, new_child_vertex$index) \n",
        "\n",
        "        index = index + 1 \n",
        "\n",
        "        if not index % 10_000:\n",
        "            graph_size = new_graph.vertices_length()\n",
        "            print(f'index: {index:>6}      vertices: {graph_size:>6}      ratio: {graph_size/index:>4.2}', file=sys.stderr)\n",
        "            sys.stderr.flush()\n",
        "\n",
        "    # trash states\n",
        "    trash_vertex = new_graph.find_or_create_vertex(np.repeat(0, state_vector_length))\n",
        "    trash_loop_vertex = new_graph.create_vertex(np.repeat(0, state_vector_length))\n",
        "    trash_vertex.add_edge(trash_loop_vertex, 1)\n",
        "    trash_loop_vertex.add_edge(trash_vertex, 1)\n",
        "\n",
        "    # add trash edges\n",
        "    for i, rate in trash_rates.items():\n",
        "        new_graph.vertex_at(i).add_edge(trash_vertex, rate) \n",
        "\n",
        "    # add edges from t-states to new final absorbing\n",
        "    new_absorbing = new_graph.create_vertex(np.repeat(0, state_vector_length))\n",
        "\n",
        "    t_vertex_indices = np.unique(t_vertex_indices)\n",
        "    \n",
        "    for i in t_vertex_indices:\n",
        "        new_graph.vertex_at(i).add_edge(new_absorbing, 1)\n",
        "\n",
        "    # normalize graph                            \n",
        "    weights_were_multiplied_with = new_graph.normalize()\n",
        "\n",
        "    if return_graph:                           \n",
        "        return(new_graph)                                             \n",
        "\n",
        "    # time spent in each of the the t-states at time stop or after some appropriately large time (these are the joint probs)\n",
        "\n",
        "    prev = None\n",
        "    for decade in range(1000):\n",
        "        accum_time_all = new_graph.accumulated_visiting_time(decade*10)\n",
        "        accum_time = np.array(accum_time_all)[t_vertex_indices]\n",
        "        if prev is not None and np.all(np.abs(accum_time - prev) < precision):\n",
        "            break\n",
        "        prev = accum_time\n",
        "\n",
        "    assert decade < 100\n",
        "\n",
        "    class Fun():\n",
        "\n",
        "        def __init__(self, new_graph, t_vertex_indices):\n",
        "            self.new_graph = new_graph\n",
        "            self.t_vertex_indices = t_vertex_indices\n",
        "\n",
        "        def __call__(self, tup):\n",
        "\n",
        "        # def __call__(self, stop):\n",
        "        #     accum_time_all = self.new_graph.accumulated_visiting_time(stop)\n",
        "        #     accum_time = np.array(accum_time_all)[self.t_vertex_indices]\n",
        "\n",
        "        #     states = new_graph.states()\n",
        "        #     state_reward_matrix = states[self.t_vertex_indices, :][:, reward_indices]\n",
        "        #     joint_probs = pd.DataFrame(state_reward_matrix)\n",
        "        #     index_cols = joint_probs.columns.values.tolist()\n",
        "        #     joint_probs['time'] = stop\n",
        "        #     joint_probs['prob'] = accum_time\n",
        "        #     joint_probs.set_index(index_cols, inplace=True)\n",
        "\n",
        "            return joint_probs \n",
        "\n",
        "    fun = Fun(new_graph, t_vertex_indices)\n",
        "\n",
        "    if return_fun:\n",
        "        return fun\n",
        "\n",
        "    return fun(decade*10).drop(columns='time')\n",
        "\n",
        "    # I can test if the graph is acyclic and if so, use accumulated_residence_time instead?\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph = Graph(callback=coalescent, nr_samples=4)\n",
        "graph.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.variance()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gam = graph.as_matrices()\n",
        "# gam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.pdf(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.plot(\n",
        "            nodesep=0.5,\n",
        "             subgraphfun=lambda state: 'has singletons' if np.all(state[0] > 0) else 'no singletons',\n",
        "               )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10, tot_reward_limit=np.inf):\n",
        "\n",
        "    reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n",
        "    \n",
        "    reward_dims = len(reward_limits)\n",
        "    if current_rewards is None:\n",
        "        current_rewards = np.zeros(reward_dims)\n",
        "\n",
        "    reward_rates = np.zeros(reward_dims)\n",
        "    trash_rate = 0\n",
        "    \n",
        "    for i in range(reward_dims):\n",
        "        rate = state[i] * mutation_rate \n",
        "        r = np.zeros(reward_dims)\n",
        "        r[i] = 1\n",
        "        if np.all(current_rewards + r <= reward_limits) and np.sum(current_rewards + r) <= tot_reward_limit:\n",
        "            reward_rates[i] = rate\n",
        "        else:\n",
        "            trash_rate = trash_rate + rate\n",
        "\n",
        "    return np.append(reward_rates, trash_rate)\n",
        "\n",
        "joint_probs = discrete_joint_prob(graph, reward_callback)\n",
        "\n",
        "joint_probs    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10, tot_reward_limit=np.inf):\n",
        "\n",
        "    reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n",
        "    \n",
        "    reward_dims = len(reward_limits)\n",
        "    if current_rewards is None:\n",
        "        current_rewards = np.zeros(reward_dims)\n",
        "\n",
        "    reward_rates = np.zeros(reward_dims)\n",
        "    trash_rate = 0\n",
        "    \n",
        "    for i in range(reward_dims):\n",
        "        rate = state[i] * mutation_rate \n",
        "        r = np.zeros(reward_dims)\n",
        "        r[i] = 1\n",
        "        if np.all(current_rewards + r <= reward_limits) and np.sum(current_rewards + r) <= tot_reward_limit:\n",
        "            reward_rates[i] = rate\n",
        "        else:\n",
        "            trash_rate = trash_rate + rate\n",
        "\n",
        "    return np.append(reward_rates, trash_rate)\n",
        "\n",
        "\n",
        "def joint_pmf(graph, rate_fun, reward_limit=10):\n",
        "    \"\"\"\n",
        "    Returns a joint probability mass function for the graph\n",
        "    \"\"\"\n",
        "\n",
        "    def reward_callback(state, current_rewards=None, mutation_rate=1, reward_limit=10):\n",
        "\n",
        "        reward_limits = np.append(np.repeat(reward_limit, len(state)-1), 0)\n",
        "        \n",
        "        reward_dims = len(reward_limits)\n",
        "        if current_rewards is None:\n",
        "            current_rewards = np.zeros(reward_dims)\n",
        "\n",
        "        reward_rates = np.zeros(reward_dims)\n",
        "        trash_rate = 0\n",
        "        \n",
        "        for i in range(reward_dims):\n",
        "            rate = rate_fun(state[i])\n",
        "            r = np.zeros(reward_dims)\n",
        "            r[i] = 1\n",
        "            if np.all(current_rewards + r <= reward_limits):\n",
        "                reward_rates[i] = rate\n",
        "            else:\n",
        "                trash_rate = trash_rate + rate\n",
        "\n",
        "        return np.append(reward_rates, trash_rate)\n",
        "\n",
        "    return discrete_joint_prob(graph, reward_callback, return_fun=True)\n",
        "\n",
        "\n",
        "\n",
        "fun = joint_pmf(graph, lambda x: x*1, reward_limit=10)\n",
        "fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_probs.at[(0, 1, 0, 0, 0), 'prob']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def joint_pmf(graph, reward_callback):\n",
        "    df = \n",
        "    df.loc[(0, 1, 0, 0)]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "outcomes = np.matrix(list(map(list, joint_probs.index.values)))\n",
        "probs = joint_probs['prob'].values\n",
        "with_deficit = probs @ outcomes\n",
        "with_deficit = with_deficit[:,:nr_samples-1]\n",
        "no_deficit = np.matrix([2/x for x in range(1, 4)])\n",
        "deficit = (no_deficit - with_deficit) / no_deficit\n",
        "deficit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_prob_at_time = discrete_joint_prob(graph, reward_rates, return_fun=True)\n",
        "joint_prob_at_time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.concat([joint_prob_at_time(t) for t in np.arange(1, 10, 1)])\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.pivot(columns='time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_graph = discrete_joint_prob(graph, reward_rates, return_graph=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "new_graph.plot(size=(8, 8), ranksep=0.6, nodesep=0.3, rainbow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "new_graph.plot(size=(8, 8), ranksep=3, nodesep=0.3, rainbow=True,\n",
        "    subgraphfun=lambda state: ','.join(map(str, state[:nr_samples])),\n",
        "    splines='line',\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a82e62c",
      "metadata": {},
      "source": [
        "## Finite Markov Chains (FMC)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d33c368e",
      "metadata": {},
      "source": [
        "### Distribution of steps spent in a state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loop():\n",
        "\n",
        "    def callback(state):\n",
        "        if not state.size:\n",
        "            return [([1, 0], 0.5), ([0, 1], 0.5)]\n",
        "\n",
        "        transitions = []\n",
        "\n",
        "        if state.sum() > 1:\n",
        "            return transitions\n",
        "\n",
        "        if state[0] == 0:\n",
        "            new_state = state.copy()\n",
        "            new_state[0] += 1\n",
        "            new_state[1] -= 1            \n",
        "            transitions.append((new_state, 1))\n",
        "        else:\n",
        "            new_state = state.copy()\n",
        "            new_state[0] -= 1\n",
        "            new_state[1] += 1\n",
        "            transitions.append((new_state, 1))\n",
        "\n",
        "        new_state = state.copy()\n",
        "        new_state[0] = 9\n",
        "        new_state[1] = 9\n",
        "        transitions.append((new_state, 1))\n",
        "\n",
        "        return transitions\n",
        "\n",
        "    graph = Graph(callback=callback)\n",
        "    return graph\n",
        "        \n",
        "graph = loop()\n",
        "graph.plot(rainbow=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def loop_reward_rates(new_state, current_rewards=None, mutation_rate=None, reward_limit=10, tot_reward_limit=5):\n",
        "\n",
        "    target_state = np.array([0, 1])\n",
        "\n",
        "    reward_limits = np.append(np.repeat(reward_limit, len(new_state)-1), 0)\n",
        "    \n",
        "    reward_dims = len(reward_limits)\n",
        "    if current_rewards is None:\n",
        "        current_rewards = np.zeros(reward_dims)\n",
        "\n",
        "    result = np.zeros(reward_dims)\n",
        "    trash_rate = 0\n",
        "    \n",
        "    for i in range(reward_dims):\n",
        "        rate = new_state[i] * mutation_rate \n",
        "        r = np.zeros(reward_dims)\n",
        "        r[i] = 1\n",
        "        \n",
        "        if np.all(new_state == target_state) and np.sum(current_rewards + r) <= tot_reward_limit:\n",
        "        # if np.all(current_rewards + r <= reward_limits) and np.sum(current_rewards + r) <= tot_reward_limit:\n",
        "            result[i] = rate\n",
        "        else:\n",
        "            trash_rate = trash_rate + rate\n",
        "\n",
        "    return np.append(result, trash_rate)\n",
        "\n",
        "\n",
        "# reward_rates = partial(coalescent_reward_rates, mutation_rate=1, reward_limit=1, tot_reward_limit=2)\n",
        "reward_rates = partial(loop_reward_rates, mutation_rate=1, reward_limit=2)\n",
        "\n",
        "joint_probs = discrete_joint_prob(graph, reward_rates)\n",
        "\n",
        "joint_probs#.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discrete_joint_prob(graph, reward_rates, return_graph=True).plot(size=(8, 8), ranksep=1, nodesep=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "23670f53",
      "metadata": {},
      "source": [
        "### Nr of runs of a particular state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = 5\n",
        "graph = coalescent(sample_size)\n",
        "graph.plot(rainbow=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "new_graph = graph.copy()\n",
        "\n",
        "target_vertex = new_graph.vertex_at(5)\n",
        "\n",
        "new_vertices = []\n",
        "for vertex in new_graph.vertices():\n",
        "    for edge in vertex.edges():\n",
        "        if edge.to() == target_vertex:\n",
        "            # create new vertex\n",
        "            new_vertex = new_graph.find_or_create_vertex(np.repeat(-vertex.index(), vertex.state().size))\n",
        "\n",
        "            # make edge point that instead\n",
        "            edge.update_to(new_vertex)\n",
        "\n",
        "            # add edge from new_vertex to target_vertex with weight 1\n",
        "            new_vertex.add_edge(target_vertex, 1)\n",
        "\n",
        "            # keep index of added vertex\n",
        "            new_vertices.append(new_vertex.index())\n",
        "\n",
        "# rewards = make_discrete(new_graph, mutation_rate, skip=new_vertices)\n",
        "rewards = make_discrete(new_graph, 1, skip_states=new_vertices)\n",
        "\n",
        "print(rewards)\n",
        "\n",
        "rev = np.zeros(new_graph.vertices_length())\n",
        "for i in new_vertices:\n",
        "    rev[i] = 1\n",
        "\n",
        "print(new_graph.expectation(rev))\n",
        "# print(new_graph.accumulated_visiting_time(10))\n",
        "print(new_graph.accumulated_visits_discrete(1000))\n",
        "\n",
        "new_graph.plot(rainbow=True, size=(10, 10))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loop(state):\n",
        "    if not state.size:\n",
        "        return [([1], 1)]\n",
        "    elif state[0] < 3:\n",
        "        return [(state+1, 4)]\n",
        "    return []\n",
        "\n",
        "graph = ptd.Graph(callback=loop)\n",
        "graph.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.expectation(), graph.expected_waiting_time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "discr_graph, discr_rewards = graph.discretize(reward_rate=1)\n",
        "discr_graph.plot()\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.sum(discr_rewards, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discr_graph.expected_waiting_time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discr_graph.expectation(np.sum(discr_rewards, axis=0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.sum(discr_rewards, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discr_graph.expectation(discr_rewards)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.expectation(np.sum(discr_rewards, axis=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "discr_graph.expectation(rewards = np.sum(discr_rewards, axis=1))\n",
        "#graph.expectation(np.sum(discr_rewards, axis=1) * 0.1)\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loop():\n",
        "\n",
        "    def callback(state):\n",
        "        transitions = []\n",
        "        if state[0] == 0:\n",
        "            new_state = state[:]\n",
        "            new_state[0] += 1\n",
        "            new_state[1] -= 1\n",
        "            transitions.append((new_state, 1))\n",
        "        else:\n",
        "            new_state = state[:]\n",
        "            new_state[0] -= 1\n",
        "            new_state[1] += 1\n",
        "            transitions.append((new_state, 1))\n",
        "        return transitions\n",
        "\n",
        "    graph = ptd.Graph(callback=callback, initial=[1, 0])\n",
        "    return graph\n",
        "        \n",
        "graph = loop()\n",
        "graph.plot(rainbow=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3329d53a",
      "metadata": {},
      "source": [
        "### I could add an fmc argument that adds a slot to initial and increments that for all states returned by callback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def loop():\n",
        "\n",
        "    def callback(state):\n",
        "\n",
        "        if not state.size:\n",
        "            return [([1, 0, 0], 1)]\n",
        "\n",
        "        if state[2] == 5:\n",
        "            return []\n",
        "\n",
        "        if state[0] == 0:\n",
        "            new_state = state[:]\n",
        "            new_state[0] += 1\n",
        "            new_state[1] -= 1\n",
        "            new_state[2] += 1\n",
        "            return [(new_state, 1)]\n",
        "        else:\n",
        "            new_state = state[:]\n",
        "            new_state[0] -= 1\n",
        "            new_state[1] += 1\n",
        "            new_state[2] += 1\n",
        "            return [(new_state, 1)]\n",
        "\n",
        "    graph = ptd.Graph(callback=callback)\n",
        "    return graph\n",
        "        \n",
        "graph = loop()\n",
        "graph.plot(rainbow=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rewards = make_discrete(graph, 1, skip_slots=[graph.state_length()-1])\n",
        "graph.plot(rainbow=True)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.accumulated_visits_discrete(1000)\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2311657",
      "metadata": {},
      "source": [
        "### Length of longest run of a state in an FMC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# D: A->A\n",
        "# A: A->B\n",
        "# B: B->A\n",
        "# D: B->B\n",
        "\n",
        "def maxlen():\n",
        "\n",
        "    def callback(state):\n",
        "\n",
        "        A, B, C, D = 1, 1, 1, 1\n",
        "\n",
        "        if not state.size:\n",
        "            return [([1, 0, 0], 1)]\n",
        "\n",
        "        x, y, z = state\n",
        "        \n",
        "        max_y, max_z = 2, 6\n",
        "\n",
        "        absorb = (0, max_y, max_z)\n",
        "        # absorb = (0, 0, 0)\n",
        "        if np.all(state == absorb):\n",
        "            return []\n",
        "\n",
        "        trash1, trash2 = (-1, -1, -1), (-2, -2, -2)\n",
        "        # trash1, trash2 = (0, 0, 0), (0, 0, 0)\n",
        "        if np.all(state == trash1):\n",
        "            return [(trash2, 1)]\n",
        "        if np.all(state == trash2):\n",
        "            return [(trash1, 1)]\n",
        "\n",
        "        if z+1 == max_z:\n",
        "            return [(absorb, 1)]\n",
        "        \n",
        "        if y == 0:\n",
        "            return [((x, y, z+1), C/(B+C)),\n",
        "                    ((x, y+1, z+1), A/(A+D))]\n",
        "        if y == max_y:\n",
        "            return [(trash1, D/(A+D)), # trash\n",
        "                    ((y, 0, z+1), B/(B+C))]\n",
        "\n",
        "        return [((x, y+1, z+1), D/(A+D)),\n",
        "                ((y, 0, z+1), B/(B+C))]\n",
        "\n",
        "    graph = ptd.Graph(callback=callback)\n",
        "    return graph\n",
        "        \n",
        "graph = maxlen()\n",
        "graph.plot(rainbow=True, ranksep=1, nodesep=0.3, size=(10, 10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "graph.states()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_probs %>% filter(V1==1, V2==0, V3==1) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4f09039-4ea5-4def-9d87-53aeaadd55cf",
      "metadata": {},
      "source": [
        "With `sample_size <- 4`, `mutation_rate <- 1`, `reward_limits <- rep(20, sample_size-1)`, and `tot_reward_limit <- Inf`, tothe marginal probabilities match the SFS:\n",
        "\n",
        "```\n",
        "c(sum(joint_probs$V1 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V2 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V3 * joint_probs$accum_time))\n",
        "```\n",
        "\n",
        "```\n",
        "1.99981743759578 0.998152771395828 0.666638375487117\n",
        "```\n",
        "\n",
        "and the joint prob of a singleton and a trippleton is:\n",
        "\n",
        "```\n",
        "1\t0\t1\t0.03111111\n",
        "```\n",
        "\n",
        "which is exactly what we also get with `reward_limits <- rep(1, sample_size-1)`.\n",
        "\n",
        "Setting `tot_reward_limit <- 2` also produces `0.03111111`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joint_probs %>% rename_with(gsub, pattern=\"V\", replacement=\"ton\") %>% group_by(ton1, ton2) %>% summarize(prob=sum(accum_time), .groups=\"keep\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5bb87dcc-9f5f-4d4e-acac-93e1cadc501c",
      "metadata": {},
      "source": [
        "## Two-locus ARG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ggplot(plot_df, aes(x=ton0x1, y=ton1x0)) +\n",
        "    geom_tile(aes(fill = accum_time)) + \n",
        "    geom_text(aes(label = round(accum_time, 3))) +\n",
        "    scale_fill_viridis() +\n",
        "    # scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "    #                 limit=max(abs(plot_df$prob)) * c(-1, 1)\n",
        "    #                 ) +\n",
        "    theme_minimal() +\n",
        "     theme(panel.grid.major = element_blank(), \n",
        "            panel.grid.minor = element_blank(), \n",
        "            text=element_text(size=17))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59025cf2-796a-461e-bd46-b1850fa5345d",
      "metadata": {},
      "source": [
        "# Base-n approach\n",
        "\n",
        "## State space for joint proability computation\n",
        "\n",
        "Generate coalescent state space like normal with the following modifications\n",
        "\n",
        "- Change state space from (4, 0, 0, 0) to (4, 0, 0, 0, t1, t2, t3, t4). The last extra \"ton\" states keep track of the number accumulated mutations of each kind. We simply double the state vector so we keep track of the counts lineages with descendants, but also the counts of mutations happened on such lineages.\n",
        "- Each state can mutate to accumulate a \"ton\" in accordance with its state vector. E.g., a `(4, 0, 0, 0, 0, 0, 0, 0)` state can only make singletons,  a `(2, 1, 0, 0, 0, 0, 0, 0)` state can only make singletons and doubletons.\n",
        "- A mutation event is a transition to a siter state E.g., `(4, 0, 0, 0, 0, 0, 0, 0) -> (4, 0, 0, 0, 1, 0, 0, 0)`\n",
        "- The ton counts have a maximum value (base-1). If this value is reached, the mutation transition instead leads to a trash state with an infinite self loop. The transitions to trash represents the part of the deficient PDF not covered because we only run up to a max nr of tons."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e531025-71c8-4ffe-a658-a5e751c9956c",
      "metadata": {},
      "source": [
        "## Reward transform\n",
        "\n",
        "- Convert the last half of each state (with ton counts) to numbers in some base.\n",
        "- Use these for reward transformation.\n",
        "- Compute PDF for t <- 1:sample_size^(base-1)\n",
        "- Convert each time t back to the corresponding ton vector and associate it with the probability\n",
        "- group by two tons and sum probs in groups to get all pairwise combinations for a joint probability matrix."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b1f6f252-ef42-41a8-95a4-4e295e858b58",
      "metadata": {},
      "source": [
        "## Figure out why you get NAs in multi_rewards with max_tons <- 1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7cfd5180-27f1-4920-a148-662e38288df7",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, # rainbow=TRUE,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "expectation(graph)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_graph(graph_as_matrix(graph), #rainbow=TRUE, \n",
        "           size=c(10, 8), #align=TRUE,\n",
        "               fontsize=16, ranksep=1, nodesep=0.25,\n",
        "             # subgraph=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "apply(rewards[1:3,], 1, function(x) expectation(graph, x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pdph(1:10, rev_graph)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c3381999-d744-465c-b6be-b2572c5110ab",
      "metadata": {},
      "source": [
        "## Compute joint prob"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aec3aa7d-855a-4682-872a-688f18072d38",
      "metadata": {},
      "source": [
        "> **Constraining the total number of mutations does not work**\n",
        "> \n",
        "> The deficit is computed correctly as long as all max rewards so that all r scalar values in the CDF represents a reward combination in the MDF\n",
        "> \n",
        "> Just like we can limit the number of each king of tons in the state space contruction, we might also limit the total number of mutations so that we, for example, can have at most one instance of two different tons (`total_tons=2`). E.g., a singleton and a tripleton.\n",
        "> \n",
        "> However, this gives a a deficit problem I am not sure I can solve with this approach. In principle, the deficit should be taken care of, and I should just discard all joint probs for total numbers of tons larger than `total_tons` - but that does not seem to be the case..."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "04142edc-bfed-4fb8-b6ad-d70bd85ad345",
      "metadata": {},
      "source": [
        "**maybe I don't need loops if they are not selff-loops anyway. If aux->C has rate 1 then A->aux->C is the same as A->C. Below I just changed two things**\n",
        "\n",
        "1. normalize the graph\n",
        "2. use pdph instead of pph\n",
        "\n",
        "**BUT** if I normalize I need to represent the residual prob as reward, which means I need to reward transform, which I cannot if I want to do everying in one go with the scalar trick. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (vertices_length(graph) < 50)\n",
        "    plot_graph(graph_as_matrix(graph), size=c(10, 8), align=TRUE, rainbow=TRUE,\n",
        "               fontsize=16, ranksep=2, nodesep=0.5,\n",
        "             subgraphs=TRUE,         \n",
        "           subgraphfun=function(state, index) paste(state[1:sample_size], collapse=\"\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49855f7e-6066-4c38-8ae4-9ce979b0701d",
      "metadata": {},
      "source": [
        "Get last halves of states that server as mutation rewards:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "35a1299d-b226-4122-97c2-50ca95759370",
      "metadata": {},
      "source": [
        "Turn reward vectors into scalars (with the appropriate base):"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "967d8ea3-ecc9-46a9-98ec-f7789a60cc73",
      "metadata": {},
      "source": [
        "Loop over states except starting to find trash vertices and give them a reward so they won't dissapear in the reward transformation. They will not contribute this reward because they are dead ends:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "multi_rewards"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aadd23ab-4f43-4f78-84bb-7e83ea91b808",
      "metadata": {},
      "source": [
        "Reward transform graph using scalar rewards:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if (vertices_length(graph) < 50)\n",
        "    plot_graph(graph_as_matrix(rew_graph),\n",
        "           rainbow=TRUE,\n",
        "           size=c(8, 8), \n",
        "           align=TRUE,\n",
        "           fontsize=14, ranksep=1, nodesep=0.5, \n",
        "           # subgraphs=TRUE, subgraphfun=function(state, index) as.character((index+1) %/% 2)\n",
        "           )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8dd4a3b-88fb-4197-aab5-84d651419674",
      "metadata": {},
      "source": [
        "Compute CDF assming no mutation count exceeds `max_tons`:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06996680-f800-4b0e-a59d-4a3451b7e5d4",
      "metadata": {},
      "source": [
        "Convert reward scalars back into state vectors representing ton counts:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e6db536-1fdf-489a-b34d-d42b459e065e",
      "metadata": {},
      "source": [
        "The deficit is taken care of, so you should discard all joint probs for total numbers of tons larger than `total_tons`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=cdf)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine + ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6abffbee-02a9-4119-ae39-7fc059609100",
      "metadata": {},
      "source": [
        "Compute probability of standing in on of the trash states for each time t in our CDF. These represent the deficit of the computed CDF:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ea43497d-429a-41a8-a3f7-eba09fbab7ef",
      "metadata": {},
      "source": [
        "> Make sure the stop_probability is the discrete version of that is what we are doing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f01b411-ceb7-4879-9a88-b82d5179504d",
      "metadata": {},
      "source": [
        "CDF deficit:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=cdf_deficit)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine + ylim(0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe6364c4-9f95-4b62-90ec-bfbd288c2a82",
      "metadata": {},
      "source": [
        "Sanity check: adding CDF and deficit should produce a CDF that goes to 1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=cdf_incl_deficit)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine + \n",
        "    ylim(0, 1) + \n",
        "    geom_hline(yintercept=1, linetype=\"dashed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90f9d697-f685-4952-8bec-50b9f6609095",
      "metadata": {},
      "source": [
        "I.e., and a PDF that sum to one:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=pdf_from_cdf_incl_deficit)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sum(df$pdf_from_cdf_incl_deficit)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e85cf02-54de-4d02-a4d5-a5f8f56e6138",
      "metadata": {},
      "source": [
        "It **almost** does... Maybe a numerical issue"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e689faea-c08a-4250-bc57-f1c18a44c666",
      "metadata": {},
      "source": [
        "Compute PDF from the CDF (**this is the one we are after**):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=pdf_from_cdf)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c00f68d-df0d-4d8a-a0a0-9f5a4c794b52",
      "metadata": {},
      "source": [
        "The reason we need to go through the CDF to get the PDF is that the PDF function in PtD computes the distribution of times when the absorbing state is reached. It this cannot take the deficit in trash_states into account. The PDF commputed directly looks like this:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f796db8c-a992-4952-8f50-bac73e34044a",
      "metadata": {},
      "source": [
        "> Make sure I ues the discrete version here if I also use the dicscrete CDF above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df %>% ggplot(aes(x=t, y=pdf)) + \n",
        "    geom_bar(stat=\"identity\") +\n",
        "    labs(x='scaled time', y='probability') + \n",
        "    despine "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e327b443-4880-4963-905b-feb06bd9e954",
      "metadata": {},
      "source": [
        "## When we do the discrete version, we don't need to go through the CDF to get the PDF. We can just use the `ddph` directly"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9c694718-7478-49b6-b342-da81fd79cf5b",
      "metadata": {},
      "source": [
        "\n",
        "The marginal expectations does not match the SFS proportions, because paths that accumulate more than `max_tons` singletons will end in the trash state and not have the opportunity to also accumulate doubletons etc. That reflects that the the joint prob of a singleton *and* a doubleton is be a subset of the singleton probability. That way the total marginal singleton prob will be roughly sfs expectation, but the total marginal doubleton prob will be much too small:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df$X1==1 & df$X2==0 & df$X3==1, ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c(sum(joint_probs$V1 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V2 * joint_probs$accum_time), \n",
        "  sum(joint_probs$V3 * joint_probs$accum_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "c(sum(df$X1 * df$prob), sum(df$X2 * df$prob), sum(df$X3 * df$prob))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ggplot(plot_df, aes(x=X2, y=X3)) +\n",
        "    geom_tile(aes(fill = prob)) + \n",
        "    geom_text(aes(label = round(prob, 3))) +\n",
        "    scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "                    limit=max(abs(plot_df$prob)) * c(-1, 1)\n",
        "                    ) +\n",
        "    theme_minimal() +\n",
        "     theme(panel.grid.major = element_blank(), \n",
        "            panel.grid.minor = element_blank(), \n",
        "            text=element_text(size=17))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ggplot(plot_df, aes(x=X2, y=X3)) +\n",
        "    geom_tile(aes(fill = log10(prob))) + \n",
        "    geom_text(aes(label = round(log10(prob), 2))) +\n",
        "    scale_fill_distiller(palette = 'PiYG',direction = 1,\n",
        "                    limit=max(abs(log10(plot_df$prob))) * c(-1, 1)\n",
        "                    ) +\n",
        "theme_minimal() +\n",
        " theme(panel.grid.major = element_blank(), \n",
        "        panel.grid.minor = element_blank(), \n",
        "        text=element_text(size=17))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}