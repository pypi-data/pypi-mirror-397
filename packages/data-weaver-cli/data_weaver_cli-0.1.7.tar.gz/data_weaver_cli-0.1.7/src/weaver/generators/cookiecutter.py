"""
Cookiecutter-based project generator for Weaver.

This generator uses the bundled entity-resolution cookiecutter template.
"""
from pathlib import Path
from typing import Dict, List, Any
from weaver.config import Config
import subprocess
import shutil

from cookiecutter.main import cookiecutter
from cookiecutter.exceptions import CookiecutterException
from rich.progress import Progress, SpinnerColumn, TextColumn
from rich import print as rprint

from .base import (
    BaseGenerator,
    GenerationResult
)

class CookiecutterGenerator(BaseGenerator):
    """Generator that uses the bundled entity-resolution cookiecutter template"""

    @property
    def TEMPLATE_REPO(self) -> str:
        """Get path to bundled template"""
        # Get the path to the templates directory
        templates_dir = Path(__file__).parent.parent / "templates" / "entity-resolution"
        return str(templates_dir.absolute())

    # Template mappings - all use the bundled entity-resolution template
    # with different context overrides
    TEMPLATE_MAPPINGS = {
        "advanced-search": {
            "description": "Hybrid sparse and vector search",
            "context_overrides": {
                "include_vector_search": "yes",
                "include_api_scraping": "yes",
                "include_web_scraping": "no",
                "database": "postgresql",
                "search_engine": "vector_hybrid",
                "orchestrator": "prefect",
                "api_framework": "fastapi"
            }
        },
        "knowledge-graph": {
            "description": "AI company knowledge graph",
            "context_overrides": {
                "project_type": "knowledge_graph",
                "include_vector_search": "no",
                "include_api_scraping": "yes",
                "include_web_scraping": "yes",
                "database": "neo4j",
                "search_engine": "none",
                "orchestrator": "prefect",
                "api_framework": "fastapi"
            }
        },
        "news-analyzer": {
            "description": "News aggregator with bias analysis",
            "context_overrides": {
                "include_vector_search": "yes",
                "include_web_scraping": "yes",
                "include_nlp": "yes",
                "database": "postgresql",
                "search_engine": "elasticsearch",
                "orchestrator": "prefect",
                "api_framework": "fastapi"
            }
        },
        "basic": {
            "description": "Basic entity-relationship project",
            "context_overrides": {
                "project_type": "basic",
                "include_vector_search": "no",
                "include_api_scraping": "yes",
                "include_web_scraping": "no",
                "database": "sqlite",
                "search_engine": "none",
                "orchestrator": "simple",
                "api_framework": "fastapi"
            }
        }
    }

    def __init__(self):
        super().__init__()

    def generate(self, config: Config) -> GenerationResult:
        """Generate a project using your cookiecutter template"""

        try:
            # Validate prerequisites
            prereq_errors = self._validate_prerequisites()
            if prereq_errors:
                return GenerationResult(
                    success=False,
                    error_message=f"Prerequisites not met: {', '.join(prereq_errors)}"
                )

            # Validate configuration
            config_errors = self.validate_config(config)
            if config_errors:
                return GenerationResult(
                    success=False,
                    error_message=f"Configuration errors: {', '.join(config_errors)}"
                )

            # Pre-generation hook
            if not self.pre_generate_hook(config):
                return GenerationResult(
                    success=False,
                    error_message="Pre-generation hook failed"
                )

            # Prepare cookiecutter context for your template
            extra_context = self._prepare_cookiecutter_context(config)

            # Set output directory
            project_path = Path(config.project_slug)

            # Check if a project directory already exists
            if self._check_directory_exists(project_path):
                backup_path = self._backup_existing_directory(project_path)

            # Generate a project with progress indication
            with Progress(
                    SpinnerColumn(),
                    TextColumn("[progress.description]{task.description}"),
                    console=self.console
            ) as progress:
                task = progress.add_task("ðŸ•·ï¸ Weaving project structure...", total=None)

                try:
                    # Run cookiecutter with your template
                    result_path = cookiecutter(
                        self.TEMPLATE_REPO,
                        extra_context=extra_context,
                        no_input=True,  # Use provided context without prompting
                        overwrite_if_exists=True
                    )

                    project_path = Path(result_path)
                    progress.update(task, completed=True)

                except CookiecutterException as e:
                    return GenerationResult(
                        success=False,
                        error_message=f"Cookiecutter generation failed: {str(e)}"
                    )

            # Post-process the generated project
            warnings = self._post_process_project(config, project_path)

            # Collect created files
            created_files = list(project_path.rglob("*")) if project_path.exists() else []

            # Generate next steps
            next_steps = self._generate_next_steps(config, project_path)

            # Create result
            result = GenerationResult(
                success=True,
                project_path=project_path,
                created_files=created_files,
                next_steps=next_steps,
                warnings=warnings
            )

            # Post-generation hook
            self.post_generate_hook(config, result)

            return result

        except Exception as e:
            return GenerationResult(
                success=False,
                error_message=f"Unexpected error during generation: {str(e)}"
            )

    def _prepare_cookiecutter_context(self, config: Config) -> Dict[str, Any]:
        """Prepare context dictionary for cookiecutter template"""

        # Start with base context that matches cookiecutter.json
        context = {
            "project_name": config.project_name,
            "project_slug": config.project_slug,
            "description": config.description,
            "author_name": config.author_name,
            "author_email": config.author_email,
            "github_username": config.github_username or "yourusername",
            "project_type": config.project_type or "basic",
        }

        # Storage backend
        context["database"] = config.database

        # Pipeline orchestrator
        context["orchestrator"] = config.orchestrator

        # API framework
        context["api_framework"] = config.api_framework

        # Feature flags - convert booleans to "yes"/"no"
        context["use_docker"] = "yes" if config.use_docker else "no"
        context["use_pytest"] = "yes" if config.use_pytest else "no"
        context["include_nlp"] = "yes" if config.include_nlp else "no"
        context["include_vector_search"] = "yes" if config.include_vector_search else "no"
        context["include_api_scraping"] = "yes" if config.include_api_scraping else "no"
        context["include_web_scraping"] = "yes" if config.include_web_scraping else "no"

        # Search engine
        context["search_engine"] = config.search_engine or "none"

        # Ontology generation settings
        context["include_ontology_generator"] = "yes" if config.include_ontology_generator else "no"
        context["generate_ontology"] = "yes" if config.generate_ontology else "no"
        context["llm_provider"] = config.llm_provider or "anthropic"

        # Database configuration
        context["database_type"] = config.database_type or config.database or "postgresql"
        context["database_host"] = config.database_host or "localhost"
        context["database_port"] = config.database_port or "5432"

        return context

    def validate_config(self, config: Config) -> List[str]:
        """Validate configuration for cookiecutter template"""
        errors = []

        # Basic validation
        if not config.project_name:
            errors.append("Project name is required")

        if not config.project_slug:
            errors.append("Project slug is required")

        if not config.author_name:
            errors.append("Author name is required")

        # Project type validation
        valid_project_types = ["basic", "search_engine", "knowledge_graph"]
        if config.project_type and config.project_type not in valid_project_types:
            errors.append(f"Invalid project type: {config.project_type}. Must be one of: {', '.join(valid_project_types)}")

        # Storage backend validation
        valid_backends = ["postgresql", "sqlite", "neo4j", "mongodb"]
        if config.database and config.database not in valid_backends:
            errors.append(f"Invalid storage backend: {config.database}. Must be one of: {', '.join(valid_backends)}")

        # Database type validation (for database_type field)
        valid_db_types = ["postgresql", "mysql", "sqlite"]
        if config.database_type and config.database_type not in valid_db_types:
            errors.append(f"Invalid database type: {config.database_type}. Must be one of: {', '.join(valid_db_types)}")

        # Vector search validation
        if config.include_vector_search and config.database not in ["postgresql"]:
            errors.append("Vector search currently only supported with PostgreSQL + pgvector")

        # Pipeline orchestrator validation
        valid_orchestrators = ["prefect", "dagster", "simple"]
        if config.orchestrator and config.orchestrator not in valid_orchestrators:
            errors.append(f"Invalid pipeline orchestrator: {config.orchestrator}. Must be one of: {', '.join(valid_orchestrators)}")

        # API framework validation
        valid_apis = ["fastapi", "flask", "django", "none"]
        if config.api_framework and config.api_framework not in valid_apis:
            errors.append(f"Invalid API framework: {config.api_framework}. Must be one of: {', '.join(valid_apis)}")

        # Search engine validation
        valid_search_engines = ["none", "vector_hybrid", "elasticsearch"]
        if config.search_engine and config.search_engine not in valid_search_engines:
            errors.append(f"Invalid search engine: {config.search_engine}. Must be one of: {', '.join(valid_search_engines)}")

        # LLM provider validation
        valid_llm_providers = ["anthropic", "openai"]
        if config.llm_provider and config.llm_provider not in valid_llm_providers:
            errors.append(f"Invalid LLM provider: {config.llm_provider}. Must be one of: {', '.join(valid_llm_providers)}")

        return errors

    def get_dependencies(self, config: Config) -> List[str]:
        """Get Python dependencies based on configuration"""
        deps = [
            "python-dotenv>=1.0.0",
            "pydantic>=2.0.0",
            "pydantic-settings>=2.0.0",
            "typer>=0.9.0",
            "rich>=13.0.0",
            "loguru>=0.7.0",
            "pandas>=2.0.0"
        ]

        # Data source dependencies
        if "web_scraping" in config.data_sources:
            deps.extend([
                "requests>=2.31.0",
                "beautifulsoup4>=4.12.0",
                "scrapy>=2.10.0",
                "selenium>=4.15.0"
            ])

        if "api" in config.data_sources:
            deps.extend([
                "httpx>=0.25.0",
                "aiohttp>=3.9.0"
            ])

        if "rss" in config.data_sources:
            deps.append("feedparser>=6.0.0")

        # Storage dependencies
        if config.database == "postgresql":
            deps.extend([
                "psycopg2-binary>=2.9.0",
                "sqlalchemy>=2.0.0",
                "alembic>=1.12.0"
            ])
            if config.include_vector_search:
                deps.append("pgvector>=0.2.0")

        elif config.database == "neo4j":
            deps.extend([
                "neo4j>=5.14.0",
                "py2neo>=2022.1.0"
            ])

        elif config.database == "mongodb":
            deps.extend([
                "motor>=3.3.0",
                "pymongo>=4.6.0"
            ])

        elif config.database == "sqlite":
            deps.extend([
                "sqlalchemy>=2.0.0",
                "aiosqlite>=0.19.0"
            ])

        # Search engine dependencies
        if config.search_engine == "elasticsearch":
            deps.append("elasticsearch>=8.11.0")
        elif config.search_engine == "vector_hybrid":
            deps.extend([
                "qdrant-client>=1.7.0",
            ])

        # Pipeline dependencies
        if config.orchestrator == "prefect":
            deps.append("prefect>=2.14.0")
        elif config.orchestrator == "airflow":
            deps.append("apache-airflow>=2.7.0")

        # API framework dependencies
        if config.api_framework == "fastapi":
            deps.extend([
                "fastapi>=0.104.0",
                "uvicorn[standard]>=0.24.0"
            ])
        elif config.api_framework == "flask":
            deps.extend([
                "flask>=3.0.0",
                "flask-cors>=4.0.0"
            ])
        elif config.api_framework == "django":
            deps.extend([
                "django>=4.2.0",
                "djangorestframework>=3.14.0"
            ])

        # NLP dependencies
        if config.include_nlp:
            deps.extend([
                "spacy>=3.7.0",
                "transformers>=4.35.0",
                "torch>=2.1.0",
                "scikit-learn>=1.3.0"
            ])

        # Vector search dependencies
        if config.include_vector_search:
            deps.extend([
                "sentence-transformers>=2.2.0",
                "numpy>=1.24.0",
                "faiss-cpu>=1.7.4"
            ])

        return sorted(set(deps))  # Remove duplicates and sort

    def _post_process_project(self, config: Config, project_path: Path) -> List[str]:
        """Post-process the generated project"""
        warnings = []

        try:
            # Create .env file from .env.example if it exists
            env_example = project_path / ".env.example"
            env_file = project_path / ".env"
            if env_example.exists() and not env_file.exists():
                shutil.copy(env_example, env_file)
                rprint("âœ… Created .env file from template")

            # Set up pre-commit hooks if config exists
            pre_commit_config = project_path / ".pre-commit-config.yaml"
            if pre_commit_config.exists():
                try:
                    subprocess.run(
                        ["pre-commit", "install"],
                        cwd=project_path,
                        capture_output=True,
                        check=True
                    )
                    rprint("âœ… Installed pre-commit hooks")
                except (subprocess.CalledProcessError, FileNotFoundError):
                    warnings.append("Could not install pre-commit hooks (pre-commit not installed)")

        except Exception as e:
            warnings.append(f"Post-processing error: {str(e)}")

        return warnings


    def list_available_templates(self) -> Dict[str, Dict[str, str]]:
        """List all available templates"""
        return {
            name: {
                "description": info["description"],
                "template": "entity-resolution (bundled)"
            }
            for name, info in self.TEMPLATE_MAPPINGS.items()
        }

    def _validate_prerequisites(self) -> List[str]:
        """Validate cookiecutter-specific prerequisites"""
        errors = super()._validate_prerequisites()

        # Check if cookiecutter is installed
        try:
            import cookiecutter
        except ImportError:
            errors.append("cookiecutter package is required but not installed (pip install cookiecutter)")

        return errors
