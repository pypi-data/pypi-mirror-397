"""
è‹±æ–‡èªéŸ³è¾¨è­˜æ ¡æ­£ç¯„ä¾‹

æœ¬æª”æ¡ˆå±•ç¤º EnglishEngine çš„æ‰€æœ‰æ ¸å¿ƒåŠŸèƒ½ï¼š
1. åŸºç¤ç”¨æ³• - Engine.create_corrector() å·¥å» æ–¹æ³•
2. æ¨¡ç³Šè©å…¸ç”Ÿæˆ - surface variants + representative variants
3. ç™¼éŸ³ç›¸ä¼¼èª¤è½ - å°ˆæœ‰åè©è¢«è½æˆå¸¸è¦‹è©å½™
4. ä¸Šä¸‹æ–‡é—œéµå­— - æ ¹æ“šå‰å¾Œæ–‡åˆ¤æ–·æ›¿æ› (åŒéŸ³ç•°ç¾©è©)
5. ä¸Šä¸‹æ–‡æ’é™¤ - é¿å…éŒ¯èª¤ä¿®æ­£
6. æ¬Šé‡ç³»çµ± - æ§åˆ¶æ›¿æ›å„ªå…ˆç´š
7. åŒéŸ³éæ¿¾ - ä»¥ IPA phonetic key å»é‡ï¼Œé¿å…è©å…¸è†¨è„¹
8. æ··åˆæ ¼å¼é…ç½® - list/dict æ··ç”¨
9. é•·æ–‡ç« æ ¡æ­£ - å®Œæ•´æ®µè½æ¸¬è©¦

æ³¨æ„ï¼šè‡ªèªè¨€æ¨¡çµ„é‡æ§‹å¾Œï¼Œsurface variants é è¨­é—œé–‰ã€‚
å¦‚éœ€ã€Œè‡ªå‹•ç”Ÿæˆåˆ¥åï¼ˆåˆ†è©/åˆ†éš”ç¬¦/å¤§å°å¯«/å¯é¸çš„ä»£è¡¨æ‹¼å¯«ï¼‰ã€è«‹å»ºç«‹ Engine æ™‚é–‹å•Ÿï¼š
- enable_surface_variants=True
- enable_representative_variants=True  (è¼ƒ aggressiveï¼Œæœƒç”Ÿæˆæ›´å¤šå€™é¸)
"""

from _example_utils import add_repo_to_sys_path, print_case

add_repo_to_sys_path()

from phonofix import EnglishEngine

# å…¨åŸŸ Engine (å–®ä¾‹æ¨¡å¼ï¼Œé¿å…é‡è¤‡åˆå§‹åŒ–)
engine = EnglishEngine(verbose=False)


# =============================================================================
# ç¯„ä¾‹ 1: åŸºç¤ç”¨æ³• - è‡ªå‹•ç”Ÿæˆ IPA éŸ³æ¨™ç´¢å¼•
# =============================================================================
def example_1_basic_usage():
    """
    æœ€ç°¡å–®çš„ç”¨æ³•ï¼šåªæä¾›æ­£ç¢ºè©å½™ï¼Œç³»çµ±è‡ªå‹•é€é IPA éŸ³æ¨™é€²è¡Œæ¨¡ç³Šæ¯”å°ã€‚
    é‡é»å±•ç¤ºï¼šASR å°‡å°ˆæœ‰åè©èª¤è½ç‚ºç™¼éŸ³ç›¸ä¼¼çš„å¸¸è¦‹è©å½™ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 1: åŸºç¤ç”¨æ³• (Basic Usage)")
    print("=" * 60)

    # åªéœ€æä¾›æ­£ç¢ºçš„è©å½™
    corrector = engine.create_corrector(
        [
            "TensorFlow",  # ASR å¯èƒ½èª¤è½ç‚º "tensor flow"
            "Kubernetes",  # ASR å¯èƒ½èª¤è½ç‚º "cooper net ease"
            "PostgreSQL",  # ASR å¯èƒ½èª¤è½ç‚º "post grass sequel"
            "Django",  # ASR å¯èƒ½èª¤è½ç‚º "jango" (D è¢«åƒæ‰)
        ]
    )

    test_cases = [
        ("Learning tensor flow for AI", "ASR èª¤è½ç‚ºå¸¸è¦‹è© (tensor flow -> TensorFlow)"),
        ("Deploy on cooper net ease", "ç™¼éŸ³ç›¸ä¼¼èª¤è½ (cooper net ease -> Kubernetes)"),
        ("Using post grass sequel database", "ç™¼éŸ³ç›¸ä¼¼èª¤è½ (post grass sequel -> PostgreSQL)"),
        ("The jango framework is great", "é¦–å­—æ¯éºå¤± (jango -> Django)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Basic", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 2: æ‰‹å‹•åˆ¥å - å·²çŸ¥çš„ ASR éŒ¯èª¤æ¨¡å¼
# =============================================================================
def example_2_manual_aliases():
    """
    æ‰‹å‹•æä¾›åˆ¥åï¼Œè™•ç†å·²çŸ¥çš„ ASR éŒ¯èª¤æ¨¡å¼ã€‚
    ç•¶ä½ çŸ¥é“ç‰¹å®šè©å½™ç¶“å¸¸è¢«èª¤è½ç‚ºä»€éº¼æ™‚ï¼Œå¯ä»¥ç›´æ¥æŒ‡å®šã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 2: æ‰‹å‹•åˆ¥å (Manual Aliases)")
    print("=" * 60)

    corrector = engine.create_corrector({
        # ASR ç¶“å¸¸å°‡å°ˆæœ‰åè©èª¤è½ç‚ºç™¼éŸ³ç›¸ä¼¼çš„å¸¸è¦‹è©çµ„
        "TensorFlow": ["tensor flow", "tens are flow", "ten so flow"],
        "PyTorch": ["pie torch", "pi torch", "by torch"],
        "scikit-learn": ["psychic learn", "sky kit learn", "sigh kit learn"],
    })

    test_cases = [
        ("I learned tens are flow yesterday", "èª¤è½ç‚ºå¸¸è¦‹è© (tens are flow -> TensorFlow)"),
        ("Training models with pie torch", "èª¤è½ç‚ºå¸¸è¦‹è© (pie torch -> PyTorch)"),
        ("Using psychic learn for ML", "ç™¼éŸ³ç›¸ä¼¼èª¤è½ (psychic learn -> scikit-learn)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Manual Aliases", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 3: ç™¼éŸ³ç›¸ä¼¼èª¤è½ (Phonetic Mishearing)
# =============================================================================
def example_3_phonetic_mishearing():
    """
    è™•ç† ASR å°‡å°ˆæœ‰åè©èª¤è½ç‚ºç™¼éŸ³ç›¸ä¼¼è©å½™çš„æƒ…æ³ã€‚
    é€™æ˜¯èªéŸ³è¾¨è­˜æœ€å¸¸è¦‹çš„éŒ¯èª¤é¡å‹ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 3: ç™¼éŸ³ç›¸ä¼¼èª¤è½ (Phonetic Mishearing)")
    print("=" * 60)

    corrector = engine.create_corrector({
        # é†«ç™‚/ç§‘å­¸è¡“èªç¶“å¸¸è¢«èª¤è½
        "acetaminophen": ["a set a mini fan", "acid a mini fan"],
        "algorithm": ["Al Gore rhythm", "all go rhythm"],
        "Alzheimer's": ["all timers", "old timers"],
    })

    test_cases = [
        ("Take a set a mini fan for pain", "è—¥åèª¤è½ (a set a mini fan -> acetaminophen)"),
        ("The Al Gore rhythm is efficient", "è¡“èªèª¤è½ (Al Gore rhythm -> algorithm)"),
        ("My grandma has all timers disease", "ç–¾ç—…åèª¤è½ (all timers -> Alzheimer's)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Phonetic", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 4: ä¸Šä¸‹æ–‡é—œéµå­— (Context Keywords)
# =============================================================================
def example_4_context_keywords():
    """
    ä½¿ç”¨ keywords é€²è¡ŒåŒéŸ³ç•°ç¾©è©è¾¨æã€‚
    ç•¶ ASR èª¤è½çµæœå¯èƒ½å°æ‡‰å¤šå€‹å°ˆæœ‰åè©æ™‚ï¼Œæ ¹æ“šä¸Šä¸‹æ–‡æ±ºå®šã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 4: ä¸Šä¸‹æ–‡é—œéµå­— (Context Keywords)")
    print("=" * 60)

    corrector = engine.create_corrector({
        # "cell" å¯èƒ½æ˜¯å¤šç¨®å°ˆæœ‰åè©çš„èª¤è½
        "Excel": {
            "aliases": ["egg cell", "ex cell"],
            "keywords": ["spreadsheet", "Microsoft", "table", "formula"],
            "weight": 0.5
        },
        "Axel": {
            "aliases": ["axle", "ex cell"],
            "keywords": ["jump", "skating", "figure", "triple"],
            "weight": 0.5
        },
        # "1 kg" å¯èƒ½æ˜¯ EKG çš„èª¤è½
        "EKG": {
            "aliases": ["1 kg", "one kg", "e k g"],
            "keywords": ["heart", "medical", "patient", "monitor"],
            "weight": 0.5
        },
    })

    test_cases = [
        ("Open the egg cell spreadsheet", "ä¸Šä¸‹æ–‡: spreadsheet -> Excel"),
        ("She landed a triple ex cell", "ä¸Šä¸‹æ–‡: triple/skating -> Axel (èŠ±å¼æ»‘å†°è·³èº)"),
        ("Check the patient's 1 kg reading", "ä¸Šä¸‹æ–‡: patient -> EKG (å¿ƒé›»åœ–)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Keywords", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 5: ä¸Šä¸‹æ–‡æ’é™¤ (Context Exclusion)
# =============================================================================
def example_5_exclude_when():
    """
    ä½¿ç”¨ exclude_when é¿å…éŒ¯èª¤ä¿®æ­£ã€‚
    ç•¶ä¸Šä¸‹æ–‡æ˜ç¢ºè¡¨ç¤ºé€™ä¸æ˜¯å°ˆæœ‰åè©æ™‚ï¼Œä¸é€²è¡Œæ›¿æ›ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 5: ä¸Šä¸‹æ–‡æ’é™¤ (Context Exclusion)")
    print("=" * 60)

    corrector = engine.create_corrector({
        # "1 kg" é€šå¸¸æ˜¯ EKG çš„èª¤è½ï¼Œä½†åœ¨é‡é‡ç›¸é—œèªå¢ƒå‰‡ä¸æ˜¯
        "EKG": {
            "aliases": ["1 kg", "one kg"],
            "keywords": ["medical", "heart", "patient"],
            "exclude_when": ["weight", "heavy", "kilogram", "weighs", "pounds"],
        },
        # "cell" å¯èƒ½æ˜¯ Excel çš„èª¤è½ï¼Œä½†åœ¨ç”Ÿç‰©å­¸èªå¢ƒå‰‡ä¸æ˜¯
        "Excel": {
            "aliases": ["egg cell"],
            "keywords": ["spreadsheet", "Microsoft"],
            "exclude_when": ["biology", "membrane", "organism", "microscope"],
        }
    })

    test_cases = [
        ("The patient's 1 kg shows normal rhythm", "é†«ç™‚èªå¢ƒ -> EKG"),
        ("This box weighs 1 kg", "æ’é™¤è© 'weighs' -> ä¸ä¿®æ­£ (çœŸçš„æ˜¯ä¸€å…¬æ–¤)"),
        ("Open egg cell in Microsoft", "è»Ÿé«”èªå¢ƒ -> Excel"),
        ("The egg cell under microscope", "æ’é™¤è© 'microscope' -> ä¸ä¿®æ­£ (çœŸçš„æ˜¯åµç´°èƒ)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Exclusion", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 6: æ¬Šé‡ç³»çµ± (Weight System)
# =============================================================================
def example_6_weight_system():
    """
    ä½¿ç”¨æ¬Šé‡æ§åˆ¶å„ªå…ˆç´šã€‚
    ç•¶åŒä¸€å€‹èª¤è½çµæœå¯èƒ½å°æ‡‰å¤šå€‹å°ˆæœ‰åè©æ™‚ï¼Œé«˜æ¬Šé‡è€…å„ªå…ˆã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 6: æ¬Šé‡ç³»çµ± (Weight System)")
    print("=" * 60)

    corrector = engine.create_corrector({
        # "neural" å¯èƒ½è¢«èª¤è½ç‚ºå¤šå€‹ç›¸ä¼¼ç™¼éŸ³çš„è©
        "NumPy": {
            "aliases": ["numb pie", "num pie"],
            "weight": 0.8  # è¼ƒå¸¸è¦‹ï¼Œè¼ƒé«˜å„ªå…ˆç´š
        },
        "Gnome": {
            "aliases": ["numb", "num"],
            "weight": 0.2  # è¼ƒå°‘è¦‹ï¼Œè¼ƒä½å„ªå…ˆç´š
        }
    })

    test_cases = [
        ("Import numb pie for arrays", "é«˜æ¬Šé‡ -> NumPy (è¼ƒå¸¸è¦‹çš„é¸æ“‡)"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Weight", text, result, explanation)



# =============================================================================
# ç¯„ä¾‹ 7: åŒéŸ³éæ¿¾ + è®Šé«”è¦†è“‹ (Homophone Filtering)
# =============================================================================
def example_7_homophone_filtering():
    """
    å±•ç¤º EnglishFuzzyGenerator çš„è¦†è“‹ç¯„åœï¼Œä»¥åŠã€ŒåŒ IPA phonetic key å»é‡ã€çš„æ•ˆæœã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 7: åŒéŸ³éæ¿¾ + è®Šé«”è¦†è“‹ (Homophone Filtering)")
    print("=" * 60)

    from phonofix.languages.english.fuzzy_generator import EnglishFuzzyGenerator

    generator_safe = EnglishFuzzyGenerator(enable_representative_variants=False)
    generator_repr = EnglishFuzzyGenerator(enable_representative_variants=True)

    terms = [
        "TensorFlow",
        "Kubernetes",
        "PostgreSQL",
        "scikit-learn",
    ]

    for term in terms:
        safe_variants = generator_safe.generate_variants(term, max_variants=20)
        repr_variants = generator_repr.generate_variants(term, max_variants=20)

        print(f"ç›®æ¨™è©: {term}")
        print(f"å®‰å…¨è®Šé«”æ•¸ (safe): {len(safe_variants)}")
        print(f"ä»£è¡¨è®Šé«”æ•¸ (repr): {len(repr_variants)}")
        print(f"safe å‰10å€‹: {safe_variants[:10]}")
        print(f"repr å‰10å€‹: {repr_variants[:10]}")
        print("èªªæ˜: ç”Ÿæˆéšæ®µæœƒä»¥ IPA key å»é‡ï¼Œé¿å…åŒéŸ³è®Šé«”é€ æˆè©å…¸è†¨è„¹")
        print()

# =============================================================================
# ç¯„ä¾‹ 8: æ··åˆæ ¼å¼ (Mixed Format)
# =============================================================================
def example_8_mixed_format():
    """
    æ··åˆä½¿ç”¨åˆ—è¡¨å’Œå­—å…¸é…ç½®ã€‚
    å±•ç¤ºä¸åŒé…ç½®æ–¹å¼çš„éˆæ´»æ€§ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 8: æ··åˆæ ¼å¼ (Mixed Format)")
    print("=" * 60)

    corrector = engine.create_corrector(
        {
            # ç°¡å–®åˆ—è¡¨ï¼šåªæŒ‡å®šå·²çŸ¥èª¤è½
            "PyTorch": ["pie torch", "by torch"],
            # ç©ºå­—å…¸ï¼šè®“ç³»çµ±è‡ªå‹•ç”Ÿæˆç™¼éŸ³ç›¸ä¼¼è®Šé«”ï¼ˆéœ€é–‹å•Ÿ enable_surface_variantsï¼‰
            "Matplotlib": {},
            # å®Œæ•´é…ç½®ï¼šç²¾ç´°æ§åˆ¶
            "scikit-learn": {
                "aliases": ["psychic learn", "sigh kit learn"],
                "keywords": ["machine learning", "classifier", "regression"],
                "weight": 0.5,
            },
        }
    )

    test_cases = [
        ("Training with pie torch", "ç°¡å–®åˆ—è¡¨ -> PyTorch"),
        ("Plot with mat plot lib", "è‡ªå‹•ç”Ÿæˆè®Šé«” -> Matplotlib"),
        ("Using psychic learn classifier", "å®Œæ•´é…ç½® + ä¸Šä¸‹æ–‡ -> scikit-learn"),
    ]

    for text, explanation in test_cases:
        result = corrector.correct(text)
        print_case("Mixed", text, result, explanation)


# =============================================================================
# ç¯„ä¾‹ 9: é•·æ–‡ç« æ ¡æ­£ (Long Article)
# =============================================================================
def example_9_long_article():
    """
    é•·æ–‡ç« ç¶œåˆæ¸¬è©¦ã€‚
    æ¨¡æ“¬çœŸå¯¦çš„èªéŸ³è½‰æ–‡å­—è¼¸å‡ºï¼ŒåŒ…å«å¤šç¨® ASR èª¤è½ã€‚
    """
    print("=" * 60)
    print("ç¯„ä¾‹ 9: é•·æ–‡ç« æ ¡æ­£ (Long Article)")
    print("=" * 60)

    terms = {
        "TensorFlow": ["tensor flow", "tens are flow"],
        "PyTorch": ["pie torch", "by torch"],
        "scikit-learn": ["psychic learn", "sigh kit learn"],
        "Kubernetes": ["cooper net ease", "cube and at ease"],
        "PostgreSQL": ["post grass sequel", "post gress sequel"],
        "algorithm": ["Al Gore rhythm", "all go rhythm"],
    }
    
    corrector = engine.create_corrector(terms)

    article = (
        "Today I learned about tensor flow and pie torch for deep learning. "
        "The psychic learn library is great for classical machine learning. "
        "We deploy our models on cooper net ease with post grass sequel as the database. "
        "The Al Gore rhythm we developed runs very efficiently."
    )

    print("åŸæ–‡ (Original):")
    print(article)
    print("-" * 40)
    
    result = corrector.correct(article)
    
    print("ä¿®æ­£å¾Œ (Corrected):")
    print(result)
    print("-" * 40)





# =============================================================================
# ä¸»ç¨‹å¼
# =============================================================================
if __name__ == "__main__":
    print("\n" + "ğŸ‡ºğŸ‡¸" * 20)
    print("  è‹±æ–‡èªéŸ³è¾¨è­˜æ ¡æ­£ç¯„ä¾‹ (English Examples)")
    print("ğŸ‡ºğŸ‡¸" * 20 + "\n")

    examples = [
        example_1_basic_usage,
        example_2_manual_aliases,
        example_3_phonetic_mishearing,
        example_4_context_keywords,
        example_5_exclude_when,
        example_6_weight_system,
        example_7_homophone_filtering,
        example_8_mixed_format,
        example_9_long_article,
    ]

    for func in examples:
        try:
            func()
        except Exception as e:
            print(f"ç¯„ä¾‹åŸ·è¡Œå¤±æ•—: {e}")
            import traceback
            traceback.print_exc()
        print()

    print("=" * 60)
    print("æ‰€æœ‰ç¯„ä¾‹åŸ·è¡Œå®Œæˆ!")
    print("=" * 60)
