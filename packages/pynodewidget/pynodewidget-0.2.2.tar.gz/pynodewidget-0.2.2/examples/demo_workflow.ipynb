{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c76d6c6",
   "metadata": {},
   "source": [
    "# Workflow Progress Visualization Demo\n",
    "\n",
    "This notebook demonstrates real-time progress visualization in PyNodeWidget nodes.\n",
    "\n",
    "## Features:\n",
    "- **Progress bar field** - Custom field type that displays visual progress\n",
    "- **Real-time updates** - Python updates sync to frontend automatically\n",
    "- **Multi-node workflow** - Simulate a data processing pipeline\n",
    "- **Thread-based execution** - Non-blocking progress updates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8588d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from pynodewidget import NodeFlowWidget, JsonSchemaNodeWidget\n",
    "import time\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401cea4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderParams(BaseModel):\n",
    "    \"\"\"Parameters for data loading node.\"\"\"\n",
    "    source: str = Field(default=\"database\", description=\"Data source\")\n",
    "    batch_size: int = Field(default=100, ge=1, le=1000, description=\"Batch size\")\n",
    "    progress: int = Field(\n",
    "        default=0,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Loading progress\",\n",
    "        json_schema_extra={\"type\": \"progress\"}\n",
    "    )\n",
    "\n",
    "\n",
    "class ProcessorParams(BaseModel):\n",
    "    \"\"\"Parameters for data processing node.\"\"\"\n",
    "    algorithm: str = Field(default=\"transform\", description=\"Processing algorithm\")\n",
    "    workers: int = Field(default=4, ge=1, le=16, description=\"Number of workers\")\n",
    "    progress: int = Field(\n",
    "        default=0,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Processing progress\",\n",
    "        json_schema_extra={\"type\": \"progress\"}\n",
    "    )\n",
    "\n",
    "\n",
    "class AnalyzerParams(BaseModel):\n",
    "    \"\"\"Parameters for analysis node.\"\"\"\n",
    "    method: str = Field(default=\"statistical\", description=\"Analysis method\")\n",
    "    confidence: float = Field(default=0.95, ge=0, le=1, description=\"Confidence level\")\n",
    "    progress: int = Field(\n",
    "        default=0,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Analysis progress\",\n",
    "        json_schema_extra={\"type\": \"progress\"}\n",
    "    )\n",
    "\n",
    "\n",
    "class OutputParams(BaseModel):\n",
    "    \"\"\"Parameters for output node.\"\"\"\n",
    "    format: str = Field(default=\"json\", description=\"Output format\")\n",
    "    compress: bool = Field(default=False, description=\"Compress output\")\n",
    "    progress: int = Field(\n",
    "        default=0,\n",
    "        ge=0,\n",
    "        le=100,\n",
    "        description=\"Export progress\",\n",
    "        json_schema_extra={\"type\": \"progress\"}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598e2c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoaderNode(JsonSchemaNodeWidget):\n",
    "    \"\"\"Load data from source.\"\"\"\n",
    "    label = \"Data Loader\"\n",
    "    parameters = DataLoaderParams\n",
    "    icon = \"üì•\"\n",
    "    description = \"Load data from various sources\"\n",
    "    outputs = [{\"id\": \"data\", \"label\": \"Data\"}]\n",
    "\n",
    "\n",
    "class ProcessorNode(JsonSchemaNodeWidget):\n",
    "    \"\"\"Process data with configurable algorithm.\"\"\"\n",
    "    label = \"Processor\"\n",
    "    parameters = ProcessorParams\n",
    "    icon = \"‚öôÔ∏è\"\n",
    "    description = \"Process data with selected algorithm\"\n",
    "    inputs = [{\"id\": \"input\", \"label\": \"Input\"}]\n",
    "    outputs = [{\"id\": \"output\", \"label\": \"Output\"}]\n",
    "\n",
    "\n",
    "class AnalyzerNode(JsonSchemaNodeWidget):\n",
    "    \"\"\"Analyze processed data.\"\"\"\n",
    "    label = \"Analyzer\"\n",
    "    parameters = AnalyzerParams\n",
    "    icon = \"üìä\"\n",
    "    description = \"Perform statistical analysis\"\n",
    "    inputs = [{\"id\": \"data\", \"label\": \"Data\"}]\n",
    "    outputs = [{\"id\": \"results\", \"label\": \"Results\"}]\n",
    "\n",
    "\n",
    "class OutputNode(JsonSchemaNodeWidget):\n",
    "    \"\"\"Export results to file.\"\"\"\n",
    "    label = \"Output\"\n",
    "    parameters = OutputParams\n",
    "    icon = \"üíæ\"\n",
    "    description = \"Save results to file\"\n",
    "    inputs = [{\"id\": \"results\", \"label\": \"Results\"}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf6b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create widget with all node types\n",
    "flow = NodeFlowWidget(\n",
    "    nodes=[DataLoaderNode, ProcessorNode, AnalyzerNode, OutputNode],\n",
    "    height=\"700px\"\n",
    ")\n",
    "\n",
    "# Create a sample workflow with 4 nodes\n",
    "flow.nodes = [\n",
    "    {\n",
    "        \"id\": \"loader-1\",\n",
    "        \"type\": \"data_loader_node\",\n",
    "        \"position\": {\"x\": 50, \"y\": 100},\n",
    "        \"data\": {\n",
    "            \"label\": \"Data Loader\",\n",
    "            \"parameters\": flow.node_templates[0][\"defaultData\"][\"parameters\"],\n",
    "            \"outputs\": [{\"id\": \"data\", \"label\": \"Data\"}],\n",
    "            \"inputs\": [],\n",
    "            \"values\": {\"source\": \"database\", \"batch_size\": 100, \"progress\": 0}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"processor-1\",\n",
    "        \"type\": \"processor_node\",\n",
    "        \"position\": {\"x\": 350, \"y\": 100},\n",
    "        \"data\": {\n",
    "            \"label\": \"Processor\",\n",
    "            \"parameters\": flow.node_templates[1][\"defaultData\"][\"parameters\"],\n",
    "            \"inputs\": [{\"id\": \"input\", \"label\": \"Input\"}],\n",
    "            \"outputs\": [{\"id\": \"output\", \"label\": \"Output\"}],\n",
    "            \"values\": {\"algorithm\": \"transform\", \"workers\": 4, \"progress\": 0}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"analyzer-1\",\n",
    "        \"type\": \"analyzer_node\",\n",
    "        \"position\": {\"x\": 650, \"y\": 100},\n",
    "        \"data\": {\n",
    "            \"label\": \"Analyzer\",\n",
    "            \"parameters\": flow.node_templates[2][\"defaultData\"][\"parameters\"],\n",
    "            \"inputs\": [{\"id\": \"data\", \"label\": \"Data\"}],\n",
    "            \"outputs\": [{\"id\": \"results\", \"label\": \"Results\"}],\n",
    "            \"values\": {\"method\": \"statistical\", \"confidence\": 0.95, \"progress\": 0}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"output-1\",\n",
    "        \"type\": \"output_node\",\n",
    "        \"position\": {\"x\": 950, \"y\": 100},\n",
    "        \"data\": {\n",
    "            \"label\": \"Output\",\n",
    "            \"parameters\": flow.node_templates[3][\"defaultData\"][\"parameters\"],\n",
    "            \"inputs\": [{\"id\": \"results\", \"label\": \"Results\"}],\n",
    "            \"outputs\": [],\n",
    "            \"values\": {\"format\": \"json\", \"compress\": False, \"progress\": 0}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "# Connect the nodes\n",
    "flow.edges = [\n",
    "    {\n",
    "        \"id\": \"e1-2\",\n",
    "        \"source\": \"loader-1\",\n",
    "        \"target\": \"processor-1\",\n",
    "        \"sourceHandle\": \"data\",\n",
    "        \"targetHandle\": \"input\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"e2-3\",\n",
    "        \"source\": \"processor-1\",\n",
    "        \"target\": \"analyzer-1\",\n",
    "        \"sourceHandle\": \"output\",\n",
    "        \"targetHandle\": \"data\"\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"e3-4\",\n",
    "        \"source\": \"analyzer-1\",\n",
    "        \"target\": \"output-1\",\n",
    "        \"sourceHandle\": \"results\",\n",
    "        \"targetHandle\": \"results\"\n",
    "    }\n",
    "]\n",
    "\n",
    "flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_node_execution(flow_widget, node_id, duration=2.0, steps=20):\n",
    "    \"\"\"\n",
    "    Simulate node execution by updating progress from 0 to 100.\n",
    "    \n",
    "    Args:\n",
    "        flow_widget: NodeFlowWidget instance\n",
    "        node_id: ID of the node to update\n",
    "        duration: Total duration in seconds\n",
    "        steps: Number of progress updates\n",
    "    \"\"\"\n",
    "    step_duration = duration / steps\n",
    "    for i in range(steps + 1):\n",
    "        progress = int((i / steps) * 100)\n",
    "        flow_widget.update_node_progress(node_id, progress)\n",
    "        time.sleep(step_duration)\n",
    "\n",
    "\n",
    "def execute_workflow(flow_widget, sequential=True):\n",
    "    \"\"\"\n",
    "    Execute the workflow by simulating each node's processing.\n",
    "    \n",
    "    Args:\n",
    "        flow_widget: NodeFlowWidget instance\n",
    "        sequential: If True, execute nodes one by one; if False, execute in parallel\n",
    "    \"\"\"\n",
    "    # Reset all progress to 0\n",
    "    for node in flow_widget.nodes:\n",
    "        flow_widget.update_node_progress(node[\"id\"], 0)\n",
    "    \n",
    "    print(\"üöÄ Starting workflow execution...\")\n",
    "    \n",
    "    if sequential:\n",
    "        # Execute nodes sequentially\n",
    "        node_ids = [\"loader-1\", \"processor-1\", \"analyzer-1\", \"output-1\"]\n",
    "        node_names = [\"Data Loader\", \"Processor\", \"Analyzer\", \"Output\"]\n",
    "        \n",
    "        for node_id, node_name in zip(node_ids, node_names):\n",
    "            print(f\"  ‚ñ∂Ô∏è  Executing {node_name}...\")\n",
    "            simulate_node_execution(flow_widget, node_id, duration=2.0, steps=20)\n",
    "            print(f\"  ‚úÖ {node_name} complete\")\n",
    "    else:\n",
    "        # Execute nodes in parallel (simulating parallel processing)\n",
    "        threads = []\n",
    "        for node in flow_widget.nodes:\n",
    "            thread = threading.Thread(\n",
    "                target=simulate_node_execution,\n",
    "                args=(flow_widget, node[\"id\"], 3.0, 30)\n",
    "            )\n",
    "            threads.append(thread)\n",
    "            thread.start()\n",
    "        \n",
    "        # Wait for all threads to complete\n",
    "        for thread in threads:\n",
    "            thread.join()\n",
    "    \n",
    "    print(\"üéâ Workflow execution complete!\")\n",
    "\n",
    "\n",
    "# Execute the workflow sequentially\n",
    "execute_workflow(flow, sequential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a51329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_workflow_background():\n",
    "    \"\"\"Run workflow in background thread.\"\"\"\n",
    "    thread = threading.Thread(target=execute_workflow, args=(flow, True))\n",
    "    thread.start()\n",
    "    print(\"üîÑ Workflow started in background...\")\n",
    "    return thread\n",
    "\n",
    "# Start workflow in background\n",
    "# bg_thread = run_workflow_background()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b28516",
   "metadata": {},
   "source": [
    "## Background Execution Example\n",
    "\n",
    "Run workflow in a background thread to keep the notebook responsive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4c2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display current progress for all nodes\n",
    "for node in flow.nodes:\n",
    "    node_id = node[\"id\"]\n",
    "    label = node[\"data\"][\"label\"]\n",
    "    progress = node[\"data\"][\"values\"].get(\"progress\", 0)\n",
    "    print(f\"{label} ({node_id}): {progress}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4a8ca5",
   "metadata": {},
   "source": [
    "## Inspect Current State\n",
    "\n",
    "Check the current progress values of all nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0bae9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset all progress to 0\n",
    "for node in flow.nodes:\n",
    "    flow.update_node_progress(node[\"id\"], 0)\n",
    "print(\"‚úì All progress reset to 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0454969a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually set progress for specific nodes\n",
    "flow.update_node_progress(\"loader-1\", 75)\n",
    "flow.update_node_progress(\"processor-1\", 50)\n",
    "flow.update_node_progress(\"analyzer-1\", 25)\n",
    "flow.update_node_progress(\"output-1\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2433b691",
   "metadata": {},
   "source": [
    "## Manual Progress Control\n",
    "\n",
    "You can also manually update progress for individual nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7fd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute all nodes in parallel\n",
    "execute_workflow(flow, sequential=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326ca80",
   "metadata": {},
   "source": [
    "## Execute in Parallel\n",
    "\n",
    "Run all nodes simultaneously to see parallel progress updates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafd95bd",
   "metadata": {},
   "source": [
    "## Execute Workflow with Progress Updates\n",
    "\n",
    "Simulate workflow execution where each node updates its progress in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cabbbf",
   "metadata": {},
   "source": [
    "## Create the Workflow Widget\n",
    "\n",
    "Initialize the widget with all node types and create a sample workflow pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3521dcf4",
   "metadata": {},
   "source": [
    "## Define Workflow Nodes with Progress Fields\n",
    "\n",
    "Each node has a `progress` field with `json_schema_extra={\"type\": \"progress\"}` to use the custom progress bar renderer."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
