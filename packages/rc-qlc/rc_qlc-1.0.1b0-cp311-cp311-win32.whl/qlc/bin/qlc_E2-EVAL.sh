#!/bin/bash -e

# ============================================================================
# QLC E2-EVAL: Evaltools Statistical Analysis and Plotting
# ============================================================================
# Part of QLC (Quick Look Content) v1.0.1-beta
# An Automated Model-Observation Comparison Suite Optimized for CAMS
#
# Documentation:
#   https://docs.researchconcepts.io/qlc/latest/
#
# Description:
#   Creates comprehensive statistical plots from evaltools Evaluator objects
#   generated by E1-ECOL. Produces time series, station score maps, Taylor
#   diagrams, scatter plots, and diurnal cycles. Supports multi-experiment
#   and multi-region processing.
#
# Attribution:
#   Uses evaltools (CNRM Open Source by CNRS and Météo-France)
#   https://redmine.umr-cnrm.fr/projects/evaltools/wiki
#
# Usage:
#   Called automatically by qlc_main.sh - Do not call directly
#   For help: qlc -h
#
# Copyright (c) 2018-2025 ResearchConcepts io GmbH. All Rights Reserved.
# Questions/Comments: qlc Team @ ResearchConcepts io GmbH <qlc@researchconcepts.io>
# ============================================================================

# Source the configuration file to load the settings
. "$CONFIG_FILE"
# Include common functions
source $FUNCTIONS

PLOTTYPE="evaltools"
SCRIPT="$0"
 log  "________________________________________________________________________________________"
 log  "Start ${SCRIPT} at `date`"
 log  "Create evaltools plots for selected variables"
 log  "Multi-experiment and multi-region support enabled"
 log  "----------------------------------------------------------------------------------------"

# Loop through and process the parameters received
for param in "$@"; do
  log "Subscript $0 received parameter: $param"
done

log "$0 ANALYSIS_DIRECTORY = $ANALYSIS_DIRECTORY"
pwd -P

# Intelligent module loading with fallback to venv/conda
log "Setting up evaltools with intelligent module loading..."

# Check for evaltools Python environment (integrated or dedicated)
if ! setup_evaltools; then
  log "Error: Failed to setup evaltools" >&2
  exit 1
fi

log "Success: Evaltools configured"
log "EVALTOOLS_PYTHON: $EVALTOOLS_PYTHON"
export EVALTOOLS_PYTHON

# Create output directory if not existent
if [    ! -d "$PLOTS_DIRECTORY" ]; then
    mkdir -p "$PLOTS_DIRECTORY"
fi

# get script name without path and extension
script_name="${SCRIPT##*/}"     # Remove directory path
script_name="${script_name%.*}" # Remove extension
QLTYPE="$script_name"

# ----------------------------------------------------------------------------------------
# Parse command line arguments: <exp1> <exp2> ... <expN> <start_date> <end_date> [config]
# Experiments come first, followed by dates in YYYY-MM-DD format, optional config at end
# ----------------------------------------------------------------------------------------
parse_qlc_arguments "$@" || exit 1

# Generic experiment handling: last experiment is the reference
num_experiments=${#experiments[@]}
if [ $num_experiments -lt 1 ]; then
    log "Error: At least one experiment required"
    exit 1
fi

# Last experiment is the reference for difference plots
ref_exp="${experiments[$((num_experiments-1))]}"
log "Reference experiment (for diff plots): $ref_exp"

# Parse EXP_LABELS if defined (comma-separated list matching experiments order)
# Otherwise use experiments array for labels
if [ -n "${EXP_LABELS:-}" ]; then
    IFS=',' read -ra exp_labels_array <<< "${EXP_LABELS}"
    # Trim whitespace from each label
    for i in "${!exp_labels_array[@]}"; do
        exp_labels_array[$i]=$(echo "${exp_labels_array[$i]}" | xargs)
    done
    # Ensure we have enough labels (pad with experiment names if needed)
    while [ ${#exp_labels_array[@]} -lt ${#experiments[@]} ]; do
        exp_labels_array+=("${experiments[${#exp_labels_array[@]}]}")
    done
    log "Using EXP_LABELS: ${exp_labels_array[*]}"
else
    # Use experiments array as labels
    exp_labels_array=("${experiments[@]}")
    log "Using experiments as labels: ${exp_labels_array[*]}"
fi

# Create experiment strings for different uses
experiments_comma=$(IFS=,;  echo "${experiments[*]}") # Comma-separated for JSON
experiments_hyphen=$(IFS=-; echo "${experiments[*]}") # Hyphen-separated for paths
# For backward compatibility, set exp1 and exp2
exp1="${experiments[0]}"
exp2="${ref_exp}"

# Process dates
sDate="${sDat//[-:]/}"
eDate="${eDat//[-:]/}"
mDate="$sDate-$eDate"
ext="${QLTYPE}.${PLOTEXTENSION:-pdf}"

# Base path for outputs
base_hpath="$PLOTS_DIRECTORY/${experiments_hyphen}_${mDate}"

# Define path to the aqtool script
AQTOOL_SCRIPT="${EVALTOOLS_AQTOOL_SCRIPT:-${QLC_HOME}/config/workflows/evaltools/qlc_aqtool_1.0.9.py}"
if [ ! -f "$AQTOOL_SCRIPT" ]; then
    log "Error: aqtool script not found at ${AQTOOL_SCRIPT}. Exiting."
    exit 1
fi
log "Found aqtool script: ${AQTOOL_SCRIPT}"

# Create log directory
mkdir -p "${QLC_HOME}/log"

# Check for debug mode
DEBUG_MODE=${EVALTOOLS_DEBUG:-0}
if [[ "$*" =~ "--debug" ]] || [[ "$*" =~ "-d" ]]; then
    DEBUG_MODE=1
fi

# ============================================================================
# HELPER FUNCTIONS
# ============================================================================

# Function to discover evaluators for a region and extract experiment names
discover_evaluators_for_region() {
    local region_name=$1
    local search_dir="${EVALUATOR_OUTPUT_DIR:-${ANALYSIS_DIRECTORY}/evaluators}"
    
    log "Discovering evaluators for region: ${region_name}"
    log "Search directory: ${search_dir}"
    
    # Find evaluator files for this region
    # Pattern: {region}_{exp}_{daterange}_{var}_{time_avg}.evaluator.evaltools
    local all_evaluator_files=($(find "${search_dir}" -type f -name "${region_name}_*_${sDate}-${eDate}_*.evaluator.evaltools" 2>/dev/null))
    
    if [ ${#all_evaluator_files[@]} -eq 0 ]; then
        log "Warning: No evaluator files found for region ${region_name}"
        return 1
    fi
    
    log "Found ${#all_evaluator_files[@]} total evaluator file(s) for ${region_name}"
    
    # Filter evaluators based on config settings
    local evaluator_files=()
    local filter_experiments=true
    local filter_variables=false
    local filter_time_avg=false
    
    # Check if we should filter by experiments (command line args)
    if [ ${#experiments[@]} -eq 0 ]; then
        filter_experiments=false
    fi
    
    # Check if we should filter by variables (VARIABLES config)
    if [ -n "${VARIABLES:-}" ] && [ "${VARIABLES}" != "*" ]; then
        filter_variables=true
        IFS=',' read -ra config_vars <<< "${VARIABLES}"
        # Trim whitespace
        for i in "${!config_vars[@]}"; do
            config_vars[$i]=$(echo "${config_vars[$i]}" | xargs)
        done
    fi
    
    # Check if we should filter by time average (TIME_AVERAGE config)
    if [ -n "${TIME_AVERAGE:-}" ] && [ "${TIME_AVERAGE}" != "*" ]; then
        filter_time_avg=true
        IFS=',' read -ra config_time_avgs <<< "${TIME_AVERAGE}"
        # Trim whitespace
        for i in "${!config_time_avgs[@]}"; do
            config_time_avgs[$i]=$(echo "${config_time_avgs[$i]}" | xargs)
        done
    fi
    
    log "Filter settings: experiments=${filter_experiments}, variables=${filter_variables}, time_avg=${filter_time_avg}"
    
    # Apply filters
    for eval_file in "${all_evaluator_files[@]}"; do
        local basename=$(basename "$eval_file")
        local keep=true
        
        # Extract components from filename: {region}_{exp}_{daterange}_{var}_{time_avg}.evaluator.evaltools
        # Example: US_AIRNOW_URBAN_9191_20251101-20251107_O3_3hourly.evaluator.evaltools
        if [[ "$basename" =~ ^${region_name}_([^_]+)_[0-9]+-[0-9]+_([^_]+)_([^.]+)\.evaluator\.evaltools$ ]]; then
            local file_exp="${BASH_REMATCH[1]}"
            local file_var="${BASH_REMATCH[2]}"
            local file_time_avg="${BASH_REMATCH[3]}"
            
            # Filter by experiment
            if [ "$filter_experiments" = true ]; then
                local exp_match=false
                for exp in "${experiments[@]}"; do
                    if [ "$file_exp" = "$exp" ]; then
                        exp_match=true
                        break
                    fi
                done
                if [ "$exp_match" = false ]; then
                    keep=false
                fi
            fi
            
            # Filter by variable
            if [ "$filter_variables" = true ] && [ "$keep" = true ]; then
                local var_match=false
                for var in "${config_vars[@]}"; do
                    if [ "$file_var" = "$var" ]; then
                        var_match=true
                        break
                    fi
                done
                if [ "$var_match" = false ]; then
                    keep=false
                fi
            fi
            
            # Filter by time average
            if [ "$filter_time_avg" = true ] && [ "$keep" = true ]; then
                local time_avg_match=false
                for tavg in "${config_time_avgs[@]}"; do
                    if [ "$file_time_avg" = "$tavg" ]; then
                        time_avg_match=true
                        break
                    fi
                done
                if [ "$time_avg_match" = false ]; then
                    keep=false
                fi
            fi
            
            if [ "$keep" = true ]; then
                evaluator_files+=("$eval_file")
            fi
        else
            # If filename doesn't match expected pattern, include it anyway
            evaluator_files+=("$eval_file")
        fi
    done
    
    if [ ${#evaluator_files[@]} -eq 0 ]; then
        log "Warning: No evaluator files match the config filter for region ${region_name}"
        log "  Total files found: ${#all_evaluator_files[@]}"
        log "  Files after filtering: 0"
        return 1
    fi
    
    log "Found ${#evaluator_files[@]} evaluator file(s) matching config filter"
    
    # Extract unique experiment names and variables
    local exp_list=()
    local var_list=()
    
    for eval_file in "${evaluator_files[@]}"; do
        local basename_eval=$(basename "$eval_file" .evaluator.evaltools)
        
        # Pattern: {region}_{exp}_{daterange}_{var}_{time_res}
        # Example: EU_b2ro_20181201-20181221_NH3_daily or EU_b2ro_20181201-20181221_NH4_as_daily
        # Extract experiment and variable (variable may contain underscores like NH4_as)
        # Strategy: Match from start, then capture everything between daterange and the LAST underscore
        if [[ "$basename_eval" =~ ^${region_name}_([^_]+)_${sDate}-${eDate}_(.+)_([^_]+)$ ]]; then
            local exp_name="${BASH_REMATCH[1]}"
            local var_name="${BASH_REMATCH[2]}"
            local time_res="${BASH_REMATCH[3]}"
            
            # Add experiment to list if not present
            if [[ ! " ${exp_list[*]} " =~ " ${exp_name} " ]]; then
                exp_list+=("$exp_name")
                log "  Found experiment: $exp_name"
            fi
            
            # Add variable to list if not present
            if [[ ! " ${var_list[*]} " =~ " ${var_name} " ]]; then
                var_list+=("$var_name")
                log "  Found variable: $var_name"
            fi
        fi
    done
    
    if [ ${#exp_list[@]} -eq 0 ]; then
        log "Warning: No experiments extracted from evaluator filenames"
        return 1
    fi
    
    # Export discovered data
    region_experiments=("${exp_list[@]}")
    region_variables=("${var_list[@]}")
    
    log "Region ${region_name} experiments: ${region_experiments[*]}"
    log "Region ${region_name} variables: ${region_variables[*]}"
    
    return 0
}

# Function to run aqtool commands
# Usage: run_aqtool <plot_type> <output_file_template> <evaluator_files_array> <flags_string> <title> <preprocess>
run_aqtool() {
    local plot_type=$1
    local output_file_template=$2
    # $3 should be evaluator files (passed as "${evaluator_files[@]}")
    # We need to collect all arguments until we find one starting with "-" (flags)
    shift 2
    
    local evaluator_files=()
    local flags=""
    local title_arg=""
    local preprocess_arg=""
    
    # Collect evaluator files (all arguments until we hit one starting with "-")
    while [ $# -gt 0 ] && [[ ! "$1" =~ ^- ]]; do
        evaluator_files+=("$1")
        shift
    done
    
    # Remaining arguments: flags string, then optional title and preprocess
    if [ $# -gt 0 ]; then
        flags="$1"
        shift
    fi
    
    # Check for title (4th or 5th argument depending on whether preprocess is present)
    if [ $# -gt 0 ]; then
        title_arg="$1"
        shift
    fi
    
    # Check for preprocess (5th argument)
    if [ $# -gt 0 ]; then
        preprocess_arg="$1"
    fi

    # Properly quote the title to handle spaces
    local safe_title_arg
    if [ -n "$title_arg" ]; then
        printf -v safe_title_arg "%q" "$title_arg"
    fi

    # aqtool automatically adds the extension, so we build the name without it
    local output_file_base="${output_file_template}"
    local output_file_arg=$output_file_base
    
    log "Generating ${plot_type} plot..."
    
    # Build command array for proper argument handling
    local cmd_array=()
    cmd_array+=("${EVALTOOLS_PYTHON}")
    cmd_array+=("$AQTOOL_SCRIPT")
    
    if [ -n "$preprocess_arg" ]; then
        cmd_array+=("preprocess")
        cmd_array+=("$preprocess_arg")
    fi
    
    # Add plot command
    cmd_array+=("plot")
    cmd_array+=("$plot_type")
    
    # Add evaluator files as positional arguments
    for eval_file in "${evaluator_files[@]}"; do
        cmd_array+=("$eval_file")
    done
    
    # Parse flags string into separate arguments
    # Flags come as: "-se $sDate $eDate -mar $mrk_list -col $col_list -ann PROTOTYPE -env"
    # We need to split this properly, handling quoted values
    if [ -n "$flags" ]; then
        # Remove leading dash if present (it's already in the flags)
        local flags_clean="${flags#-}"
        # Use eval to properly parse the flags string into an array
        # This handles spaces and quoted values correctly
        eval "local flags_array=($flags)"
        cmd_array+=("${flags_array[@]}")
    fi
    
    # Add output file
    cmd_array+=("-of")
    cmd_array+=("$output_file_arg")
    
    # Add title if provided
    if [ -n "$title_arg" ]; then
        cmd_array+=("-tit")
        cmd_array+=("$title_arg")
    fi
    
    # Build command string for logging
    local full_command=""
    for arg in "${cmd_array[@]}"; do
        if [[ "$arg" =~ [[:space:]] ]]; then
            full_command="${full_command} \"${arg}\" "
        else
            full_command="${full_command}${arg} "
        fi
    done
    full_command=$(echo "$full_command" | sed 's/[[:space:]]*$//')
    
    if [ "$DEBUG_MODE" -eq 1 ]; then
        log "Command: ${full_command}"
    fi

    # Save and unset PYTHONPATH to avoid conflicts
    local saved_pythonpath="$PYTHONPATH"
    unset PYTHONPATH
    
    # Run command with output control based on debug mode
    # Use array directly instead of eval to avoid quoting issues
    # Always capture stderr for error reporting
    local temp_error_file=$(mktemp)
    if [ "$DEBUG_MODE" -eq 1 ]; then
        "${cmd_array[@]}" 2>&1
        local cmd_status=$?
    else
        "${cmd_array[@]}" > /dev/null 2>"$temp_error_file"
        local cmd_status=$?
        # If command failed, show the error
        if [ $cmd_status -ne 0 ] && [ -s "$temp_error_file" ]; then
            log "Error output from plot command:"
            cat "$temp_error_file" | while IFS= read -r line; do log "  $line"; done
        fi
    fi
    rm -f "$temp_error_file"
    
    # Restore PYTHONPATH
    export PYTHONPATH="$saved_pythonpath"

    # Check if plot was created - aqtool may create files with different extensions
    # Check for common image formats (png, pdf, svg, jpg)
    local plot_found=0
    local created_files=()
    local extensions=("png" "pdf" "svg" "jpg" "jpeg")
    
    # Also check the configured extension
    if [ -n "$PLOTEXTENSION" ]; then
        extensions=("$PLOTEXTENSION" "${extensions[@]}")
    fi
    
    for ext in "${extensions[@]}"; do
        local check_pattern="${output_file_base/\{score\}/\*}.${ext}"
        if compgen -G "$check_pattern" > /dev/null; then
            created_files+=($(compgen -G "$check_pattern"))
            plot_found=1
        fi
    done
    
    if [ $plot_found -eq 1 ]; then
        local file_count=${#created_files[@]}
        log "  ✓ Created ${plot_type} plot(s) (${file_count} file(s)):"
        for plot_file in "${created_files[@]}"; do
            log "    - $(basename "$plot_file")"
        done
        return 0
    else
        log "  ✗ Error: Plot generation failed for ${plot_type}"
        return 1
    fi
}

# Function to generate plots for a region
generate_plots_for_region() {
    local region_name=$1
    local region_hpath=$2
    
    log "========================================"
    log "Generating plots for region: ${region_name}"
    log "========================================"
    log "Region path: ${region_hpath}"
    
    # Discover evaluators for this region
    if ! discover_evaluators_for_region "${region_name}"; then
        log "Skipping region ${region_name} - no evaluators found"
        return 1
    fi
    
    log "Starting evaltools plot generation for ${region_name}..."
    if [ "$DEBUG_MODE" -eq 1 ]; then
        log "Debug mode: ENABLED (verbose plot output)"
    else
        log "Debug mode: DISABLED (silent plot output, only summaries shown)"
    fi
    
    # Cleanup old plots
    log "Cleaning up old evaltools plots from ${region_hpath}..."
    if [ -d "$region_hpath" ]; then
        rm -f "${region_hpath}"/qlc_E2_evaltools_*.${PLOTEXTENSION} 2>/dev/null
        log "✓ Removed old evaltools plots"
    else
        log "Creating plot directory: ${region_hpath}"
        mkdir -p "$region_hpath"
    fi
    
    # Define output file prefix
    EVALUATION_PREFIX="${EVALTOOLS_EVALUATION_PREFIX:-qlc_E2_evaltools}"
    
    # Parse plot format(s) from PLOTEXTENSION (can be comma-separated: "pdf,png")
    local tex_plot_format=""
    if [ -n "$PLOTEXTENSION" ]; then
        # Convert comma-separated list to array for iteration
        IFS=',' read -ra PLOT_FORMATS <<< "$PLOTEXTENSION"
        # Trim whitespace from each format
        for i in "${!PLOT_FORMATS[@]}"; do
            PLOT_FORMATS[$i]=$(echo "${PLOT_FORMATS[$i]}" | xargs)
        done
        # Use only the first plot format for TeX files
        tex_plot_format="${PLOT_FORMATS[0]}"
    else
        tex_plot_format="${EVALTOOLS_TEX_PLOT_FORMAT:-pdf}"  # Default from config
    fi
    log "Using plot format for TeX: ${tex_plot_format}"
    
    # Clean up old per-variable TeX files in base directory
    rm -f "${base_hpath}"/texPlotfiles_${QLTYPE}_${region_name}_*.tex
    rm -f "${base_hpath}"/texPlotfiles_${QLTYPE}_${region_name}_*.list
    
    # Array to store per-variable TeX files
    local per_variable_tex_files=()
    
    # Evaluator directory
    EVALUATOR_DIR="${EVALTOOLS_OUTPUT_DIR:-${ANALYSIS_DIRECTORY}/evaluators}"
    
    # For each variable, generate plots with all experiments
    for var in "${region_variables[@]}"; do
        log "Processing variable: $var for region ${region_name}"
        
        # Find all evaluator files for this variable and region
        # Pattern now includes temporal resolution: {region}_{exp}_{daterange}_{var}_{time_res}.evaluator.evaltools
        local evaluator_files=()
        for exp in "${region_experiments[@]}"; do
            # Use wildcard for temporal resolution (daily, hourly, etc.)
            local eval_pattern="${EVALUATOR_DIR}/${region_name}_${exp}_${sDate}-${eDate}_${var}_*.evaluator.evaltools"
            while IFS= read -r eval_file; do
                if [ -f "$eval_file" ]; then
                    evaluator_files+=("$eval_file")
                    log "  Found evaluator: $(basename $eval_file)"
                fi
            done < <(compgen -G "$eval_pattern" 2>/dev/null || true)
        done
        
        if [ ${#evaluator_files[@]} -eq 0 ]; then
            log "Warning: No evaluator files found for variable ${var} in region ${region_name}"
            continue
        fi
        
        log "Generating plots with ${#evaluator_files[@]} experiment(s)"
        
        # Extract time resolution from evaluator filename for unique plot names
        # Pattern: {region}_{exp}_{daterange}_{var}_{time_res}.evaluator.evaltools
        local first_eval="${evaluator_files[0]}"
        local time_res_suffix=""
        local basename_eval=$(basename "$first_eval" .evaluator.evaltools)
        if [[ "$basename_eval" =~ ^${region_name}_[^_]+_${sDate}-${eDate}_[^_]+_([^_]+)$ ]]; then
            time_res_suffix="_${BASH_REMATCH[1]}"
            log "Extracted time resolution: ${BASH_REMATCH[1]}"
        elif [[ "$basename_eval" =~ _([0-9]+hourly|daily|monthly|avg)$ ]]; then
            time_res_suffix="_${BASH_REMATCH[1]}"
            log "Extracted time resolution (fallback): ${BASH_REMATCH[1]}"
        else
            log "Warning: Could not extract time resolution from filename, plots may be overwritten"
        fi
        
        # Auto-detect temporal resolution from evaluator for plot filtering
        log "Detecting series type from evaluator..."
        series_type=$("${EVALTOOLS_PYTHON}" -c "
import pickle
import sys
try:
    with open('${first_eval}', 'rb') as f:
        ev = pickle.load(f)
    series_type = getattr(ev.observations, 'seriesType', 'unknown')
    print(series_type)
except Exception as e:
    print('unknown', file=sys.stderr)
    sys.exit(1)
" 2>/dev/null)
        
        if [ -n "$series_type" ]; then
            log "  Series type: $series_type"
            if [ "$series_type" = "hourly" ]; then
                ENABLE_DIURNAL_CYCLE=1
                ENABLE_TIME_SCORES=1
                log "  ✓ Hourly data detected - all plots enabled"
            elif [ "$series_type" = "daily" ]; then
                ENABLE_DIURNAL_CYCLE=0
                ENABLE_TIME_SCORES=0
                log "  WARNING: Daily data detected - diurnal_cycle and time_scores disabled"
            else
                ENABLE_DIURNAL_CYCLE=0
                ENABLE_TIME_SCORES=0
                log "  WARNING: Unknown series type - disabling incompatible plots"
            fi
        else
            ENABLE_DIURNAL_CYCLE=0
            ENABLE_TIME_SCORES=0
            log "  WARNING: Could not detect series type - disabling incompatible plots"
        fi

        # Define plot colors and markers based on number of experiments
        local num_exps=${#evaluator_files[@]}
        # Colors from config or defaults
        IFS=',' read -ra colors_array <<< "${EVALTOOLS_PLOT_COLORS:-firebrick,dodgerblue,forestgreen,orange,purple,brown,pink,gray,olive,cyan}"
        local colors=("${colors_array[@]}")
        # Markers from config or defaults
        IFS=',' read -ra markers_array <<< "${EVALTOOLS_PLOT_MARKERS:-^,+,o,s,D,v,^,<,>,*}"
        local markers=()
        for m in "${markers_array[@]}"; do
            markers+=("'${m}'")
        done
        
        local col_list=""
        local mrk_list=""
        for ((i=0; i<num_exps && i<${#colors[@]}; i++)); do
            col_list="$col_list ${colors[$i]}"
            mrk_list="$mrk_list ${markers[$i]}"
        done
        col_list=$(echo "$col_list" | xargs)  # Trim whitespace
        mrk_list=$(echo "$mrk_list" | xargs)
        
        # Build experiment list for title
        local experiments_title=$(IFS=" vs "; echo "${region_experiments[*]}")
        local title="Comparison for ${var} (${region_name}): ${experiments_title}"
        
        # Define scores from config or defaults
        all_scores="${EVALTOOLS_PLOT_SCORES:-FGE MMB PearsonR RMSE}"
        
        # Get region bounds from E1 JSON config file (uses 0-360 convention for evaltools)
        # Pattern: qlc_E1_evaltools_config_{region}_{daterange}_{time_avg}.json
        local json_config_file="${region_hpath}/qlc_E1_evaltools_config_${region_name}_${sDate}-${eDate}_${time_res_suffix#_}.json"
        local lat_min lat_max lon_min lon_max
        
        if [ -f "$json_config_file" ]; then
            # Read bounds from JSON config created by E1
            local bounds_json=$("${EVALTOOLS_PYTHON}" -c "
import json
try:
    with open('${json_config_file}', 'r') as f:
        config = json.load(f)
    region_info = config.get('region_info', {})
    lat_min = region_info.get('lat_min', -90.0)
    lat_max = region_info.get('lat_max', 90.0)
    lon_min = region_info.get('lon_min', 0.0)
    lon_max = region_info.get('lon_max', 360.0)
    print(f'{lat_min} {lat_max} {lon_min} {lon_max}')
except Exception as e:
    # Fallback to Globe bounds
    print('-90.0 90.0 0.0 360.0')
" 2>/dev/null)
            read lat_min lat_max lon_min lon_max <<< "$bounds_json"
            log "Read region bounds from JSON config: lat[${lat_min},${lat_max}] lon[${lon_min},${lon_max}]"
        else
            log "Warning: JSON config not found: ${json_config_file}"
            log "Using fallback: Globe bounds"
            lat_min=-90.0
            lat_max=90.0
            lon_min=0.0
            lon_max=360.0
        fi
        
        # evaltools bbox format: [lon_min, lon_max, lat_min, lat_max]
        local bbox_args="-bbo ${lon_min} ${lon_max} ${lat_min} ${lat_max}"
        log "Station_scores bbox args (lon_min lon_max lat_min lat_max): ${bbox_args}"
        
        # Generate plots (include time_res_suffix in all filenames for uniqueness)
        # Time series plot (skip if dates are identical)
        if [ "$sDate" != "$eDate" ]; then
            run_aqtool "time_series" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_timeseries" "${evaluator_files[@]}" "-se $sDate $eDate -mar $mrk_list -col $col_list -ann PROTOTYPE -env" "$title" "" || log "Warning: time_series plot failed for ${var}"
        else
            log "Skipping time_series plot (start and end dates are identical)"
        fi

        # Diurnal cycle (only for hourly data)
        if [ "$ENABLE_DIURNAL_CYCLE" -eq 1 ]; then
            run_aqtool "diurnal_cycle" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_diurnal" "${evaluator_files[@]}" "-col $col_list -mar $mrk_list -ann PROTOTYPE -env" "$title" "" || log "Warning: diurnal_cycle plot failed for ${var}"
        else
            log "Skipping diurnal_cycle plot (requires hourly data)"
        fi

        # Data density
        run_aqtool "data_density" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_density" "${evaluator_files[@]}" "-col $col_list -ann PROTOTYPE" "$title" "" || log "Warning: data_density plot failed for ${var}"
        
        # Check evaluator metadata (once per variable)
        local has_forecast_steps=false
        local eval_step=0
        local forecast_day_arg=""
        local first_eval="${evaluator_files[0]}"
        if [ -f "$first_eval" ]; then
            # Check forecast step availability and actual time step
            local eval_metadata=$("${EVALTOOLS_PYTHON}" -c "
import pickle
import sys
try:
    with open('${first_eval}', 'rb') as f:
        ev = pickle.load(f)
    has_steps = getattr(ev, 'has_forecast_steps', False)
    step = getattr(ev.observations.dataset, 'step', 1) if hasattr(ev, 'observations') else 1
    print('true' if has_steps else 'false')
    print(step if step is not None else 1)
except Exception as e:
    print('false')
    print('1')
" 2>/dev/null)
            read has_forecast_steps eval_step <<< "$eval_metadata"
            log "Evaluator metadata: has_forecast_steps=${has_forecast_steps}, step=${eval_step}"
            
            # Set forecast_day argument: use -fd 0 only if no forecast steps available
            if [ "$has_forecast_steps" = "false" ]; then
                forecast_day_arg="-fd 0"
            fi
        fi
        
        # Check if time resolution is compatible with evaltools mean/median score plots
        # These plots only work correctly with step=1 (hourly) or step=24 (daily)
        local time_scores_compatible=false
        if [ "$eval_step" -eq 1 ] || [ "$eval_step" -eq 24 ]; then
            time_scores_compatible=true
        fi
        
        # Show warning once per variable about plot limitations
        if [ "$has_forecast_steps" = "false" ] || [ "$time_scores_compatible" = "false" ]; then
            log ""
            log "┌────────────────────────────────────────────────────────────────────────┐"
            log "│ NOTE: Limited Plot Availability Due to Data Characteristics            │"
            log "├────────────────────────────────────────────────────────────────────────┤"
            
            if [ "$has_forecast_steps" = "false" ]; then
                log "│ • No forecast step dimension (NetCDF loses this during conversion)     │"
                log "│   Skipping: time_scores (requires forecast lead time information)      │"
            fi
            
            if [ "$time_scores_compatible" = "false" ]; then
                log "│ • Time resolution: ${eval_step}-hourly (not hourly or daily)           │"
                log "│   Skipping: mean_time_scores, median_station_scores, score_quartiles   │"
                log "│   Reason: These plots require hourly (step=1) or daily (step=24)       │"
            fi
            
            log "│                                                                        │"
            log "│ Available plots: timeseries, scatter, Taylor, station maps,            │"
            log "│                  bar_scores, exceedance plots, density plots           │"
            log "└────────────────────────────────────────────────────────────────────────┘"
            log ""
        fi
        
        # Score plots for each score
        # mean_time_scores and median_station_scores only work with hourly (step=1) or daily (step=24) data
        for score in $all_scores; do
            if [ "$time_scores_compatible" = "true" ]; then
                run_aqtool "mean_time_scores" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_meantimescores_${score}" "${evaluator_files[@]}" "-sco $score -col $col_list -ann PROTOTYPE" "$title" "" || log "Warning: mean_time_scores plot failed for ${var} (${score})"
                run_aqtool "median_station_scores" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_medianstationscores_${score}" "${evaluator_files[@]}" "-sco $score -col $col_list -mar $mrk_list -ann PROTOTYPE" "$title" "" || log "Warning: median_station_scores plot failed for ${var} (${score})"
            fi
            
            # Time scores (requires forecast step information AND sub-daily data)
            if [ "$has_forecast_steps" = "true" ] && [ "$ENABLE_TIME_SCORES" -eq 1 ]; then
                # Extract numeric hours from time resolution (e.g., "3hourly" -> 3, "hourly" -> 1)
                local time_res_hours=1
                if [[ "${time_res_suffix#_}" =~ ^([0-9]+)hourly$ ]]; then
                    time_res_hours="${BASH_REMATCH[1]}"
                elif [[ "${time_res_suffix#_}" == "hourly" ]]; then
                    time_res_hours=1
                elif [[ "${time_res_suffix#_}" == "daily" ]]; then
                    time_res_hours=24
                fi
                # Use extracted time resolution or config override
                local time_resolution="${EVALTOOLS_TIME_RESOLUTION:-${time_res_hours}}"
                log "Using time resolution for time_scores: ${time_resolution} hours (from ${time_res_suffix#_})"
                run_aqtool "time_scores" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_timescores_${score}" "${evaluator_files[@]}" "-sco $score -ter ${time_resolution} -col $col_list -mar $mrk_list -ann PROTOTYPE" "$title" "" || log "Warning: time_scores plot failed for ${var} (${score})"
            elif [ "$has_forecast_steps" = "false" ]; then
                log "⊗ Skipping time_scores plot for $score (requires forecast step information from GRIB data)"
            elif [ "$ENABLE_TIME_SCORES" -eq 0 ]; then
                log "Skipping time_scores plot for $score (requires sub-daily data)"
            fi
        done

        # Additional plots (using first evaluator as reference where needed)
        # Use region-specific bounds from REGION_METADATA
        # Use lower availability_ratio (0.25) for sub-daily data to account for temporal resolution mismatch
        run_aqtool "station_scores" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_stationscores" "${evaluator_files[0]}" "-sco MeanBias ${bbox_args} -ar 0.25" "$title" "" || log "Warning: station_scores plot failed for ${var}"
        local taylor_contour_levels="${EVALTOOLS_TAYLOR_CONTOUR_LEVELS:-15}"
        # Taylor diagram uses -thr (threshold) parameter, not -ar (availability_ratio)
        # Lower threshold (0.25) for sub-daily data to account for temporal resolution mismatch
        # Note: Removed -fra (frame) to show all data points even with high SD ratios
        # Use -fd 0 only when no forecast steps available (set in forecast_day_arg)
        run_aqtool "taylor_diagram" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_taylor" "${evaluator_files[@]}" "${forecast_day_arg} -col $col_list -mar $mrk_list -ann PROTOTYPE -cl ${taylor_contour_levels} -thr 0.25" "TAYLOR" "" || log "Warning: taylor_diagram plot failed for ${var}"
        
        # Score quartiles (only for hourly or daily data)
        if [ "$time_scores_compatible" = "true" ]; then
            local score_quartiles_xsc="${EVALTOOLS_SCORE_QUARTILES_XSC:-FGE}"
            local score_quartiles_ysc="${EVALTOOLS_SCORE_QUARTILES_YSC:-MMB}"
            local plot_aspect_ratio="${EVALTOOLS_PLOT_ASPECT_RATIO:-0.8}"
            run_aqtool "score_quartiles" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_scorequartiles" "${evaluator_files[@]}" "-xsc ${score_quartiles_xsc} -ysc ${score_quartiles_ysc} -col $col_list -ar ${plot_aspect_ratio} -ba -ocsv ${region_hpath}/score_quartiles_${var}${time_res_suffix}.csv" "" "" || log "Warning: score_quartiles plot failed for ${var}"
        fi
        
        # station_score_density requires sufficient data - skip for short time periods
        local min_days_for_density="${EVALTOOLS_MIN_DAYS_FOR_DENSITY:-7}"
        local start_epoch=$(date -j -f "%Y%m%d" "$sDate" "+%s" 2>/dev/null || date -d "$sDate" "+%s" 2>/dev/null)
        local end_epoch=$(date -j -f "%Y%m%d" "$eDate" "+%s" 2>/dev/null || date -d "$eDate" "+%s" 2>/dev/null)
        local days_diff=$(( (end_epoch - start_epoch) / 86400 ))
        
        if [ $days_diff -ge $min_days_for_density ]; then
            local station_score_density_score="${EVALTOOLS_STATION_SCORE_DENSITY_SCORE:-RMSE}"
            run_aqtool "station_score_density" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_scoredensity" "${evaluator_files[@]}" "-sco ${station_score_density_score} -col $col_list -ann PROTOTYPE" "$title" "" || log "Warning: station_score_density plot failed for ${var}"
        else
            log "Skipping station_score_density plot (time period ${days_diff} days < ${min_days_for_density} days required)"
        fi
        local bar_scores_score="${EVALTOOLS_BAR_SCORES_SCORE:-RMSE}"
        run_aqtool "bar_scores" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_barscores" "${evaluator_files[@]}" "-sco ${bar_scores_score} -ave median -col $col_list -ann PROTOTYPE" "$title" "" || log "Warning: bar_scores plot failed for ${var}"
        local exceedance_threshold="${EVALTOOLS_EXCEEDANCE_THRESHOLD:-90.0}"
        run_aqtool "bar_exceedances" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_barexceed" "${evaluator_files[0]}" "-thr ${exceedance_threshold} -se $sDate $eDate" "$title" "" || log "Warning: bar_exceedances plot failed for ${var}"
        run_aqtool "line_exceedances" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_lineexceed" "${evaluator_files[@]}" "-thr ${exceedance_threshold} -se $sDate $eDate -ann PROTOTYPE -col $col_list" "$title" "" || log "Warning: line_exceedances plot failed for ${var}"
        run_aqtool "bar_contingency_table" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_contingency" "${evaluator_files[@]}" "-thr ${exceedance_threshold} -se $sDate $eDate" "$title" "" || log "Warning: bar_contingency_table plot failed for ${var}"
        run_aqtool "values_scatter_plot" "${region_hpath}/${EVALUATION_PREFIX}_${region_name}_${var}_${mDate}${time_res_suffix}_valuescatter" "${evaluator_files[0]}" "-se $sDate $eDate -ann PROTOTYPE" "$title" "" || log "Warning: values_scatter_plot failed for ${var}"

        # Variable summary
        log ""
        log "✓ Completed evaltools plots for ${var} (${region_name})"
        if [ "$has_forecast_steps" = "false" ]; then
            log "  Note: time_scores plots skipped (require forecast step dimension from GRIB)"
        fi
        log ""
    done
    
    # Helper function to find and add plots for a specific format
    add_plot_if_found() {
        local plot_pattern=$1
        local target_list=$2
        find "${region_hpath}" -maxdepth 1 -type f -name "${plot_pattern}" 2>/dev/null | sort | while IFS= read -r plot_file; do
            if [ -n "$plot_file" ] && ! grep -qF "$plot_file" "${target_list}"; then
                echo "$plot_file" >> "${target_list}"
                log "Added plot to TeX list: $(basename $plot_file)"
            fi
        done
    }
    
    # Helper function to generate TeX frames for a plot list
    generate_tex_frames() {
        local plot_list_file=$1
        local output_tex_file=$2
        local var_name_for_title=$3
        
        if [ -s "${plot_list_file}" ]; then
            while IFS= read -r plot_path; do
                plot_filename=$(basename -- "$plot_path")
                var_name_tex=$(format_var_name_tex "$var_name_for_title")
                title_prefix=""
                
                # Determine title prefix
                case "$plot_filename" in
                    *_timeseries.*) title_prefix="Collocation Time Series" ;;
                    *_diurnal.*) title_prefix="Collocation Diurnal Cycle" ;;
                    *_density.*) title_prefix="Collocation Data Density" ;;
                    *_meantimescores_*) title_prefix="Collocation Mean Time Scores" ;;
                    *_medianstationscores_*) title_prefix="Collocation Median Station Scores" ;;
                    *_timescores_*) title_prefix="Collocation Time Scores" ;;
                    *_stationscores.*) title_prefix="Collocation Station Scores" ;;
                    *_taylor.*) title_prefix="Collocation Taylor Diagram" ;;
                    *_scorequartiles.*) title_prefix="Collocation Score Quartiles" ;;
                    *_scatter.*) title_prefix="Collocation Comparison Scatter" ;;
                    *_scoredensity.*) title_prefix="Collocation Station Score Density" ;;
                    *_barscores.*) title_prefix="Collocation Bar Scores" ;;
                    *_barexceed.*) title_prefix="Collocation Bar Exceedances" ;;
                    *_lineexceed.*) title_prefix="Collocation Line Exceedances" ;;
                    *_contingency.*) title_prefix="Collocation Contingency Table" ;;
                    *_valuescatter.*) title_prefix="Collocation Value Scatter Plot" ;;
                    *) title_prefix="Evaltools Plot" ;;
                esac
                
                # Build experiments title
                local experiments_title=$(IFS=" vs "; echo "${region_experiments[*]}")
                local exps_tex=$(echo "$experiments_title" | sed 's/_/\\_/g')
                local tREGION=$(echo "${region_name}" | sed 's/_/\\_/g')
                title_final="${title_prefix}: ${exps_tex}"
#               title_final="${title_prefix} for ${var_name_tex} (${tREGION}): ${exps_tex}"
                
                cat >> "${output_tex_file}" <<EOF
%===============================================================================
\frame{
\frametitle{${title_final}}
\vspace{0mm}
\centering
\includegraphics[width=${EVALTOOLS_TEX_IMAGE_WIDTH:-0.9}\textwidth]{${plot_path}}
}
EOF
                log "Generated TeX frame for $plot_filename"
            done < "${plot_list_file}"
        fi
    }
    
    # Loop through each variable to create per-variable TeX files
    for var in "${region_variables[@]}"; do
        log "Processing variable: ${var} for region ${region_name}"
        
        # Create per-variable tex and list files in base directory
        local var_texfile="${base_hpath}/texPlotfiles_${QLTYPE}_${region_name}_${var}.tex"
        local var_plotlist="${base_hpath}/texPlotfiles_${QLTYPE}_${region_name}_${var}.list"
        
        rm -f "${var_plotlist}" "${var_texfile}"
        touch "${var_plotlist}"
        
        # Detect what format was actually created by checking existing files
        # Check common formats: png, pdf, svg, jpg
        local actual_format=""
        local format_candidates=("png" "pdf" "svg" "jpg" "jpeg")
        if [ -n "$PLOTEXTENSION" ]; then
            # Prefer the configured format
            IFS=',' read -ra configured_formats <<< "$PLOTEXTENSION"
            format_candidates=("${configured_formats[0]}" "${format_candidates[@]}")
        fi
        
        # Check for any plot file with this variable name to detect format
        for fmt in "${format_candidates[@]}"; do
            local test_file=$(find "${region_hpath}" -maxdepth 1 -type f -name "${EVALUATION_PREFIX}_${region_name}_${var}_*.${fmt}" 2>/dev/null | head -1)
            if [ -n "$test_file" ] && [ -f "$test_file" ]; then
                actual_format="$fmt"
                break
            fi
        done
        
        if [ -z "$actual_format" ]; then
            # Fallback to tex_plot_format if no files found
            actual_format="$tex_plot_format"
            log "  Warning: No plot files found for ${var}, using default format: ${actual_format}"
        fi
        
        log "  Processing all ${actual_format} plots for variable ${var}"
        
        # Add plots in predefined order (matching plot generation order)
        # Only match qlc_E2_evaltools_* files (not D1-ANAL plots)
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*timeseries*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*diurnal*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*density*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*meantimescores*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*medianstationscores*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*timescores*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*stationscores*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*taylor*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*scorequartiles*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*scoredensity*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*barscores*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*barexceed*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*lineexceed*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*contingency*.${actual_format}" "${var_plotlist}"
        add_plot_if_found "${EVALUATION_PREFIX}_${region_name}_${var}_*valuescatter*.${actual_format}" "${var_plotlist}"
        
        # Generate per-variable TeX file header
        if [ -s "${var_plotlist}" ]; then
            # Format variable name with LaTeX math subscripts
            varname_tex=$(format_var_name_tex "${var}")
            local tREGION=$(echo "${region_name}" | sed 's/_/\\_/g')
            cat > "${var_texfile}" <<EOF
%===============================================================================
\section{Evaltools Analysis -- ${tREGION}}
\subsection{${varname_tex} -- ${mDate} (${TIME_AVERAGE})}
EOF
            
            # Generate frames for this variable
            generate_tex_frames "${var_plotlist}" "${var_texfile}" "${var}"
            
            per_variable_tex_files+=("${var_texfile}")
            log "Generated per-variable TeX file: ${var_texfile}"
        else
            log "No plots found for variable ${var} in region ${region_name}"
        fi
    done
    
    # Summary - count all E2-EVAL plot files (any extension)
    plot_count=$(find "${region_hpath}" -name "${EVALUATION_PREFIX}_${region_name}_*" -type f \( -name "*.png" -o -name "*.pdf" -o -name "*.svg" -o -name "*.jpg" -o -name "*.jpeg" \) 2>/dev/null | wc -l | tr -d ' ')
    log "✓ Created ${plot_count} evaltools plot(s) for region ${region_name}"
    
    log "Completed region: ${region_name}"
    return 0
}

# Function to detect and process multi-region mode
process_multi_region() {
    log "Multi-region mode detection..."
    
    # Check if base directory exists
    if [ ! -d "$base_hpath" ]; then
        log "Error: Base plots directory not found: ${base_hpath}"
        log "Please ensure qlc_D1-ANAL.sh and qlc_E1-ECOL.sh have been run successfully."
        exit 1
    fi
    
    # Look for region subdirectories
    local region_dirs=()
    local temp_file=$(mktemp)
    
    # Find directories and write to temp file
    find "${base_hpath}" -mindepth 1 -maxdepth 1 -type d 2>/dev/null > "$temp_file"
    
    # Read from temp file
    while IFS= read -r dir; do
        if [ -d "$dir" ]; then
            local region_name=$(basename "$dir")
            # Skip hidden directories
            if [[ ! "$region_name" =~ ^\. ]]; then
                region_dirs+=("$dir")
            fi
        fi
    done < "$temp_file"
    
    # Clean up temp file
    rm -f "$temp_file"
    
    if [ ${#region_dirs[@]} -eq 0 ]; then
        log "No region subdirectories found - processing base directory"
        # Process base directory as single region (legacy mode)
        generate_plots_for_region "${DEFAULT_REGION_NAME:-default}" "${base_hpath}"
    else
        log "Found ${#region_dirs[@]} region subdirectories - multi-region mode active"
        
        # Process each region
        local success_count=0
        local fail_count=0
        
        for region_dir in "${region_dirs[@]}"; do
            local region_name=$(basename "$region_dir")
            
            if generate_plots_for_region "${region_name}" "${region_dir}"; then
                success_count=$((success_count + 1))
            else
                fail_count=$((fail_count + 1))
            fi
        done
        
        log "========================================"
        log "Multi-region plot generation complete"
        log "  Successful: ${success_count}"
        log "  Failed/Skipped: ${fail_count}"
        log "========================================"
        
        if [ ${success_count} -eq 0 ]; then
            log "Error: No regions were processed successfully"
            exit 1
        fi
        
        # Per-variable TeX files are already created in base directory
        # No need for combined TeX file - Z1-XPDF will collect per-variable files
        log "Per-variable TeX files created in base directory: ${base_hpath}"
    fi
    
    return 0
}

# ============================================================================
# MAIN EXECUTION
# ============================================================================

log "Starting evaltools plot generation..."
log "Base directory: ${base_hpath}"
log "Debug mode: ${DEBUG_MODE}"

# Process regions (auto-detects multi-region vs single-region)
process_multi_region

log "========================================================================================"
log "Plot Generation Complete"
log "========================================================================================"
log "Output directory: ${base_hpath}"
log "Next step: qlc_Z1-XPDF.sh will compile plots into PDF presentation"
log "========================================================================================"

log "$ANALYSIS_DIRECTORY"
log "$PLOTS_DIRECTORY"

log  "----------------------------------------------------------------------------------------"
log  "End ${SCRIPT} at `date`"
log  "________________________________________________________________________________________"

exit 0
