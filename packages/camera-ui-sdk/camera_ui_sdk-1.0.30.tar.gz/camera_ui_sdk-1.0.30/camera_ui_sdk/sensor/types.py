"""Core sensor types and enums."""

from __future__ import annotations

from enum import Enum
from typing import Literal, NotRequired, TypedDict

from ..camera.detection import DetectionLabel

# ========== Sensor Types ==========


class SensorType(str, Enum):
    """Sensor Type Enum - identifies the type of sensor/control/trigger/info."""

    # Detection Sensors
    Motion = "motion"
    Object = "object"
    Audio = "audio"
    Face = "face"
    LicensePlate = "licensePlate"
    Classifier = "classifier"  # Custom classifier (Multi-Provider)
    Contact = "contact"

    # Controls
    Light = "light"
    Siren = "siren"
    Switch = "switch"
    PTZ = "ptz"
    SecuritySystem = "securitySystem"

    # Triggers
    Doorbell = "doorbell"

    # Info
    Battery = "battery"


class SensorCategory(str, Enum):
    """Sensor Category - categorizes sensors by their behavior."""

    Sensor = "sensor"  # Detection sensors (read-only, 1 provider)
    Control = "control"  # Bidirectional controls
    Trigger = "trigger"  # Event-based triggers
    Info = "info"  # Read-only hardware status


# ========== Model Specification for Detectors ==========


class VideoInputSpec(TypedDict):
    """Video input specification for frame-based detection."""

    width: int  # Target frame width in pixels
    height: int  # Target frame height in pixels
    format: Literal["rgb", "nv12", "gray"]  # Pixel format


class ObjectModelSpec(TypedDict):
    """
    Model specification for Object Detector sensors.

    Only defines input format - Object detectors use fixed base labels (COCO classes etc.)
    and do NOT extend the label system.

    Example:
        # Object Detection - uses fixed COCO labels
        object_model_spec: ObjectModelSpec = {
            "input": {"width": 640, "height": 640, "format": "rgb"},
        }
    """

    input: VideoInputSpec  # Video input requirements


class ModelSpec(TypedDict):
    """
    Model specification for secondary detector sensors (Face, LicensePlate, Classifier).

    Defines input format, output labels, and trigger labels for cascade detection.
    Only these sensor types can extend the label system.

    Example:
        # Face Detection (triggers on 'person' label)
        face_model_spec: ModelSpec = {
            "input": {"width": 160, "height": 160, "format": "rgb"},
            "outputLabels": ["face", "unknown_face"],
            "triggerLabels": ["person"],
        }

        # Custom Classifier (triggers on specific label)
        bird_model_spec: ModelSpec = {
            "input": {"width": 224, "height": 224, "format": "rgb"},
            "outputLabels": ["sparrow", "eagle", "crow"],
            "triggerLabels": ["bird"],
        }
    """

    input: VideoInputSpec  # Video input requirements
    outputLabels: list[str]  # Labels this detector can output
    triggerLabels: list[str]  # Labels from Object Detection that trigger this detector (required)


class AudioInputSpec(TypedDict):
    """Audio input properties for audio-based detection."""

    sampleRate: int  # Sample rate in Hz (e.g., 16000, 44100)
    channels: int  # Number of channels (1 = mono, 2 = stereo)
    format: Literal["pcm16", "float32"]  # Audio format


class AudioModelSpec(TypedDict):
    """
    Model specification for audio detector sensors.

    Defines input format and output labels for audio-based detection.

    Example:
        # Glass Break Detector
        glass_break_model_spec: AudioModelSpec = {
            "input": {"sampleRate": 16000, "channels": 1, "format": "pcm16"},
            "outputLabels": ["glass_break", "silence"],
        }

        # General Audio Classifier
        audio_classifier_model_spec: AudioModelSpec = {
            "input": {"sampleRate": 44100, "channels": 1, "format": "float32"},
            "outputLabels": ["scream", "gunshot", "dog_bark", "baby_cry"],
        }
    """

    input: AudioInputSpec  # Audio input requirements
    outputLabels: list[str]  # Labels this audio detector can output
    # Note: Audio detectors don't have triggerLabels (no cascade detection)


# ========== Core Detection Types ==========


class BoundingBox(TypedDict):
    """Bounding box for object detection (normalized 0-1)."""

    x: float  # X coordinate (0-1, relative to image width)
    y: float  # Y coordinate (0-1, relative to image height)
    width: float  # Width (0-1, relative to image width)
    height: float  # Height (0-1, relative to image height)


class Detection(TypedDict):
    """Detection result from object/motion/audio detection."""

    label: DetectionLabel  # Detection label (base category or plugin-provided)
    confidence: float  # Detection confidence (0-1)
    box: BoundingBox  # Bounding box
    sourcePluginId: NotRequired[str]  # Source plugin ID
    zone: NotRequired[str]  # Zone name (if detection zone matched)


# ========== Specialized Detection Types ==========


class FaceLandmarks(TypedDict):
    """Face landmarks."""

    leftEye: tuple[float, float]
    rightEye: tuple[float, float]
    nose: tuple[float, float]
    leftMouth: tuple[float, float]
    rightMouth: tuple[float, float]


class FaceDetection(Detection):
    """Face detection with identity info."""

    identity: NotRequired[str]  # Face identity (if recognized)
    embedding: NotRequired[list[float]]  # Face embedding vector
    landmarks: NotRequired[FaceLandmarks]  # Landmarks (eyes, nose, mouth)


class LicensePlateDetection(Detection):
    """License plate detection."""

    plateText: str  # Plate text (OCR result)
    plateConfidence: float  # Plate confidence


# ========== PTZ Types ==========


class PTZPosition(TypedDict):
    """PTZ Position."""

    pan: float  # Pan angle (-180 to 180)
    tilt: float  # Tilt angle (-90 to 90)
    zoom: float  # Zoom level (0 to 1)


class PTZDirection(TypedDict):
    """PTZ Movement direction (for continuous movement)."""

    panSpeed: float  # Pan speed (-1 to 1, negative = left)
    tiltSpeed: float  # Tilt speed (-1 to 1, negative = down)
    zoomSpeed: float  # Zoom speed (-1 to 1, negative = out)


# ========== Battery Types ==========


class ChargingState(str, Enum):
    """Charging state for battery."""

    NotChargeable = "NOT_CHARGEABLE"
    NotCharging = "NOT_CHARGING"
    Charging = "CHARGING"
    Full = "FULL"


# ========== Event Types ==========


class PropertyChangedEvent(TypedDict):
    """Property changed event."""

    cameraId: str
    sensorId: str
    sensorType: SensorType
    property: str  # SensorPropertyType
    value: object
    previousValue: NotRequired[object]
    timestamp: int


class StoredSensorData(TypedDict):
    """Stored sensor data (for sensor:added event)."""

    id: str
    type: SensorType
    name: str  # Stable name (set by plugin, used for storage key)
    displayName: str  # Display name for UI/HomeKit
    pluginId: NotRequired[str]
    properties: dict[str, object]
    capabilities: NotRequired[list[str]]
    requiresFrames: NotRequired[bool]
    # Model specification for detector sensors:
    # - ObjectModelSpec: For ObjectDetectorSensor (input only)
    # - ModelSpec: For secondary detectors (Face, LicensePlate, Classifier) with outputLabels/triggerLabels
    # - AudioModelSpec: For AudioDetectorSensor with outputLabels
    modelSpec: NotRequired[ObjectModelSpec | ModelSpec | AudioModelSpec]


class SensorRefreshedState(TypedDict):
    """Sensor refreshed state (for sensor:added event and getSensorStates RPC)."""

    type: SensorType
    properties: dict[str, object]
    capabilities: list[str]
    displayName: NotRequired[str]


class SensorAddedEvent(TypedDict):
    """Sensor added event - emitted when a new sensor is registered."""

    cameraId: str
    sensor: StoredSensorData
    state: SensorRefreshedState


class SensorRemovedEvent(TypedDict):
    """Sensor removed event - emitted when a sensor is unregistered."""

    cameraId: str
    sensorId: str
    sensorType: SensorType


class SensorCapabilitiesChangedEvent(TypedDict):
    """Sensor capabilities changed event."""

    cameraId: str
    sensorId: str
    capabilities: list[str]
