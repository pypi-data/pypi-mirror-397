Metadata-Version: 2.4
Name: nexus-aidos-brain
Version: 0.1.0
Summary: Core Conversational AI Engine for the Nexus Ecosystem
Home-page: https://github.com/nexusaihub/NEXUS-AIDOS-BRAIN
Author: Nexus AI Hub Team
Author-email: support@nexusaihub.com
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.8
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Requires-Python: >=3.8
Description-Content-Type: text/markdown
License-File: LICENSE
Requires-Dist: langchain<0.2.0,>=0.1.20
Requires-Dist: langchain-core<0.2.0,>=0.1.52
Requires-Dist: langchain-community<0.1.0,>=0.0.38
Requires-Dist: langchain-openai<0.2.0,>=0.1.7
Requires-Dist: langgraph<0.1.0,>=0.0.55
Requires-Dist: qdrant-client<2.0.0,>=1.7.0
Requires-Dist: sentence-transformers<4.0.0,>=3.0.0
Requires-Dist: redis[hiredis]<6.0.0,>=5.0.0
Requires-Dist: numpy<2.0.0,>=1.26.0
Requires-Dist: scikit-learn<2.0.0,>=1.5.0
Requires-Dist: tiktoken<1.0.0,>=0.5.0
Requires-Dist: requests<3.0.0,>=2.31.0
Requires-Dist: certifi>=2024.0.0
Provides-Extra: dev
Requires-Dist: pytest>=7.0.0; extra == "dev"
Requires-Dist: pytest-cov>=4.0.0; extra == "dev"
Requires-Dist: black>=23.0.0; extra == "dev"
Requires-Dist: flake8>=6.0.0; extra == "dev"
Requires-Dist: mypy>=1.0.0; extra == "dev"
Provides-Extra: docs
Requires-Dist: sphinx>=6.0.0; extra == "docs"
Requires-Dist: sphinx-rtd-theme>=1.0.0; extra == "docs"
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: license-file
Dynamic: provides-extra
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# NEXUS-AIDOS-BRAIN ğŸ§ 

**The Core Conversational AI Engine for the Nexus Ecosystem**

NEXUS-AIDOS-BRAIN is a production-ready Python library that provides the foundational AI capabilities for building intelligent conversational systems. Built on LangChain and LangGraph, it offers a modular, extensible architecture for implementing RAG (Retrieval-Augmented Generation), memory management, semantic caching, and multi-agent workflows.

## ğŸŒŸ Features

### Core Capabilities
- **ğŸ”— Conversational RAG Pipeline**: Context-aware document retrieval with conversation memory
- **ğŸ§  Multi-tier Memory Management**: Redis-backed conversation history with buffer and summary modes
- **âš¡ Semantic Caching**: Intelligent response caching with embedding-based similarity matching
- **ğŸ¯ Custom Retrievers**: Flexible retrieval architecture supporting multiple vector stores (Qdrant)
- **ğŸ¤– Agent Orchestration**: LangGraph-based multi-agent workflows with state management
- **ğŸ“Š Workspace Isolation**: Multi-tenant support with workspace-based data segregation

### Advanced Features
- **Query Enhancement**: Prompt-style context injection without additional LLM calls
- **Source Tracking**: Complete provenance tracking for retrieved documents
- **Configurable Chunking**: Token-based text chunking with overlap for optimal retrieval
- **OpenRouter Integration**: Support for 200+ LLM models via OpenRouter
- **Production Ready**: Comprehensive logging, error handling, and monitoring

## ğŸ—ï¸ Architecture

```
nexus_aidos/
â”œâ”€â”€ core/              # Core conversational engine
â”‚   â”œâ”€â”€ engine.py      # Main conversational engine
â”‚   â””â”€â”€ pipeline.py    # RAG pipeline orchestration
â”œâ”€â”€ memory/            # Memory management
â”‚   â”œâ”€â”€ redis_memory.py    # Redis-backed conversation memory
â”‚   â””â”€â”€ buffer_memory.py   # Buffer and summary memory
â”œâ”€â”€ retrieval/         # Document retrieval
â”‚   â”œâ”€â”€ retrievers.py      # Custom retriever implementations
â”‚   â””â”€â”€ embeddings.py      # Embedding generation
â”œâ”€â”€ cache/             # Caching services
â”‚   â”œâ”€â”€ semantic_cache.py  # Semantic similarity caching
â”‚   â””â”€â”€ exact_cache.py     # Exact match caching
â”œâ”€â”€ chains/            # LangChain components
â”‚   â”œâ”€â”€ rag_chain.py       # Conversational RAG chain
â”‚   â””â”€â”€ query_transform.py # Query transformation
â”œâ”€â”€ config/            # Configuration management
â”‚   â””â”€â”€ settings.py        # Configuration classes
â””â”€â”€ utils/             # Utilities
    â”œâ”€â”€ logging.py         # Logging utilities
    â””â”€â”€ workspace.py       # Workspace utilities
```

## ğŸš€ Quick Start

### Installation

```bash
pip install -e ./NEXUS-AIDOS-BRAIN
```

### Basic Usage

```python
from nexus_aidos import NexusEngine
from nexus_aidos.config import EngineConfig

# Initialize the engine
config = EngineConfig(
    redis_url="redis://localhost:6379",
    qdrant_url="https://your-qdrant-instance.com",
    qdrant_api_key="your-api-key",
    openrouter_api_key="your-openrouter-key"
)

engine = NexusEngine(config)

# Simple conversation
response = engine.chat(
    message="What is the revenue growth?",
    workspace_id="workspace_123"
)
print(response["answer"])
```

### RAG-Enhanced Conversation

```python
from nexus_aidos import RAGPipeline

# Initialize RAG pipeline
rag = RAGPipeline(
    workspace_id="workspace_123",
    model="gpt-4o",
    top_k=5,
    threshold=0.5
)

# Ask questions with context
response = rag.ask(
    "What were the key findings?",
    return_metadata=True
)

print(f"Answer: {response['answer']}")
print(f"Sources: {len(response['source_documents'])} documents")
```

## ğŸ“– Documentation

- [Full API Reference](docs/API.md)
- [Architecture Guide](docs/ARCHITECTURE.md)
- [Integration Guide](docs/INTEGRATION.md)
- [Examples](examples/)

## ğŸ¢ Integration with NEXUSBRAIN

This library is designed to integrate seamlessly with the NEXUSBRAIN project:

```python
# In your Flask app (server/app.py)
from nexus_aidos import NexusEngine
from nexus_aidos.config import EngineConfig

# Initialize engine
config = EngineConfig.from_env()
nexus_engine = NexusEngine(config)

@app.route('/api/chat', methods=['POST'])
def chat():
    workspace_id = request.user.get('workspace_id')
    message = request.json.get('message')
    
    response = nexus_engine.chat(
        message=message,
        workspace_id=workspace_id,
        use_rag=True,
        use_cache=True
    )
    
    return jsonify(response)
```

---

**Made with â¤ï¸ by the Nexus AI Hub Team**
