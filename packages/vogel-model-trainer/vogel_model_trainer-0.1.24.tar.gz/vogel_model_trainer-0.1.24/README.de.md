# ğŸ¦ Vogel Model Trainer

**Sprachen:** [ğŸ‡¬ğŸ‡§ English](README.md) | [ğŸ‡©ğŸ‡ª Deutsch](README.de.md) | [ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª](README.ja.md)

<p align="left">
  <a href="https://pypi.org/project/vogel-model-trainer/"><img alt="PyPI version" src="https://img.shields.io/pypi/v/vogel-model-trainer.svg"></a>
  <a href="https://pypi.org/project/vogel-model-trainer/"><img alt="Python Versions" src="https://img.shields.io/pypi/pyversions/vogel-model-trainer.svg"></a>
  <a href="https://opensource.org/licenses/MIT"><img alt="License: MIT" src="https://img.shields.io/badge/License-MIT-yellow.svg"></a>
  <a href="https://pypi.org/project/vogel-model-trainer/"><img alt="PyPI Status" src="https://img.shields.io/pypi/status/vogel-model-trainer.svg"></a>
  <a href="https://pepy.tech/project/vogel-model-trainer"><img alt="Downloads" src="https://static.pepy.tech/badge/vogel-model-trainer"></a>
</p>

**Trainiere eigene Vogelarten-Klassifizierer aus deinen eigenen Video-Aufnahmen mit YOLOv8 und EfficientNet.**

Ein spezialisiertes Toolkit zum Erstellen von hochgenauen Vogelarten-Klassifizierern, die auf dein spezifisches Monitoring-Setup zugeschnitten sind. Extrahiere Trainingsdaten aus Videos, organisiere Datasets und trainiere eigene Modelle mit >96% Genauigkeit.

---

## âœ¨ Features

- ğŸ¯ **YOLO-basierte Vogelerkennung** - Automatisches Cropping von VÃ¶geln aus Videos und Bildern mit YOLOv8
- ğŸ–¼ï¸ **Bild-UnterstÃ¼tzung** - Extrahiere VÃ¶gel aus statischen Bildern (JPG, PNG, BMP, TIFF)
- ğŸ”„ **Konvertierungsmodus** - Normalisiere existierende Vogel-DatensÃ¤tze ohne Erkennung
- ğŸ¤– **Drei Extraktions-Modi** - Manuelle Beschriftung, Auto-Sortierung oder Standard-Extraktion
- ğŸ“ **Wildcard-UnterstÃ¼tzung** - Batch-Verarbeitung mehrerer Videos/Bilder mit Glob-Patterns
- ğŸ–¼ï¸ **Flexible BildgrÃ¶ÃŸen** - 224/384/448px oder OriginalgrÃ¶ÃŸe beibehalten
- ğŸ” **Erweiterte Filterung** - Box-GrÃ¶ÃŸe, UnschÃ¤rfe-Erkennung, SchÃ¤rfe, KantenschÃ¤rfe-Schwellen
- ğŸ”„ **Duplikat-Erkennung** - Perceptual Hashing entfernt Ã¤hnliche Bilder
- âœ… **QualitÃ¤tskontrolle** - Findet verschwommene, zu kleine, beschÃ¤digte oder schlecht belichtete Bilder
- ğŸ¨ **KI-Hintergrundentfernung** - Entfernt HintergrÃ¼nde mit grauem Standard fÃ¼r optimales Training
- ğŸ§¹ **Datensatz-Validierung** - Bereinigt transparente/graue DatensÃ¤tze mit automatisierten PrÃ¼fungen
- ğŸ§  **EfficientNet-B0 Training** - Leichtgewichtiges aber leistungsstarkes Modell
- ğŸ¨ **4-Level Data Augmentation** - None/Light/Medium/Heavy IntensitÃ¤tsstufen
- âš¡ **Mixed Precision Training** - FP16/BF16-UnterstÃ¼tzung fÃ¼r schnelleres GPU-Training
- ğŸ“Š **Erweiterte Training-Optionen** - 13 konfigurierbare Parameter fÃ¼r Feinabstimmung
- ğŸ”§ **Dataset-Deduplizierung** - Bereinige existierende Datasets mit Perceptual Hashing
- â¸ï¸ **Graceful Shutdown** - Modellzustand bei Strg+C-Unterbrechung speichern
- ğŸ¯ **Batch-Klassifizierung** - Klassifiziere tausende Bilder mit CSV-Export und Auto-Sortierung
- ğŸŒ **VollstÃ¤ndige i18n-UnterstÃ¼tzung** - Englisch, Deutsch, Japanisch
- ğŸ“ˆ **Pro-Art-Metriken** - Detaillierte Genauigkeits-AufschlÃ¼sselung pro Vogelart

## ğŸ¤– Vortrainiertes Modell

**Deutscher GartenvÃ¶gel-Klassifikator** - Sofort einsatzbereit!

Wir stellen vortrainierte Modelle auf Hugging Face zur Klassifizierung von 8 hÃ¤ufigen deutschen GartenvÃ¶geln bereit:

ğŸ”— **[kamera-linux/german-bird-classifier-v2](https://huggingface.co/kamera-linux/german-bird-classifier-v2)** â­ **Empfohlen**
- âœ… **99,71% Genauigkeit** - State-of-the-art Performance
- âœ… **Perfekte Klassifikation** fÃ¼r 5 von 8 Arten
- âœ… **EfficientNet-B2** - Hochgenaue Architektur

ğŸ”— **[kamera-linux/german-bird-classifier](https://huggingface.co/kamera-linux/german-bird-classifier)** (v1, veraltet)
- 87,69% Genauigkeit - Legacy-Modell fÃ¼r KompatibilitÃ¤t

**UnterstÃ¼tzte Arten:**
- Blaumeise
- GrÃ¼nling (GrÃ¼nfink)
- Haussperling
- KernbeiÃŸer
- Kleiber
- Kohlmeise
- Rotkehlchen
- Sumpfmeise

**Verwendung bei der Extraktion:**
```bash
vogel-trainer extract video.mp4 \
  --folder ~/training-data/ \
  --species-model kamera-linux/german-bird-classifier-v2 \
  --remove-background \
  --crop-padding 20 \
  --sample-rate 20 --skip-blurry --deduplicate \
  --min-sharpness 150 --min-edge-quality 80
```

Das Modell klassifiziert erkannte VÃ¶gel automatisch wÃ¤hrend der Extraktion!

---

## ğŸš€ Schnellstart

### Installation

#### Empfohlen: Virtuelle Umgebung verwenden

```bash
# Installiere venv falls nÃ¶tig (Debian/Ubuntu)
sudo apt install python3-venv

# Virtuelle Umgebung erstellen
python3 -m venv ~/venv-vogel

# Aktivieren
source ~/venv-vogel/bin/activate  # Windows: ~/venv-vogel\Scripts\activate

# Paket installieren
pip install vogel-model-trainer

# Auto-erkennung: Installiere richtige onnxruntime Version (GPU vs CPU)
python -c "$(curl -fsSL https://raw.githubusercontent.com/kamera-linux/vogel-model-trainer/main/scripts/setup_onnxruntime.py)"

# ODER manuell:
# FÃ¼r CUDA-Systeme (GPU): pip install vogel-model-trainer[gpu]
# FÃ¼r CPU-only (Raspberry Pi): pip install vogel-model-trainer[cpu]
```

#### Schnell-Installation

```bash
# Installation von PyPI
pip install vogel-model-trainer

# Richtiges onnxruntime fÃ¼r deine Hardware installieren
python scripts/setup_onnxruntime.py  # Auto-erkennt CUDA und installiert GPU/CPU Version

# Oder Installation aus Quellcode
git clone https://github.com/kamera-linux/vogel-model-trainer.git
cd vogel-model-trainer
pip install -e .
python scripts/setup_onnxruntime.py
```

**Hardware-UnterstÃ¼tzung:**
- ğŸ® **CUDA GPU** (NVIDIA) â†’ Verwendet `onnxruntime-gpu` (schnellere Hintergrundentfernung)
- ğŸ’» **CPU-only** (Raspberry Pi, ARM64, etc.) â†’ Verwendet `onnxruntime` (kompatibel)
```

### Grundlegender Workflow

```bash
# 1. Vogelbilder aus Videos extrahieren
vogel-trainer extract video.mp4 --folder ~/training-data/ --bird kohlmeise

# 2. In Train/Validation Split organisieren
vogel-trainer organize ~/training-data/ -o ~/organized-data/

# 3. Eigenen Klassifizierer trainieren
vogel-trainer train ~/organized-data/ -o ~/models/mein-classifier/

# 4. Das trainierte Modell testen
vogel-trainer test ~/models/mein-classifier/ -d ~/organized-data/
```

---

## ğŸ“– Nutzungsanleitung

### Als Library nutzen (Neu in v0.1.2)

Alle Core-Funktionen kÃ¶nnen jetzt programmatisch in deinem Python-Code verwendet werden:

```python
from vogel_model_trainer.core import extractor, organizer, trainer, tester

# VÃ¶gel aus Video extrahieren
extractor.extract_birds_from_video(
    video_path="video.mp4",
    output_dir="output/",
    bird_species="kohlmeise",
    detection_model="yolov8n.pt",
    species_model=None,
    threshold=0.5,
    sample_rate=3,
    resize_to_target=True
)

# VÃ¶gel aus statischen Bildern extrahieren (Neu in v0.1.16)
extractor.extract_birds_from_image(
    image_path="foto.jpg",
    output_dir="output/",
    bird_species="kohlmeise",
    detection_model="yolov8n.pt",
    remove_bg=True,
    bg_transparent=True
)

# Existierende Vogel-Crops konvertieren (Neu in v0.1.16)
stats = extractor.convert_bird_images(
    source_dir="rohdaten/",
    target_dir="verarbeitete-daten/",
    remove_bg=True,
    bg_transparent=True,
    crop_padding=10,
    min_sharpness=80,
    deduplicate=True
)
print(f"Konvertiert: {stats['converted']}, Ãœbersprungen: {stats['skipped_quality']}")

# In Train/Val Splits organisieren
organizer.organize_dataset(
    source_dir="output/",
    output_dir="dataset/",
    train_ratio=0.8
)

# Modell trainieren
trainer.train_model(
    data_dir="dataset/",
    output_dir="models/",
    model_name="google/efficientnet-b0",
    batch_size=16,
    num_epochs=50,
    learning_rate=3e-4
)

# Modell testen
results = tester.test_model(
    model_path="models/bird_classifier/",
    data_dir="dataset/"
)
print(f"Genauigkeit: {results['accuracy']:.2%}")
```

### 1. Trainingsbilder extrahieren

vogel-model-trainer unterstÃ¼tzt jetzt sowohl **Videos** als auch **statische Bilder** als Eingabequellen.

#### ğŸ¬ Video-Extraktion

Extrahiere Vogel-Crops aus Videodateien mit YOLO-Erkennung:

##### Manueller Modus (Empfohlen fÃ¼r erste Sammlung)

Wenn du die Art in deinem Video kennst:

```bash
vogel-trainer extract ~/Videos/kohlmeise.mp4 \
  --folder ~/training-data/ \
  --bird kohlmeise \
  --threshold 0.5 \
  --sample-rate 3
```

##### Auto-Sort Modus (FÃ¼r iteratives Training)

Nutze ein bestehendes Modell zum automatischen Klassifizieren und Sortieren:

```bash
vogel-trainer extract ~/Videos/gemischt.mp4 \
  --folder ~/training-data/ \
  --species-model ~/models/classifier/final/ \
  --threshold 0.5
```

#### Batch-Verarbeitung mit Wildcards

```bash
# Alle Videos in einem Verzeichnis verarbeiten
vogel-trainer extract "~/Videos/*.mp4" --folder ~/data/ --bird blaumeise

# Rekursive Verzeichnis-Suche
vogel-trainer extract ~/Videos/ \
  --folder ~/data/ \
  --bird amsel \
  --recursive
```

**Parameter:**
- `--folder`: Basis-Verzeichnis fÃ¼r extrahierte Bilder (erforderlich)
- `--bird`: Manuelle Arten-Beschriftung (erstellt Unterverzeichnis)
- `--species-model`: Pfad zu trainiertem Modell fÃ¼r Auto-Klassifizierung
- `--species-threshold`: Min. Confidence fÃ¼r Arten-Klassifizierung (z.B. 0.85 fÃ¼r 85%)
- `--threshold`: YOLO Confidence-Schwellwert (Standard: 0.5)
- `--sample-rate`: Verarbeite jeden N-ten Frame (Standard: 3)
- `--detection-model`: YOLO Modell-Pfad (Standard: yolov8n.pt)
- `--image-size`: Ziel-BildgrÃ¶ÃŸe in Pixeln (Standard: 224, 0 fÃ¼r OriginalgrÃ¶ÃŸe)
- `--max-detections`: Maximale Erkennungen pro Frame (Standard: 10)
- `--min-box-size`: Minimale Bounding-Box-GrÃ¶ÃŸe in Pixeln (Standard: 50)
- `--max-box-size`: Maximale Bounding-Box-GrÃ¶ÃŸe in Pixeln (Standard: 800)
- `--quality`: JPEG-QualitÃ¤t 1-100 (Standard: 95)
- `--skip-blurry`: Unscharfe/fokussierte Bilder Ã¼berspringen (experimentell)
- `--min-sharpness`: **NEU v0.1.9** - Min. SchÃ¤rfe-Score (Laplacian-Varianz, typisch 100-300)
- `--min-edge-quality`: **NEU v0.1.9** - Min. Kanten-QualitÃ¤t (Sobel-Gradient, typisch 50-150)
- `--save-quality-report`: **NEU v0.1.9** - Detaillierten QualitÃ¤tsbericht speichern
- `--remove-background`: **ğŸ§ª EXPERIMENTELL v0.1.11** - Hintergrund mit KI entfernen (rembg)
- `--crop-padding`: **NEU v0.1.15** - Pixel um Vogel herum erweitern (erhÃ¤lt Details wie FÃ¼ÃŸe/Schnabel)
- `--bg-color [white|black|gray]`: **ğŸ§ª EXPERIMENTELL v0.1.11** - Hintergrundfarbe (Standard: gray)
- `--bg-model [u2net|u2netp|isnet-general-use]`: **ğŸ§ª EXPERIMENTELL v0.1.11** - KI-Modell fÃ¼r Hintergrundentfernung (Standard: u2net)
- `--bg-transparent`: **NEU v0.1.14** - PNG mit transparentem Hintergrund erstellen (Standard: deaktiviert, grauer Hintergrund)
- `--no-bg-transparent`: **NEU v0.1.14** - Transparenz deaktivieren, farbigen Hintergrund verwenden (Standard)
- `--bg-fill-black`: **NEU v0.1.14** - Schwarze Padding-Bereiche transparent machen (benÃ¶tigt --bg-transparent, erhÃ¤lt schwarze Federn)
- `--no-bg-fill-black`: **NEU v0.1.14** - Schwarze Padding-Bereiche opak lassen (Standard)
- `--deduplicate`: Doppelte/Ã¤hnliche Bilder Ã¼berspringen (Perceptual Hashing)
- `--similarity-threshold`: Ã„hnlichkeits-Schwelle fÃ¼r Duplikate - Hamming-Distanz 0-64 (Standard: 5)
- `--recursive, -r`: Verzeichnisse rekursiv durchsuchen
- `--log`: Console-Output in Log-Datei speichern (`/var/log/vogel-kamera-linux/YYYY/KWXX/`)

**ğŸ’¡ Wichtig:** Verwende die gleiche `--image-size` beim Extrahieren wie spÃ¤ter beim Training fÃ¼r beste Ergebnisse!

**Erweiterte Filter-Beispiele:**

```bash
# HochqualitÃ¤ts-Extraktion mit allen Filtern (v0.1.15)
vogel-trainer extract video.mp4 \
  --folder data/ \
  --bird rotkehlchen \
  --threshold 0.6 \
  --min-box-size 80 \
  --max-box-size 600 \
  --min-sharpness 150 \
  --min-edge-quality 80 \
  --skip-blurry \
  --deduplicate \
  --save-quality-report \
  --remove-background \
  --crop-padding 20 \
  --bg-color gray \
  --bg-model u2net

# Hintergrundentfernung mit Detail-Erhaltung (empfohlen)
vogel-trainer extract video.mp4 \
  --folder data/ \
  --bird blaumeise \
  --remove-background \
  --crop-padding 20 \
  --bg-color gray \
  --bg-model isnet-general-use
```

#### ğŸ–¼ï¸ Bild-Extraktion (Neu in v0.1.16)

Extrahiere Vogel-Crops aus statischen Bildern (JPG, PNG, BMP, TIFF) mit YOLO-Erkennung:

```bash
# Einzelnes Bild
vogel-trainer extract foto.jpg --folder ~/training-data/ --bird amsel

# Mehrere Bilder mit Glob-Pattern
vogel-trainer extract "~/fotos/*.jpg" --folder ~/training-data/ --bird rotkehlchen

# Rekursive Verzeichnis-Suche
vogel-trainer extract ~/fotos/ \
  --folder ~/training-data/ \
  --bird blaumeise \
  --recursive

# Mit Hintergrundentfernung und QualitÃ¤tsfilterung
vogel-trainer extract foto.jpg \
  --folder ~/training-data/ \
  --bird kohlmeise \
  --remove-background \
  --bg-transparent \
  --crop-padding 10 \
  --min-sharpness 100 \
  --save-quality-report

# Auto-Klassifizierung mit trainiertem Modell
vogel-trainer extract foto.jpg \
  --folder ~/training-data/ \
  --species-model ~/models/classifier/final/ \
  --species-threshold 0.85

# Batch-Verarbeitung mit Auto-Sortierung
vogel-trainer extract "~/fotos/*.jpg" \
  --folder ~/training-data/ \
  --species-model kamera-linux/german-bird-classifier-v2 \
  --recursive
```

**Hinweis:** Alle Video-Extraktions-Parameter (Filterung, Hintergrundentfernung, QualitÃ¤tskontrolle) sind auch fÃ¼r die Bild-Extraktion verfÃ¼gbar.

**ğŸ§ª Hintergrundentfernung (EXPERIMENTELL v0.1.11+, Stabil v0.1.14):**

Das `--remove-background` Feature nutzt die KI-gestÃ¼tzte rembg-Bibliothek zur automatischen Vogelsegmentierung.

**NEU in v0.1.14:** Grauer Hintergrund ist jetzt STANDARD fÃ¼r optimales Training! Kleinere JPEG-Dateien, bessere KompatibilitÃ¤t.

**NEU in v0.1.15:** Crop-Padding Feature zur Erhaltung von Vogeldetails (FÃ¼ÃŸe, Schnabel, Federn)!

- **Crop-Padding (v0.1.15+):**
  - `--crop-padding N`: Erweitert die Vordergrundmaske um N Pixel rund um den erkannten Vogel
  - Verhindert den Verlust wichtiger Details (FÃ¼ÃŸe, Schnabel, Schwanzfedern) bei der Hintergrundentfernung
  - Empfohlener Wert: `20` Pixel fÃ¼r optimale Ergebnisse
  - Funktioniert nur mit `--remove-background` Flag
  - Beispiel: `--crop-padding 20` behÃ¤lt 20 zusÃ¤tzliche Pixel um den Vogel herum

- **Modelle:**
  - `u2net` (Standard): Beste GesamtqualitÃ¤t, ~180MB Download
  - `u2netp`: Schneller, kleineres Modell fÃ¼r schnelle Verarbeitung
  - `isnet-general-use`: Beste KantenqualitÃ¤t fÃ¼r detaillierte Federn

- **Hintergrundfarben (NEU STANDARD v0.1.14):**
  - `gray` (STANDARD): Neutraler grauer Hintergrund (#808080) - optimal fÃ¼rs Training
  - `white`: Sauberer weiÃŸer Hintergrund (#FFFFFF)
  - `black`: Kontrastreicher schwarzer Hintergrund (#000000)
  - `green-screen`: Chroma-Key GrÃ¼n (#00FF00)
  - `blue-screen`: Chroma-Key Blau (#0000FF)

- **Transparenz-Optionen:**
  - `--bg-transparent`: PNG mit Alpha-Kanal erstellen (flexibel aber grÃ¶ÃŸere Dateien)
  - `--no-bg-transparent` (STANDARD): Farbiger Hintergrund (kleinere JPEG-Dateien)
  - `--bg-fill-black`: Macht schwarze Box-Bereiche transparent (benÃ¶tigt --bg-transparent)
  - `--no-bg-fill-black` (STANDARD): Padding-Bereiche mit Hintergrundfarbe behalten

- **Funktionen:**
  - KI-basierte UÂ²-Net Segmentierung fÃ¼r prÃ¤zise Vogelisolierung
  - Alpha Matting fÃ¼r glatte, professionelle Kanten
  - Nachbearbeitung mit morphologischen Operationen
  - Funktioniert mit komplexen HintergrÃ¼nden (Ã„ste, BlÃ¤tter, GebÃ¤ude)
  - Arbeitet mit verschiedenem Vogelgefieder und feinen Federdetails
  - Speichert automatisch als PNG (transparent) oder JPEG (deckend)

- **Hinweis:** Erster Aufruf lÃ¤dt ~180MB Modell (danach gecached), benÃ¶tigt `rembg>=2.0.50` AbhÃ¤ngigkeit

**ğŸ’¡ Training mit transparenten HintergrÃ¼nden (NEU v0.1.15):**

Beim Training mit PNG-Bildern mit transparentem Hintergrund wendet der Trainer automatisch **zufÃ¤llige Hintergrund-Augmentierung** an:
- WÃ¤hrend des Trainings: Jedes Bild bekommt einen zufÃ¤lligen grau/schwarz/weiÃŸen Hintergrund
- WÃ¤hrend der Validierung/Tests: Konsistenter neutraler grauer Hintergrund
- **Vorteil**: Modell lernt sich auf Vogelmerkmale zu konzentrieren, nicht auf Hintergrundfarbe
- **Ergebnis**: Robusterer Klassifikator, der mit jedem Hintergrund funktioniert

Um dieses Feature zu nutzen, einfach mit `--remove-background --bg-transparent` extrahieren:
```bash
# Extraktion mit transparenten HintergrÃ¼nden
vogel-trainer extract video.mp4 \
  --folder data/ \
  --bird rotkehlchen \
  --remove-background \
  --crop-padding 20 \
  --bg-transparent \
  --sample-rate 30

# Training - zufÃ¤llige HintergrÃ¼nde werden automatisch angewendet!
vogel-trainer train data/ --output-dir models/
```

**ğŸ’¡ Best Practice fÃ¼r Ã¶ffentliche Modelle:**
```bash
# Empfohlene Einstellungen fÃ¼r neutralen Datensatz (v0.1.15)
# Mit festem grauen Hintergrund (kleinere Dateien, konsistent)
vogel-trainer extract video.mp4 \
  --folder data/ \
  --bird rotkehlchen \
  --remove-background \
  --crop-padding 20 \
  --bg-color gray \
  --sample-rate 30 \
  --skip-blurry \
  --deduplicate \
  --save-quality-report \
  --quality 98

# Extraktion mit Duplikat-Erkennung (verhindert Ã¤hnliche Bilder)
vogel-trainer extract ~/Videos/*.mp4 \
  --folder data/ \
  --bird kohlmeise \
  --deduplicate \
  --similarity-threshold 3

# GroÃŸe BildgrÃ¶ÃŸe fÃ¼r hochdetailliertes Training
vogel-trainer extract video.mp4 \
  --folder data/ \
  --bird amsel \
  --image-size 384

# Auto-Sortierung mit Confidence-Filter (nur hochsichere Klassifizierungen)
vogel-trainer extract video.mp4 \
  --folder data/ \
  --species-model ~/models/classifier/ \
  --species-threshold 0.90 \
  --deduplicate
```

**Logging-Beispiel:**

```bash
# Output in Log-Datei speichern
vogel-trainer extract ~/Videos/kohlmeise.mp4 \
  --folder ~/data/ \
  --bird kohlmeise \
  --log

# Log-Datei-Pfad: /var/log/vogel-kamera-linux/2025/KW45/20251109_160000_extract.log
```

### 1b. Transparente Bilder bereinigen (NEU v0.1.12) ğŸ§¹

Nach der Extraktion mit `--remove-background` kÃ¶nnen fragmentierte oder unvollstÃ¤ndige VÃ¶gel mit `clean-transparent` entfernt werden:

```bash
# Sicherer Modus: Nur Bericht (keine Dateien geÃ¤ndert)
vogel-trainer clean-transparent ~/training-data/ --mode report

# Verschiebe ungÃ¼ltige Bilder in invalid_transparent/ Ordner
vogel-trainer clean-transparent ~/training-data/ --mode move

# Permanentes LÃ¶schen ungÃ¼ltiger Bilder
vogel-trainer clean-transparent ~/training-data/ --mode delete

# Rekursiver Scan durch alle Unterverzeichnisse
vogel-trainer clean-transparent ~/training-data/ --mode move --recursive

# Eigene Schwellwerte
vogel-trainer clean-transparent ~/training-data/ \
  --min-pixels 1000 \
  --max-transparency 0.90 \
  --min-region 200 \
  --mode move
```

### 1b. Datensatz-Bilder bereinigen (NEU v0.1.12+) ğŸ§¹

**Transparente Bilder bereinigen** - FÃ¼r transparente PNG-DatensÃ¤tze:

```bash
# Sicherer Modus: Nur Bericht (keine Dateien geÃ¤ndert)
vogel-trainer clean-transparent ~/training-data/ --mode report

# UngÃ¼ltige Bilder in invalid_transparent/ verschieben
vogel-trainer clean-transparent ~/training-data/ --mode move --recursive
```

**Bilder mit grauem Hintergrund bereinigen (NEU v0.1.14)** - FÃ¼r graue Hintergrund-DatensÃ¤tze:

```bash
# Grau-Hintergrund-Anteil prÃ¼fen
vogel-trainer clean-gray ~/training-data/ --mode report

# Bilder mit falschem Grau-Anteil nach invalid_gray/ verschieben
vogel-trainer clean-gray ~/training-data/ --mode move --recursive

# Benutzerdefinierte Schwellenwerte
vogel-trainer clean-gray ~/training-data/ \
  --min-gray 0.10 \
  --max-gray 0.90 \
  --gray-tolerance 30 \
  --mode move
```

**Erkennungskriterien:**

*clean-transparent:*
- **Min. sichtbare Pixel** (`--min-pixels`, Standard: 500): Minimum nicht-transparente Pixel
- **Max. Transparenz** (`--max-transparency`, Standard: 0.95): Maximal 95% Transparenz erlaubt
- **Min. RegiongrÃ¶ÃŸe** (`--min-region`, Standard: 100): Minimale GrÃ¶ÃŸe des grÃ¶ÃŸten zusammenhÃ¤ngenden Objekts

*clean-gray:*
- **Min. Grau-Anteil** (`--min-gray`, Standard: 0.05): Mindestens 5% grauer Hintergrund erforderlich
- **Max. Grau-Anteil** (`--max-gray`, Standard: 0.95): Maximal 95% Grau erlaubt (Vogel muss sichtbar sein)
- **Grau-Toleranz** (`--gray-tolerance`, Standard: 30): Toleranz fÃ¼r Grau-Erkennung (Râ‰ˆGâ‰ˆBÂ±30)

**AnwendungsfÃ¤lle:**
- Winzige Fragmente nach Hintergrundentfernung entfernen
- Partielle Erkennungen bereinigen (Vogel flog aus dem Bild)
- Bilder mit zu viel/wenig Hintergrund eliminieren
- Bilder finden, wo Vogel kaum sichtbar oder fehlend ist

### 2. Dataset organisieren

```bash
# Basis-Organisation (80/20 Split)
vogel-trainer organize ~/training-data/ -o ~/organized-data/

# Mit Class Balance Kontrolle (NEU in v0.1.8)
vogel-trainer organize ~/training-data/ -o ~/organized-data/ \
  --max-images-per-class 100 \
  --tolerance 15.0
```

**Class Balance Features:**
- `--max-images-per-class N`: Limitiert auf N Bilder pro Klasse, lÃ¶scht Ã¼berschÃ¼ssige
- `--tolerance N`: Maximal erlaubtes Ungleichgewicht % (Standard: 15)
  - < 10%: âœ… Perfekt
  - 10-15%: âš ï¸ Warnung
  - > 15%: âŒ Fehler mit Empfehlungen

Erstellt einen 80/20 Train/Validation Split:
```
organized/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ kohlmeise/
â”‚   â”œâ”€â”€ blaumeise/
â”‚   â””â”€â”€ rotkehlchen/
â””â”€â”€ val/
    â”œâ”€â”€ kohlmeise/
    â”œâ”€â”€ blaumeise/
    â””â”€â”€ rotkehlchen/
```

### 3. Klassifizierer trainieren

```bash
vogel-trainer train organized-data/ -o models/
```

**Erweiterte Optionen:**
```bash
vogel-trainer train organized-data/ -o models/ \
  --epochs 100 \
  --batch-size 32 \
  --learning-rate 1e-4 \
  --early-stopping-patience 5 \
  --weight-decay 0.02 \
  --augmentation-strength heavy \
  --image-size 384 \
  --scheduler cosine \
  --mixed-precision fp16 \
  --log
```

**VerfÃ¼gbare Parameter:**
- `--model` - Basis-Modell (Standard: `google/efficientnet-b0`)
- `--batch-size` - Batch-GrÃ¶ÃŸe (Standard: `16`)
- `--epochs` - Anzahl Epochen (Standard: `50`)
- `--learning-rate` - Learning Rate (Standard: `2e-4`)
- `--early-stopping-patience` - Early Stopping Geduld in Epochen (Standard: `5`, `0` zum Deaktivieren)
- `--weight-decay` - Weight Decay fÃ¼r Regularisierung (Standard: `0.01`)
- `--warmup-ratio` - Learning Rate Warmup Ratio (Standard: `0.1`)
- `--label-smoothing` - Label Smoothing Faktor (Standard: `0.1`, `0` zum Deaktivieren)
- `--save-total-limit` - Maximale Anzahl zu behaltender Checkpoints (Standard: `3`)
- `--augmentation-strength` - Data Augmentation IntensitÃ¤t: `none`, `light`, `medium`, `heavy` (Standard: `medium`)
- `--image-size` - EingabebildgrÃ¶ÃŸe in Pixeln (Standard: `224`)
- `--scheduler` - Learning Rate Scheduler: `cosine`, `linear`, `constant` (Standard: `cosine`)
- `--seed` - Random Seed fÃ¼r Reproduzierbarkeit (Standard: `42`)
- `--resume-from-checkpoint` - Pfad zu Checkpoint um Training fortzusetzen
- `--gradient-accumulation-steps` - Gradient Accumulation Schritte (Standard: `1`)
- `--mixed-precision` - Mixed Precision Training: `no`, `fp16`, `bf16` (Standard: `no`)
- `--push-to-hub` - Trainiertes Modell zu HuggingFace Hub hochladen
- `--log` - Console-Output in Log-Datei speichern

**Augmentation-Stufen:**
- **none** - Keine Augmentation (nur Normalisierung)
- **light** - Kleine Rotationen (Â±10Â°), minimale Color Jitter
- **medium** (Standard) - Moderate Rotationen (Â±20Â°), Affine-Transforms, Color Jitter, Gaussian Blur
- **heavy** - Starke Rotationen (Â±30Â°), aggressive Transforms, starke Farbvariationen

**Mixed Precision Training:**
- `fp16` - 16-bit Floating Point (ca. 2x schneller auf modernen GPUs, benÃ¶tigt Ampere/Volta)
- `bf16` - Brain Float 16 (bessere numerische StabilitÃ¤t, benÃ¶tigt neueste GPUs)
- `no` - VollstÃ¤ndige 32-bit PrÃ¤zision (am langsamsten, aber kompatibel)

**Erweiterte Training-Beispiele:**

```bash
# Hochgenauigkeits-Training mit groÃŸen Bildern und Heavy Augmentation
vogel-trainer train ~/organized-data/ \
  -o ~/models/high-accuracy/ \
  --image-size 384 \
  --augmentation-strength heavy \
  --epochs 100 \
  --early-stopping-patience 10 \
  --batch-size 8

# Schnelles Training mit Mixed Precision (benÃ¶tigt GPU)
vogel-trainer train ~/organized-data/ \
  -o ~/models/fast/ \
  --mixed-precision fp16 \
  --batch-size 32 \
  --gradient-accumulation-steps 2

# Reproduzierbares Training mit festem Seed
vogel-trainer train ~/organized-data/ \
  -o ~/models/reproducible/ \
  --seed 12345 \
  --augmentation-strength light

# Unterbrochenes Training fortsetzen
vogel-trainer train ~/organized-data/ \
  -o ~/models/continued/ \
  --resume-from-checkpoint ~/models/my-classifier/checkpoints/checkpoint-1000

# Training mit Logging
vogel-trainer train ~/organized-data/ \
  -o ~/models/logged/ \
  --log
```

**Training-Konfiguration:**
- Basis-Modell: `google/efficientnet-b0` (8.5M Parameter)
- Optimizer: AdamW mit konfigurierbarem LR Schedule
- Augmentation: 4 IntensitÃ¤tsstufen (none/light/medium/heavy)
- Regularisierung: Weight Decay, Label Smoothing, Early Stopping
- Mixed Precision: FP16/BF16-UnterstÃ¼tzung fÃ¼r schnelleres GPU-Training

**Output:**
```
~/models/bird-classifier-20251108_143000/
â”œâ”€â”€ checkpoints/     # Zwischencheckpoints
â”œâ”€â”€ logs/           # TensorBoard Logs
â””â”€â”€ final/          # Finales trainiertes Modell
    â”œâ”€â”€ config.json
    â”œâ”€â”€ model.safetensors
    â””â”€â”€ preprocessor_config.json
```

### 4. Dataset deduplizieren

Entferne doppelte oder sehr Ã¤hnliche Bilder aus deinem Dataset, um die TrainingsqualitÃ¤t zu verbessern:

```bash
# Duplikate anzeigen ohne zu lÃ¶schen
vogel-trainer deduplicate ~/training-data/ --recursive

# Duplikate lÃ¶schen (erste Instanz behalten)
vogel-trainer deduplicate ~/training-data/ \
  --mode delete \
  --recursive

# Duplikate in separaten Ordner verschieben
vogel-trainer deduplicate ~/training-data/ \
  --mode move \
  --recursive

# Striktere Duplikat-Erkennung
vogel-trainer deduplicate ~/training-data/ \
  --threshold 3 \
  --recursive

# GrÃ¶ÃŸte Datei behalten statt erste
vogel-trainer deduplicate ~/training-data/ \
  --mode delete \
  --keep largest \
  --recursive
```

**Deduplizierungs-Parameter:**
- `--threshold`: Ã„hnlichkeits-Schwelle - Hamming-Distanz 0-64, niedriger=strenger (Standard: 5)
- `--method`: Hash-Methode: `phash` (Standard, empfohlen), `dhash`, `whash`, `average_hash`
- `--mode`: Aktion: `report` (nur anzeigen, Standard), `delete` (lÃ¶schen), `move` (nach duplicates/ verschieben)
- `--keep`: Welches Duplikat behalten: `first` (chronologisch, Standard) oder `largest` (DateigrÃ¶ÃŸe)
- `--recursive, -r`: Unterverzeichnisse rekursiv durchsuchen

**Funktionsweise:**
- Verwendet Perceptual Hashing (pHash) zur Erkennung visuell Ã¤hnlicher Bilder
- Robust gegen GrÃ¶ÃŸenÃ¤nderung, Beschnitt und kleine FarbÃ¤nderungen
- Schwelle von 5 = sehr Ã¤hnlich, 10 = Ã¤hnlich, >15 = verschieden
- Sicherer Standard: `report`-Modus verhindert versehentliches LÃ¶schen

### 5. QualitÃ¤tskontrolle (Neu!)

ÃœberprÃ¼fe dein Dataset auf Bilder mit niedriger QualitÃ¤t (verschwommen, zu klein, beschÃ¤digt, Belichtungsprobleme):

```bash
# QualitÃ¤tsprobleme anzeigen ohne zu lÃ¶schen
vogel-trainer quality-check ~/training-data/ --recursive

# Bilder mit niedriger QualitÃ¤t lÃ¶schen
vogel-trainer quality-check ~/training-data/ \
  --mode delete \
  --recursive

# Bilder mit niedriger QualitÃ¤t in separaten Ordner verschieben
vogel-trainer quality-check ~/training-data/ \
  --mode move \
  --recursive

# Strengere UnschÃ¤rfe-Erkennung
vogel-trainer quality-check ~/training-data/ \
  --blur-threshold 150.0 \
  --recursive

# Auf Helligkeits-/Kontrastprobleme prÃ¼fen
vogel-trainer quality-check ~/training-data/ \
  --check-brightness \
  --recursive

# Umfassende QualitÃ¤tskontrolle mit benutzerdefinierten Schwellen
vogel-trainer quality-check ~/training-data/ \
  --blur-threshold 120.0 \
  --min-resolution 100 \
  --min-filesize 2048 \
  --check-brightness \
  --mode move \
  --recursive
```

**QualitÃ¤tskontroll-Parameter:**
- `--blur-threshold`: Minimaler SchÃ¤rfe-Wert (Laplacian-Varianz), niedriger=mehr UnschÃ¤rfe (Standard: 100.0)
- `--min-resolution`: Minimale Bildbreite/-hÃ¶he in Pixeln (Standard: 50)
- `--min-filesize`: Minimale DateigrÃ¶ÃŸe in Bytes (Standard: 1024)
- `--check-brightness`: Auch auf Helligkeits-/Kontrastprobleme prÃ¼fen (zu dunkel oder Ã¼berbelichtet)
- `--mode`: Aktion: `report` (nur anzeigen, Standard), `delete` (lÃ¶schen), `move` (nach low_quality/ verschieben)
- `--recursive, -r`: Unterverzeichnisse rekursiv durchsuchen

**âš ï¸ WARNUNG - LÃ¶sch-Modus:**
- Die Option `--mode delete` **lÃ¶scht Dateien dauerhaft** ohne Backup
- **FÃ¼hren Sie immer zuerst `--mode report` aus**, um zu sehen, was gelÃ¶scht wird
- **Sichern Sie Ihr Dataset**, bevor Sie den LÃ¶sch-Modus verwenden
- ErwÃ¤gen Sie stattdessen `--mode move` (behÃ¤lt Dateien im `low_quality/`-Ordner)

**Was wird geprÃ¼ft:**
- âœ… **SchÃ¤rfe**: Erkennt verschwommene/unscharfe Bilder mittels Laplacian-Varianz
- âœ… **AuflÃ¶sung**: Filtert zu kleine Bilder, die das Training beeintrÃ¤chtigen
- âœ… **DateigrÃ¶ÃŸe**: Erkennt beschÃ¤digte oder leere Dateien
- âœ… **Lesbarkeit**: PrÃ¼ft, ob Bilder geÃ¶ffnet und verarbeitet werden kÃ¶nnen
- âœ… **Helligkeit** (optional): Erkennt zu dunkle oder Ã¼berbelichtete Bilder

**Typische Schwellenwerte:**
- UnschÃ¤rfe: 100.0 (Standard) = moderat, 150.0 = strenger, 50.0 = nachsichtiger
- AuflÃ¶sung: 50px (Standard) = sehr tolerant, 100px = empfohlen, 224px = streng
- DateigrÃ¶ÃŸe: 1024 Bytes (Standard) = erkennt beschÃ¤digte Dateien

**Empfohlener Workflow:**
```bash
# 1. Erst Probleme anzeigen (sicher)
vogel-trainer quality-check ~/data/ --mode report --recursive

# 2. Problematische Bilder verschieben (reversibel)
vogel-trainer quality-check ~/data/ --mode move --recursive

# 3. Verschobene Dateien im low_quality/ Ordner prÃ¼fen
# 4. Bei Zufriedenheit manuell lÃ¶schen: rm -rf ~/data/low_quality/
```

**Typische Schwellenwerte:**
- UnschÃ¤rfe: 100.0 (Standard) = moderat, 150.0 = strenger, 50.0 = toleranter
- AuflÃ¶sung: 50px (Standard) = sehr tolerant, 100px = empfohlen, 224px = streng
- DateigrÃ¶ÃŸe: 1024 Bytes (Standard) = erkennt beschÃ¤digte Dateien

### 6. Modell testen

**Test auf einzelnem Bild:**
```bash
# Mit vollstÃ¤ndiger Ausgabe (Top-5 Vorhersagen)
vogel-trainer test ~/models/final/ -i image.jpg
vogel-trainer test ~/models/final/ --image foto.jpg

# Kurzform (ohne Flag)
vogel-trainer test ~/models/final/ image.jpg

# Output:
# ğŸ–¼ï¸  Classifying image: image.jpg
# 
# Results:
# ==================================================
# 1. kohlmeise      - 0.9850 (98.5%)
# 2. blaumeise      - 0.0120 (1.2%)
# 3. sumpfmeise     - 0.0025 (0.3%)
# 4. tannenmeise    - 0.0003 (0.0%)
# 5. haubenmeise    - 0.0002 (0.0%)
```

**Test auf Validierungsset:**
```bash
# Testet Modell auf kompletten Validierungsdaten
vogel-trainer test ~/models/final/ -d ~/organized-data/
vogel-trainer test ~/models/final/ --data ~/dataset/

# Output:
# ğŸ§ª Testing on validation set: ~/organized-data/val
# ======================================================================
#    kohlmeise   : 5/5 = 100.0%
#    blaumeise   : 4/5 = 80.0%
#    rotkehlchen : 5/5 = 100.0%
# ======================================================================
# ğŸ“Š Overall accuracy: 14/15 = 93.3%
```

**Parameter:**
- `model`: Pfad zum trainierten Modell (erforderlich)
- `-i, --image`: Einzelnes Bild testen (zeigt Top-5 Vorhersagen)
- `-d, --data`: Validierungsset testen (berechnet Genauigkeit)

**Hinweis:** Entweder `-i` oder `-d` muss angegeben werden!

### 7. Bilder klassifizieren (Batch-Inferenz)

Klassifiziere groÃŸe Mengen von Vogelbildern automatisch mit deinem trainierten Modell:

```bash
# Einfache Klassifizierung mit CSV-Export (lokales Modell)
vogel-trainer classify --species-model ~/models/final/ ~/camera-trap-images/ \
  --csv-report results.csv

# Hugging Face Modell verwenden (lÃ¤dt automatisch herunter)
vogel-trainer classify --species-model kamera-linux/german-bird-classifier-v2 ~/camera-trap-images/ \
  --csv-report results.csv

# Auto-Sortierung nach Arten
vogel-trainer classify --species-model ~/models/final/ ~/camera-trap-images/ \
  --sort-output ~/sorted-birds/

# Mit Confidence-Schwelle (nur sichere Klassifikationen sortieren)
vogel-trainer classify --species-model kamera-linux/german-bird-classifier-v2 ~/camera-trap-images/ \
  --sort-output ~/sorted-birds/ \
  --min-confidence 0.85

# VollstÃ¤ndig: CSV + Sortieren + Top-3 Vorhersagen
vogel-trainer classify --species-model ~/models/final/ ~/camera-trap-images/ \
  --csv-report results.csv \
  --sort-output ~/sorted-birds/ \
  --top-k 3 \
  --batch-size 32
```

**Dateiverwaltungs-Optionen:**

```bash
# Standard: Kopieren (Original bleibt erhalten)
vogel-trainer classify --species-model ~/models/final/ ~/images/ \
  --sort-output ~/sorted/

# Verschieben statt Kopieren (spart Speicherplatz)
vogel-trainer classify --species-model ~/models/final/ ~/images/ \
  --sort-output ~/sorted/ \
  --move

# Quellverzeichnis nach Verarbeitung lÃ¶schen
vogel-trainer classify --species-model kamera-linux/german-bird-classifier-v2 ~/images/ \
  --sort-output ~/sorted/ \
  --delete-source

# Kombination: Verschieben + Quellverzeichnis aufrÃ¤umen
vogel-trainer classify --species-model ~/models/final/ ~/images/ \
  --sort-output ~/sorted/ \
  --move \
  --delete-source

# Probelauf (nichts wird geÃ¤ndert)
vogel-trainer classify --species-model ~/models/final/ ~/images/ \
  --sort-output ~/sorted/ \
  --delete-source \
  --dry-run

# FÃ¼r Skripte: BestÃ¤tigungs-Prompt Ã¼berspringen
vogel-trainer classify --species-model ~/models/final/ ~/images/ \
  --sort-output ~/sorted/ \
  --delete-source \
  --force
```

**Parameter:**
- `--species-model`: Pfad zum trainierten Modell oder Hugging Face Model ID (erforderlich)
- `input`: Verzeichnis mit zu klassifizierenden Bildern (erforderlich)
- `--sort-output, -s`: Ausgabeverzeichnis fÃ¼r nach Arten sortierte Bilder
- `--min-confidence`: Minimale Confidence fÃ¼r Sortierung (0.0-1.0, Standard: 0.0)
- `--csv-report, -c`: CSV-Datei mit detaillierten Klassifizierungsergebnissen
- `--top-k, -k`: Anzahl Top-Vorhersagen (1-5, Standard: 1)
- `--batch-size, -b`: Verarbeitungs-Batch-GrÃ¶ÃŸe (Standard: 32)
- `--move`: Dateien verschieben statt kopieren (spart Speicherplatz)
- `--delete-source`: âš ï¸ Quellverzeichnis nach Verarbeitung lÃ¶schen
- `--force, -f`: BestÃ¤tigungs-Prompts Ã¼berspringen (fÃ¼r Automatisierung)
- `--dry-run`: Probelauf ohne tatsÃ¤chliche Ã„nderungen
- `--no-recursive`: Nur Top-Level Bilder verarbeiten

**CSV-Format:**
```csv
filename,predicted_species,confidence,top_2_species,top_2_confidence,top_3_species,top_3_confidence
bird001.jpg,blaumeise,0.9750,kohlmeise,0.0180,rotkehlchen,0.0045
bird002.jpg,amsel,0.9200,rotkehlchen,0.0520,buchfink,0.0210
```

**Ausgabe-Struktur:**
```
sorted-birds/
â”œâ”€â”€ blaumeise/       # Klassifiziert als Blaumeise
â”œâ”€â”€ kohlmeise/       # Klassifiziert als Kohlmeise
â”œâ”€â”€ rotkehlchen/     # Klassifiziert als Rotkehlchen
â””â”€â”€ unknown/         # Unter Confidence-Schwelle
```

**AnwendungsfÃ¤lle:**
- ğŸ“¸ **Camera-Trap-Auswertung**: Automatische Artbestimmung fÃ¼r tausende Fotos
- ğŸ” **Citizen Science**: Hobby-Ornithologen kÃ¶nnen ihre Fotos klassifizieren
- ğŸ“Š **Monitoring-Projekte**: Zeitreihen-Analysen von Vogelpopulationen
- âœ… **Dataset-QualitÃ¤t**: Existierende Datasets auf Fehlklassifikationen prÃ¼fen

**Sicherheitshinweise:**
- âš ï¸ `--delete-source` lÃ¶scht das Quellverzeichnis **DAUERHAFT**
- ğŸ’¡ Immer erst `--dry-run` ausfÃ¼hren zum Testen
- ğŸ“¦ Backups vor `--delete-source` erstellen
- âœ… `--move` als sichere Alternative (behÃ¤lt Originale in sorted/)

---

### 8. Modell-Performance evaluieren

Umfassende Modell-Evaluierung mit detaillierten Metriken und Fehleranalyse:

```bash
# Basis-Evaluierung auf Test-Set
vogel-trainer evaluate \
  --species-model ~/models/final/ \
  --test-dir ~/test-dataset/

# Mit Hugging Face Modell
vogel-trainer evaluate \
  --species-model kamera-linux/german-bird-classifier-v2 \
  --test-dir ~/test-dataset/

# VollstÃ¤ndige Analyse mit Exporten
vogel-trainer evaluate \
  --species-model ~/models/final/ \
  --test-dir ~/test-dataset/ \
  --export-misclassified fehlklassifikationen.csv \
  --export-json metriken.json
```

**Test-Verzeichnis-Struktur:**
```
test-dataset/
â”œâ”€â”€ blaumeise/          # Ground Truth: Blaumeise
â”‚   â”œâ”€â”€ image001.jpg
â”‚   â””â”€â”€ image002.jpg
â”œâ”€â”€ kohlmeise/          # Ground Truth: Kohlmeise
â”‚   â”œâ”€â”€ image003.jpg
â”‚   â””â”€â”€ image004.jpg
â””â”€â”€ rotkehlchen/        # Ground Truth: Rotkehlchen
    â”œâ”€â”€ image005.jpg
    â””â”€â”€ image006.jpg
```

**Ausgabe:**

```
================================================================================
Modell-Evaluierung & Analytik
================================================================================
ğŸ¤– Lade Modell: ~/models/final/
   âœ… Modell geladen auf GPU mit 8 Arten
ğŸ“¸ 240 Test-Bilder Ã¼ber 8 Arten gefunden

ğŸ”„ Evaluiere Modell...
Arten: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:03<00:00, 2.5it/s]

================================================================================
Konfusionsmatrix
================================================================================
Actual/Predicted  blaumeise  kohlmeise  rotkehlchen  ...
------------------------------------------------------------
blaumeise               28          2            0
kohlmeise                1         29            0
rotkehlchen              0          0           30
...

================================================================================
Metriken pro Art
================================================================================
Species               Precision     Recall   F1-Score    Samples
--------------------------------------------------------------------------------
blaumeise                 96.6%     93.3%      94.9%         30
kohlmeise                 93.5%     96.7%      95.1%         30
rotkehlchen              100.0%    100.0%     100.0%         30
...
--------------------------------------------------------------------------------
Macro Average                                   96.8%        240
Weighted Average                                96.8%           

================================================================================
ğŸ“Š Gesamtgenauigkeit: 96.25%
Korrekt: 231/240
Fehlklassifiziert: 9
================================================================================
```

**Parameter:**
- `--species-model`: Pfad zum trainierten Modell oder Hugging Face Model ID (erforderlich)
- `--test-dir`: Test-Verzeichnis mit Arten-Unterordnern (erforderlich)
- `--export-misclassified`: Exportiere fehlklassifizierte Bilder in CSV-Datei
- `--export-json`: Exportiere alle Metriken (Konfusionsmatrix, Pro-Art-Metriken) nach JSON
- `--min-confidence`: Minimale Confidence-Schwelle fÃ¼r Evaluierung (0.0-1.0, Standard: 0.0)

**Exportierte Dateien:**

**fehlklassifikationen.csv:**
```csv
image,actual,predicted,confidence
/test/kohlmeise/img001.jpg,kohlmeise,blaumeise,0.6234
/test/blaumeise/img045.jpg,blaumeise,kohlmeise,0.5891
```

**metriken.json:**
```json
{
  "overall_accuracy": 0.9625,
  "metrics": {
    "blaumeise": {
      "precision": 0.966,
      "recall": 0.933,
      "f1_score": 0.949,
      "true_positives": 28,
      "false_positives": 1,
      "false_negatives": 2,
      "total": 30
    },
    ...
  },
  "confusion_matrix": { ... }
}
```

**AnwendungsfÃ¤lle:**
- ğŸ“Š **Modell-Vergleich**: Verschiedene TrainingslÃ¤ufe vergleichen
- ğŸ” **Fehleranalyse**: Identifizieren welche Arten verwechselt werden
- ğŸ“ˆ **Fortschritts-Tracking**: Verbesserung Ã¼ber Trainingsiterationen hinweg messen
- âœ… **QualitÃ¤tssicherung**: Modell vor Deployment validieren
- ğŸ› **Training-Debug**: Dataset-Probleme oder Klassen-Ungleichgewichte finden

---

## ğŸ”„ Iterativer Training-Workflow

Verbessere deine Modell-Genauigkeit durch iterative Verfeinerung mit Auto-Klassifizierung:

```mermaid
flowchart TD
    Start([ğŸ“‹ Phase 1: Initiales Modell<br/>Manuelle Beschriftung]) --> Extract1[1ï¸âƒ£ Extraktion mit manuellen Labels<br/><code>vogel-trainer extract video.mp4<br/>--folder data/ --bird kohlmeise</code>]
    
    Extract1 --> Organize1[2ï¸âƒ£ Dataset organisieren 80/20 Split<br/><code>vogel-trainer organize data/<br/>-o organized/</code>]
    
    Organize1 --> Train1[3ï¸âƒ£ Initiales Modell trainieren<br/><code>vogel-trainer train organized/<br/>-o models/v1/</code><br/>âœ… <b>Ergebnis: 92% Genauigkeit</b>]
    
    Train1 --> Phase2([ğŸ”„ Phase 2: Modell-Verbesserung<br/>Auto-Klassifizierung])
    
    Phase2 --> Extract2[4ï¸âƒ£ Auto-Extraktion mit trainiertem Modell<br/><code>vogel-trainer extract neue-videos/<br/>--folder data-v2/<br/>--species-model models/v1/final/<br/>--species-threshold 0.85</code><br/>ğŸ¯ <b>Automatisch nach Arten sortiert!</b>]
    
    Extract2 --> Review[5ï¸âƒ£ Manuelle ÃœberprÃ¼fung & Korrekturen<br/>â€¢ Auto-Klassifizierungen prÃ¼fen<br/>â€¢ Falsch klassifizierte Bilder verschieben<br/>â€¢ Mit vorherigem Dataset zusammenfÃ¼hren]
    
    Review --> Train2[6ï¸âƒ£ Neutraining mit erweitertem Dataset<br/><code>vogel-trainer organize data-v2/<br/>-o organized-v2/<br/>vogel-trainer train organized-v2/<br/>-o models/v2/</code><br/>ğŸ‰ <b>Ergebnis: 96% Genauigkeit!</b>]
    
    Train2 --> Repeat{â™»ï¸ Weiter<br/>verbessern?}
    Repeat -->|Ja| Extract2
    Repeat -->|Nein| End([âœ… Finales Modell])
    
    style Start fill:#e1f5ff,stroke:#0066cc,stroke-width:3px
    style Phase2 fill:#e1f5ff,stroke:#0066cc,stroke-width:3px
    style Train1 fill:#d4edda,stroke:#28a745,stroke-width:2px
    style Train2 fill:#d4edda,stroke:#28a745,stroke-width:2px
    style End fill:#d4edda,stroke:#28a745,stroke-width:3px
    style Extract2 fill:#fff3cd,stroke:#ffc107,stroke-width:2px
    style Review fill:#f8d7da,stroke:#dc3545,stroke-width:2px
```

**Hauptvorteile:**
- ğŸš€ **Schnellere Beschriftung**: Auto-Klassifizierung spart manuelle Arbeit
- ğŸ“ˆ **Bessere Genauigkeit**: Mehr Trainingsdaten = besseres Modell
- ğŸ¯ **QualitÃ¤tskontrolle**: `--species-threshold` filtert unsichere Vorhersagen
- ğŸ”„ **Kontinuierliche Verbesserung**: Jede Iteration verbessert das Modell

**Beispiel-Befehle:**

```bash
# Phase 1: Manuelles Training (initiales Dataset)
vogel-trainer extract ~/Videos/batch1/*.mp4 --folder ~/data/ --bird kohlmeise
vogel-trainer organize ~/data/ -o ~/data/organized/
vogel-trainer train ~/data/organized/ -o ~/models/v1/

# Phase 2: Auto-Klassifizierung mit trainiertem Modell
vogel-trainer extract ~/Videos/batch2/*.mp4 \
  --folder ~/data-v2/ \
  --species-model ~/models/v1/final/ \
  --species-threshold 0.85

# Klassifizierungen in ~/data-v2/<art>/ Ordnern Ã¼berprÃ¼fen
# Falsch klassifizierte Bilder in korrekte Arten-Ordner verschieben

# Datasets zusammenfÃ¼hren und neu trainieren
cp -r ~/data-v2/* ~/data/
vogel-trainer organize ~/data/ -o ~/data/organized-v2/
vogel-trainer train ~/data/organized-v2/ -o ~/models/v2/
```

---

## ğŸ“Š Performance & Best Practices

### Empfehlungen zur Dataset-GrÃ¶ÃŸe

| QualitÃ¤t | Bilder pro Art | Erwartete Genauigkeit |
|----------|----------------|----------------------|
| Minimum  | 20-30         | ~85-90%             |
| Gut      | 50-100        | ~92-96%             |
| Optimal  | 100+          | >96%                |

### Tipps fÃ¼r bessere Ergebnisse

1. **Dataset-DiversitÃ¤t**
   - Verschiedene LichtverhÃ¤ltnisse einbeziehen
   - Verschiedene Posen erfassen (Seite, Vorne, Hinten)
   - Verschiedene Jahreszeiten abdecken (Federkleid Ã¤ndert sich)

2. **Klassen-Balance**
   - Ã„hnliche Bildzahl pro Art anstreben
   - Vermeide eine dominierende Klasse

3. **QualitÃ¤t vor QuantitÃ¤t**
   - Nutze Threshold 0.5-0.6 fÃ¼r klare Detektionen
   - Manuelle Review von auto-sortierten Bildern verbessert QualitÃ¤t

4. **Training monitoren**
   - PrÃ¼fe Pro-Klassen-Genauigkeit fÃ¼r schwache Arten
   - Nutze Confusion Matrix um Ã¤hnliche Arten zu identifizieren
   - FÃ¼ge mehr Daten fÃ¼r schlecht performende Klassen hinzu

---

## ğŸ”— Integration mit vogel-video-analyzer

Nutze dein trainiertes Modell zur Artenerkennung:

```bash
vogel-analyze --identify-species \
  --species-model ~/models/final/ \
  --species-threshold 0.3 \
  video.mp4
```

---

## ğŸ› ï¸ Entwicklung

```bash
# Repository klonen
git clone https://github.com/kamera-linux/vogel-model-trainer.git
cd vogel-model-trainer

# Im Entwicklungsmodus installieren
pip install -e ".[dev]"

# Tests ausfÃ¼hren
pytest tests/
```

---

## ğŸ“ Lizenz

MIT License - siehe [LICENSE](LICENSE) fÃ¼r Details.

---

## ğŸ™ Credits

- **YOLO** von [Ultralytics](https://github.com/ultralytics/ultralytics)
- **EfficientNet** von [Google Research](https://github.com/google/automl)
- **Transformers** von [Hugging Face](https://huggingface.co/transformers)

---

## ğŸ“® Support & Contributing

- **Issues**: [GitHub Issues](https://github.com/kamera-linux/vogel-model-trainer/issues)
- **Discussions**: [GitHub Discussions](https://github.com/kamera-linux/vogel-model-trainer/discussions)
- **Pull Requests**: Contributions willkommen!

---

Made with â¤ï¸ for bird watching enthusiasts ğŸ¦
