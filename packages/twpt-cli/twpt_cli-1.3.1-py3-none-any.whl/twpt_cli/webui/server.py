"""Flask web server for ThreatWinds Pentest CLI Web UI."""

import os
import json
import socket
import uuid
import asyncio
import threading
import queue
import time
import logging
from datetime import datetime
from pathlib import Path
from typing import Optional, Dict, Any, List, Generator

import secrets
from functools import wraps

from flask import Flask, render_template, jsonify, request, send_file, send_from_directory, Response, session

from flask_cors import CORS

from ..sdk.http_client import HTTPClient
from ..sdk.grpc_client import GRPCClient

# ===========================================
# Phase 1.1: Global gRPC Initialization
# ===========================================
# gRPC async should only be initialized once per process
_grpc_initialized = False
_grpc_init_lock = threading.Lock()

def _ensure_grpc_initialized():
    """Initialize gRPC async once globally (thread-safe)."""
    global _grpc_initialized
    if not _grpc_initialized:
        with _grpc_init_lock:
            if not _grpc_initialized:
                try:
                    from grpc import aio as grpc_aio
                    grpc_aio.init_grpc_aio()
                    _grpc_initialized = True
                    logging.debug("gRPC async initialized globally")
                except Exception as e:
                    logging.warning(f"Failed to initialize gRPC async: {e}")

# ===========================================
# Phase 1.3: Concurrent Stream Limiting
# ===========================================
MAX_CONCURRENT_STREAMS = 20
_stream_semaphore = threading.Semaphore(MAX_CONCURRENT_STREAMS)
_active_streams = 0
_streams_lock = threading.Lock()

def _acquire_stream_slot() -> bool:
    """Try to acquire a stream slot. Returns True if successful."""
    global _active_streams
    if _stream_semaphore.acquire(blocking=False):
        with _streams_lock:
            _active_streams += 1
        return True
    return False

def _release_stream_slot():
    """Release a stream slot."""
    global _active_streams
    with _streams_lock:
        _active_streams = max(0, _active_streams - 1)
    _stream_semaphore.release()

def _get_stream_stats() -> Dict[str, int]:
    """Get current stream statistics."""
    with _streams_lock:
        return {
            'active_streams': _active_streams,
            'max_streams': MAX_CONCURRENT_STREAMS,
            'available_slots': MAX_CONCURRENT_STREAMS - _active_streams
        }

# ===========================================
# Phase 2.1: Per-Request Event Loop (Fixed)
# ===========================================
# NOTE: Shared event loop was removed because it creates a single point of failure.
# When one gRPC stream hangs, it blocks ALL streams. Per-request loops isolate failures.

def _create_request_loop() -> asyncio.AbstractEventLoop:
    """Create a new event loop for a single request."""
    loop = asyncio.new_event_loop()

    def handle_exception(loop, context):
        exc = context.get('exception')
        if isinstance(exc, (BlockingIOError, asyncio.CancelledError)):
            return  # Silently ignore these
        logging.warning(f"Event loop exception: {context.get('message', 'Unknown error')}")

    loop.set_exception_handler(handle_exception)
    return loop

def _cleanup_request_loop(loop: asyncio.AbstractEventLoop):
    """Clean up a request-specific event loop."""
    try:
        # Cancel all pending tasks
        pending = asyncio.all_tasks(loop) if hasattr(asyncio, 'all_tasks') else asyncio.Task.all_tasks(loop)
        for task in pending:
            task.cancel()

        # Run loop briefly to process cancellations
        if pending:
            loop.run_until_complete(asyncio.gather(*pending, return_exceptions=True))

        loop.close()
    except Exception:
        pass  # Ignore cleanup errors

# Keep these for backwards compatibility but mark as deprecated
_shared_loop: Optional[asyncio.AbstractEventLoop] = None
_loop_thread: Optional[threading.Thread] = None
_loop_lock = threading.Lock()

def _get_shared_loop() -> asyncio.AbstractEventLoop:
    """DEPRECATED: Returns a per-request loop instead of shared loop."""
    # For safety, return a new loop per call instead of shared
    return _create_request_loop()

def _shutdown_shared_loop():
    """DEPRECATED: No-op since we use per-request loops now."""
    pass

# ===========================================
# Phase 1.2 & 2.2: Connection Timeouts
# ===========================================
GRPC_CONNECT_TIMEOUT = 30.0  # seconds
GRPC_CLOSE_TIMEOUT = 5.0  # seconds
STREAM_IDLE_TIMEOUT = 120.0  # 2 minutes max idle time (reduced from 5 min)
STREAM_QUEUE_TIMEOUT = 30.0  # Queue wait timeout for faster disconnect detection
GRPC_MESSAGE_TIMEOUT = 60.0  # Timeout for each message in gRPC stream (prevents silent hangs)
STREAM_THREAD_TIMEOUT = 10.0  # How long to wait for stream thread to finish after stop signal


# ===========================================
# Per-Message Timeout Iterator
# ===========================================
async def _iterate_with_timeout(async_iterator, timeout: float, stop_event: threading.Event):
    """Iterate over an async iterator with per-message timeout.

    This prevents silent hangs where gRPC streams stop sending data
    but don't raise any exception.

    Args:
        async_iterator: The async iterator to wrap
        timeout: Timeout in seconds for each message
        stop_event: Threading event to check for early termination

    Yields:
        Items from the iterator

    Raises:
        asyncio.TimeoutError: If no message received within timeout
        StopAsyncIteration: When iterator is exhausted
    """
    aiter = async_iterator.__aiter__()
    while not stop_event.is_set():
        try:
            item = await asyncio.wait_for(aiter.__anext__(), timeout=timeout)
            yield item
        except StopAsyncIteration:
            break
        except asyncio.TimeoutError:
            logging.warning(f"gRPC stream timeout after {timeout}s - no message received")
            raise
from ..sdk.models import (
    Credentials,
    HTTPSchedulePentestRequest,
    HTTPTargetRequest,
    HTTPScope,
    HTTPType,
    HTTPStyle,
    UpdateType,
)
from ..config.constants import (
    USER_CONFIG_PATH,
    CONFIG_FILE_NAME,
    ENDPOINT_FILE_NAME,
    DEFAULT_API_HOST,
    DEFAULT_GRPC_HOST,
    API_PORT,
    GRPC_PORT,
)
from ..config.credentials import (
    load_credentials,
    save_credentials,
    get_api_endpoint,
    get_grpc_endpoint,
    save_endpoint_config,
    load_endpoint_config,
    check_configured,
)


# Server profiles storage - use user config path (~/.twpt) instead of /opt/twpt
SERVERS_FILE = USER_CONFIG_PATH / 'servers.json'


def load_servers() -> List[Dict[str, Any]]:
    """Load server profiles from file."""
    try:
        if not SERVERS_FILE.exists():
            return []
        with open(SERVERS_FILE, 'r') as f:
            return json.load(f)
    except (PermissionError, OSError, json.JSONDecodeError):
        return []


def save_servers(servers: List[Dict[str, Any]]) -> None:
    """Save server profiles to file."""
    try:
        SERVERS_FILE.parent.mkdir(parents=True, exist_ok=True)
        with open(SERVERS_FILE, 'w') as f:
            json.dump(servers, f, indent=2)
    except (PermissionError, OSError) as e:
        raise RuntimeError(f"Cannot save servers file: {e}")


def get_active_server() -> Optional[Dict[str, Any]]:
    """Get the currently active server."""
    servers = load_servers()
    for server in servers:
        if server.get('active'):
            return server
    return servers[0] if servers else None


def create_app(
    api_endpoint: Optional[str] = None,
    grpc_endpoint: Optional[str] = None,
    api_key: Optional[str] = None,
    api_secret: Optional[str] = None,
) -> Flask:
    """Create and configure the Flask application.

    Args:
        api_endpoint: Override REST API endpoint (e.g., "http://localhost:9741").
                      If None, uses config from ~/.twpt/endpoint.json.
        grpc_endpoint: Override gRPC endpoint (e.g., "localhost:9742").
                       If None, uses config from ~/.twpt/endpoint.json.
        api_key: Override API key. If None, uses config from ~/.twpt/config.json.
        api_secret: Override API secret. If None, uses config from ~/.twpt/config.json.

    Returns:
        Configured Flask application instance.
    """
    # Get the directory where this file is located
    webui_dir = Path(__file__).parent
    webui_simple_dir = webui_dir.parent / 'webui_simple'

    app = Flask(
        __name__,
        template_folder=str(webui_dir / 'templates'),
        static_folder=str(webui_dir / 'static'),
    )

    # Enable CORS for API endpoints with credentials support
    CORS(app, supports_credentials=True)

    # Initialize gRPC async globally (Phase 1.1)
    _ensure_grpc_initialized()

    # Initialize the shared event loop (Phase 2.1)
    _get_shared_loop()

    # Configure session - use a random secret key per server instance
    # This means sessions are lost on server restart, which is acceptable
    app.secret_key = secrets.token_hex(32)
    app.config['SESSION_COOKIE_HTTPONLY'] = True
    app.config['SESSION_COOKIE_SAMESITE'] = 'Lax'

    # Track server start time for health checks
    app.start_time = datetime.utcnow()

    def require_auth(f):
        """Decorator to require session authentication for routes."""
        @wraps(f)
        def decorated_function(*args, **kwargs):
            if not session.get('authenticated'):
                return jsonify({'error': 'Authentication required', 'authenticated': False}), 401
            return f(*args, **kwargs)
        return decorated_function

    # Store client instance
    app.http_client = None
    # Use user config path (~/.twpt) for evidence storage instead of /opt/twpt
    app.evidence_base_path = USER_CONFIG_PATH / 'evidence'

    # Store endpoint overrides on the app for use by get_client and routes
    app.api_endpoint_override = api_endpoint
    app.grpc_endpoint_override = grpc_endpoint
    app.credentials_override = None
    if api_key and api_secret:
        app.credentials_override = Credentials(api_key=api_key, api_secret=api_secret)

    def get_configured_api_endpoint() -> str:
        """Get API endpoint, using override if provided."""
        if app.api_endpoint_override:
            return app.api_endpoint_override
        return get_api_endpoint()

    def get_configured_grpc_endpoint() -> str:
        """Get gRPC endpoint, using override if provided."""
        if app.grpc_endpoint_override:
            return app.grpc_endpoint_override
        return get_grpc_endpoint()

    def get_configured_credentials() -> Optional[Credentials]:
        """Get credentials, using override if provided."""
        if app.credentials_override:
            return app.credentials_override
        return load_credentials()

    # Store helper functions on app for use by routes
    app.get_configured_api_endpoint = get_configured_api_endpoint
    app.get_configured_grpc_endpoint = get_configured_grpc_endpoint
    app.get_configured_credentials = get_configured_credentials

    def get_client() -> Optional[HTTPClient]:
        """Get or create HTTP client instance."""
        if app.http_client is not None:
            return app.http_client

        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return None

            api_url = get_configured_api_endpoint()
            app.http_client = HTTPClient(api_url, credentials)
            return app.http_client
        except Exception:
            return None

    def reset_client():
        """Reset the HTTP client to force reconnection."""
        app.http_client = None

    def get_local_ip() -> str:
        """Get the local IP address."""
        try:
            s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
            s.connect(("8.8.8.8", 80))
            ip = s.getsockname()[0]
            s.close()
            return ip
        except Exception:
            return "127.0.0.1"

    def get_country_from_ip(ip: str) -> Optional[str]:
        """Get country name from IP address using ip-api.com."""
        import requests
        try:
            # Skip for localhost/private IPs
            if ip in ('127.0.0.1', 'localhost') or ip.startswith('192.168.') or ip.startswith('10.') or ip.startswith('172.'):
                return None

            response = requests.get(f'http://ip-api.com/json/{ip}?fields=status,country', timeout=3)
            if response.status_code == 200:
                data = response.json()
                if data.get('status') == 'success':
                    return data.get('country')
        except Exception:
            pass
        return None

    def get_geolocation_from_ip(ip: str) -> Optional[Dict[str, Any]]:
        """Get full geolocation data (lat, lon, country, city) from IP address using local GeoLite2 database."""
        try:
            # Return default location for localhost/private IPs (approximate center of US as fallback)
            if ip in ('127.0.0.1', 'localhost') or ip.startswith('192.168.') or ip.startswith('10.') or ip.startswith('172.'):
                return {
                    'ip': ip,
                    'lat': 39.8,
                    'lon': -98.5,
                    'country': 'Local Network',
                    'city': 'Private',
                    'isp': 'Local'
                }

            # Use local GeoLite2 database for IP geolocation
            from geolite2 import geolite2
            reader = geolite2.reader()
            match = reader.get(ip)

            if match:
                location = match.get('location', {})
                country_data = match.get('country', {})
                city_data = match.get('city', {})

                lat = location.get('latitude')
                lon = location.get('longitude')
                country = country_data.get('names', {}).get('en', 'Unknown')
                city = city_data.get('names', {}).get('en', 'Unknown')

                if lat is not None and lon is not None:
                    return {
                        'ip': ip,
                        'lat': lat,
                        'lon': lon,
                        'country': country,
                        'city': city,
                        'isp': 'Unknown'
                    }
        except ImportError:
            # Fall back to ip-api.com if geolite2 is not installed
            import requests
            try:
                response = requests.get(
                    f'http://ip-api.com/json/{ip}?fields=status,country,city,lat,lon,isp,query',
                    timeout=5
                )
                if response.status_code == 200:
                    data = response.json()
                    if data.get('status') == 'success':
                        return {
                            'ip': data.get('query', ip),
                            'lat': data.get('lat'),
                            'lon': data.get('lon'),
                            'country': data.get('country'),
                            'city': data.get('city'),
                            'isp': data.get('isp')
                        }
            except Exception:
                pass
        except Exception:
            pass
        return None

    def resolve_hostname_to_ip(hostname: str) -> Optional[str]:
        """Resolve a hostname/domain to its public IP address (fast, no ping)."""
        try:
            # Use socket resolution only (fast, no ping fallback)
            ip = socket.gethostbyname(hostname)
            # Check if it's not a private IP
            if not (ip.startswith('192.168.') or ip.startswith('10.') or ip.startswith('172.') or ip == '127.0.0.1'):
                return ip
        except socket.gaierror:
            pass
        except Exception:
            pass
        return None

    # Routes
    @app.route('/')
    def index():
        """Serve the main page (advanced UI)."""
        return render_template('index.html')

    @app.route('/simple')
    def simple_ui():
        """Serve the simplified UI."""
        return send_file(webui_simple_dir / 'templates' / 'index.html')

    @app.route('/static/<path:filename>')
    def serve_static(filename):
        """Serve static files for advanced UI."""
        return send_from_directory(app.static_folder, filename)

    @app.route('/simple/static/<path:subpath>/<path:filename>')
    def serve_simple_static(subpath, filename):
        """Serve static files for simplified UI."""
        static_path = webui_simple_dir / 'static' / subpath
        return send_from_directory(static_path, filename)

    # API Routes
    @app.route('/api/status')
    def api_status():
        """Get connection status.

        Returns authentication state based on session, not global config.
        Each browser session must authenticate independently.
        """
        # Check if THIS session is authenticated
        is_authenticated = session.get('authenticated', False)

        # Only try to connect if session is authenticated
        connected = False
        server = f"{DEFAULT_API_HOST}:{API_PORT}"
        country = None

        if is_authenticated:
            client = get_client()
            connected = client is not None

            try:
                api_url = get_configured_api_endpoint()
                server = api_url.replace('http://', '').replace('https://', '')
            except Exception:
                pass

            # Extract server host IP for geolocation
            server_host = server.split(':')[0] if ':' in server else server
            country = get_country_from_ip(server_host)

        return jsonify({
            'connected': connected,
            'server': server,
            'ip': get_local_ip(),
            'authenticated': is_authenticated,
            # Keep has_credentials for backward compatibility but it now reflects session state
            'has_credentials': is_authenticated,
            'country': country,
        })

    # ===========================================
    # Phase 2.3: Health Check Endpoint
    # ===========================================
    @app.route('/api/health')
    def api_health():
        """Health check endpoint for monitoring.

        Returns server health status, stream statistics, and uptime.
        This endpoint does NOT require authentication to allow external
        monitoring systems to check server health.
        """
        try:
            stream_stats = _get_stream_stats()
            uptime_seconds = (datetime.utcnow() - app.start_time).total_seconds()

            health = {
                'status': 'healthy',
                'timestamp': datetime.utcnow().isoformat(),
                'uptime_seconds': int(uptime_seconds),
                'streams': stream_stats,
                'grpc_initialized': _grpc_initialized,
                'architecture': 'per_request_loop',  # New: indicates per-request event loops
            }

            # Check if we're running low on stream capacity
            if stream_stats['available_slots'] == 0:
                health['status'] = 'degraded'
                health['message'] = 'All stream slots in use'
            elif stream_stats['available_slots'] <= 3:
                health['status'] = 'warning'
                health['message'] = f"Only {stream_stats['available_slots']} stream slots available"

            status_code = 200 if health['status'] in ('healthy', 'warning') else 503
            return jsonify(health), status_code

        except Exception as e:
            return jsonify({
                'status': 'unhealthy',
                'timestamp': datetime.utcnow().isoformat(),
                'error': str(e)
            }), 503

    @app.route('/api/credentials', methods=['POST'])
    def api_save_credentials():
        """Save API credentials and authenticate this session.

        Each browser session must authenticate independently.
        Credentials are validated and stored in the session.
        """
        try:
            data = request.get_json()
            api_key = data.get('api_key', '').strip()
            api_secret = data.get('api_secret', '').strip()
            host = data.get('host', 'localhost').strip()
            port = data.get('port', '9741').strip()

            if not api_key or not api_secret:
                return jsonify({'success': False, 'error': 'API key and secret required'}), 400

            # Save credentials to config (for CLI usage and persistence)
            save_credentials(api_key, api_secret)

            # Save endpoint config
            save_endpoint_config(host, port)

            # Create initial server profile
            servers = load_servers()
            if not servers:
                server_id = str(uuid.uuid4())
                servers.append({
                    'id': server_id,
                    'name': 'Default Server',
                    'host': host,
                    'port': port,
                    'grpc_port': '9742',
                    'active': True,
                })
                save_servers(servers)

            # Reset client to use new credentials
            reset_client()

            # Mark THIS session as authenticated
            session['authenticated'] = True
            session.permanent = True  # Session survives browser close

            return jsonify({'success': True, 'authenticated': True})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/login', methods=['POST'])
    def api_login():
        """Authenticate this session using stored or provided credentials.

        If credentials are already configured in ~/.twpt/config.json, users
        can authenticate their session by providing the same API key/secret.
        This ensures each browser session authenticates independently.
        """
        try:
            data = request.get_json()
            api_key = data.get('api_key', '').strip()
            api_secret = data.get('api_secret', '').strip()

            if not api_key or not api_secret:
                return jsonify({'success': False, 'error': 'API key and secret required'}), 400

            # Verify credentials by attempting to connect
            # Build the API endpoint
            try:
                api_url = get_configured_api_endpoint()
            except Exception:
                api_url = f"http://{DEFAULT_API_HOST}:{API_PORT}"

            # Try to create a client with these credentials
            test_creds = Credentials(api_key=api_key, api_secret=api_secret)
            test_client = HTTPClient(api_url, test_creds)

            # Attempt a simple API call to validate credentials
            try:
                # Try to list pentests - this will fail if credentials are invalid
                test_client.list_pentests(page=1, page_size=1)
            except Exception as e:
                error_msg = str(e).lower()
                if 'unauthorized' in error_msg or '401' in error_msg or 'forbidden' in error_msg or '403' in error_msg:
                    return jsonify({'success': False, 'error': 'Invalid credentials'}), 401
                # Other errors might be connectivity issues, still allow login
                # since we want to authenticate the session

            # Save credentials if validation passed
            save_credentials(api_key, api_secret)

            # Reset client to use new credentials
            reset_client()

            # Mark THIS session as authenticated
            session['authenticated'] = True
            session.permanent = True

            return jsonify({'success': True, 'authenticated': True})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/logout', methods=['POST'])
    def api_logout():
        """Log out this session.

        Clears the session authentication state. Does not affect other sessions
        or the stored credentials.
        """
        session.clear()
        return jsonify({'success': True, 'authenticated': False})

    @app.route('/api/servers', methods=['GET'])
    @require_auth
    def api_list_servers():
        """List all configured servers."""
        servers = load_servers()
        active_server = get_active_server()

        return jsonify({
            'servers': servers,
            'active_server': active_server,
        })

    @app.route('/api/servers', methods=['POST'])
    @require_auth
    def api_add_server():
        """Add a new server."""
        try:
            data = request.get_json()
            name = data.get('name', '').strip()
            host = data.get('host', '').strip()
            port = data.get('port', '9741').strip()
            grpc_port = data.get('grpc_port', '9742').strip()
            use_existing = data.get('use_existing_credentials', True)

            if not name or not host:
                return jsonify({'success': False, 'error': 'Name and host required'}), 400

            servers = load_servers()
            server_id = str(uuid.uuid4())

            new_server = {
                'id': server_id,
                'name': name,
                'host': host,
                'port': port,
                'grpc_port': grpc_port,
                'active': False,
            }

            # If using different credentials, store them separately
            if not use_existing:
                api_key = data.get('api_key', '').strip()
                api_secret = data.get('api_secret', '').strip()
                if api_key and api_secret:
                    new_server['api_key'] = api_key
                    new_server['api_secret'] = api_secret

            servers.append(new_server)
            save_servers(servers)

            return jsonify({'success': True, 'server_id': server_id})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/servers/<server_id>', methods=['DELETE'])
    @require_auth
    def api_remove_server(server_id: str):
        """Remove a server."""
        try:
            servers = load_servers()
            servers = [s for s in servers if s.get('id') != server_id]
            save_servers(servers)
            return jsonify({'success': True})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/servers/switch', methods=['POST'])
    @require_auth
    def api_switch_server():
        """Switch to a different server."""
        try:
            data = request.get_json()
            server_id = data.get('server_id')

            if not server_id:
                return jsonify({'success': False, 'error': 'Server ID required'}), 400

            servers = load_servers()
            target_server = None

            for server in servers:
                if server.get('id') == server_id:
                    server['active'] = True
                    target_server = server
                else:
                    server['active'] = False

            if not target_server:
                return jsonify({'success': False, 'error': 'Server not found'}), 404

            save_servers(servers)

            # Update endpoint config
            save_endpoint_config(
                target_server['host'],
                target_server['port'],
                target_server['host'],
                target_server.get('grpc_port', '9742')
            )

            # If server has custom credentials, use them
            if target_server.get('api_key') and target_server.get('api_secret'):
                save_credentials(target_server['api_key'], target_server['api_secret'])

            # Reset client to reconnect
            reset_client()

            return jsonify({
                'success': True,
                'server_name': target_server['name'],
            })
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/version')
    @require_auth
    def api_version():
        """Get version information."""
        client = get_client()
        version = "1.0.0"

        if client:
            try:
                version = client.get_current_version()
            except Exception:
                pass

        return jsonify({'version': version})

    @app.route('/api/pentests')
    @require_auth
    def api_list_pentests():
        """List all pentests."""
        client = get_client()
        if not client:
            return jsonify({'error': 'Not connected', 'pentests': []}), 503

        try:
            page = request.args.get('page', 1, type=int)
            page_size = request.args.get('page_size', 50, type=int)

            result = client.list_pentests(page=page, page_size=page_size)

            # Convert to dict format
            pentests = []
            for p in result.pentests:
                pentest_dict = {
                    'id': p.id,
                    'status': p.status,
                    'style': p.style,
                    'exploit': p.exploit,
                    'created_at': p.created_at.isoformat() if p.created_at else None,
                    'started_at': p.started_at.isoformat() if p.started_at else None,
                    'finished_at': p.finished_at.isoformat() if p.finished_at else None,
                    'severity': p.severity,
                    'findings': p.findings,
                    'targets': []
                }

                for t in p.targets:
                    pentest_dict['targets'].append({
                        'target': t.target,
                        'scope': t.scope,
                        'type': t.type,
                        'status': t.status,
                        'phase': t.phase,
                        'severity': t.severity,
                        'findings': t.findings,
                    })

                pentests.append(pentest_dict)

            return jsonify({
                'pentests': pentests,
                'total': result.total,
                'page': result.page,
                'page_size': result.page_size,
                'total_pages': result.total_pages,
            })
        except Exception as e:
            return jsonify({'error': str(e), 'pentests': []}), 500

    @app.route('/api/pentests/<pentest_id>')
    @require_auth
    def api_get_pentest(pentest_id: str):
        """Get a specific pentest."""
        client = get_client()
        if not client:
            return jsonify({'error': 'Not connected'}), 503

        try:
            p = client.get_pentest(pentest_id)

            pentest_dict = {
                'id': p.id,
                'status': p.status,
                'style': p.style,
                'exploit': p.exploit,
                'created_at': p.created_at.isoformat() if p.created_at else None,
                'started_at': p.started_at.isoformat() if p.started_at else None,
                'finished_at': p.finished_at.isoformat() if p.finished_at else None,
                'severity': p.severity,
                'findings': p.findings,
                'targets': []
            }

            for t in p.targets:
                pentest_dict['targets'].append({
                    'target': t.target,
                    'scope': t.scope,
                    'type': t.type,
                    'status': t.status,
                    'phase': t.phase,
                    'severity': t.severity,
                    'findings': t.findings,
                })

            return jsonify(pentest_dict)
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/<pentest_id>/chat', methods=['POST'])
    @require_auth
    def api_chat_with_pentest(pentest_id: str):
        """Chat about a pentest's results using AI analysis."""
        client = get_client()
        if not client:
            return jsonify({'success': False, 'error': 'Not connected', 'pentest_id': pentest_id}), 503

        try:
            data = request.get_json()
            question = data.get('question', '').strip()

            if not question:
                return jsonify({
                    'success': False,
                    'error': 'Question is required',
                    'pentest_id': pentest_id
                }), 400

            # Call the backend chat API
            result = client.chat_with_pentest(pentest_id, question)

            return jsonify(result)
        except Exception as e:
            return jsonify({
                'success': False,
                'error': str(e),
                'pentest_id': pentest_id
            }), 500

    @app.route('/api/pentests/schedule', methods=['POST'])
    @require_auth
    def api_schedule_pentest():
        """Schedule a new pentest with optional playbook and memory support."""
        client = get_client()
        if not client:
            return jsonify({'error': 'Not connected'}), 503

        try:
            data = request.get_json()

            # Build targets
            targets = []
            for t in data.get('targets', []):
                scope = HTTPScope(t.get('scope', 'TARGETED'))
                ptype = HTTPType(t.get('type', 'BLACK_BOX'))

                target = HTTPTargetRequest(
                    target=t['target'],
                    scope=scope,
                    type=ptype,
                    credentials=t.get('credentials'),
                )
                targets.append(target)

            if not targets:
                return jsonify({'error': 'No targets provided'}), 400

            style = HTTPStyle(data.get('style', 'AGGRESSIVE'))
            exploit = data.get('exploit', True)

            req = HTTPSchedulePentestRequest(
                style=style,
                exploit=exploit,
                targets=targets,
            )

            # Handle playbook if provided
            playbook_name = data.get('playbook')
            if playbook_name:
                from ..config.playbooks import resolve_playbook_reference, get_playbook_metadata
                try:
                    plan_content = resolve_playbook_reference(playbook_name)
                    plan_meta = get_playbook_metadata(playbook_name)
                    req.custom_plan_content = plan_content
                    req.is_custom_plan = True
                    req.plan_metadata = plan_meta
                except (FileNotFoundError, ValueError) as e:
                    return jsonify({'error': f'Playbook error: {e}'}), 400

            # Handle memory items if provided
            memory_names = data.get('memory', [])
            inline_memory = data.get('inline_memory', [])
            include_default = data.get('include_default_memory', True) and not playbook_name

            if memory_names or inline_memory or include_default:
                from ..config.memory import get_memory_for_pentest
                memory_items = get_memory_for_pentest(
                    memory_names=memory_names if memory_names else None,
                    inline_memory=inline_memory if inline_memory else None,
                    include_default=include_default,
                )
                if memory_items:
                    req.memory_items = memory_items

            pentest_id = client.schedule_pentest(req)

            return jsonify({
                'pentest_id': pentest_id,
                'message': 'Pentest scheduled successfully',
            })
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/<pentest_id>/download')
    @require_auth
    def api_download_evidence(pentest_id: str):
        """Download evidence for a pentest."""
        client = get_client()
        if not client:
            return jsonify({'error': 'Not connected'}), 503

        try:
            # Create evidence directory
            evidence_dir = app.evidence_base_path / pentest_id
            evidence_dir.mkdir(parents=True, exist_ok=True)

            # Download evidence
            result_path = client.download_evidence(
                pentest_id=pentest_id,
                output_path=str(evidence_dir),
                extract=False,
            )

            return send_file(
                result_path,
                mimetype='application/zip',
                as_attachment=True,
                download_name=f'pentest_{pentest_id}_evidence.zip'
            )
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/stream', methods=['POST'])
    @require_auth
    def api_stream_pentest():
        """Schedule a pentest and stream real-time updates via SSE.

        This endpoint uses Server-Sent Events to stream gRPC updates
        to the client in real-time.
        """
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            data = request.get_json()

            # Build targets
            targets = []
            for t in data.get('targets', []):
                targets.append({
                    'target': t['target'],
                    'scope': t.get('scope', 'TARGETED'),
                    'type': t.get('type', 'BLACK_BOX'),
                    'credentials': t.get('credentials'),
                })

            if not targets:
                return jsonify({'error': 'No targets provided'}), 400

            request_dict = {
                'style': data.get('style', 'AGGRESSIVE'),
                'exploit': data.get('exploit', True),
                'targets': targets,
            }

            def generate_events() -> Generator[str, None, None]:
                """Generate SSE events from gRPC stream."""
                # Phase 1.3: Check stream slot availability
                if not _acquire_stream_slot():
                    yield f"event: error\ndata: {json.dumps({'error': 'Too many concurrent streams. Please try again later.'})}\n\n"
                    return

                event_queue = queue.Queue()
                stop_event = threading.Event()
                stream_acquired = True
                loop_ref = [None]  # Track loop for cleanup

                def run_stream():
                    """Run the async gRPC stream in a dedicated per-request event loop."""
                    # Create per-request event loop (isolates failures)
                    loop = _create_request_loop()
                    loop_ref[0] = loop
                    asyncio.set_event_loop(loop)

                    async def stream_handler():
                        grpc_client = None
                        try:
                            grpc_address = get_configured_grpc_endpoint()
                            grpc_client = GRPCClient(grpc_address, credentials)
                            # Phase 1.2: Add connection timeout
                            await asyncio.wait_for(grpc_client.connect(), timeout=GRPC_CONNECT_TIMEOUT)

                            # Use per-message timeout to prevent silent hangs
                            async for response in _iterate_with_timeout(
                                grpc_client.schedule_pentest_stream(request_dict),
                                timeout=GRPC_MESSAGE_TIMEOUT,
                                stop_event=stop_event
                            ):
                                if stop_event.is_set():
                                    break
                                event_queue.put(('data', response))

                            event_queue.put(('done', None))
                        except asyncio.TimeoutError:
                            event_queue.put(('error', 'Stream timeout - no data received'))
                        except asyncio.CancelledError:
                            event_queue.put(('done', None))  # Client disconnected
                        except Exception as e:
                            event_queue.put(('error', str(e)))
                        finally:
                            if grpc_client:
                                try:
                                    await asyncio.wait_for(grpc_client.close(), timeout=GRPC_CLOSE_TIMEOUT)
                                except Exception:
                                    pass

                    try:
                        loop.run_until_complete(stream_handler())
                    except Exception:
                        pass
                    finally:
                        _cleanup_request_loop(loop)

                # Start streaming in background thread
                stream_thread = threading.Thread(target=run_stream, daemon=True)
                stream_thread.start()

                try:
                    while True:
                        try:
                            event_type, data = event_queue.get(timeout=STREAM_QUEUE_TIMEOUT)

                            if event_type == 'done':
                                yield f"event: done\ndata: {json.dumps({'message': 'Stream completed'})}\n\n"
                                break
                            elif event_type == 'error':
                                yield f"event: error\ndata: {json.dumps({'error': data})}\n\n"
                                break
                            elif event_type == 'data':
                                yield f"event: message\ndata: {json.dumps(data)}\n\n"

                        except queue.Empty:
                            # Send keepalive
                            yield f"event: keepalive\ndata: {json.dumps({'timestamp': 'ping'})}\n\n"
                except GeneratorExit:
                    pass  # Client disconnected
                finally:
                    # Signal stop to allow thread to exit cleanly
                    stop_event.set()
                    # Wait briefly for thread to finish
                    stream_thread.join(timeout=STREAM_THREAD_TIMEOUT)
                    # Phase 1.3: Always release stream slot
                    if stream_acquired:
                        _release_stream_slot()

            return Response(
                generate_events(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/<pentest_id>/watch')
    @require_auth
    def api_watch_pentest(pentest_id: str):
        """Watch a pentest's real-time updates via SSE using gRPC streaming.

        This endpoint uses gRPC streaming to receive real-time updates
        for an existing pentest, including detailed progress messages.
        """
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            def generate_events() -> Generator[str, None, None]:
                """Generate SSE events from gRPC stream."""
                # Phase 1.3: Check stream slot availability
                if not _acquire_stream_slot():
                    yield f"event: error\ndata: {json.dumps({'error': 'Too many concurrent streams. Please try again later.'})}\n\n"
                    return

                event_queue = queue.Queue()
                stop_event = threading.Event()
                stream_acquired = True
                loop_ref = [None]

                def run_stream():
                    """Run the async gRPC stream in a dedicated per-request event loop."""
                    loop = _create_request_loop()
                    loop_ref[0] = loop
                    asyncio.set_event_loop(loop)

                    async def stream_handler():
                        grpc_client = None
                        try:
                            grpc_address = get_configured_grpc_endpoint()
                            grpc_client = GRPCClient(grpc_address, credentials)
                            await asyncio.wait_for(grpc_client.connect(), timeout=GRPC_CONNECT_TIMEOUT)

                            async for response in _iterate_with_timeout(
                                grpc_client.watch_pentest_stream(pentest_id),
                                timeout=GRPC_MESSAGE_TIMEOUT,
                                stop_event=stop_event
                            ):
                                if stop_event.is_set():
                                    break
                                event_queue.put(('data', response))

                            event_queue.put(('done', None))
                        except asyncio.TimeoutError:
                            event_queue.put(('error', 'Stream timeout - no data received'))
                        except asyncio.CancelledError:
                            event_queue.put(('done', None))
                        except Exception as e:
                            event_queue.put(('error', str(e)))
                        finally:
                            if grpc_client:
                                try:
                                    await asyncio.wait_for(grpc_client.close(), timeout=GRPC_CLOSE_TIMEOUT)
                                except Exception:
                                    pass

                    try:
                        loop.run_until_complete(stream_handler())
                    except Exception:
                        pass
                    finally:
                        _cleanup_request_loop(loop)

                stream_thread = threading.Thread(target=run_stream, daemon=True)
                stream_thread.start()

                try:
                    while True:
                        try:
                            event_type, data = event_queue.get(timeout=STREAM_QUEUE_TIMEOUT)

                            if event_type == 'done':
                                yield f"event: done\ndata: {json.dumps({'message': 'Stream completed'})}\n\n"
                                break
                            elif event_type == 'error':
                                yield f"event: error\ndata: {json.dumps({'error': data})}\n\n"
                                break
                            elif event_type == 'data':
                                response_type = data.get('type', 'message')
                                if response_type == 'status_update':
                                    yield f"event: status\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'pentest_data':
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"
                                    status_val = data.get('status', '')
                                    if status_val in ['COMPLETED', 'FAILED']:
                                        done_msg = {'message': f'Pentest {status_val.lower()}'}
                                        yield f"event: done\ndata: {json.dumps(done_msg)}\n\n"
                                        stop_event.set()
                                        break
                                else:
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"

                        except queue.Empty:
                            yield f"event: keepalive\ndata: {json.dumps({'timestamp': 'ping'})}\n\n"
                except GeneratorExit:
                    pass
                finally:
                    stop_event.set()
                    stream_thread.join(timeout=STREAM_THREAD_TIMEOUT)
                    if stream_acquired:
                        _release_stream_slot()

            return Response(
                generate_events(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/<pentest_id>/attach')
    @require_auth
    def api_attach_pentest(pentest_id: str):
        """Attach to a running pentest stream via SSE with late-join support.

        This endpoint uses the subscribe_pentest_stream gRPC method to:
        1. Connect to a running pentest
        2. Optionally replay historical events (use ?include_history=false to skip)
        3. Stream real-time updates as they happen

        This allows clients to reconnect to a pentest stream at any time,
        even after closing the browser and returning later.
        """
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            include_history = request.args.get('include_history', 'true').lower() == 'true'

            def generate_events() -> Generator[str, None, None]:
                """Generate SSE events from gRPC subscribe stream."""
                if not _acquire_stream_slot():
                    yield f"event: error\ndata: {json.dumps({'error': 'Too many concurrent streams. Please try again later.'})}\n\n"
                    return

                event_queue = queue.Queue()
                stop_event = threading.Event()
                stream_acquired = True
                loop_ref = [None]

                def run_stream():
                    loop = _create_request_loop()
                    loop_ref[0] = loop
                    asyncio.set_event_loop(loop)

                    async def stream_handler():
                        grpc_client = None
                        try:
                            grpc_address = get_configured_grpc_endpoint()
                            grpc_client = GRPCClient(grpc_address, credentials)
                            await asyncio.wait_for(grpc_client.connect(), timeout=GRPC_CONNECT_TIMEOUT)

                            async for response in _iterate_with_timeout(
                                grpc_client.subscribe_pentest_stream(
                                    pentest_id,
                                    include_history=include_history
                                ),
                                timeout=GRPC_MESSAGE_TIMEOUT,
                                stop_event=stop_event
                            ):
                                if stop_event.is_set():
                                    break
                                event_queue.put(('data', response))

                            event_queue.put(('done', None))
                        except asyncio.TimeoutError:
                            event_queue.put(('error', 'Stream timeout - no data received'))
                        except asyncio.CancelledError:
                            event_queue.put(('done', None))
                        except Exception as e:
                            event_queue.put(('error', str(e)))
                        finally:
                            if grpc_client:
                                try:
                                    await asyncio.wait_for(grpc_client.close(), timeout=GRPC_CLOSE_TIMEOUT)
                                except Exception:
                                    pass

                    try:
                        loop.run_until_complete(stream_handler())
                    except Exception:
                        pass
                    finally:
                        _cleanup_request_loop(loop)

                stream_thread = threading.Thread(target=run_stream, daemon=True)
                stream_thread.start()

                try:
                    while True:
                        try:
                            event_type, data = event_queue.get(timeout=STREAM_QUEUE_TIMEOUT)

                            if event_type == 'done':
                                yield f"event: done\ndata: {json.dumps({'message': 'Stream completed'})}\n\n"
                                break
                            elif event_type == 'error':
                                yield f"event: error\ndata: {json.dumps({'error': data})}\n\n"
                                break
                            elif event_type == 'data':
                                response_type = data.get('type', 'message')

                                if response_type == 'subscribe_response':
                                    yield f"event: subscribed\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'status_update':
                                    yield f"event: status\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'pentest_data':
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"
                                    status_val = data.get('status', '')
                                    if status_val in ['COMPLETED', 'FAILED']:
                                        done_msg = {'message': f'Pentest {status_val.lower()}'}
                                        yield f"event: done\ndata: {json.dumps(done_msg)}\n\n"
                                        stop_event.set()
                                        break
                                else:
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"

                        except queue.Empty:
                            yield f"event: keepalive\ndata: {json.dumps({'timestamp': 'ping'})}\n\n"
                except GeneratorExit:
                    pass
                finally:
                    stop_event.set()
                    stream_thread.join(timeout=STREAM_THREAD_TIMEOUT)
                    if stream_acquired:
                        _release_stream_slot()

            return Response(
                generate_events(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/pentests/<pentest_id>/files')
    @require_auth
    def api_list_evidence_files(pentest_id: str):
        """List evidence files for a pentest."""
        evidence_dir = app.evidence_base_path / pentest_id

        try:
            if not evidence_dir.exists():
                return jsonify({'files': {}})
        except PermissionError:
            return jsonify({'files': {}, 'error': 'Permission denied accessing evidence directory'})

        def build_tree(path: Path) -> Dict[str, Any]:
            """Build a file tree structure."""
            result = {}
            try:
                for item in sorted(path.iterdir()):
                    if item.is_dir():
                        result[item.name] = {
                            'type': 'directory',
                            'children': build_tree(item)
                        }
                    else:
                        result[item.name] = {
                            'type': 'file',
                            'size': item.stat().st_size,
                        }
            except PermissionError:
                pass
            return result

        files = build_tree(evidence_dir)
        return jsonify({'files': files})

    @app.route('/api/pentests/<pentest_id>/download-and-extract', methods=['POST'])
    @require_auth
    def api_download_and_extract(pentest_id: str):
        """Download and extract evidence for a pentest."""
        import shutil

        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured', 'success': False}), 503

            api_address = get_configured_api_endpoint()
            http_client = HTTPClient(api_address, credentials)

            # Create evidence directory for this pentest
            evidence_dir = app.evidence_base_path / pentest_id
            evidence_dir.mkdir(parents=True, exist_ok=True)

            # download_evidence expects a directory path and handles extraction itself
            # It returns the path to the extracted folder
            extracted_path = http_client.download_evidence(
                pentest_id,
                str(evidence_dir),
                extract=True
            )

            # Move extracted contents to evidence_dir root if nested
            extracted_dir = Path(extracted_path)
            if extracted_dir != evidence_dir and extracted_dir.exists():
                # Move all files from extracted subfolder to evidence_dir
                for item in extracted_dir.iterdir():
                    dest = evidence_dir / item.name
                    if dest.exists():
                        if dest.is_dir():
                            shutil.rmtree(dest)
                        else:
                            dest.unlink()
                    shutil.move(str(item), str(evidence_dir))
                # Remove the now-empty extracted subfolder
                if extracted_dir.exists() and extracted_dir != evidence_dir:
                    try:
                        extracted_dir.rmdir()
                    except OSError:
                        pass  # Directory not empty, leave it

            return jsonify({
                'success': True,
                'message': 'Evidence downloaded and extracted',
                'path': str(evidence_dir)
            })

        except Exception as e:
            return jsonify({'error': str(e), 'success': False}), 500

    @app.route('/api/files/preview')
    @require_auth
    def api_preview_file():
        """Preview a file's content."""
        file_path = request.args.get('path', '')
        if not file_path:
            return jsonify({'error': 'No path provided'}), 400

        # Security: ensure the path is within evidence directory
        try:
            full_path = (app.evidence_base_path / file_path).resolve()
            if not str(full_path).startswith(str(app.evidence_base_path.resolve())):
                return jsonify({'error': 'Invalid path'}), 400

            if not full_path.exists():
                return jsonify({'error': 'File not found'}), 404

            if not full_path.is_file():
                return jsonify({'error': 'Not a file'}), 400

            # Read file content (limit to 100KB)
            max_size = 100 * 1024
            file_size = full_path.stat().st_size

            if file_size > max_size:
                content = full_path.read_bytes()[:max_size].decode('utf-8', errors='replace')
                content += f"\n\n... [Truncated, file size: {file_size} bytes]"
            else:
                content = full_path.read_text(errors='replace')

            return jsonify({'content': content, 'size': file_size})
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/geolocation/server')
    @require_auth
    def api_server_geolocation():
        """Get geolocation of the connected server."""
        try:
            api_url = get_configured_api_endpoint()
            server_host = api_url.replace('http://', '').replace('https://', '').split(':')[0]

            # Resolve server host if it's a hostname
            ip = server_host
            if not server_host.replace('.', '').isdigit():
                resolved = resolve_hostname_to_ip(server_host)
                if resolved:
                    ip = resolved

            geo = get_geolocation_from_ip(ip)
            if geo:
                return jsonify({
                    'success': True,
                    'host': server_host,
                    **geo
                })
            else:
                return jsonify({
                    'success': False,
                    'error': 'Could not determine server location',
                    'host': server_host,
                    # Default to center of US
                    'lat': 39.8,
                    'lon': -98.5,
                })
        except Exception as e:
            return jsonify({
                'success': False,
                'error': str(e),
                'lat': 39.8,
                'lon': -98.5,
            })

    @app.route('/api/geolocation/resolve', methods=['POST'])
    @require_auth
    def api_resolve_target():
        """Resolve a hostname/domain to IP and get its geolocation."""
        try:
            data = request.get_json()
            target = data.get('target', '').strip()

            if not target:
                return jsonify({'success': False, 'error': 'No target provided'}), 400

            # Check if target is already an IP
            ip_pattern = r'^(\d{1,3}\.){3}\d{1,3}$'
            import re
            if re.match(ip_pattern, target):
                ip = target
            else:
                # Resolve hostname to IP
                ip = resolve_hostname_to_ip(target)
                if not ip:
                    return jsonify({
                        'success': False,
                        'error': 'Could not resolve hostname',
                        'target': target,
                    })

            # Get geolocation for the IP
            geo = get_geolocation_from_ip(ip)
            if geo:
                return jsonify({
                    'success': True,
                    'target': target,
                    'resolved_ip': ip,
                    **geo
                })
            else:
                return jsonify({
                    'success': False,
                    'error': 'Could not get geolocation',
                    'target': target,
                    'resolved_ip': ip,
                })
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    # ===========================================
    # Custom Task API Endpoints
    # ===========================================

    @app.route('/api/tasks', methods=['GET'])
    @require_auth
    def api_list_custom_tasks():
        """List all custom task sessions."""
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured', 'tasks': []}), 503

            async def get_tasks():
                grpc_address = get_configured_grpc_endpoint()
                grpc_client = GRPCClient(grpc_address, credentials)
                await grpc_client.connect()

                try:
                    page = request.args.get('page', 1, type=int)
                    page_size = request.args.get('page_size', 20, type=int)
                    result = await grpc_client.list_custom_tasks(page=page, page_size=page_size)
                    return result
                finally:
                    await grpc_client.close()

            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(get_tasks())
                return jsonify(result)
            finally:
                loop.close()

        except Exception as e:
            return jsonify({'error': str(e), 'tasks': []}), 500

    @app.route('/api/tasks/<task_id>', methods=['GET'])
    @require_auth
    def api_get_custom_task(task_id: str):
        """Get a specific custom task session."""
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            async def get_task():
                grpc_address = get_configured_grpc_endpoint()
                grpc_client = GRPCClient(grpc_address, credentials)
                await grpc_client.connect()

                try:
                    result = await grpc_client.get_custom_task(task_id)
                    return result
                finally:
                    await grpc_client.close()

            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(get_task())
                return jsonify(result)
            finally:
                loop.close()

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/tasks/<task_id>', methods=['DELETE'])
    @require_auth
    def api_close_custom_task(task_id: str):
        """Close a custom task session."""
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            async def close_task():
                grpc_address = get_configured_grpc_endpoint()
                grpc_client = GRPCClient(grpc_address, credentials)
                await grpc_client.connect()

                try:
                    result = await grpc_client.close_custom_task(task_id)
                    return result
                finally:
                    await grpc_client.close()

            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(close_task())
                return jsonify(result)
            finally:
                loop.close()

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/tasks/submit', methods=['POST'])
    @require_auth
    def api_submit_custom_task():
        """Submit a custom task and stream real-time updates via SSE."""
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            data = request.get_json()
            description = data.get('description', '').strip()
            target = data.get('target', '').strip()
            parameters = data.get('parameters', [])
            task_id = data.get('task_id')  # Optional: reuse session

            if not description or not target:
                return jsonify({'error': 'Description and target required'}), 400

            def generate_events() -> Generator[str, None, None]:
                """Generate SSE events from gRPC stream."""
                if not _acquire_stream_slot():
                    yield f"event: error\ndata: {json.dumps({'error': 'Too many concurrent streams. Please try again later.'})}\n\n"
                    return

                event_queue = queue.Queue()
                stop_event = threading.Event()
                stream_acquired = True
                loop_ref = [None]

                def run_stream():
                    loop = _create_request_loop()
                    loop_ref[0] = loop
                    asyncio.set_event_loop(loop)

                    async def stream_handler():
                        grpc_client = None
                        try:
                            grpc_address = get_configured_grpc_endpoint()
                            grpc_client = GRPCClient(grpc_address, credentials)
                            await asyncio.wait_for(grpc_client.connect(), timeout=GRPC_CONNECT_TIMEOUT)

                            async for response in _iterate_with_timeout(
                                grpc_client.submit_custom_task_stream(
                                    description=description,
                                    target=target,
                                    parameters=parameters,
                                    task_id=task_id
                                ),
                                timeout=GRPC_MESSAGE_TIMEOUT,
                                stop_event=stop_event
                            ):
                                if stop_event.is_set():
                                    break
                                event_queue.put(('data', response))

                            event_queue.put(('done', None))
                        except asyncio.TimeoutError:
                            event_queue.put(('error', 'Stream timeout - no data received'))
                        except asyncio.CancelledError:
                            event_queue.put(('done', None))
                        except Exception as e:
                            event_queue.put(('error', str(e)))
                        finally:
                            if grpc_client:
                                try:
                                    await asyncio.wait_for(grpc_client.close(), timeout=GRPC_CLOSE_TIMEOUT)
                                except Exception:
                                    pass

                    try:
                        loop.run_until_complete(stream_handler())
                    except Exception:
                        pass
                    finally:
                        _cleanup_request_loop(loop)

                stream_thread = threading.Thread(target=run_stream, daemon=True)
                stream_thread.start()

                try:
                    while True:
                        try:
                            event_type, data = event_queue.get(timeout=STREAM_QUEUE_TIMEOUT)

                            if event_type == 'done':
                                yield f"event: done\ndata: {json.dumps({'message': 'Task completed'})}\n\n"
                                break
                            elif event_type == 'error':
                                yield f"event: error\ndata: {json.dumps({'error': data})}\n\n"
                                break
                            elif event_type == 'data':
                                response_type = data.get('type', 'message')
                                if response_type == 'custom_task_response':
                                    yield f"event: task_started\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'status_update':
                                    yield f"event: update\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'custom_task_data':
                                    yield f"event: task_data\ndata: {json.dumps(data)}\n\n"
                                else:
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"

                        except queue.Empty:
                            yield f"event: keepalive\ndata: {json.dumps({'timestamp': 'ping'})}\n\n"
                except GeneratorExit:
                    pass
                finally:
                    stop_event.set()
                    stream_thread.join(timeout=STREAM_THREAD_TIMEOUT)
                    if stream_acquired:
                        _release_stream_slot()

            return Response(
                generate_events(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/tasks/<task_id>/attach')
    @require_auth
    def api_attach_custom_task(task_id: str):
        """Attach to a running custom task stream via SSE."""
        try:
            credentials = get_configured_credentials()
            if credentials is None:
                return jsonify({'error': 'Not configured'}), 503

            include_history = request.args.get('include_history', 'true').lower() == 'true'

            def generate_events() -> Generator[str, None, None]:
                """Generate SSE events from gRPC stream."""
                if not _acquire_stream_slot():
                    yield f"event: error\ndata: {json.dumps({'error': 'Too many concurrent streams. Please try again later.'})}\n\n"
                    return

                event_queue = queue.Queue()
                stop_event = threading.Event()
                stream_acquired = True
                loop_ref = [None]

                def run_stream():
                    loop = _create_request_loop()
                    loop_ref[0] = loop
                    asyncio.set_event_loop(loop)

                    async def stream_handler():
                        grpc_client = None
                        try:
                            grpc_address = get_configured_grpc_endpoint()
                            grpc_client = GRPCClient(grpc_address, credentials)
                            await asyncio.wait_for(grpc_client.connect(), timeout=GRPC_CONNECT_TIMEOUT)

                            async for response in _iterate_with_timeout(
                                grpc_client.subscribe_custom_task_stream(
                                    task_id,
                                    include_history=include_history
                                ),
                                timeout=GRPC_MESSAGE_TIMEOUT,
                                stop_event=stop_event
                            ):
                                if stop_event.is_set():
                                    break
                                event_queue.put(('data', response))

                            event_queue.put(('done', None))
                        except asyncio.TimeoutError:
                            event_queue.put(('error', 'Stream timeout - no data received'))
                        except asyncio.CancelledError:
                            event_queue.put(('done', None))
                        except Exception as e:
                            event_queue.put(('error', str(e)))
                        finally:
                            if grpc_client:
                                try:
                                    await asyncio.wait_for(grpc_client.close(), timeout=GRPC_CLOSE_TIMEOUT)
                                except Exception:
                                    pass

                    try:
                        loop.run_until_complete(stream_handler())
                    except Exception:
                        pass
                    finally:
                        _cleanup_request_loop(loop)

                stream_thread = threading.Thread(target=run_stream, daemon=True)
                stream_thread.start()

                try:
                    while True:
                        try:
                            event_type, data = event_queue.get(timeout=STREAM_QUEUE_TIMEOUT)

                            if event_type == 'done':
                                yield f"event: done\ndata: {json.dumps({'message': 'Stream completed'})}\n\n"
                                break
                            elif event_type == 'error':
                                yield f"event: error\ndata: {json.dumps({'error': data})}\n\n"
                                break
                            elif event_type == 'data':
                                response_type = data.get('type', 'message')
                                if response_type == 'subscribe_custom_task_response':
                                    yield f"event: subscribed\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'status_update':
                                    yield f"event: update\ndata: {json.dumps(data)}\n\n"
                                elif response_type == 'custom_task_data':
                                    yield f"event: task_data\ndata: {json.dumps(data)}\n\n"
                                else:
                                    yield f"event: message\ndata: {json.dumps(data)}\n\n"

                        except queue.Empty:
                            yield f"event: keepalive\ndata: {json.dumps({'timestamp': 'ping'})}\n\n"
                except GeneratorExit:
                    pass
                finally:
                    stop_event.set()
                    stream_thread.join(timeout=STREAM_THREAD_TIMEOUT)
                    if stream_acquired:
                        _release_stream_slot()

            return Response(
                generate_events(),
                mimetype='text/event-stream',
                headers={
                    'Cache-Control': 'no-cache',
                    'Connection': 'keep-alive',
                    'X-Accel-Buffering': 'no',
                }
            )

        except Exception as e:
            return jsonify({'error': str(e)}), 500

    @app.route('/api/tasks/<task_id>/download')
    @require_auth
    def api_download_task_evidence(task_id: str):
        """Download evidence for a custom task."""
        client = get_client()
        if not client:
            return jsonify({'error': 'Not connected'}), 503

        try:
            # Create evidence directory
            evidence_dir = app.evidence_base_path / f"custom_task_{task_id}"
            evidence_dir.mkdir(parents=True, exist_ok=True)

            # Download evidence
            result_path = client.download_evidence(
                pentest_id=task_id,
                output_path=str(evidence_dir),
                extract=False,
            )

            return send_file(
                result_path,
                mimetype='application/zip',
                as_attachment=True,
                download_name=f'task_{task_id}_evidence.zip'
            )
        except Exception as e:
            return jsonify({'error': str(e)}), 500

    # ===========================================
    # Geolocation API Endpoints
    # ===========================================

    @app.route('/api/geolocation/batch', methods=['POST'])
    @require_auth
    def api_batch_resolve():
        """Batch resolve multiple targets to get their geolocations (concurrent)."""
        from concurrent.futures import ThreadPoolExecutor, as_completed
        import re

        def resolve_single_target(target: str) -> Dict[str, Any]:
            """Resolve a single target to geolocation."""
            target = target.strip()
            result = {'target': target, 'success': False}

            if not target:
                return result

            ip_pattern = r'^(\d{1,3}\.){3}\d{1,3}$'

            try:
                # Check if target is already an IP
                if re.match(ip_pattern, target):
                    ip = target
                else:
                    ip = resolve_hostname_to_ip(target)

                if ip:
                    result['resolved_ip'] = ip
                    geo = get_geolocation_from_ip(ip)
                    if geo:
                        result.update(geo)
                        result['success'] = True
            except Exception:
                pass

            return result

        try:
            data = request.get_json()
            targets = data.get('targets', [])

            if not targets:
                return jsonify({'success': True, 'results': []})

            # Limit to 50 targets
            targets = targets[:50]

            # Use ThreadPoolExecutor for concurrent resolution
            results = []
            with ThreadPoolExecutor(max_workers=10) as executor:
                # Submit all tasks
                future_to_target = {executor.submit(resolve_single_target, t): t for t in targets}

                # Collect results as they complete
                for future in as_completed(future_to_target):
                    result = future.result()
                    results.append(result)

            # Sort results to maintain original order
            target_order = {t: i for i, t in enumerate(targets)}
            results.sort(key=lambda r: target_order.get(r.get('target', ''), 999))

            return jsonify({'success': True, 'results': results})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    # ===========================================
    # Playbook Management API Endpoints
    # ===========================================

    @app.route('/api/playbooks', methods=['GET'])
    @require_auth
    def api_list_playbooks():
        """List all saved playbooks."""
        try:
            from ..config.playbooks import list_playbooks, get_playbooks_dir
            items = list_playbooks()
            return jsonify({
                'success': True,
                'playbooks': items,
                'path': str(get_playbooks_dir())
            })
        except Exception as e:
            return jsonify({'success': False, 'error': str(e), 'playbooks': []}), 500

    @app.route('/api/playbooks/<name>', methods=['GET'])
    @require_auth
    def api_get_playbook(name: str):
        """Get a specific playbook's content."""
        try:
            from ..config.playbooks import get_playbook
            playbook = get_playbook(name)
            if not playbook:
                return jsonify({'success': False, 'error': 'Playbook not found'}), 404
            return jsonify({'success': True, 'playbook': playbook})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/playbooks/<name>', methods=['PUT'])
    @require_auth
    def api_save_playbook(name: str):
        """Save or update a playbook."""
        try:
            from ..config.playbooks import save_playbook
            data = request.get_json()
            content = data.get('content', '')
            if not content:
                return jsonify({'success': False, 'error': 'Content is required'}), 400
            result = save_playbook(name=name, content=content)
            return jsonify({'success': True, **result})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/playbooks/<name>', methods=['DELETE'])
    @require_auth
    def api_delete_playbook(name: str):
        """Delete a playbook."""
        try:
            from ..config.playbooks import delete_playbook
            if delete_playbook(name):
                return jsonify({'success': True, 'message': f'Playbook {name} deleted'})
            return jsonify({'success': False, 'error': 'Failed to delete playbook'}), 500
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    # ===========================================
    # Memory Management API Endpoints
    # ===========================================

    @app.route('/api/memory', methods=['GET'])
    @require_auth
    def api_list_memory():
        """List all saved memory items."""
        try:
            from ..config.memory import list_memory, get_memory_dir
            items = list_memory()
            return jsonify({
                'success': True,
                'items': items,
                'path': str(get_memory_dir())
            })
        except Exception as e:
            return jsonify({'success': False, 'error': str(e), 'items': []}), 500

    @app.route('/api/memory/<name>', methods=['GET'])
    @require_auth
    def api_get_memory(name: str):
        """Get a specific memory item's content."""
        try:
            from ..config.memory import get_memory
            item = get_memory(name)
            if not item:
                return jsonify({'success': False, 'error': 'Memory item not found'}), 404
            return jsonify({'success': True, 'item': item})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/memory/<name>', methods=['PUT'])
    @require_auth
    def api_save_memory(name: str):
        """Save or update a memory item."""
        try:
            from ..config.memory import save_memory
            data = request.get_json()
            content = data.get('content', '')
            if not content:
                return jsonify({'success': False, 'error': 'Content is required'}), 400
            result = save_memory(name=name, content=content)
            return jsonify({'success': True, **result})
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    @app.route('/api/memory/<name>', methods=['DELETE'])
    @require_auth
    def api_delete_memory(name: str):
        """Delete a memory item."""
        try:
            from ..config.memory import delete_memory
            if delete_memory(name):
                return jsonify({'success': True, 'message': f'Memory item {name} deleted'})
            return jsonify({'success': False, 'error': 'Failed to delete memory item'}), 500
        except Exception as e:
            return jsonify({'success': False, 'error': str(e)}), 500

    return app


# ===========================================
# Phase 3.2: Watchdog for Stuck Processes
# ===========================================
class WebUIWatchdog:
    """Monitors WebUI health and logs warnings when issues are detected."""

    def __init__(self, check_interval: int = 60, max_response_time: float = 5.0, port: int = 8080):
        self.check_interval = check_interval
        self.max_response_time = max_response_time
        self.port = port
        self._stop_event = threading.Event()
        self._thread: Optional[threading.Thread] = None
        self._consecutive_failures = 0

    def start(self):
        """Start the watchdog monitoring thread."""
        self._thread = threading.Thread(target=self._monitor, daemon=True, name="WebUIWatchdog")
        self._thread.start()
        logging.info("WebUI watchdog started")

    def stop(self):
        """Stop the watchdog."""
        self._stop_event.set()
        if self._thread:
            self._thread.join(timeout=5)
        logging.info("WebUI watchdog stopped")

    def _monitor(self):
        """Monitor the webui health periodically."""
        import requests

        # Wait a bit for the server to start
        time.sleep(10)

        while not self._stop_event.wait(self.check_interval):
            try:
                start = time.time()
                resp = requests.get(
                    f'http://127.0.0.1:{self.port}/api/health',
                    timeout=self.max_response_time
                )
                elapsed = time.time() - start

                if resp.status_code == 200:
                    self._consecutive_failures = 0
                    health = resp.json()
                    if health.get('status') == 'degraded':
                        logging.warning(f"WebUI health degraded: {health.get('message', 'unknown')}")
                    elif health.get('status') == 'warning':
                        logging.warning(f"WebUI health warning: {health.get('message', 'unknown')}")
                elif resp.status_code == 503:
                    self._consecutive_failures += 1
                    logging.error(f"WebUI unhealthy (503): {resp.text}")
                else:
                    self._consecutive_failures += 1
                    logging.warning(f"WebUI health check returned {resp.status_code}")

                if elapsed > self.max_response_time * 0.8:
                    logging.warning(f"WebUI health check slow: {elapsed:.2f}s")

                # Log critical if multiple consecutive failures
                if self._consecutive_failures >= 3:
                    logging.critical(
                        f"WebUI has failed {self._consecutive_failures} consecutive health checks. "
                        "Consider restarting the service."
                    )

            except requests.exceptions.Timeout:
                self._consecutive_failures += 1
                logging.error(f"WebUI health check timed out after {self.max_response_time}s")
            except requests.exceptions.ConnectionError:
                self._consecutive_failures += 1
                logging.error("WebUI health check failed: connection refused")
            except Exception as e:
                self._consecutive_failures += 1
                logging.error(f"WebUI health check exception: {e}")


# Global watchdog instance
_watchdog: Optional[WebUIWatchdog] = None


def run_server(
    host: str = '0.0.0.0',
    port: int = 8080,
    debug: bool = False,
    api_endpoint: Optional[str] = None,
    grpc_endpoint: Optional[str] = None,
    api_key: Optional[str] = None,
    api_secret: Optional[str] = None,
    workers: int = 4,
    use_gunicorn: bool = False,
    enable_watchdog: bool = True,
):
    """Run the web server.

    Args:
        host: Host to bind to
        port: Port to listen on
        debug: Enable debug mode
        api_endpoint: Override REST API endpoint (e.g., "http://localhost:9741")
        grpc_endpoint: Override gRPC endpoint (e.g., "localhost:9742")
        api_key: Override API key for authentication
        api_secret: Override API secret for authentication
        workers: Number of Gunicorn workers (only used with use_gunicorn=True)
        use_gunicorn: Use Gunicorn instead of Flask dev server (requires gunicorn package)
        enable_watchdog: Enable health monitoring watchdog (Phase 3.2)
    """
    global _watchdog

    app = create_app(
        api_endpoint=api_endpoint,
        grpc_endpoint=grpc_endpoint,
        api_key=api_key,
        api_secret=api_secret,
    )

    print(f"Starting ThreatWinds Pentest Web UI on http://{host}:{port}")
    if api_endpoint:
        print(f"  API endpoint: {api_endpoint}")
    if grpc_endpoint:
        print(f"  gRPC endpoint: {grpc_endpoint}")

    # Phase 3.2: Start watchdog if enabled
    if enable_watchdog and not debug:
        _watchdog = WebUIWatchdog(port=port)
        _watchdog.start()

    # Phase 3.1: Use Gunicorn if requested and available
    if use_gunicorn and not debug:
        try:
            from gunicorn.app.base import BaseApplication

            class WebUIApplication(BaseApplication):
                def __init__(self, application, options=None):
                    self.options = options or {}
                    self.application = application
                    super().__init__()

                def load_config(self):
                    for key, value in self.options.items():
                        if key in self.cfg.settings and value is not None:
                            self.cfg.set(key.lower(), value)

                def load(self):
                    return self.application

            options = {
                'bind': f'{host}:{port}',
                'workers': workers,
                'worker_class': 'sync',  # Use sync for SSE compatibility
                'timeout': 120,
                'keepalive': 5,
                'max_requests': 1000,
                'max_requests_jitter': 50,
                'preload_app': True,
            }

            # Try to use gevent if available for better SSE handling
            try:
                import gevent
                options['worker_class'] = 'gevent'
                print("  Using gevent worker for better SSE handling")
            except ImportError:
                print("  Using sync worker (install gevent for better SSE handling)")

            print(f"  Gunicorn workers: {workers}")
            WebUIApplication(app, options).run()

        except ImportError:
            print("  Gunicorn not available, falling back to Flask dev server")
            print("  Install gunicorn for production use: pip install gunicorn")
            app.run(host=host, port=port, debug=debug, threaded=True)
    else:
        # Use Flask's development server
        if not debug:
            print("  WARNING: Using Flask development server. Not recommended for production.")
            print("  Use --use-gunicorn for production deployments.")
        app.run(host=host, port=port, debug=debug, threaded=True)


def shutdown_server():
    """Gracefully shutdown the server and cleanup resources."""
    global _watchdog

    # Stop watchdog
    if _watchdog:
        _watchdog.stop()
        _watchdog = None

    # Shutdown shared event loop
    _shutdown_shared_loop()

    logging.info("WebUI server shutdown complete")


if __name__ == '__main__':
    run_server(debug=True)
