"""
@generated by mypy-protobuf.  Do not edit manually!
isort:skip_file
Copyright 2025 Phonexia s.r.o.

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.

Phonexia Referential Deepfake Detection gRPC API.
"""

import builtins
import google.protobuf.descriptor
import google.protobuf.duration_pb2
import google.protobuf.message
import phonexia.grpc.common.core_pb2
import sys
import typing

if sys.version_info >= (3, 10):
    import typing as typing_extensions
else:
    import typing_extensions

DESCRIPTOR: google.protobuf.descriptor.FileDescriptor

@typing.final
class DetectRequest(google.protobuf.message.Message):
    """The top level message sent by the client for the <code>Detect</code> method.

    This message contains both reference and questioned data for deepfake detection.
    Currently, only audio input is supported.

    The service will compare the reference data against the questioned data to determine
    if the questioned data is likely to be a deepfake of the reference speaker's voice.

    When using streaming, send the reference audio first, followed by the questioned audio.

    <b>IMPORTANT:</b> The reference data must be bona fide (genuine). If the reference
    is a deepfake, the algorithm will fail to produce valid results. Additionally, the speaker
    roles cannot be interchanged -- you must send the reference speaker in audio_reference and the
    questioned speaker in audio_questioned. Reversing these assignments may yield an incorrect score.

    The audio should contain at least 0.3125 seconds of speech. If the audio contains less speech,
    the <code>score</code> will be empty.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    AUDIO_REFERENCE_FIELD_NUMBER: builtins.int
    AUDIO_QUESTIONED_FIELD_NUMBER: builtins.int
    CONFIG_FIELD_NUMBER: builtins.int
    @property
    def audio_reference(self) -> phonexia.grpc.common.core_pb2.Audio: ...
    @property
    def audio_questioned(self) -> phonexia.grpc.common.core_pb2.Audio: ...
    @property
    def config(self) -> Global___DetectConfig:
        """Optional configuration for the detection."""

    def __init__(
        self,
        *,
        audio_reference: phonexia.grpc.common.core_pb2.Audio | None = ...,
        audio_questioned: phonexia.grpc.common.core_pb2.Audio | None = ...,
        config: Global___DetectConfig | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["audio_questioned", b"audio_questioned", "audio_reference", b"audio_reference", "config", b"config", "questioned", b"questioned", "reference", b"reference"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["audio_questioned", b"audio_questioned", "audio_reference", b"audio_reference", "config", b"config", "questioned", b"questioned", "reference", b"reference"]) -> None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["questioned", b"questioned"]) -> typing.Literal["audio_questioned"] | None: ...
    @typing.overload
    def WhichOneof(self, oneof_group: typing.Literal["reference", b"reference"]) -> typing.Literal["audio_reference"] | None: ...

Global___DetectRequest: typing_extensions.TypeAlias = DetectRequest

@typing.final
class DetectConfig(google.protobuf.message.Message):
    """Configuration for the referential deepfake detection."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SPEECH_LENGTH_FIELD_NUMBER: builtins.int
    @property
    def speech_length(self) -> google.protobuf.duration_pb2.Duration:
        """Maximum speech length to process from both reference and questioned audio.
        If set, only the first speech_length duration of speech will be processed
        from each audio. If not set, all available speech will be processed.
        """

    def __init__(
        self,
        *,
        speech_length: google.protobuf.duration_pb2.Duration | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["speech_length", b"speech_length"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["speech_length", b"speech_length"]) -> None: ...

Global___DetectConfig: typing_extensions.TypeAlias = DetectConfig

@typing.final
class DetectResponse(google.protobuf.message.Message):
    """The top level message returned to the client by the <code>Detect</code>
    method.
    """

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    RESULT_FIELD_NUMBER: builtins.int
    PROCESSED_AUDIO_LENGTH_FIELD_NUMBER: builtins.int
    @property
    def result(self) -> Global___DetectResult:
        """The result of referential deepfake detection."""

    @property
    def processed_audio_length(self) -> google.protobuf.duration_pb2.Duration:
        """Total length of the processed audio."""

    def __init__(
        self,
        *,
        result: Global___DetectResult | None = ...,
        processed_audio_length: google.protobuf.duration_pb2.Duration | None = ...,
    ) -> None: ...
    def HasField(self, field_name: typing.Literal["processed_audio_length", b"processed_audio_length", "result", b"result"]) -> builtins.bool: ...
    def ClearField(self, field_name: typing.Literal["processed_audio_length", b"processed_audio_length", "result", b"result"]) -> None: ...

Global___DetectResponse: typing_extensions.TypeAlias = DetectResponse

@typing.final
class DetectResult(google.protobuf.message.Message):
    """Message representing the result of referential deepfake detection."""

    DESCRIPTOR: google.protobuf.descriptor.Descriptor

    SCORE_FIELD_NUMBER: builtins.int
    score: builtins.float
    """Score of the referential deepfake detection. A higher score indicates a higher 
    likelihood of the questioned data being a deepfake. The score is a floating-point
    value. While technically limited by floating-point representation,
    scores are typically within a certain range that varies model to model.
    Empty if not enough speech was present in the input data.
    """
    def __init__(
        self,
        *,
        score: builtins.float = ...,
    ) -> None: ...
    def ClearField(self, field_name: typing.Literal["score", b"score"]) -> None: ...

Global___DetectResult: typing_extensions.TypeAlias = DetectResult
