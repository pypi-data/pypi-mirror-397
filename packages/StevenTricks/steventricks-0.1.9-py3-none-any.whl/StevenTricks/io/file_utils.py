# -*- coding: utf-8 -*-
"""
File Utility Toolkit
Consolidated utilities for file management, metadata access, serialization, and logging.
"""



from datetime import datetime
import pickle
from os import makedirs
from pathlib import Path
import pandas as pd

def runninginfo():
    """Print the current execution time and source file (if available)."""
    t = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    try:
        file = __file__
    except NameError:
        file = ""
    print(f"åœ¨{t}/nåŸ·è¡Œ{file}")
    return {"Time": t, "File": file}


def pickleio(path, data=None, mode="load"):
    """Unified function to save or load Python objects using pickle.

    Parameters:
        path (str): Path to the pickle file.
        data (any): Data to be saved (required if mode='save').
        mode (str): 'save' or 'load'.

    Returns:
        Loaded data if mode is 'load'. None if mode is 'save'.
    """
    if mode == "save":
        makedirs(Path(path).parent, exist_ok=True)
        with open(path, 'wb') as f:
            pickle.dump(data, f)
    elif mode == "load":
        with open(path, 'rb') as f:
            return pickle.load(f)
    else:
        raise ValueError("mode must be either 'save' or 'load'")


def pathlevel(left, right):
    """è¨ˆç®— right ç›¸å°æ–¼ left çš„ç›®éŒ„å±¤æ•¸"""
    left, right = Path(left).resolve(), Path(right).resolve()
    try:
        return len(right.relative_to(left).parts)
    except ValueError:
        return None  # è‹¥ right ä¸åœ¨ left ä¹‹ä¸‹ï¼Œè¿”å› None

def _get_path_stat(p: Path):
    """Extract file/directory timestamps or return None values."""
    stat = p.stat() if p.exists() else None
    return {
        "created_time": datetime.fromtimestamp(stat.st_ctime) if stat else None,
        "modified_time": datetime.fromtimestamp(stat.st_mtime) if stat else None,
        "accessed_time": datetime.fromtimestamp(stat.st_atime) if stat else None
    }


def _list_files(path, file_filter=None):
    """Internal utility to list all files recursively under a path."""
    base = Path(path)
    for p in base.rglob("*"):
        if p.is_file() and (file_filter is None or file_filter(p)):
            yield p


def PathWalk_df(path, dirinclude=[], direxclude=[], fileexclude=[], fileinclude=[], level=None, name_format=None):
    """
    ğŸ” éæ­·æŒ‡å®šè³‡æ–™å¤¾ä¸‹çš„æ‰€æœ‰æª”æ¡ˆï¼Œä¾ç…§æ¢ä»¶é€²è¡Œç¯©é¸èˆ‡è§£æï¼Œå›å‚³ç‚ºä¸€å€‹ pandas DataFrameã€‚

    âœ… åŠŸèƒ½äº®é»ï¼š
        - éè¿´åˆ—å‡ºæ‰€æœ‰æª”æ¡ˆï¼ŒåŒ…å«å®Œæ•´è·¯å¾‘èˆ‡å±¤ç´šè³‡è¨Šã€‚
        - æ”¯æ´è³‡æ–™å¤¾/æª”æ¡ˆçš„ã€ŒåŒ…å«ã€èˆ‡ã€Œæ’é™¤ã€æ¢ä»¶ã€‚
        - å¯é™åˆ¶æœ€æ·±æœå°‹å±¤ç´šã€‚
        - å¯è§£ææª”åæ ¼å¼ï¼Œåˆ†å‡º codeã€timeã€orderã€ext ç­‰æ¬„ä½ã€‚
        - âœ… å…§å»º `dir` æ¬„ä½ï¼Œä»£è¡¨æ¯å€‹æª”æ¡ˆæ‰€å±¬çš„è³‡æ–™å¤¾åç¨±ã€‚

    ğŸ“¥ åƒæ•¸èªªæ˜ï¼š
        path (str or Path):
            è¦æœå°‹çš„æ ¹ç›®éŒ„ã€‚

        dirinclude (list[str]):
            åªåŒ…å«è·¯å¾‘ä¸­å«æœ‰é€™äº›å­—ä¸²çš„æª”æ¡ˆï¼ˆé€šå¸¸ç”¨æ–¼è³‡æ–™å¤¾åç¨±éæ¿¾ï¼‰ã€‚

        direxclude (list[str]):
            æ’é™¤è·¯å¾‘ä¸­å«æœ‰é€™äº›å­—ä¸²çš„æª”æ¡ˆã€‚

        fileinclude (list[str]):
            åªåŒ…å«æª”åä¸­å«æœ‰é€™äº›å­—ä¸²çš„æª”æ¡ˆï¼ˆä¾‹å¦‚åªåŒ…å« ".pkl"ï¼‰ã€‚

        fileexclude (list[str]):
            æ’é™¤æª”åä¸­å«æœ‰é€™äº›å­—ä¸²çš„æª”æ¡ˆã€‚

        level (int or None):
            é™åˆ¶æª”æ¡ˆè·é›¢æ ¹ç›®éŒ„çš„æœ€å¤§å±¤æ•¸ï¼ˆæ ¹ç›®éŒ„ç‚º 0ï¼‰ï¼ŒNone å‰‡ä¸é™åˆ¶ã€‚

        name_format (str or None):
            æŒ‡å®šæª”åæ ¼å¼ï¼Œä¾‹å¦‚ "code_time_order.ext"ã€‚ç¬¦åˆæ ¼å¼çš„æª”åæœƒè§£ææˆå¤šå€‹æ¬„ä½ã€‚

    ğŸ“¤ å›å‚³ï¼š
        pandas.DataFrameï¼ŒåŒ…å«ä»¥ä¸‹æ¬„ä½ï¼š
            - fileï¼šæª”æ¡ˆåç¨±ï¼ˆä¸å«è·¯å¾‘ï¼‰
            - pathï¼šå®Œæ•´è·¯å¾‘
            - levelï¼šç›¸å°æ–¼æ ¹ç›®éŒ„çš„å±¤æ•¸ï¼ˆæ ¹ç›®éŒ„ä¸‹çš„æª”æ¡ˆç‚º 1ï¼Œå­è³‡æ–™å¤¾ç‚º 2ï¼Œä»¥æ­¤é¡æ¨ï¼‰
            - dirï¼šçˆ¶è³‡æ–™å¤¾åç¨±
            - [code/time/order/ext]ï¼šè‹¥æœ‰çµ¦å®š name_formatï¼Œæœƒé¡å¤–è§£æå‡ºå°æ‡‰æ¬„ä½
    """

    # â¬‡ï¸ å»ºç«‹æ‰€æœ‰æª”æ¡ˆçš„ç´€éŒ„æ¸…å–®
    rows = []
    for p in _list_files(path):
        rel = str(p.relative_to(path))         # ç›¸å°è·¯å¾‘å­—ä¸²ï¼ˆæœªä½¿ç”¨ä½†å¯æ‹“å±•ï¼‰
        file = p.name                          # æª”æ¡ˆåç¨±
        full_path = str(p)                     # çµ•å°è·¯å¾‘å­—ä¸²
        level_val = pathlevel(path, p)         # ç›¸å°å±¤ç´š
        dir_name = p.parent.name               # æ‰€å±¬è³‡æ–™å¤¾åç¨±
        rows.append((file, full_path, level_val, dir_name))

    # â¬‡ï¸ å»ºç«‹æˆ DataFrame
    df = pd.DataFrame(rows, columns=["file", "path", "level", "dir"])

    # â¬‡ï¸ éæ¿¾å±¤ç´š
    if level is not None:
        df = df[df["level"] <= level]

    # â¬‡ï¸ éæ¿¾è³‡æ–™å¤¾åŒ…å«å­—ä¸²ï¼ˆé€éè·¯å¾‘æ¯”å°ï¼‰
    if dirinclude:
        df = df[df["path"].str.contains("|".join(dirinclude), na=False)]

    # â¬‡ï¸ æ’é™¤è³‡æ–™å¤¾åŒ…å«å­—ä¸²
    if direxclude:
        df = df[~df["path"].str.contains("|".join(direxclude), na=False)]

    # â¬‡ï¸ æª”ååŒ…å«å­—ä¸²éæ¿¾
    if fileinclude:
        df = df[df["file"].str.contains("|".join(fileinclude), na=False)]

    # â¬‡ï¸ æª”åæ’é™¤å­—ä¸²éæ¿¾
    if fileexclude:
        df = df[~df["file"].str.contains("|".join(fileexclude), na=False)]

    # â¬‡ï¸ è‹¥æŒ‡å®š name_formatï¼Œè§£ææª”åç‚ºå¤šå€‹æ¬„ä½
    if name_format:
        format_parts = name_format.split("_")
        has_ext = format_parts[-1].endswith(".ext")
        split_keys = [p.replace(".ext", "") for p in format_parts]

        def parse_parts(filename: str):
            # å°‡æª”ååˆ†æˆä¸»é«”èˆ‡å‰¯æª”å
            stem, ext = filename, None
            if has_ext and "." in filename:
                stem, ext = filename.rsplit(".", 1)
            parts = stem.split("_")
            result = {}
            for i, key in enumerate(split_keys):
                result[key] = parts[i] if i < len(parts) else None
            result["ext"] = ext if has_ext else None
            return result

        parsed = df["file"].apply(parse_parts)
        parsed_df = pd.DataFrame(parsed.tolist())
        df = pd.concat([df, parsed_df], axis=1)

    return df.reset_index(drop=True)

def merge_excel_sheets_from_folder(
    root,
    output_filename="çµ±æ•´.xlsx",
    level=None,
    dirinclude=None,
    direxclude=None,
    fileinclude=None,
    fileexclude=None,
):
    """
    å°‡è³‡æ–™å¤¾åº•ä¸‹æ‰€æœ‰ Excel æª”æ¡ˆçš„å·¥ä½œè¡¨ï¼Œä¾ã€Œå·¥ä½œè¡¨åç¨±ã€é€²è¡Œç¸±å‘åˆä½µï¼Œ
    ä¸¦è¼¸å‡ºæˆä¸€å€‹æ–°çš„ Excel æª”ï¼ˆæ¯å€‹å·¥ä½œè¡¨ä¸€å€‹ sheetï¼‰ã€‚

    ä½¿ç”¨æƒ…å¢ƒï¼ˆå°æ‡‰ä½ åŸæœ¬çš„ file_append.pyï¼‰ï¼š
        - æŒ‡å®šä¸€å€‹è³‡æ–™å¤¾ root
        - æ‰¾å‡ºè£¡é¢çš„æ‰€æœ‰ Excel æª”ï¼ˆå«å­è³‡æ–™å¤¾ï¼‰
        - æ¯æ”¯æª”æ¡ˆç”¨ `pd.read_excel(..., sheet_name=None)` è®€æˆå¤šå·¥ä½œè¡¨
        - ä¾å·¥ä½œè¡¨åç¨±æŠŠ DataFrame concat èµ·ä¾†
        - æœ€å¾Œå¯«å‡ºä¸€å€‹ `çµ±æ•´.xlsx` æ”¾åœ¨ root åº•ä¸‹

    Parameters
    ----------
    root : str or pathlib.Path
        è¦æœå°‹çš„æ ¹ç›®éŒ„ã€‚
    output_filename : str or pathlib.Path, default "çµ±æ•´.xlsx"
        è¼¸å‡ºçš„ Excel æª”åã€‚å¦‚æœçµ¦ç›¸å°è·¯å¾‘ï¼Œæœƒå¯«åœ¨ root åº•ä¸‹ã€‚
    level : int or None, default None
        å‚³çµ¦ PathWalk_dfï¼Œç”¨ä¾†é™åˆ¶æœå°‹çš„ç›®éŒ„å±¤ç´šã€‚
    dirinclude, direxclude, fileinclude, fileexclude : list[str] or None
        åŒ PathWalk_df çš„éæ¿¾æ¢ä»¶ã€‚é è¨­ None ä»£è¡¨ä¸ç‰¹åˆ¥é™åˆ¶ã€‚

    Returns
    -------
    pathlib.Path
        å¯¦éš›å¯«å‡ºçš„æª”æ¡ˆå®Œæ•´è·¯å¾‘ã€‚

    Notes
    -----
    - ç›®å‰æœƒæœå°‹å‰¯æª”åç‚º .xls / .xlsx / .xlsm çš„æª”æ¡ˆã€‚
    - å¦‚æœæ²’æœ‰æ‰¾åˆ°ä»»ä½•ç¬¦åˆæ¢ä»¶çš„ Excel æª”ï¼Œæœƒ raise FileNotFoundErrorã€‚
    """

    root = Path(root).resolve()

    # ä½¿ç”¨æ—¢æœ‰çš„ PathWalk_df å–å¾—æª”æ¡ˆæ¸…å–®
    df_paths = PathWalk_df(
        root,
        dirinclude=dirinclude or [],
        direxclude=direxclude or [],
        fileexclude=fileexclude or [],
        fileinclude=fileinclude or [],
        level=level,
    )

    if df_paths.empty:
        raise FileNotFoundError(f"åœ¨è³‡æ–™å¤¾ {root} åº•ä¸‹æ‰¾ä¸åˆ°ä»»ä½•æª”æ¡ˆï¼ˆPathWalk_df çµæœç‚ºç©ºï¼‰")

    # åªä¿ç•™ Excel æª”
    excel_mask = df_paths["file"].str.lower().str.endswith((".xls", ".xlsx", ".xlsm"))
    df_paths = df_paths[excel_mask]

    if df_paths.empty:
        raise FileNotFoundError(f"åœ¨è³‡æ–™å¤¾ {root} åº•ä¸‹æ‰¾ä¸åˆ°ä»»ä½• Excel æª”ï¼ˆ.xls/.xlsx/.xlsmï¼‰")

    # é–‹å§‹ä¾å·¥ä½œè¡¨åç¨±ç´¯ç© DataFrame
    sheets: dict[str, pd.DataFrame] = {}

    for path_str in df_paths["path"]:
        path_file = Path(path_str)
        # è®€å–æ•´æ”¯ Excelï¼šå›å‚³ dict(sheet_name -> DataFrame)
        xls_dict = pd.read_excel(path_file, sheet_name=None)

        for sheet_name, df in xls_dict.items():
            if sheet_name not in sheets:
                sheets[sheet_name] = df.copy()
            else:
                sheets[sheet_name] = pd.concat(
                    [sheets[sheet_name], df],
                    ignore_index=True,
                )

    # æ±ºå®šè¼¸å‡ºè·¯å¾‘
    out_path = Path(output_filename)
    if not out_path.is_absolute():
        out_path = root / out_path

    # å¯«æˆä¸€å€‹å¤šå·¥ä½œè¡¨çš„çµ±æ•´æª”æ¡ˆ
    if not sheets:
        raise RuntimeError("æ²’æœ‰ä»»ä½•å·¥ä½œè¡¨å¯ä»¥å¯«å‡ºï¼ˆsheets ç‚ºç©ºï¼‰ã€‚")

    with pd.ExcelWriter(out_path) as writer:
        for sheet_name, df in sheets.items():
            # Excel sheet åç¨±æœ€å¤š 31 å­—å…ƒï¼Œè¶…éå°±æˆªæ–·
            safe_name = str(sheet_name)[:31]
            df.to_excel(writer, sheet_name=safe_name, index=False)

    return out_path

def logmaker(write_dt, data_dt, log=pd.Series(dtype='object'), period=None, index=None):
    """Compose a logging Series with optional period granularity."""
    if period == "month":
        period = str(data_dt).rsplit("-", 1)[0]
    elif period == "year":
        period = str(data_dt.year)
    elif period == "day":
        period = data_dt
    base = pd.Series({
        "write_dt": write_dt,
        "data_dt": data_dt,
        "period": period,
        "index": index
    }, dtype='object')
    return pd.concat([base, log], axis=1).dropna(how="any", axis=1)

def logfromfolder(path_df, log=None, fillval=None, avoid=None):
    """
    æ ¹æ“šè³‡æ–™å¤¾å…§å¯¦éš›å­˜åœ¨çš„æª”æ¡ˆï¼Œæ›´æ–° log DataFrameã€‚

    åƒæ•¸
    ----
    path_df : pandas.DataFrame
        é€šå¸¸ç”± PathWalk_df å›å‚³çš„çµæœï¼Œè‡³å°‘éœ€è¦ 'file' æ¬„ä½ã€‚
    log : pandas.DataFrame or None
        åŸæœ¬çš„ log è³‡æ–™è¡¨ï¼Œindex é€šå¸¸æ˜¯ã€ŒæŸç¨® IDã€ï¼Œæ¬„ä½æ˜¯ç‹€æ…‹æ¬„ä½ã€‚
        è‹¥ç‚º Noneï¼Œå‰‡å»ºç«‹ä¸€å€‹æ–°çš„ç©º DataFrameã€‚
    fillval : Any
        æ‰¾åˆ°å°æ‡‰æª”æ¡ˆæ™‚ï¼Œè¦å¡«å…¥ log çš„å€¼ï¼Œä¾‹å¦‚ "succeed" / True ç­‰ã€‚
    avoid : list or None
        è‹¥ log åŸæœ¬è©²æ ¼çš„å€¼åœ¨ avoid è£¡ï¼Œå°±è·³éä¸è¦†è“‹ã€‚

    å›å‚³
    ----
    pandas.DataFrame
        æ›´æ–°å¾Œçš„ logã€‚
    """
    import pandas as pd

    if log is None:
        log = pd.DataFrame()

    if avoid is None:
        avoid = []

    # å…ˆæŠŠæ—¢æœ‰çš„ 'succeed' è¦–ç‚ºå¾…ç¢ºèªç‹€æ…‹ï¼ˆç…§ä½ åŸæœ¬é‚è¼¯ï¼‰
    log = log.replace({"succeed": "wait"})

    for name in path_df["file"]:
        parts = name.split("_")
        if len(parts) < 2:
            continue

        col = parts[0]
        ind = parts[1].split(".")[0]

        if col in log and ind in log.index:
            if log.loc[ind, col] in avoid:
                # é€™äº›ç‹€æ…‹ä¸è¦†å¯«
                continue

        log.loc[ind, col] = fillval

    return log


"""
from StevenTricks.io.file_utils import merge_excel_sheets_from_folder

root = r"D:\è½‰æª”\nums_applicationè³‡æ–™æ¸…ç†\10AH25YA23TA_AU_è³‡æ–™åŒ¯å…¥9è‡³16"

out_path = merge_excel_sheets_from_folder(root)
print(out_path)


# åªè™•ç†ç¬¬ 0 å±¤ï¼ˆä¸å¾€å­è³‡æ–™å¤¾è·‘ï¼‰ï¼Œä¸”åªåƒæª”åå«ã€Œ_9è‡³16ã€çš„
out_path = merge_excel_sheets_from_folder(
    root,
    level=0,
    fileinclude=["9è‡³16"],
)
from StevenTricks.io.file_utils import merge_excel_sheets_from_folder
merge_excel_sheets_from_folder(r"D:\è½‰æª”\...")


"""