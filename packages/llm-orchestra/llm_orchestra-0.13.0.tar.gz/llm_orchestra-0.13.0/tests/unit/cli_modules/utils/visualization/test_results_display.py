"""Comprehensive tests for results display module."""

from typing import Any
from unittest.mock import Mock, patch

from llm_orc.cli_modules.utils.visualization.results_display import (
    _display_detailed_plain_text,
    _display_plain_text_dependency_graph,
    _display_simplified_plain_text,
    _format_performance_metrics,
    _has_code_content,
    _process_agent_results,
    display_plain_text_results,
    display_results,
    display_simplified_results,
)


class TestDisplayResults:
    """Test main results display functions."""

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.find_final_agent")
    def test_display_results_simple_mode(
        self, mock_find_final: Mock, mock_console_class: Mock
    ) -> None:
        """Test display results in simple mode."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console
        mock_find_final.return_value = "agent_a"

        results = {"agent_a": {"response": "Hello world"}}
        metadata: dict[str, Any] = {}
        agents = [{"name": "agent_a"}]

        display_results(results, metadata, agents, detailed=False)

        mock_console.print.assert_called()
        assert mock_console.print.call_count >= 1

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._process_agent_results"
    )
    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._format_performance_metrics"
    )
    def test_display_results_detailed_mode(
        self,
        mock_format_perf: Mock,
        mock_process_results: Mock,
        mock_console_class: Mock,
    ) -> None:
        """Test display results in detailed mode."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console
        mock_process_results.return_value = {
            "agent_a": {
                "status": "success",
                "response": "Hello",
                "error": "",
                "has_code": False,
            }
        }
        mock_format_perf.return_value = ["Performance: Good"]

        results = {"agent_a": {"status": "success", "response": "Hello"}}
        metadata = {"usage": {"totals": {"tokens": 100}}}
        agents = [{"name": "agent_a"}]

        display_results(results, metadata, agents, detailed=True)

        mock_process_results.assert_called_once_with(results)
        mock_format_perf.assert_called_once_with(metadata)
        assert mock_console.print.call_count >= 1

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.find_final_agent")
    def test_display_results_no_final_agent(
        self, mock_find_final: Mock, mock_console_class: Mock
    ) -> None:
        """Test display results when no final agent found."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console
        mock_find_final.return_value = None

        results: dict[str, Any] = {}
        metadata: dict[str, Any] = {}
        agents: list[dict[str, Any]] = []

        display_results(results, metadata, agents, detailed=False)

        mock_console.print.assert_called_with("No results to display")

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.find_final_agent")
    def test_display_results_final_agent_no_response(
        self, mock_find_final: Mock, mock_console_class: Mock
    ) -> None:
        """Test display results when final agent has no response."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console
        mock_find_final.return_value = "agent_a"

        results = {"agent_a": {"status": "success"}}  # No response field
        metadata: dict[str, Any] = {}
        agents = [{"name": "agent_a"}]

        display_results(results, metadata, agents, detailed=False)

        mock_console.print.assert_called_with("No results to display")


class TestDisplayPlainTextResults:
    """Test plain text results display."""

    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._display_detailed_plain_text"
    )
    def test_display_plain_text_results_detailed(self, mock_detailed: Mock) -> None:
        """Test plain text display in detailed mode."""
        results = {"agent_a": {"status": "success"}}
        metadata: dict[str, Any] = {}
        agents = [{"name": "agent_a"}]

        display_plain_text_results(results, metadata, detailed=True, agents=agents)

        mock_detailed.assert_called_once_with(results, metadata, agents)

    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._display_simplified_plain_text"
    )
    def test_display_plain_text_results_simple(self, mock_simplified: Mock) -> None:
        """Test plain text display in simple mode."""
        results = {"agent_a": {"status": "success"}}
        metadata: dict[str, Any] = {}

        display_plain_text_results(results, metadata, detailed=False)

        mock_simplified.assert_called_once_with(results, metadata)

    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._display_detailed_plain_text"
    )
    def test_display_plain_text_results_no_agents(self, mock_detailed: Mock) -> None:
        """Test plain text display with no agents parameter."""
        results = {"agent_a": {"status": "success"}}
        metadata: dict[str, Any] = {}

        display_plain_text_results(results, metadata, detailed=True)

        mock_detailed.assert_called_once_with(results, metadata, [])


class TestDisplaySimplifiedResults:
    """Test simplified results display."""

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_simplified_results_success(
        self, mock_echo: Mock, mock_console_class: Mock
    ) -> None:
        """Test simplified display with successful results."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console

        results = {
            "agent_a": {"status": "success", "response": "Hello"},
            "agent_b": {"status": "failed"},
        }
        metadata = {"usage": {"totals": {"agents_count": 2}}, "duration": "5s"}

        display_simplified_results(results, metadata)

        mock_echo.assert_called()
        # Should show result from agent_a and performance summary
        calls = []
        for call in mock_echo.call_args_list:
            if call[0]:  # Check if call has positional arguments
                calls.append(call[0][0])
        assert any("Result from agent_a:" in call for call in calls)
        assert any("Hello" in call for call in calls)

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_simplified_results_no_success(
        self, mock_echo: Mock, mock_console_class: Mock
    ) -> None:
        """Test simplified display with no successful results."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console

        results = {
            "agent_a": {"status": "failed"},
            "agent_b": {"status": "error"},
        }
        metadata: dict[str, Any] = {}

        display_simplified_results(results, metadata)

        mock_echo.assert_called_with("âŒ No successful results found")

    @patch("llm_orc.cli_modules.utils.visualization.results_display.Console")
    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_simplified_results_with_performance(
        self, mock_echo: Mock, mock_console_class: Mock
    ) -> None:
        """Test simplified display includes performance info."""
        mock_console = Mock()
        mock_console_class.return_value = mock_console

        results = {"agent_a": {"status": "success", "response": "Hello"}}
        metadata = {"usage": {"totals": {"agents_count": 1}}, "duration": "2s"}

        display_simplified_results(results, metadata)

        calls = []
        for call in mock_echo.call_args_list:
            if call[0]:  # Check if call has positional arguments
                calls.append(call[0][0])
        assert any("âš¡ 1 agents completed in 2s" in call for call in calls)


class TestProcessAgentResults:
    """Test processing agent results."""

    def test_process_agent_results_success(self) -> None:
        """Test processing successful agent results."""
        results = {
            "agent_a": {
                "status": "success",
                "response": "def hello(): pass",
                "error": "",
            }
        }

        processed = _process_agent_results(results)

        assert "agent_a" in processed
        assert processed["agent_a"]["status"] == "success"
        assert processed["agent_a"]["response"] == "def hello(): pass"
        assert processed["agent_a"]["error"] == ""
        assert processed["agent_a"]["has_code"]

    def test_process_agent_results_with_content_field(self) -> None:
        """Test processing results with content field instead of response."""
        results = {
            "agent_a": {
                "status": "success",
                "content": "Hello world",
            }
        }

        processed = _process_agent_results(results)

        assert processed["agent_a"]["response"] == "Hello world"
        assert not processed["agent_a"]["has_code"]

    def test_process_agent_results_with_error(self) -> None:
        """Test processing results with errors."""
        results = {"agent_a": {"status": "failed", "error": "Connection timeout"}}

        processed = _process_agent_results(results)

        assert processed["agent_a"]["status"] == "failed"
        assert processed["agent_a"]["error"] == "Connection timeout"
        assert processed["agent_a"]["response"] == ""

    def test_process_agent_results_defaults(self) -> None:
        """Test processing results with missing fields."""
        results: dict[str, Any] = {"agent_a": {}}

        processed = _process_agent_results(results)

        assert processed["agent_a"]["status"] == "unknown"
        assert processed["agent_a"]["response"] == ""
        assert processed["agent_a"]["error"] == ""
        assert not processed["agent_a"]["has_code"]


class TestFormatPerformanceMetrics:
    """Test formatting performance metrics."""

    def test_format_performance_metrics_with_usage(self) -> None:
        """Test formatting metrics with usage data."""
        metadata = {
            "usage": {
                "totals": {
                    "agents_count": 3,
                    "total_tokens": 1500,
                    "total_cost_usd": 0.0234,
                }
            },
            "duration": "12.5s",
        }

        result = _format_performance_metrics(metadata)

        assert len(result) > 0
        result_str = "\n".join(result)
        assert "ðŸ“Š Performance Summary" in result_str
        assert "Total agents: 3" in result_str
        assert "Total tokens: 1,500" in result_str
        assert "Total cost: $0.0234" in result_str
        assert "Duration: 12.5s" in result_str

    def test_format_performance_metrics_no_usage(self) -> None:
        """Test formatting metrics without usage data."""
        metadata = {"duration": "5s"}

        result = _format_performance_metrics(metadata)

        assert result == []

    def test_format_performance_metrics_empty(self) -> None:
        """Test formatting with empty metadata."""
        result = _format_performance_metrics({})

        assert result == []


class TestHasCodeContent:
    """Test code content detection."""

    def test_has_code_content_function_def(self) -> None:
        """Test detecting function definition."""
        text = "def hello_world(): return 'Hello'"

        assert _has_code_content(text)

    def test_has_code_content_class_def(self) -> None:
        """Test detecting class definition."""
        text = "class MyClass: pass"

        assert _has_code_content(text)

    def test_has_code_content_code_block(self) -> None:
        """Test detecting code block."""
        text = "Here's some code:\n```python\nprint('hello')\n```"

        assert _has_code_content(text)

    def test_has_code_content_import_statement(self) -> None:
        """Test detecting import statement."""
        text = "import os\nfrom typing import List"

        assert _has_code_content(text)

    def test_has_code_content_braces(self) -> None:
        """Test detecting braces."""
        text = "const obj = { key: 'value' };"

        assert _has_code_content(text)

    def test_has_code_content_regular_text(self) -> None:
        """Test regular text doesn't trigger detection."""
        text = "This is just regular text with no code indicators."

        assert not _has_code_content(text)

    def test_has_code_content_empty(self) -> None:
        """Test empty text."""
        assert not _has_code_content("")
        # Test empty string instead of None since function expects str
        assert not _has_code_content("")


class TestHelperDisplayFunctions:
    """Test helper display functions."""

    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._display_plain_text_dependency_graph"
    )
    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._format_performance_metrics"
    )
    def test_display_detailed_plain_text(
        self, mock_format_perf: Mock, mock_display_graph: Mock, mock_echo: Mock
    ) -> None:
        """Test detailed plain text display."""
        mock_format_perf.return_value = ["Performance: Good"]

        results = {
            "agent_a": {"status": "success", "response": "Hello"},
            "agent_b": {"status": "failed", "error": "Error occurred"},
        }
        metadata: dict[str, Any] = {}
        agents = [{"name": "agent_a"}, {"name": "agent_b"}]

        _display_detailed_plain_text(results, metadata, agents)

        mock_display_graph.assert_called_once_with(agents)
        mock_format_perf.assert_called_once_with(metadata)
        mock_echo.assert_called()

    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_simplified_plain_text(self, mock_echo: Mock) -> None:
        """Test simplified plain text display."""
        results = {
            "agent_a": {"status": "success", "response": "Hello world"},
            "agent_b": {"status": "failed"},
        }
        metadata: dict[str, Any] = {}

        _display_simplified_plain_text(results, metadata)

        calls = [call[0][0] for call in mock_echo.call_args_list]
        assert any("Result from agent_a:" in call for call in calls)
        assert any("Hello world" in call for call in calls)

    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_simplified_plain_text_no_success(self, mock_echo: Mock) -> None:
        """Test simplified plain text with no successful results."""
        results = {"agent_a": {"status": "failed"}}
        metadata: dict[str, Any] = {}

        _display_simplified_plain_text(results, metadata)

        mock_echo.assert_called_with("âŒ No successful results found")

    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    @patch(
        "llm_orc.cli_modules.utils.visualization.results_display._create_plain_text_dependency_graph"
    )
    def test_display_plain_text_dependency_graph(
        self, mock_create_graph: Mock, mock_echo: Mock
    ) -> None:
        """Test plain text dependency graph display."""
        mock_create_graph.return_value = ["agent_a", "â†’", "agent_b"]
        agents = [{"name": "agent_a"}, {"name": "agent_b"}]

        _display_plain_text_dependency_graph(agents)

        mock_create_graph.assert_called_once_with(agents)
        mock_echo.assert_called()

    @patch("llm_orc.cli_modules.utils.visualization.results_display.click.echo")
    def test_display_plain_text_dependency_graph_empty(self, mock_echo: Mock) -> None:
        """Test plain text dependency graph with empty agents."""
        _display_plain_text_dependency_graph([])

        # Should not call echo since there are no agents
        assert mock_echo.call_count == 0  # Only "Agent Dependencies:" and empty line


class TestNewHelperFunctions:
    """Test the new helper functions created during complexity refactoring."""

    def test_format_usage_summary(self) -> None:
        """Test _format_usage_summary function."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_usage_summary,
        )

        metadata = {
            "usage": {
                "totals": {
                    "agents_count": 2,
                    "total_tokens": 1000,
                    "total_cost_usd": 0.05,
                },
                "agents": {"agent_a": {"total_tokens": 500}},
            },
            "duration": "10s",
        }

        result = _format_usage_summary(metadata)

        assert len(result) > 0
        result_str = "\n".join(result)
        assert "ðŸ“Š Performance Summary" in result_str
        assert "Total agents: 2" in result_str
        assert "Total tokens: 1,000" in result_str
        assert "Duration: 10s" in result_str

    def test_format_usage_summary_no_usage(self) -> None:
        """Test _format_usage_summary with no usage data."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_usage_summary,
        )

        result = _format_usage_summary({})
        assert result == []

    def test_format_single_agent_usage(self) -> None:
        """Test _format_single_agent_usage function."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_single_agent_usage,
        )

        agent_usage = {
            "total_tokens": 500,
            "total_cost_usd": 0.025,
            "input_tokens": 300,
            "output_tokens": 200,
            "duration_seconds": 5.5,
            "peak_cpu": 80.0,
            "avg_cpu": 65.0,
            "peak_memory": 150.0,
            "avg_memory": 120.0,
        }

        result = _format_single_agent_usage("test_agent", agent_usage)

        assert len(result) > 0
        result_str = "\n".join(result)
        assert "test_agent:" in result_str
        assert "Tokens: 500" in result_str
        assert "input: 300" in result_str
        assert "output: 200" in result_str
        assert "Cost: $0.0250" in result_str
        assert "Duration: 5.50s" in result_str
        assert "Peak CPU: 80.0%" in result_str
        assert "Avg CPU: 65.0%" in result_str

    def test_format_concurrency_info(self) -> None:
        """Test _format_concurrency_info function."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_concurrency_info,
        )

        arm = {
            "concurrency_decisions": [
                {"configured_limit": 5},
                {"configured_limit": 3},
            ]
        }

        result = _format_concurrency_info(arm)

        assert len(result) > 0
        assert "Max concurrency limit used: 5" in result[0]

    def test_format_concurrency_info_no_decisions(self) -> None:
        """Test _format_concurrency_info with no decisions."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_concurrency_info,
        )

        result = _format_concurrency_info({})
        assert result == []

    def test_format_single_phase(self) -> None:
        """Test _format_single_phase function."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_single_phase,
        )

        phase = {
            "duration_seconds": 8.5,
            "agent_names": ["agent_a", "agent_b", "agent_c"],
            "peak_cpu": 75.0,
            "avg_cpu": 60.0,
        }

        result = _format_single_phase(0, phase, 2)

        assert len(result) > 0
        result_str = "\n".join(result)
        assert "Phase 1: 8.50s" in result_str
        assert "Agents: agent_a, agent_b, agent_c" in result_str

    def test_format_single_phase_many_agents(self) -> None:
        """Test _format_single_phase with many agents."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_single_phase,
        )

        phase = {
            "agent_names": ["agent_a", "agent_b", "agent_c", "agent_d", "agent_e"],
        }

        result = _format_single_phase(0, phase, 1)

        result_str = "\n".join(result)
        assert "(+1 more)" in result_str

    def test_format_phase_resource_metrics(self) -> None:
        """Test _format_phase_resource_metrics function."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_phase_resource_metrics,
        )

        phase = {
            "peak_cpu": 85.5,
            "avg_cpu": 70.2,
            "peak_memory": 200.0,
            "avg_memory": 150.0,
        }

        result = _format_phase_resource_metrics(phase)

        assert len(result) > 0
        # Should have multiple resource lines, so they get displayed separately
        result_str = "\n".join(result)
        assert "Peak CPU: 85.5%" in result_str
        assert "Avg CPU: 70.2%" in result_str
        assert "Peak memory: 200.0 MB" in result_str
        assert "Avg memory: 150.0 MB" in result_str

    def test_format_phase_resource_metrics_few_metrics(self) -> None:
        """Test _format_phase_resource_metrics with few metrics."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_phase_resource_metrics,
        )

        phase = {"peak_cpu": 75.0, "avg_cpu": 60.0}

        result = _format_phase_resource_metrics(phase)

        # Should combine into single line since <= 2 metrics
        assert len(result) == 1
        assert "Peak CPU: 75.0% â€¢ Avg CPU: 60.0%" in result[0]

    def test_format_phase_resource_metrics_empty(self) -> None:
        """Test _format_phase_resource_metrics with empty phase."""
        from llm_orc.cli_modules.utils.visualization.results_display import (
            _format_phase_resource_metrics,
        )

        result = _format_phase_resource_metrics({})
        assert result == []
