name: gemma-swarm-vs-claude-study
description: |
  Compare performance of many small models (Gemma 1B swarm) vs single large model (Claude).
  Tests if collective intelligence can match individual large model performance.

agents:
  # Set up experimental parameters and replication
  - name: experiment-setup
    script: primitives/control-flow/replicate_n_times.py
    parameters:
      replications: 10  # Number of experimental runs for statistical power
      experiment_id: "swarm-vs-claude-2024"
      
  # Swarm execution with multiple Gemma agents
  - name: swarm-execution
    script: experiments/swarm/execute_gemma_swarm.py
    depends_on: [experiment-setup]
    parameters:
      swarm_size: 5           # 5 Gemma agents (manageable for local testing)
      model_profile: swarm-coordinator
      consensus_mechanism: majority_vote
      problem_type: reasoning_task
      task_description: |
        Analyze the following complex scenario and provide a comprehensive solution.
        Each agent should contribute their perspective, then reach consensus.
        
  # Single Claude baseline for comparison
  - name: claude-baseline
    model_profile: research-analyst
    system_prompt: |
      You are a comprehensive AI assistant. Analyze the complex scenario 
      and provide a thorough solution. Match the depth and quality that 
      multiple specialized agents might achieve together.
    depends_on: [experiment-setup]
    
  # Collect and analyze performance metrics
  - name: performance-analysis
    script: primitives/research/compare_performance.py
    depends_on: [swarm-execution, claude-baseline]
    parameters:
      metrics:
        - response_quality
        - problem_coverage
        - solution_creativity
        - factual_accuracy
        - coherence_score
      comparison_method: statistical
      
  # Statistical significance testing
  - name: statistical-comparison
    script: primitives/research/t_test.py
    depends_on: [performance-analysis]
    parameters:
      comparison_groups: [swarm, single_model]
      significance_level: 0.05
      test_type: two_sample
      
  # Generate research conclusions
  - name: research-conclusions
    model_profile: research-analyst
    system_prompt: |
      Analyze the swarm intelligence vs single model comparison results.
      
      Key questions to address:
      1. Can multiple small models match single large model performance?
      2. What are the trade-offs in accuracy, creativity, and coherence?
      3. When might swarm approaches be preferable?
      4. What does this tell us about collective intelligence?
      
      Provide scientific conclusions suitable for publication.
    depends_on: [statistical-comparison]