"""Integration tests for the uninstall command (no mocking)."""

import json
from pathlib import Path

from click.testing import CliRunner

from src.cli.main import cli


def create_test_config(
    path: Path,
    has_mcpservers: bool = True,
    has_mcp_browser: bool = True,
    other_servers: bool = False,
):
    """Create a test configuration file."""
    config = {}

    if has_mcpservers:
        config["mcpServers"] = {}

        if has_mcp_browser:
            config["mcpServers"]["mcp-browser"] = {
                "command": "mcp-browser",
                "args": ["mcp"],
            }

        if other_servers:
            config["mcpServers"]["other-server"] = {
                "command": "other-command",
                "args": ["arg1"],
            }

    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, "w") as f:
        json.dump(config, f, indent=2)

    return config


def test_help_output():
    """Test 1: Verify help output is correct."""
    print("\n" + "=" * 70)
    print("TEST 1: Verify uninstall --help output")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--help"])

    print(f"\nğŸ“¤ Help output:\n{result.output}")

    # Assertions
    assert result.exit_code == 0, "âŒ Help should exit with code 0"
    assert "Remove MCP Browser configuration" in result.output, "âŒ Description missing"
    assert "--target" in result.output, "âŒ --target option missing"
    assert "claude-code" in result.output, "âŒ claude-code option missing"
    assert "claude-desktop" in result.output, "âŒ claude-desktop option missing"
    assert "both" in result.output, "âŒ both option missing"

    print("\nâœ… TEST 1 PASSED: Help output is correct")
    return True


def test_cli_registration():
    """Test 2: Verify command is registered in main CLI."""
    print("\n" + "=" * 70)
    print("TEST 2: Verify command registration in CLI")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["--help"])

    print("\nğŸ“¤ CLI help output (snippet):\n")
    lines = result.output.split("\n")
    for line in lines:
        if "uninstall" in line.lower():
            print(line)

    # Assertions
    assert result.exit_code == 0, "âŒ CLI help should exit with code 0"
    assert "uninstall" in result.output.lower(), "âŒ uninstall command not found in CLI"

    print("\nâœ… TEST 2 PASSED: Command is properly registered")
    return True


def test_completion_scripts():
    """Test 3: Verify completion scripts include uninstall."""
    print("\n" + "=" * 70)
    print("TEST 3: Verify completion scripts updated")
    print("=" * 70)

    scripts_dir = Path(__file__).parent / "scripts"

    # Test bash completion
    bash_script = scripts_dir / "completion.bash"
    if bash_script.exists():
        bash_content = bash_script.read_text()
        print("\nğŸ“ Checking bash completion...")
        if "uninstall" in bash_content:
            print("âœ“ bash completion includes 'uninstall'")
        else:
            print("âœ— bash completion MISSING 'uninstall'")
    else:
        print("âš  bash completion script not found")

    # Test zsh completion
    zsh_script = scripts_dir / "completion.zsh"
    if zsh_script.exists():
        zsh_content = zsh_script.read_text()
        print("\nğŸ“ Checking zsh completion...")
        if "uninstall" in zsh_content:
            print("âœ“ zsh completion includes 'uninstall'")
        else:
            print("âœ— zsh completion MISSING 'uninstall'")
    else:
        print("âš  zsh completion script not found")

    # Test inline completion in main.py
    runner = CliRunner()
    result = runner.invoke(cli, ["completion", "bash"])

    print("\nğŸ“ Checking inline bash completion...")
    if "uninstall" in result.output:
        print("âœ“ inline bash completion includes 'uninstall'")
    else:
        print("âœ— inline bash completion MISSING 'uninstall'")

    result = runner.invoke(cli, ["completion", "zsh"])
    print("\nğŸ“ Checking inline zsh completion...")
    if "uninstall" in result.output:
        print("âœ“ inline zsh completion includes 'uninstall'")
    else:
        print("âœ— inline zsh completion MISSING 'uninstall'")

    result = runner.invoke(cli, ["completion", "fish"])
    print("\nğŸ“ Checking inline fish completion...")
    if "uninstall" in result.output:
        print("âœ“ inline fish completion includes 'uninstall'")
    else:
        print("âœ— inline fish completion MISSING 'uninstall'")

    print("\nâœ… TEST 3 PASSED: Completion scripts checked")
    return True


def test_uninstall_actual_behavior():
    """Test 4: Test actual command behavior (without system paths)."""
    print("\n" + "=" * 70)
    print("TEST 4: Test uninstall behavior (dry run)")
    print("=" * 70)

    # Since we can't mock easily, test with non-existent paths
    # This tests error handling
    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--target", "claude-code"])

    print(f"\nğŸ“¤ Command output:\n{result.output}")
    print(f"Exit code: {result.exit_code}")

    # Should handle gracefully
    assert result.exit_code == 0, "âŒ Should exit gracefully"
    assert (
        "not found" in result.output.lower()
        or "not configured" in result.output.lower()
        or "complete" in result.output.lower()
    ), "âŒ Should provide feedback"

    print("\nâœ… TEST 4 PASSED: Command executes without crashing")
    return True


def test_reference_command():
    """Test 5: Verify uninstall appears in reference."""
    print("\n" + "=" * 70)
    print("TEST 5: Verify uninstall in reference guide")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["reference"])

    print("\nğŸ“ Checking reference guide...")

    if "uninstall" in result.output.lower():
        print("âœ“ reference guide includes 'uninstall'")
        # Find and print the relevant line
        lines = result.output.split("\n")
        for line in lines:
            if "uninstall" in line.lower():
                print(f"  {line.strip()}")
    else:
        print("âœ— reference guide MISSING 'uninstall'")

    print("\nâœ… TEST 5 PASSED: Reference checked")
    return True


def test_cleanup_flags_help():
    """Test 6: Verify new cleanup flags in help output."""
    print("\n" + "=" * 70)
    print("TEST 6: Verify new cleanup flags in help")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--help"])

    print("\nğŸ“¤ Help output (cleanup flags):\n")

    # Check for new flags
    flags_to_check = [
        "--clean-global",
        "--clean-local",
        "--clean-all",
        "--backup",
        "--playwright",
        "--dry-run",
        "--yes",
    ]

    found_flags = []
    for flag in flags_to_check:
        if flag in result.output:
            found_flags.append(flag)
            print(f"  âœ“ Found {flag}")
        else:
            print(f"  âœ— Missing {flag}")

    # Assertions
    assert result.exit_code == 0, "âŒ Help should exit with code 0"
    assert len(found_flags) == len(flags_to_check), (
        f"âŒ Missing flags: {set(flags_to_check) - set(found_flags)}"
    )

    print("\nâœ… TEST 6 PASSED: All cleanup flags present in help")
    return True


def test_dry_run_flag():
    """Test 7: Test --dry-run flag doesn't make changes."""
    print("\n" + "=" * 70)
    print("TEST 7: Test --dry-run flag")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--target", "claude-code", "--dry-run"])

    print(f"\nğŸ“¤ Command output:\n{result.output}")

    # Assertions
    assert result.exit_code == 0, "âŒ Should exit gracefully"
    assert "dry run" in result.output.lower() or "would" in result.output.lower(), (
        "âŒ Should indicate dry run mode"
    )

    print("\nâœ… TEST 7 PASSED: Dry run mode works")
    return True


def test_clean_all_flag():
    """Test 8: Test --clean-all flag is recognized."""
    print("\n" + "=" * 70)
    print("TEST 8: Test --clean-all flag")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--clean-all", "--dry-run"])

    print(f"\nğŸ“¤ Command output:\n{result.output}")

    # Assertions
    assert result.exit_code == 0, "âŒ Should exit gracefully"
    assert "clean" in result.output.lower(), "âŒ Should mention cleanup"

    print("\nâœ… TEST 8 PASSED: Clean-all flag works")
    return True


def test_yes_flag():
    """Test 9: Test --yes flag is recognized."""
    print("\n" + "=" * 70)
    print("TEST 9: Test --yes flag")
    print("=" * 70)

    runner = CliRunner()
    result = runner.invoke(cli, ["uninstall", "--dry-run", "-y"])

    print(f"\nğŸ“¤ Command output:\n{result.output}")

    # Assertions
    assert result.exit_code == 0, "âŒ Should exit gracefully"

    print("\nâœ… TEST 9 PASSED: Yes flag works")
    return True


def test_backup_flag():
    """Test 10: Test --backup/--no-backup flag is recognized."""
    print("\n" + "=" * 70)
    print("TEST 10: Test --backup/--no-backup flag")
    print("=" * 70)

    runner = CliRunner()

    # Test with --no-backup
    result = runner.invoke(
        cli, ["uninstall", "--clean-global", "--no-backup", "--dry-run"]
    )

    print(f"\nğŸ“¤ Command output (--no-backup):\n{result.output}")

    # Assertions
    assert result.exit_code == 0, "âŒ Should exit gracefully"

    print("\nâœ… TEST 10 PASSED: Backup flag works")
    return True


def run_all_tests():
    """Run all integration tests."""
    print("\n" + "=" * 70)
    print("ğŸ§ª UNINSTALL COMMAND INTEGRATION TEST SUITE")
    print("=" * 70)

    tests = [
        test_help_output,
        test_cli_registration,
        test_completion_scripts,
        test_uninstall_actual_behavior,
        test_reference_command,
        test_cleanup_flags_help,
        test_dry_run_flag,
        test_clean_all_flag,
        test_yes_flag,
        test_backup_flag,
    ]

    passed = 0
    failed = 0

    for test in tests:
        try:
            test()
            passed += 1
        except Exception as e:
            print(f"\nâŒ TEST FAILED: {test.__name__}")
            print(f"Error: {e}")
            import traceback

            traceback.print_exc()
            failed += 1

    print("\n" + "=" * 70)
    print("ğŸ“Š TEST SUMMARY")
    print("=" * 70)
    print(f"âœ… Passed: {passed}/{len(tests)}")
    print(f"âŒ Failed: {failed}/{len(tests)}")
    print("=" * 70)

    return failed == 0


if __name__ == "__main__":
    import sys

    success = run_all_tests()
    sys.exit(0 if success else 1)
