Index: eoml/automation/experience.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>\"\"\"\nExperience information module for machine learning experiments.\n\nThis module defines data structures for storing experiment information including\nraster readers, mappers, transformers, and spatial bounds for ML experiments.\n\"\"\"\nimport logging\nfrom pathlib import Path\nfrom typing import Any, Optional, Dict, List, Union, Literal\nimport tomli\nfrom pydantic import BaseModel, Field, field_validator, model_validator\n\nfrom eoml.automation.configuration import SystemConfigModel\nfrom eoml.raster.raster_utils import read_gdal_stats, SigmaNormalizer\n\nlogger = logging.getLogger(__name__)\n\nfrom eoml.raster.raster_reader import RasterReader, MultiRasterReader, append_raster_reader\nfrom eoml.raster.band import Band\nfrom eoml.torch.cnn.db_dataset import Mapper\nfrom eoml.torch.cnn.outputs_transformer import OutputTransformer\n\n\nclass MapperCategoryConfig(BaseModel):\n    \"\"\"Configuration for a single mapper category.\"\"\"\n\n    name: str = Field(\n        ...,\n        description=\"Name of the output category\"\n    )\n\n    labels: List[Union[int, str]] = Field(\n        ...,\n        description=\"List of input labels that map to this category\",\n        min_length=1\n    )\n\n    map_value: Optional[int] = Field(\n        None,\n        description=\"Output value for this category. If None, uses category index\"\n    )\n\n\nclass MapperConfig(BaseModel):\n    \"\"\"Configuration for the label mapper.\"\"\"\n\n    no_target: int = Field(\n        -1,\n        description=\"Value to use for invalid/missing labels\"\n    )\n\n    vectorize: bool = Field(\n        False,\n        description=\"Whether to use one-hot vector outputs instead of scalar\"\n    )\n\n    label_dictionary: Optional[Dict[str, int]] = Field(\n        None,\n        description=\"Optional mapping from label names to integer values\"\n    )\n\n    categories: List[MapperCategoryConfig] = Field(\n        ...,\n        description=\"List of output categories\",\n        min_length=1\n    )\n\n    def build_mapper(self) -> Mapper:\n        \"\"\"Build a Mapper instance from this configuration.\"\"\"\n        mapper = Mapper(\n            no_target=self.no_target,\n            vectorize=self.vectorize,\n            label_dictionary=self.label_dictionary\n        )\n\n        for category in self.categories:\n            mapper.add_category(\n                name=category.name,\n                labels=category.labels,\n                map_value=category.map_value\n            )\n\n        return mapper\n\n\nclass RasterReaderConfig(BaseModel):\n    \"\"\"Configuration for a single raster reader.\"\"\"\n\n    type: Literal[\"single\"] = Field(\n        \"single\",\n        description=\"Type of raster reader\"\n    )\n\n    path: str = Field(\n        ...,\n        description=\"Path to the raster file\"\n    )\n\n    bands: Optional[List[int]] = Field(\n        None,\n        description=\"List of band indices to use (1-indexed). If None, uses all bands\"\n    )\n\n    stats_path: Optional[str] = Field(\n        None,\n        description=\"Path to statistics file for normalization\"\n    )\n\n    interpolation: Optional[str] = Field(\n        None,\n        description=\"Interpolation method for resampling\"\n    )\n\n    read_profile: Optional[Dict[str, Any]] = Field(\n        None,\n        description=\"Rasterio read profile configuration\"\n    )\n\n    sharing: bool = Field(\n        False,\n        description=\"Enable file sharing mode\"\n    )\n\n    def build_reader(self) -> RasterReader:\n        \"\"\"Build a RasterReader instance from this configuration.\"\"\"\n        # Create Band object\n        if self.bands is not None:\n            band = Band(self.bands)\n        else:\n            band = Band.from_file(self.path)\n\n        # Load transformer (normalizer) if stats provided\n        normalizers = None\n        if self.stats_path:\n            raster_stat = read_gdal_stats(self.stats_path)\n\n            normalizers = SigmaNormalizer(raster_stat[band.selected, 0],\n                                          raster_stat[band.selected, 1],\n                                          3, True, 0)\n\n\n        return RasterReader(\n            path=self.path,\n            bands_list=band,\n            transformer=normalizers,\n            interpolation=self.interpolation,\n            read_profile=self.read_profile,\n            sharing=self.sharing\n        )\n\n\nclass MultiRasterReaderConfig(BaseModel):\n    \"\"\"Configuration for multiple raster readers.\"\"\"\n\n    type: Literal[\"multi\"] = Field(\n        \"multi\",\n        description=\"Type of raster reader\"\n    )\n\n    readers: List[RasterReaderConfig] = Field(\n        ...,\n        description=\"List of raster reader configurations\",\n        min_length=1\n    )\n\n    reference_index: int = Field(\n        0,\n        description=\"Index of the reader to use as spatial reference\",\n        ge=0\n    )\n\n    read_profile: Optional[Dict[str, Any]] = Field(\n        None,\n        description=\"Rasterio read profile configuration\"\n    )\n\n    sharing: bool = Field(\n        False,\n        description=\"Enable file sharing mode\"\n    )\n\n    @field_validator('reference_index')\n    @classmethod\n    def validate_reference_index(cls, v, info):\n        \"\"\"Ensure reference_index is within bounds of readers list.\"\"\"\n        readers = info.data.get('readers', [])\n        if readers and v >= len(readers):\n            raise ValueError(f\"reference_index {v} is out of bounds for {len(readers)} readers\")\n        return v\n\n    def build_reader(self) -> MultiRasterReader:\n        \"\"\"Build a MultiRasterReader instance from this configuration.\"\"\"\n        readers_list = [r.build_reader() for r in self.readers]\n\n        return append_raster_reader(\n            readers_list,\n            reference_index=self.reference_index,\n            read_profile=self.read_profile,\n            sharing=self.sharing\n        )\n\n\nclass BoundariesConfig(BaseModel):\n    \"\"\"Configuration for spatial boundaries and masks.\"\"\"\n\n    map_bounds: Optional[List[float]] = Field(\n        None,\n        description=\"Spatial bounds for mapping [minx, miny, maxx, maxy]\",\n        min_length=4,\n        max_length=4\n    )\n\n    map_mask: Optional[str] = Field(\n        None,\n        description=\"Path to mask defining valid mapping areas\"\n    )\n\n    sample_mask: Optional[str] = Field(\n        None,\n        description=\"Path to mask for filtering training/validation samples\"\n    )\n\n    @field_validator('map_bounds')\n    @classmethod\n    def validate_bounds(cls, v):\n        \"\"\"Ensure bounds are valid [minx, miny, maxx, maxy].\"\"\"\n        if v is not None:\n            if len(v) != 4:\n                raise ValueError(\"map_bounds must contain exactly 4 values [minx, miny, maxx, maxy]\")\n        return v\n\n\nclass ExperimentConfig(BaseModel):\n    \"\"\"Configuration for experiment parameters.\"\"\"\n\n    gps_file: str = Field(\n        \"CH_39_all\",\n        description=\"Name of the geopackage file (without extension)\"\n    )\n\n    extract_size: int = Field(\n        47,\n        description=\"Size of extracted windows from raster data\",\n        gt=0\n    )\n\n    size: int = Field(\n        31,\n        description=\"Size of input windows for the neural network\",\n        gt=0\n    )\n\n    class_label: str = Field(\n        \"Class\",\n        description=\"Name of the class label column in the geopackage\"\n    )\n\n    model_name: str = Field(\n        \"Resnet20\",\n        description=\"Name of the neural network model to use\"\n    )\n\n    batch_mult: float = Field(\n        0.25,\n        description=\"Batch size multiplier for training\",\n        gt=0\n    )\n\n    batch_mult_map: float = Field(\n        0.5,\n        description=\"Batch size multiplier for mapping\",\n        gt=0\n    )\n\n    epoch: int = Field(\n        1,\n        description=\"Number of training epochs\",\n        gt=0\n    )\n\n    map_tag_name: Optional[str] = Field(\n        None,\n        description=\"Tag name for the mapping output\"\n    )\n\n    nfold: int = Field(\n        5,\n        description=\"Number of folds for k-fold cross-validation\",\n        gt=0\n    )\n\n    device: Union[str, List[int]] = Field(\n        \"auto\",\n        description=\"Device selection: 'auto', 'cpu', 'cuda', 'gpu', or list of CUDA device IDs [0, 1, 2]\"\n    )\n\n    random_seed: Optional[int] = Field(\n        None,\n        description=\"Master random seed for reproducibility. If None, a random seed will be generated. \"\n                    \"This sets the default for all other seeds if they are not specified.\",\n        ge=0\n    )\n\n    python_seed: Optional[int] = Field(\n        None,\n        description=\"Seed for Python's random module. If None, uses random_seed.\",\n        ge=0\n    )\n\n    numpy_seed: Optional[int] = Field(\n        None,\n        description=\"Seed for NumPy's random number generator. If None, uses random_seed.\",\n        ge=0\n    )\n\n    torch_seed: Optional[int] = Field(\n        None,\n        description=\"Seed for PyTorch's random number generator. If None, uses random_seed.\",\n        ge=0\n    )\n\n    torch_deterministic: bool = Field(\n        False,\n        description=\"Enable deterministic behavior in PyTorch (may reduce performance). \"\n                    \"When True, sets torch.use_deterministic_algorithms(True) and \"\n                    \"configures cuDNN for deterministic behavior.\"\n    )\n\n    @field_validator('size')\n    @classmethod\n    def validate_size(cls, v, info):\n        \"\"\"Ensure size <= extract_size.\"\"\"\n        extract_size = info.data.get('extract_size')\n        if extract_size is not None and v > extract_size:\n            raise ValueError(f\"size ({v}) must be <= extract_size ({extract_size})\")\n        return v\n\n    @field_validator('map_tag_name')\n    @classmethod\n    def set_default_map_tag_name(cls, v, info):\n        \"\"\"Set default map_tag_name based on gps_file if not provided.\"\"\"\n        if v is None:\n            gps_file = info.data.get('gps_file', 'CH_39_all')\n            return f\"CH_2022_{gps_file}\"\n        return v\n\n    @field_validator('device')\n    @classmethod\n    def validate_device(cls, v):\n        \"\"\"Validate device configuration.\"\"\"\n        if isinstance(v, str):\n            v_lower = v.lower()\n            if v_lower not in ['auto', 'automatic', 'cpu', 'cuda', 'gpu']:\n                raise ValueError(\n                    f\"Invalid device string '{v}'. Must be one of: 'auto', 'automatic', 'cpu', 'cuda', 'gpu'\"\n                )\n            # Normalize to standard values\n            if v_lower in ['automatic', 'gpu']:\n                return 'auto' if v_lower == 'automatic' else 'cuda'\n            return v_lower\n        elif isinstance(v, list):\n            # Validate list of device IDs\n            if not all(isinstance(x, int) and x >= 0 for x in v):\n                raise ValueError(\n                    f\"Device list must contain only non-negative integers, got: {v}\"\n                )\n            if len(v) == 0:\n                raise ValueError(\"Device list cannot be empty\")\n            return v\n        else:\n            raise ValueError(\n                f\"Device must be a string or list of integers, got: {type(v).__name__}\"\n            )\n\n    @field_validator('random_seed')\n    @classmethod\n    def validate_random_seed(cls, v):\n        \"\"\"Validate random seed and generate one if None.\"\"\"\n        if v is None:\n            # Generate a random seed\n            import random\n            import time\n            return int(time.time() * 1000) % (2**31)  # Use timestamp-based seed\n        return v\n\n    @model_validator(mode='after')\n    def set_default_seeds(self):\n        \"\"\"\n        Set individual seeds based on random_seed if not specified.\n\n        Instead of using identical seeds (which can cause correlations), we derive\n        independent seeds from the master seed using a simple but effective method:\n        - python_seed = random_seed + 0\n        - numpy_seed = random_seed + 1\n        - torch_seed = random_seed + 2\n\n        This ensures reproducibility while avoiding unwanted correlations between RNGs.\n        \"\"\"\n        if self.python_seed is None:\n            self.python_seed = self.random_seed\n        if self.numpy_seed is None:\n            # Derive a different seed to avoid correlation\n            self.numpy_seed = (self.random_seed + 1) % (2**31)\n        if self.torch_seed is None:\n            # Derive yet another different seed\n            self.torch_seed = (self.random_seed + 2) % (2**31)\n        return self\n\n    def get_device(self) -> str:\n        \"\"\"\n        Get the PyTorch device string based on configuration.\n\n        Returns:\n            str: PyTorch device string (e.g., 'cpu', 'cuda', 'cuda:0', 'cuda:1')\n        \"\"\"\n        import torch\n\n        if isinstance(self.device, list):\n            # Use first device in list as primary\n            if torch.cuda.is_available():\n                return f\"cuda:{self.device[0]}\"\n            else:\n                logger.warning(\"CUDA not available, falling back to CPU\")\n                return \"cpu\"\n\n        device_str = self.device.lower()\n\n        if device_str == 'auto':\n            return 'cuda' if torch.cuda.is_available() else 'cpu'\n        elif device_str in ['cuda', 'gpu']:\n            if torch.cuda.is_available():\n                return 'cuda'\n            else:\n                logger.warning(\"CUDA not available, falling back to CPU\")\n                return 'cpu'\n        else:  # 'cpu'\n            return 'cpu'\n\n    def get_map_mode(self) -> int:\n        \"\"\"\n        Get the mapping mode based on device configuration.\n\n        Returns:\n            int: Mapping mode (0 for CPU, 1 for GPU)\n        \"\"\"\n        device = self.get_device()\n        return 1 if device.startswith('cuda') else 0\n\n    def initialize_seeds(self, verbose: bool = True) -> Dict[str, int]:\n        \"\"\"\n        Initialize all random number generators with configured seeds.\n\n        Args:\n            verbose: If True, print seed information. Defaults to True.\n\n        Returns:\n            Dict[str, int]: Dictionary of all seeds that were set.\n        \"\"\"\n        import random\n        import numpy as np\n        import torch\n\n        seed_info = {\n            'master_seed': self.random_seed,\n            'python_seed': self.python_seed,\n            'numpy_seed': self.numpy_seed,\n            'torch_seed': self.torch_seed,\n        }\n\n        # Set Python random seed\n        random.seed(self.python_seed)\n\n        # Set NumPy random seed\n        np.random.seed(self.numpy_seed)\n\n        # Set PyTorch random seed\n        torch.manual_seed(self.torch_seed)\n        if torch.cuda.is_available():\n            torch.cuda.manual_seed_all(self.torch_seed)\n\n        # Configure deterministic behavior\n        if self.torch_deterministic:\n            torch.use_deterministic_algorithms(True)\n            torch.backends.cudnn.deterministic = True\n            torch.backends.cudnn.benchmark = False\n            seed_info['deterministic'] = True\n\n            # Set environment variable for CUDA determinism\n            import os\n            os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n        else:\n            seed_info['deterministic'] = False\n\n        if verbose:\n            logger.info(\"Random seeds initialized:\")\n            logger.info(f\"  - Master seed: {self.random_seed}\")\n\n            # Show individual seeds (with indication if they're derived or custom)\n            expected_numpy = (self.random_seed + 1) % (2**31)\n            expected_torch = (self.random_seed + 2) % (2**31)\n\n            if self.python_seed == self.random_seed:\n                logger.info(f\"  - Python:  {self.python_seed} (derived)\")\n            else:\n                logger.info(f\"  - Python:  {self.python_seed} (custom)\")\n\n            if self.numpy_seed == expected_numpy:\n                logger.info(f\"  - NumPy:   {self.numpy_seed} (derived)\")\n            else:\n                logger.info(f\"  - NumPy:   {self.numpy_seed} (custom)\")\n\n            if self.torch_seed == expected_torch:\n                logger.info(f\"  - PyTorch: {self.torch_seed} (derived)\")\n            else:\n                logger.info(f\"  - PyTorch: {self.torch_seed} (custom)\")\n\n            if self.torch_deterministic:\n                logger.info(\"  - Deterministic mode: ENABLED (may reduce performance)\")\n            else:\n                logger.info(\"  - Deterministic mode: Disabled\")\n\n        return seed_info\n\n\nclass ExperienceInfo(BaseModel):\n    \"\"\"\n    Complete configuration and runtime container for machine learning experiments.\n\n    This class stores both the configuration (loaded from TOML) and built runtime\n    components for running a machine learning experiment including data readers,\n    neural network mappers, and output transformers.\n\n    The class uses Pydantic for configuration parsing and validation. After loading,\n    the raster_reader and mapper fields are automatically transformed from config\n    objects to built runtime objects.\n\n    Attributes:\n        system_config: System configuration (paths, IO profiles, device/mapping settings).\n        experiment: Experiment parameters (training settings, model config, etc.).\n        raster_reader: Configuration (during init), then built reader object after validation.\n        mapper: Configuration (during init), then built mapper object after validation.\n        boundaries: Spatial boundaries and masks.\n        nn_output_transformer: Built transformer for post-processing model outputs (property).\n    \"\"\"\n\n    # Configuration fields\n    system_config: Optional[SystemConfigModel] = Field(\n        None,\n        description=\"System configuration (paths, IO profiles, device/mapping settings)\"\n    )\n\n    experiment: ExperimentConfig = Field(\n        default_factory=ExperimentConfig,\n        description=\"Experiment parameters\"\n    )\n\n    raster_reader: Union[RasterReaderConfig, MultiRasterReaderConfig] = Field(\n        ...,\n        description=\"Raster reader configuration\",\n        discriminator='type'\n    )\n\n    mapper: MapperConfig = Field(\n        ...,\n        description=\"Label mapper configuration\"\n    )\n\n    boundaries: BoundariesConfig = Field(\n        default_factory=BoundariesConfig,\n        description=\"Spatial boundaries and masks\"\n    )\n\n    # Runtime objects (stored privately, exposed via properties after building)\n    _built_raster_reader: Optional[Any] = None\n    _built_mapper: Optional[Any] = None\n    _built_nn_output_transformer: Optional[Any] = None\n\n    class Config:\n        arbitrary_types_allowed = True\n        underscore_attrs_are_private = True\n\n    @model_validator(mode='after')\n    def build_runtime_objects(self):\n        \"\"\"Build runtime objects from configuration.\"\"\"\n        # Build and store runtime objects\n        self._built_raster_reader = self.raster_reader.build_reader()\n        self._built_mapper = self.mapper.build_mapper()\n        self._built_nn_output_transformer = self._built_mapper.map_output_transformer()\n\n        # Override the config fields with runtime objects for backward compatibility\n        object.__setattr__(self, 'raster_reader', self._built_raster_reader)\n        object.__setattr__(self, 'mapper', self._built_mapper)\n\n        return self\n\n    @property\n    def nn_output_transformer(self) -> Any:\n        \"\"\"Get the built neural network output transformer.\"\"\"\n        return self._built_nn_output_transformer\n\n    @classmethod\n    def from_toml(cls, toml_path: str) -> \"ExperienceInfo\":\n        \"\"\"Load ExperienceInfo from a TOML configuration file with full validation.\n\n        This method loads and validates the configuration using Pydantic,\n        then automatically builds all runtime objects.\n\n        Args:\n            toml_path: Path to the TOML configuration file.\n\n        Returns:\n            ExperienceInfo: Fully configured and validated experiment information object.\n\n        Raises:\n            ValidationError: If the TOML configuration is invalid.\n            FileNotFoundError: If the TOML file doesn't exist.\n        \"\"\"\n        with open(toml_path, 'rb') as f:\n            config_dict = tomli.load(f)\n\n        # Pydantic will validate and build runtime objects automatically\n        return cls(**config_dict)\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/eoml/automation/experience.py b/eoml/automation/experience.py
--- a/eoml/automation/experience.py	(revision 2e0f1231a5d575419703a0aa1216e9dd547d9cda)
+++ b/eoml/automation/experience.py	(date 1765796104458)
@@ -8,7 +8,7 @@
 from pathlib import Path
 from typing import Any, Optional, Dict, List, Union, Literal
 import tomli
-from pydantic import BaseModel, Field, field_validator, model_validator
+from pydantic import BaseModel, Field, field_validator, model_validator, FilePath
 
 from eoml.automation.configuration import SystemConfigModel
 from eoml.raster.raster_utils import read_gdal_stats, SigmaNormalizer
@@ -91,7 +91,7 @@
         description="Type of raster reader"
     )
 
-    path: str = Field(
+    path: FilePath = Field(
         ...,
         description="Path to the raster file"
     )
@@ -101,7 +101,7 @@
         description="List of band indices to use (1-indexed). If None, uses all bands"
     )
 
-    stats_path: Optional[str] = Field(
+    stats_path: Optional[FilePath] = Field(
         None,
         description="Path to statistics file for normalization"
     )
@@ -575,9 +575,6 @@
     _built_mapper: Optional[Any] = None
     _built_nn_output_transformer: Optional[Any] = None
 
-    class Config:
-        arbitrary_types_allowed = True
-        underscore_attrs_are_private = True
 
     @model_validator(mode='after')
     def build_runtime_objects(self):
