"""
ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã®å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰äºˆæ¸¬ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

éå»ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç·šå½¢å›å¸°ã«ã‚ˆã‚Šå°†æ¥ã®ä½¿ç”¨é‡ã‚’äºˆæ¸¬ã—ã€
ãƒ‡ã‚£ã‚¹ã‚¯å®¹é‡ãŒ90%ã«åˆ°é”ã™ã‚‹äºˆæ¸¬æ—¥ã‚’ç®—å‡ºã—ã¾ã™ã€‚
ã¾ãŸã€å‰æ—¥æ¯”ã§10%ä»¥ä¸Šã®æ€¥æ¿€ãªå¢—åŠ ã‚’æ¤œå‡ºã—ã€æ—©æœŸè­¦å‘Šã‚’ç™ºã—ã¾ã™ã€‚
"""

import os
import csv
from datetime import datetime, date, timedelta
from pathlib import Path
from typing import Optional


# å®šæ•°å®šç¾©
HISTORY_DIR = "data/usage_history"
RAPID_CHANGE_THRESHOLD = 10.0  # æ€¥æ¿€ãªå¤‰åŒ–ã®é–¾å€¤ï¼ˆ%ï¼‰
TARGET_USAGE = 90.0  # äºˆæ¸¬å¯¾è±¡ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ï¼ˆ%ï¼‰
SAFE_PREDICTION_DAYS = 36500  # 100å¹´ï¼ˆå½“é¢ã¯å®‰å…¨ã¨ã¿ãªã™æ—¥æ•°ï¼‰



def load_disk_history(days: int = 7) -> list[tuple[datetime, float]]:
    """
    éå»Næ—¥åˆ†ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
    
    Args:
        days: èª­ã¿è¾¼ã‚€æ—¥æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 7ï¼‰
        
    Returns:
        list[tuple[datetime, float]]: [(æ—¥æ™‚, ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡), ...]
        
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°:
        - ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆ: ç©ºãƒªã‚¹ãƒˆã‚’è¿”ã™
        - ãƒ•ã‚¡ã‚¤ãƒ«ãŒèª­ã‚ãªã„å ´åˆ: ãã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¹ã‚­ãƒƒãƒ—
        - æ•°å€¤å¤‰æ›ã‚¨ãƒ©ãƒ¼: ãã®ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ã‚¹ã‚­ãƒƒãƒ—
    """
    if not os.path.exists(HISTORY_DIR):
        return []
    
    # å¯¾è±¡æœŸé–“ã®è¨ˆç®—
    end_date = datetime.now()
    start_date = end_date - timedelta(days=days)
    
    # å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—
    history_files = sorted(
        Path(HISTORY_DIR).glob("usage_*.csv"),
        key=lambda p: p.stat().st_mtime
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã®åé›†
    data = []
    
    for file_path in history_files:
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰æ—¥æ™‚ã‚’å–å¾—ï¼ˆusage_20251122_093000.csvï¼‰
            filename = file_path.stem
            date_str = filename.replace('usage_', '')
            file_datetime = datetime.strptime(date_str, '%Y%m%d_%H%M%S')
            
            # æœŸé–“å†…ã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿å‡¦ç†
            if start_date <= file_datetime <= end_date:
                with open(file_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        try:
                            disk_usage = float(row.get('disk', 0))
                            data.append((file_datetime, disk_usage))
                            break  # æœ€åˆã®è¡Œã®ã¿
                        except (ValueError, KeyError):
                            # æ•°å€¤å¤‰æ›ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—
                            continue
        except (ValueError, Exception):
            # ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼ã¯ã‚¹ã‚­ãƒƒãƒ—
            continue
    
    # æ—¥æ™‚ã§ã‚½ãƒ¼ãƒˆ
    data.sort(key=lambda x: x[0])
    
    return data



def calculate_daily_average(data: list[tuple[datetime, float]]) -> list[tuple[date, float]]:
    """
    æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ—¥æ¬¡å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¾ã™ã€‚
    
    Args:
        data: [(æ—¥æ™‚, ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨ç‡), ...]
        
    Returns:
        list[tuple[date, float]]: [(æ—¥ä»˜, å¹³å‡ä½¿ç”¨ç‡), ...]
    """
    if not data:
        return []
    
    # æ—¥ä»˜ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
    daily_data = {}
    for dt, usage in data:
        day = dt.date()
        if day not in daily_data:
            daily_data[day] = []
        daily_data[day].append(usage)
    
    # å„æ—¥ã®å¹³å‡å€¤ã‚’è¨ˆç®—
    daily_averages = []
    for day, usages in daily_data.items():
        avg_usage = sum(usages) / len(usages)
        daily_averages.append((day, avg_usage))
    
    # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
    daily_averages.sort(key=lambda x: x[0])
    
    return daily_averages



def predict_disk_trend(daily_data: list[tuple[date, float]]) -> dict:
    """
    ç·šå½¢å›å¸°ã«ã‚ˆã‚Šå°†æ¥ã®ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã‚’äºˆæ¸¬ã—ã¾ã™ã€‚
    
    Args:
        daily_data: [(æ—¥ä»˜, å¹³å‡ä½¿ç”¨ç‡), ...]
        
    Returns:
        dict: {
            'slope': float,              # å‚¾ãï¼ˆ%/æ—¥ï¼‰
            'intercept': float,          # åˆ‡ç‰‡
            'current_usage': float,      # ç¾åœ¨ã®ä½¿ç”¨ç‡
            'days_to_90': int | None,    # 90%åˆ°é”ã¾ã§ã®æ—¥æ•°
            'prediction_date': str | None, # 90%åˆ°é”äºˆæ¸¬æ—¥ï¼ˆYYYY-MM-DDå½¢å¼ï¼‰
            'trend': str                 # 'increasing', 'stable', 'decreasing'
        }
        
    Raises:
        ValueError: ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ãŒ2ä»¶æœªæº€ã®å ´åˆ
    """
    if len(daily_data) < 2:
        raise ValueError("äºˆæ¸¬ã«ã¯æœ€ä½2ä»¶ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦ã§ã™")
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’æ•°å€¤ã«å¤‰æ›ï¼ˆæ—¥ä»˜ã‚’0ã‹ã‚‰ã®æ—¥æ•°ã«å¤‰æ›ï¼‰
    base_date = daily_data[0][0]
    x_values = [(d - base_date).days for d, _ in daily_data]
    y_values = [usage for _, usage in daily_data]
    
    n = len(x_values)
    
    # æœ€å°äºŒä¹—æ³•ã§å‚¾ãã¨åˆ‡ç‰‡ã‚’è¨ˆç®—
    # slope = (n * Î£xy - Î£x * Î£y) / (n * Î£xÂ² - (Î£x)Â²)
    # intercept = (Î£y - slope * Î£x) / n
    
    sum_x = sum(x_values)
    sum_y = sum(y_values)
    sum_xy = sum(x * y for x, y in zip(x_values, y_values))
    sum_x_squared = sum(x * x for x in x_values)
    
    denominator = n * sum_x_squared - sum_x * sum_x
    
    if denominator == 0:
        # å…¨ã¦ã®xå€¤ãŒåŒã˜ï¼ˆ1æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
        slope = 0.0
        intercept = sum_y / n
    else:
        slope = (n * sum_xy - sum_x * sum_y) / denominator
        intercept = (sum_y - slope * sum_x) / n
    
    # ç¾åœ¨ã®ä½¿ç”¨ç‡ï¼ˆæœ€æ–°æ—¥ã®ãƒ‡ãƒ¼ã‚¿ï¼‰
    current_usage = y_values[-1]
    
    # ãƒˆãƒ¬ãƒ³ãƒ‰åˆ¤å®š
    if slope > 0.01:
        trend = 'increasing'
    elif slope < -0.01:
        trend = 'decreasing'
    else:
        trend = 'stable'
    
    # 90%åˆ°é”äºˆæ¸¬æ—¥ã®è¨ˆç®—
    days_to_90 = None
    prediction_date = None
    
    if slope > 0.001 and current_usage < TARGET_USAGE:
        # å¢—åŠ å‚¾å‘ã§ã€ã¾ã 90%æœªæº€ã®å ´åˆ
        try:
            days_to_90_float = (TARGET_USAGE - current_usage) / slope
            
            # infinityã‚„NaNã®ãƒã‚§ãƒƒã‚¯
            if days_to_90_float > SAFE_PREDICTION_DAYS or days_to_90_float != days_to_90_float:
                # 100å¹´ä»¥ä¸Šå…ˆã¾ãŸã¯NaNã®å ´åˆã¯ã€Œå½“é¢ã¯å®‰å…¨ã€
                days_to_90 = None
                prediction_date = None
            else:
                days_to_90 = int(days_to_90_float)
                # äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
                latest_date = daily_data[-1][0]
                pred_date = latest_date + timedelta(days=days_to_90)
                prediction_date = pred_date.strftime('%Y-%m-%d')
        except (OverflowError, ValueError):
            # ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚„ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯äºˆæ¸¬ãªã—
            days_to_90 = None
            prediction_date = None
    
    return {
        'slope': slope,
        'intercept': intercept,
        'current_usage': current_usage,
        'days_to_90': days_to_90,
        'prediction_date': prediction_date,
        'trend': trend
    }



def detect_rapid_change(daily_data: list[tuple[date, float]]) -> dict:
    """
    å‰æ—¥æ¯”ã§æ€¥æ¿€ãªå¤‰åŒ–ã‚’æ¤œå‡ºã—ã¾ã™ã€‚
    
    Args:
        daily_data: [(æ—¥ä»˜, å¹³å‡ä½¿ç”¨ç‡), ...]
        
    Returns:
        dict: {
            'is_rapid': bool,           # æ€¥æ¿€ãªå¤‰åŒ–ãŒã‚ã‚‹ã‹
            'change_percent': float,    # å‰æ—¥æ¯”ã®å¤‰åŒ–ç‡ï¼ˆ%ï¼‰
            'previous_usage': float,    # å‰æ—¥ã®ä½¿ç”¨ç‡
            'current_usage': float      # ç¾åœ¨ã®ä½¿ç”¨ç‡
        }
    """
    # ãƒ‡ãƒ¼ã‚¿ãŒ2ä»¶æœªæº€ã®å ´åˆ
    if len(daily_data) < 2:
        return {
            'is_rapid': False,
            'change_percent': 0.0,
            'previous_usage': 0.0,
            'current_usage': daily_data[0][1] if daily_data else 0.0
        }
    
    # æœ€æ–°æ—¥ã¨å‰æ—¥ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    previous_usage = daily_data[-2][1]
    current_usage = daily_data[-1][1]
    
    # å‰æ—¥æ¯”ã‚’è¨ˆç®—
    change_percent = current_usage - previous_usage
    
    # 10%ä»¥ä¸Šã®å¢—åŠ ã®å ´åˆã€æ€¥æ¿€ãªå¤‰åŒ–ã¨ã™ã‚‹
    is_rapid = change_percent >= RAPID_CHANGE_THRESHOLD
    
    return {
        'is_rapid': is_rapid,
        'change_percent': change_percent,
        'previous_usage': previous_usage,
        'current_usage': current_usage
    }



def format_prediction_message(prediction: dict, rapid_change: dict) -> str:
    """
    äºˆæ¸¬çµæœã‚’åˆ†ã‹ã‚Šã‚„ã™ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¤‰æ›ã—ã¾ã™ã€‚
    
    Args:
        prediction: äºˆæ¸¬çµæœ
        rapid_change: æ€¥æ¿€ãªå¤‰åŒ–ã®æ¤œå‡ºçµæœ
        
    Returns:
        str: ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã•ã‚ŒãŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    messages = []
    
    # å„ªå…ˆåº¦1: æ€¥æ¿€ãªå¤‰åŒ–ã®è­¦å‘Š
    if rapid_change['is_rapid']:
        messages.append("âš ï¸ ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ãŒæ€¥æ¿€ã«å¢—åŠ ã—ã¦ã„ã¾ã™ï¼")
        messages.append(
            f"å‰æ—¥æ¯”: +{rapid_change['change_percent']:.1f}%"
            f"ï¼ˆ{rapid_change['previous_usage']:.1f}% â†’ {rapid_change['current_usage']:.1f}%ï¼‰"
        )
        messages.append("")
    
    # å„ªå…ˆåº¦2: 90%åˆ°é”äºˆæ¸¬
    if prediction['days_to_90'] is not None:
        # æ€¥æ¿€ãªå¤‰åŒ–ãŒãªã„å ´åˆã¯ã€ãƒˆãƒ¬ãƒ³ãƒ‰æƒ…å ±ã‚‚è¡¨ç¤º
        if not rapid_change['is_rapid']:
            messages.append("ğŸ“Š ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã®å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰")
            messages.append(f"ç¾åœ¨ã®ä½¿ç”¨ç‡: {prediction['current_usage']:.1f}%")
            messages.append(f"å¢—åŠ ç‡: +{prediction['slope']:.2f}%/æ—¥")
            messages.append("")
        
        messages.append(f"ã“ã®ã¾ã¾ã ã¨ã€ã‚ã¨{prediction['days_to_90']}æ—¥ã§90%ã«åˆ°é”ã™ã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚")
        messages.append(f"äºˆæ¸¬åˆ°é”æ—¥: {prediction['prediction_date']}")
        messages.append("")
        
        # æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
        messages.append("ğŸ’¡ æ¨å¥¨ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼š")
        messages.append("- å¤ã„ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤: journalctl --vacuum-time=7d")
        messages.append("- ä¸è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª: du -sh /* | sort -h")
    elif rapid_change['is_rapid']:
        # æ€¥æ¿€ãªå¤‰åŒ–ã¯ã‚ã‚‹ãŒã€90%åˆ°é”äºˆæ¸¬ãŒãªã„å ´åˆ
        messages.append("ç¾åœ¨ã®å¢—åŠ ç‡ã§ã¯90%åˆ°é”ã¾ã§ä½™è£•ãŒã‚ã‚Šã¾ã™ãŒã€")
        messages.append("æ€¥æ¿€ãªå¤‰åŒ–ãŒç¶šãå ´åˆã¯æ³¨æ„ãŒå¿…è¦ã§ã™ã€‚")
    else:
        # å„ªå…ˆåº¦3: é€šå¸¸ã®å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰
        if prediction['trend'] == 'increasing':
            messages.append("ğŸ“Š ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã®å¢—åŠ ãƒˆãƒ¬ãƒ³ãƒ‰")
            messages.append(f"ç¾åœ¨ã®ä½¿ç”¨ç‡: {prediction['current_usage']:.1f}%")
            messages.append(f"å¢—åŠ ç‡: +{prediction['slope']:.2f}%/æ—¥")
            messages.append("")
            messages.append("å½“é¢ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ãŒã€å®šæœŸçš„ãªç¢ºèªã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚")
        elif prediction['trend'] == 'decreasing':
            messages.append("âœ… ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã¯æ¸›å°‘å‚¾å‘ã§ã™")
            messages.append(f"ç¾åœ¨ã®ä½¿ç”¨ç‡: {prediction['current_usage']:.1f}%")
            messages.append(f"æ¸›å°‘ç‡: {prediction['slope']:.2f}%/æ—¥")
            messages.append("")
            messages.append("å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚")
        else:
            # å®‰å…¨ãªçŠ¶æ…‹
            messages.append("âœ… ãƒ‡ã‚£ã‚¹ã‚¯ä½¿ç”¨é‡ã¯å®‰å®šã—ã¦ã„ã¾ã™")
            messages.append(f"ç¾åœ¨ã®ä½¿ç”¨ç‡: {prediction['current_usage']:.1f}%")
            messages.append(f"å¢—åŠ ç‡: +{prediction['slope']:.2f}%/æ—¥")
            messages.append("")
            messages.append("å½“é¢ã¯å•é¡Œã‚ã‚Šã¾ã›ã‚“ã€‚")
    
    return "\n".join(messages)
