# Default Image Tokenizer Configuration
# This file configures image tokenization settings for dataset to CAR conversion

# Tokenizer configuration
tokenizer_type: "image"  # Image tokenizer for efficient representation learning

# Image processing settings
image_size: [224, 224]  # Target image size [width, height]
maintain_aspect_ratio: false  # Whether to maintain aspect ratio during resize
normalize_images: true  # Whether to normalize images

# Model settings
device: "cuda"  # Options: cuda, cpu, auto
dtype: "bfloat16"  # Options: float32, float16, bfloat16

# Quality settings
quality_threshold: 0.0  # Quality threshold for processing

# Output format
output_format: "car"  # Options: pt, car

# Advanced settings (uncomment and modify as needed)
# For high-quality processing:
# image_size: [512, 512]  # Higher resolution processing
# dtype: "float32"  # Higher precision

# preprocessing:
#   crop_mode: "center"  # Options: center, random
#   padding_mode: "constant"  # Padding mode for resizing
#   interpolation: "bilinear"  # Interpolation method

# Performance settings
# batch_size: 1  # Batch size for processing
# num_workers: 4  # Number of worker threads