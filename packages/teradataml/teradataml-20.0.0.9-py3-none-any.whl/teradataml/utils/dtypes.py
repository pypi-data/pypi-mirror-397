from teradatasqlalchemy import (BYTEINT, SMALLINT, INTEGER, BIGINT, DECIMAL, FLOAT, NUMBER)
from teradatasqlalchemy import (TIMESTAMP, DATE, TIME)
from teradatasqlalchemy import (CHAR, VARCHAR, CLOB)
from teradatasqlalchemy import (BYTE, VARBYTE, BLOB)
from teradatasqlalchemy import (PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP)
from teradatasqlalchemy import (INTERVAL_YEAR, INTERVAL_YEAR_TO_MONTH, INTERVAL_MONTH, INTERVAL_DAY,
                                INTERVAL_DAY_TO_HOUR, INTERVAL_DAY_TO_MINUTE, INTERVAL_DAY_TO_SECOND,
                                INTERVAL_HOUR, INTERVAL_HOUR_TO_MINUTE, INTERVAL_HOUR_TO_SECOND,
                                INTERVAL_MINUTE, INTERVAL_MINUTE_TO_SECOND, INTERVAL_SECOND)
from teradatasqlalchemy import (GEOMETRY, MBB, MBR)
from teradatasqlalchemy import VECTOR
import teradatasqlalchemy as tdsqlalchemy
from teradataml.common.td_coltype_code_to_tdtype import HELP_COL_TYPE_TO_TDTYPE
from teradataml.common.constants import TeradataTypes, PythonTypes
from datetime import datetime, time, date
from decimal import Decimal
import pandas as pd

# Common charset mapping for server charset codes
CHARSET_MAPPING = {
    1: 'LATIN',
    2: 'UNICODE', 
    3: 'KANJISJIS',
    4: 'GRAPHIC',
    5: 'KANJI1'
}

#
# Pre-defined class for validating argument types for args that accept list or
# tuple as input.
#
class _ListOf:
    """
    A class to imitate the type - List of x-type.
    For example,
        list of str
        list of int or float
        etc.
    """
    def __init__(self, dtypes):
        """
        Constructor of the class.

        PARAMETERS:
            dtypes:
                Required Argument.
                Specifies the types, which can be part of the list.
                Types: type or tuple of types
        """
        self._type = dtypes
        self.__explicit_bool_validation = False
        self.__is_tuple = False
        self._str_repr_prefix = "list of "
        # If individual element type to be checked is int,
        # then the bool values should be handled carefully, and
        # hence set the '__explicit_bool_validation' to True.
        if isinstance(self._type, type):
            if self._type == int:
                self.__explicit_bool_validation = True
        elif isinstance(self._type, tuple):
            self.__is_tuple = True
            if int in self._type:
                self.__explicit_bool_validation = True

    def __str__(self):
        """
        Returns the string representation of the class for printing in errors.
        """
        if isinstance(self._type, type):
            # If _type is instance of type, then retrieve the type name
            # directly.
            tval = self._type.__name__
        elif isinstance(self._type, tuple):
            # If _type is instance of type, then retrieve the name
            # of the each type by joining them with " or ".
            tval = " or ".join([x.__name__ for x in list(self._type)])
        else:
            # Anything else, just use it as is.
            tval = self._type
        return "{}{}".format(self._str_repr_prefix, tval)

    def _element_instance_check(self, obj):
        """
        Function validates each and every element in "obj" against the
        expected type.

        PARAMETERS:
            obj:
                Required Arguments.
                Specifies the object containing elements to be verified.
                Types: list

        RETURNS:
            True, if all elements are of type reference by self,__type,
            False, otherwise.
        """
        inst_bools = []
        for val in obj:
            if self.__explicit_bool_validation:
                if self.__is_tuple:
                    inst_bools.append(type(val) in self._type)
                else:
                    inst_bools.append(type(val) == self._type)
            else:
                inst_bools.append(isinstance(val, self._type))
        return all(inst_bools)

    def __instancecheck__(self, obj):
        """
        Overrides a method to perform isinstance check.
        """
        if not isinstance(obj, list):
            # If obj is not instance of list, return False.
            return False

        return self._element_instance_check(obj)

class _TupleOf(_ListOf):
    """
    A class to imitate the type - Tuple of x-type.
    For example,
        tuple of str
        tuple of int or float
        etc.
    """

    def __init__(self, dtypes):
        """
        Constructor of the class.

        PARAMETERS:
            dtypes:
                Required Argument.
                Specifies the types, which can be part of the tuple.
                Types: type or tuple of types
        """
        super(_TupleOf, self).__init__(dtypes)
        self._str_repr_prefix = "tuple of "

    def __instancecheck__(self, obj):
        """
        Overrides a method to perform isinstance check.
        """
        if not isinstance(obj, tuple):
            # If obj is not instance of list, return False.
            return False

        return self._element_instance_check(obj)

# Some predefined types for list and tuples
_str_list = _ListOf(str)
_int_list = _ListOf(int)
_float_list = _ListOf(float)
_int_float_list = _ListOf((int, float))
_tuple_list = _ListOf(tuple)
_int_float_tuple_list = _ListOf(_TupleOf((int, float)))

# DataTypes mapper to store various categories of DataTypes.
_GET_DATATYPES = {
    'NON_NUMERIC': [BLOB, BYTE, CHAR, CLOB, DATE, INTERVAL_DAY, INTERVAL_DAY_TO_HOUR, INTERVAL_DAY_TO_MINUTE,
                    INTERVAL_DAY_TO_SECOND, INTERVAL_HOUR, INTERVAL_HOUR_TO_MINUTE, INTERVAL_HOUR_TO_SECOND,
                    INTERVAL_MINUTE, INTERVAL_MINUTE_TO_SECOND, INTERVAL_MONTH, INTERVAL_SECOND, INTERVAL_YEAR,
                    INTERVAL_YEAR_TO_MONTH, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, TIME, TIMESTAMP, VARBYTE,
                    VARCHAR, GEOMETRY, MBB, MBR, VECTOR],
    'NON_NUM_DATE_INTERVAL': [BLOB, BYTE, CHAR, CLOB, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, TIME, TIMESTAMP,
                              VARBYTE, VARCHAR, GEOMETRY, MBB, MBR],
    'NON_NUM_INTERVAL': [BLOB, BYTE, CHAR, CLOB, DATE, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, TIME, TIMESTAMP,
                         VARBYTE, VARCHAR, GEOMETRY, MBB, MBR],
    'LOB_PERIOD': [BLOB, CLOB, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, GEOMETRY, MBB, MBR],
    'INTERVAL': [INTERVAL_YEAR, INTERVAL_YEAR_TO_MONTH, INTERVAL_MONTH, INTERVAL_DAY,
                 INTERVAL_DAY_TO_HOUR, INTERVAL_DAY_TO_MINUTE, INTERVAL_DAY_TO_SECOND,
                 INTERVAL_HOUR, INTERVAL_HOUR_TO_MINUTE, INTERVAL_HOUR_TO_SECOND,
                 INTERVAL_MINUTE, INTERVAL_MINUTE_TO_SECOND, INTERVAL_SECOND],
    'PERIOD': [PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP],
    'DATETIME': [DATE, TIME, TIMESTAMP],
    'LOB_PERIOD_BYTE_GEOM': [BLOB, CLOB, BYTE, VARBYTE, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, GEOMETRY, MBB, MBR]
}


class _DtypesMappers:
    AGGREGATE_UNSUPPORTED_TYPES = {
        'avg': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'mavg': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'bottom': _GET_DATATYPES["NON_NUMERIC"],
        'bottom with ties': _GET_DATATYPES["NON_NUMERIC"],
        'count': [],
        'first': _GET_DATATYPES["NON_NUMERIC"],
        'kurtosis': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'last': _GET_DATATYPES["NON_NUMERIC"],
        'mad': _GET_DATATYPES["NON_NUMERIC"],
        'max': _GET_DATATYPES["LOB_PERIOD"],
        'mean': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'median': _GET_DATATYPES["NON_NUMERIC"],
        'min': _GET_DATATYPES["LOB_PERIOD"],
        'mode': _GET_DATATYPES["NON_NUMERIC"],
        'percentile': _GET_DATATYPES["NON_NUMERIC"],
        'percentile_cont': _GET_DATATYPES["NON_NUMERIC"],
        'percentile_disc': _GET_DATATYPES["NON_NUMERIC"],
        'skew': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'sum': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'csum': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'msum': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'mdiff': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'mlinreg': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'std': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'stddev_pop': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'stddev_samp': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'top': _GET_DATATYPES["NON_NUMERIC"],
        'top with ties': _GET_DATATYPES["NON_NUMERIC"],
        'unique': [],
        'var': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'var_pop': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'var_samp': _GET_DATATYPES["NON_NUM_DATE_INTERVAL"],
        'corr': _GET_DATATYPES["NON_NUMERIC"],
        'regr_avgx': _GET_DATATYPES["NON_NUMERIC"],
        'regr_avgy': _GET_DATATYPES["NON_NUMERIC"],
        'regr_count': _GET_DATATYPES["NON_NUMERIC"],
        'regr_intercept': _GET_DATATYPES["NON_NUMERIC"],
        'regr_r2': _GET_DATATYPES["NON_NUMERIC"],
        'regr_slope': _GET_DATATYPES["NON_NUMERIC"],
        'regr_sxx': _GET_DATATYPES["NON_NUMERIC"],
        'regr_sxy': _GET_DATATYPES["NON_NUMERIC"],
        'regr_syy': _GET_DATATYPES["NON_NUMERIC"],
        'covar_pop': _GET_DATATYPES["NON_NUMERIC"],
        'covar_samp': _GET_DATATYPES["NON_NUMERIC"]
    }

    WINDOW_AGGREGATE_UNSUPPORTED_TYPES = {
        'count': [PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP],
        'max': [BYTE, VARBYTE, BLOB, CLOB, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP,
                GEOMETRY, MBB, MBR],
        'min': [BYTE, VARBYTE, BLOB, CLOB, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP,
                GEOMETRY, MBB, MBR],
        'lead': _GET_DATATYPES["LOB_PERIOD_BYTE_GEOM"],
        'lag': _GET_DATATYPES["LOB_PERIOD_BYTE_GEOM"],
        'first_value': _GET_DATATYPES["LOB_PERIOD_BYTE_GEOM"],
        'last_value': _GET_DATATYPES["LOB_PERIOD_BYTE_GEOM"]
    }

    DESCRIBE_AGGREGATE_UNSUPPORTED_TYPES = {
        'bottom': _GET_DATATYPES["NON_NUMERIC"],
        'bottom with ties': _GET_DATATYPES["NON_NUMERIC"],
        'count': [],
        'first': _GET_DATATYPES["NON_NUMERIC"],
        'last': _GET_DATATYPES["NON_NUMERIC"],
        'mad': _GET_DATATYPES["NON_NUMERIC"],
        'max': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'mean': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'avg': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'median': _GET_DATATYPES["NON_NUMERIC"],
        'min': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'mode': _GET_DATATYPES["NON_NUMERIC"],
        'percentile_cont': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'percentile': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'std': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'stddev_samp': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'sum': _GET_DATATYPES["NON_NUM_INTERVAL"],
        'top': _GET_DATATYPES["NON_NUMERIC"],
        'top with ties': _GET_DATATYPES["NON_NUMERIC"],
        'unique': [BYTEINT, SMALLINT, INTEGER, BIGINT, DECIMAL, FLOAT, NUMBER]
    }
    PY_TD_MAPPER = {int: INTEGER,
                    float: FLOAT,
                    str: VARCHAR(1024),
                    bool: BYTEINT,
                    datetime: TIMESTAMP,
                    date: DATE,
                    time: TIME,
                    bytes: BLOB,
                    Decimal: DECIMAL,
                    pd.Timestamp: TIMESTAMP,
                    }

    # Mapper which stores the mapping between TD type specified in in analytic JSON files to Python type.
    JSON_TD_TO_PYTHON_TYPE_MAPPER = {"BOOLEAN": bool,
                                     "STRING": str,
                                     "INTEGER": int,
                                     "NUMERIC": (int, float),
                                     "DOUBLE PRECISION": float,
                                     "double precision": float,
                                     "DOUBLE": (int, float),
                                     "FLOAT": float,
                                     "LONG": int,
                                     "ARGLIST": list,
                                     "COLUMNS": str,
                                     "COLUMN": str,
                                     "<TD_FORMULA>": str,
                                     "COLUMN_NAMES": str,
                                     "TIMESTAMPWZ": str,
                                     "TIME-DURATION": str,
                                     "JSON": dict
                                     }

    DATETIME_PERIOD_TYPES = _GET_DATATYPES["PERIOD"] + _GET_DATATYPES["DATETIME"]
    INTERVAL_TYPES = _GET_DATATYPES["INTERVAL"]

    TDSQLALCHEMY_DATATYPE_TO_VAL_STRING_MAPPER = {
        BIGINT: lambda x: x.__class__.__name__,
        BYTEINT: lambda x: x.__class__.__name__,
        CHAR: lambda x: "{0},{1}".format(x.__class__.__name__, x.length),
        DATE: lambda x: x.__class__.__name__,
        DECIMAL: lambda x: "{0},{1},{2}".format(x.__class__.__name__, x.precision, x.scale),
        FLOAT: lambda x: x.__class__.__name__,
        NUMBER: lambda x: ','.join(map(str, (filter(None, [x.__class__.__name__, x.precision, x.scale])))),
        INTEGER: lambda x: x.__class__.__name__,
        SMALLINT: lambda x: x.__class__.__name__,
        TIME: lambda x: "{0},{1}".format(x.__class__.__name__, x.precision),
        TIMESTAMP: lambda x: "{0},{1}".format(x.__class__.__name__, x.precision),
        VARCHAR: lambda x: "{0},{1}".format(x.__class__.__name__, x.length)
    }

    # Holds mapping between string representation of teradatasqlalchemy type
    # and actual teradatasqlalchemy type.
    DATALAKE_STR_to_TDSQLALCHEMY_DATATYPE_MAPPER = {
        "CHAR": CHAR,
        "VARCHAR": VARCHAR,

        "BYTEINT": BYTEINT,
        "SMALLINT": SMALLINT,
        "INTEGER": INTEGER,
        "BIGINT": BIGINT,

        "REAL": FLOAT,
        "FLOAT": FLOAT,
        "DOUBLE": FLOAT,
        "DECIMAL": DECIMAL,
        "NUMBER": NUMBER,

        "DATE": DATE,
        "TIME": TIME,
        "TIMESTAMP": TIMESTAMP,
        "TIMESTAMP_WTZ": TIMESTAMP,

        "BYTE": BYTE,
        "VARBYTE": VARBYTE,
        "BLOB": BLOB,
        # TODO: Add CLOB type when support is added from OTF.

        # TODO: Check these types when corresponding data type support
        #  is available from OTF support or not.
        "INTERVAL_YEAR": INTERVAL_YEAR,
        "INTERVAL_YTM": INTERVAL_YEAR_TO_MONTH,
        "INTERVAL_MONTH": INTERVAL_MONTH,
        "INTERVAL_DAY": INTERVAL_DAY,

        "INTERVAL_DTH": INTERVAL_DAY_TO_HOUR,
        "INTERVAL_DTM": INTERVAL_DAY_TO_MINUTE,
        "INTERVAL_DTS": INTERVAL_DAY_TO_SECOND,
        "INTERVAL_HOUR": INTERVAL_HOUR,
        "INTERVAL_HTM": INTERVAL_HOUR_TO_MINUTE,
        "INTERVAL_HTS": INTERVAL_HOUR_TO_SECOND,
        "INTERVAL_MINUTE": INTERVAL_MINUTE,
        "INTERVAL_MTS": INTERVAL_MINUTE_TO_SECOND,
        "INTERVAL_SECOND": INTERVAL_SECOND
    }


class _SuppArgTypes:
    VAL_ARG_DATATYPE = (str, BIGINT, BYTEINT, CHAR, DATE, DECIMAL, FLOAT, INTEGER, NUMBER, SMALLINT, TIME,
                        TIMESTAMP, VARCHAR)


class _Dtypes:

    @staticmethod
    def _get_numeric_datatypes():
        """
        Returns the numeric data types used in Teradata Vantage
        **From : https://www.info.teradata.com/HTMLPubs/DB_TTU_16_00/
        index.html#page/General_Reference/B035-1091-160K/psa1472241434371.html

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of numeric data types used in Teradata Vantage
        """
        return [BYTEINT, SMALLINT, INTEGER, BIGINT, DECIMAL, FLOAT, NUMBER]

    @staticmethod
    def _get_timedate_datatypes():
        """
        Returns a list of TimeDate data types.

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of TimeDate data types used in Teradata Vantage
        """
        return [TIMESTAMP, DATE, TIME]

    @staticmethod
    def _get_character_datatypes():
        """
        Returns a list of Character data types.

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of Character data types used in Teradata Vantage
        """
        return [CHAR, VARCHAR, CLOB]

    @staticmethod
    def _get_byte_datatypes():
        """
        Returns a list of byte like data types.

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of Byte data types used in Teradata Vantage
        """
        return [BYTE, VARBYTE, BLOB]

    @staticmethod
    def _get_categorical_datatypes():
        """
        Returns a list of containing Character and TimeDate data types.

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of Character and TimeDate data types used in Teradata Vantage
        """
        return list.__add__(_Dtypes._get_character_datatypes(), _Dtypes._get_timedate_datatypes())

    @staticmethod
    def _get_all_datatypes():
        """
        Returns a list of Character, Numeric and TimeDate data types.

        PARAMETERS:
            None

        RAISES:
            None

        RETURNS:
            List of Character, Numeric and TimeDate data types used in Teradata Vantage
        """
        return list.__add__(_Dtypes._get_categorical_datatypes(), _Dtypes._get_numeric_datatypes())

    @staticmethod
    def _get_unsupported_data_types_for_aggregate_operations(operation,
                                                             as_time_series_aggregate=False,
                                                             is_window_aggregate=False):
        """
        Returns the data types on which aggregate operations cannot
        be performed eg : min, max, avg

        PARAMETERS:
            operation:
                Required Argument.
                Specifies an aggregate operation to be performed on the dataframe.
                Types: str

            as_time_series_aggregate:
                Optional Argument.
                Specifies whether aggregate operation is a Time Series aggregate or not.
                Default Values: False
                Types: bool

            is_window_aggregate:
                Optional Argument.
                Specifies whether aggregate operation is a Window aggregate or not.
                Default Values: False
                Types: bool

        RAISES:
            None

        RETURNS:
            List of unsupported data types for aggregate operation in
            Teradata Vantage eg : min, max, avg
        """
        if operation == 'median' and not as_time_series_aggregate:
            # For median as regular aggregate unsupported types are different than the ones
            # mentioned in _DtypesMappers.AGGREGATE_UNSUPPORTED_TYPES
            return [BLOB, BYTE, CHAR, CLOB, DATE, PERIOD_DATE, PERIOD_TIME, PERIOD_TIMESTAMP, TIME, TIMESTAMP, VARCHAR]

        # Return the unsupported types list, if key with 'operation' is found.
        # If 'operation' is not found, return empty list which means all types
        # are supported.
        if is_window_aggregate:
            # If operation is not present in WINDOW_AGGREGATE_UNSUPPORTED_TYPES
            # then return the value from the AGGREGATE_UNSUPPORTED_TYPES mapper.
            return _DtypesMappers.WINDOW_AGGREGATE_UNSUPPORTED_TYPES.get(operation,
                    _DtypesMappers.AGGREGATE_UNSUPPORTED_TYPES.get(operation, []))
        return _DtypesMappers.AGGREGATE_UNSUPPORTED_TYPES.get(operation, [])

    @staticmethod
    def _get_unsupported_data_types_for_describe_operations(operation):
        """
        Returns the data types on which the specified describe aggregate 'operation' cannot
        be performed. This function is used by the method DataFrame.describe().

        PARAMETERS:
            operation : String. An aggregate operation to be performed on the dataframe.
                        possible values are 'sum', 'min', 'max', 'mean','std', 'percentile',
                        'count', and 'unique'.

        RAISES:
            None

        RETURNS:
            List of unsupported data types for describe operation in
            Teradata Vantage eg : min, max, avg
        """
        try:
            # Return the unsupported types list, if key with operation 'operation' is found.
            return _DtypesMappers.DESCRIBE_AGGREGATE_UNSUPPORTED_TYPES[operation]
        except KeyError:
            # We are here means, there are not unsupported types mentioned in
            # _DtypesMappers.DESCRIBE_AGGREGATE_UNSUPPORTED_TYPES, so that means all types are supported.
            return []

    @staticmethod
    def _get_sort_unsupported_data_types():
        """
        Returns the data types on which sorting is invalid.

        RAISES:
            None

        RETURNS:
            list of teradatasqlalchemy.types

        EXAMPLES:
            _Dtypes._get_sort_unsupported_data_types()
        """
        return [CLOB, BLOB]

    @staticmethod
    def _teradata_type_to_python_type(td_type):
        """
        Translate the Teradata type from metaexpr to Python types.
        PARAMETERS:
            td_type - The Teradata type from metaexpr.

        RETURNS:
            The Python type for the given td_type.

        RAISES:

        EXAMPLES:
            # o is an instance of INTEGER
            pytype = _Dtypes._teradata_type_to_python_type(o)

        """

        # loggerlogger.debug("_help_col_to_python_type td_type = {0} ".format(td_type))
        if type(td_type) in TeradataTypes.TD_INTEGER_TYPES.value:
            return PythonTypes.PY_INT_TYPE.value
        elif type(td_type) in TeradataTypes.TD_FLOAT_TYPES.value:
            return PythonTypes.PY_FLOAT_TYPE.value
        elif type(td_type) in TeradataTypes.TD_DECIMAL_TYPES.value:
            return PythonTypes.PY_DECIMAL_TYPE.value
        elif type(td_type) in TeradataTypes.TD_BYTE_TYPES.value:
            return PythonTypes.PY_BYTES_TYPE.value
        elif type(td_type) in TeradataTypes.TD_DATETIME_TYPES.value:
            return PythonTypes.PY_DATETIME_TYPE.value
        elif type(td_type) in TeradataTypes.TD_TIME_TYPES.value:
            return PythonTypes.PY_TIME_TYPE.value
        elif type(td_type) in TeradataTypes.TD_DATE_TYPES.value:
            return PythonTypes.PY_DATE_TYPE.value

        return PythonTypes.PY_STRING_TYPE.value

    @staticmethod
    def _python_type_to_teradata_type(py_type):
        """
        DESCRIPTION:
            Translate the Python types to Teradata type.

        PARAMETERS:
            py_type:
               Required Argument.
               Specifies the Python type.
               Types: type

        RETURNS:
            The teradatasqlalchemy type for the given py_type.

        RAISES:
            None

        EXAMPLES:
            tdtype = _Dtypes._python_type_to_teradata_type(int)

        """

        return _DtypesMappers.PY_TD_MAPPER.get(py_type)

    @staticmethod
    def _help_col_to_python_type(col_type, storage_format):
        """
        Translate the 1 or 2 character TD type codes from HELP COLUMN to Python types.
        PARAMETERS:
            col_type - The 1 or 2 character type code from HELP COLUMN command.
            storage_format - The storage format from HELP COLUMN command.

        RETURNS:
            The Python type for the given col_type.

        RAISES:

        EXAMPLES:
            pytype = _Dtypes._help_col_to_python_type('CV', None)
            pytype = _Dtypes._help_col_to_python_type('DT', 'CSV')

        """
        if col_type in TeradataTypes.TD_INTEGER_CODES.value:
            return PythonTypes.PY_INT_TYPE.value
        elif col_type in TeradataTypes.TD_FLOAT_CODES.value:
            return PythonTypes.PY_FLOAT_TYPE.value
        elif col_type in TeradataTypes.TD_DECIMAL_CODES.value:
            return PythonTypes.PY_DECIMAL_TYPE.value
        elif col_type in TeradataTypes.TD_BYTE_CODES.value:
            return PythonTypes.PY_BYTES_TYPE.value
        elif col_type in TeradataTypes.TD_DATETIME_CODES.value:
            return PythonTypes.PY_DATETIME_TYPE.value
        elif col_type in TeradataTypes.TD_TIME_CODES.value:
            return PythonTypes.PY_TIME_TYPE.value
        elif col_type in TeradataTypes.TD_DATE_CODES.value:
            return PythonTypes.PY_DATE_TYPE.value
        elif col_type == "DT":
            sfmt = storage_format.strip()
            if sfmt == "CSV":
                return PythonTypes.PY_STRING_TYPE.value
            elif sfmt == "AVRO":
                return PythonTypes.PY_BYTES_TYPE.value

        return PythonTypes.PY_STRING_TYPE.value

    @staticmethod
    def _help_col_to_td_type(col_type, udt_name, storage_format):
        """
        Translate the 2 character TD type codes from HELP COLUMN to Teradata types.
        PARAMETERS:
            col_type - The 2 character type code from HELP COLUMN command.
            udt_name - The UDT name from the HELP COLUMN command.
            storage_format - The storage format from HELP COLUMN command.

        RETURNS:
            The Teradata type for the given colType.

        RAISES:

        EXAMPLES:
            tdtype = _Dtypes._help_col_to_td_type('CV', None, None)

        """
        # logger.debug("helpColumnToTeradataTypeName colType = {0} udtName = {1} storageFormat {2}".format(colType, udtName, storageFormat))
        if col_type in HELP_COL_TYPE_TO_TDTYPE:
            return HELP_COL_TYPE_TO_TDTYPE[col_type]

        if col_type == "DT":
            return "DATASET STORAGE FORMAT {0}".format(storage_format.strip())

        if col_type in ["UD", "US", "UT", "A1", "AN"]:
            if udt_name:
                return udt_name

        return col_type

    @staticmethod
    def _anly_json_type_to_python_type(json_td_type):
        """
        DESCRIPTION:
            Get the Python type equivalent to the specified type in analytic
            JSON files.

        PARAMETERS:
            json_td_type:
               Required Argument.
               Specifies the TD type specified in analytic function json file.
               Types: type

        RETURNS:
            type

        EXAMPLES:
            tdtype = _Dtypes._anly_json_type_to_python_type("NUMBER")

        """
        from teradataml.dataframe.dataframe import TDSeries, TDMatrix, TDGenSeries, TDAnalyticResult
        from teradataml.store.feature_store.feature_store import Feature
        _DtypesMappers.JSON_TD_TO_PYTHON_TYPE_MAPPER.update({"SERIES": TDSeries,
                        "MATRIX": TDMatrix,
                        "ART": TDAnalyticResult,
                        "GENSERIES": TDGenSeries,
                        "COLUMN": (str, Feature),
                        "COLUMNS": (str, Feature)})

        return _DtypesMappers.JSON_TD_TO_PYTHON_TYPE_MAPPER.get(json_td_type.upper())


    @staticmethod
    def _get_interval_data_types():
        """
        Returns the INTERVAL data types.

        RAISES:
            None

        RETURNS:
            list of teradatasqlalchemy.types

        EXAMPLES:
            _Dtypes._get_interval_data_types()
        """
        return _DtypesMappers.INTERVAL_TYPES

    @staticmethod
    def _get_datetime_period_data_types():
        """
        Returns the PERIOD and DATETIME data types.

        RAISES:
            None

        RETURNS:
            list of teradatasqlalchemy.types

        EXAMPLES:
            _Dtypes._get_datetime_period_data_types()
        """
        return _DtypesMappers.DATETIME_PERIOD_TYPES

    @staticmethod
    def _get_normalized_type(td_type):
        """
        DESCRIPTION:
            Get the normalized types for DataFrame Types.

        PARAMETERS:
            None

        RETURNS:
            tuple

        RAISES:
            None

        EXAMPLES:
            >>> _Dtypes._get_normalized_types()
        """
        # Storing the details of the normalized types.

        # Decimal type with any precision and scale, normalie it to DECIMAL(38, 19).
        decimal_precision = 38
        decimal_scale = 19

        # Byte type with any length, normalize it to BYTE(64000).
        byte_length = 64000

        # Number type with any precision and scale, normalize it to NUMBER(38, 10).
        number_precision = 38
        number_scale = 10

        # Time and Timestamp with any precision, normalize it to TIME(6) and TIMESTAMP(6).
        time_precision = 6

        # Interval types with any precision and fractional precision, normalize it
        # to store maximum precision and fractional precision.
        interval_precision = 4
        frac_precision = 6

        # Character types with any length, normalize it to CHAR(2000) and VARCHAR(2000).
        char_length = 2000

        type_ = td_type.__class__

        types_ = {
            INTEGER: BIGINT(),
            SMALLINT: BIGINT(),
            BIGINT: BIGINT(),
            DECIMAL: DECIMAL(precision=decimal_precision, scale=decimal_scale),
            BYTEINT: BYTEINT(),
            BYTE: BYTE(length=byte_length),
            VARBYTE: VARBYTE(length=byte_length),
            FLOAT: FLOAT(),
            NUMBER: NUMBER(precision=number_precision, scale=number_scale),
            DATE: DATE(),
            INTERVAL_YEAR: INTERVAL_YEAR(precision=interval_precision),
            INTERVAL_YEAR_TO_MONTH: INTERVAL_YEAR_TO_MONTH(precision=interval_precision),
            INTERVAL_MONTH: INTERVAL_MONTH(precision=interval_precision),
            INTERVAL_DAY: INTERVAL_DAY(precision=interval_precision),
            INTERVAL_DAY_TO_HOUR: INTERVAL_DAY_TO_HOUR(precision=interval_precision),
            INTERVAL_DAY_TO_MINUTE: INTERVAL_DAY_TO_MINUTE(precision=interval_precision),
            INTERVAL_DAY_TO_SECOND: INTERVAL_DAY_TO_SECOND(
                precision=interval_precision, frac_precision=frac_precision),
            INTERVAL_HOUR: INTERVAL_HOUR(precision=interval_precision),
            INTERVAL_HOUR_TO_MINUTE: INTERVAL_HOUR_TO_MINUTE(precision=interval_precision),
            INTERVAL_HOUR_TO_SECOND: INTERVAL_HOUR_TO_SECOND(
                precision=interval_precision, frac_precision=frac_precision),
            INTERVAL_MINUTE: INTERVAL_MINUTE(precision=interval_precision),
            INTERVAL_MINUTE_TO_SECOND: INTERVAL_MINUTE_TO_SECOND(
                precision=interval_precision, frac_precision=frac_precision),
            INTERVAL_SECOND: INTERVAL_SECOND(
                precision=interval_precision, frac_precision=frac_precision),
            PERIOD_DATE: PERIOD_DATE(),
            DATE: DATE()
        }

        type_ = types_.get(type_)
        if type_:
            return type_, type_.__class__.__name__
        elif isinstance(td_type, TIME):
            type_ = TIME(precision=time_precision, timezone=td_type.timezone)
            return type_, "TIME_{}".format(type_.timezone)
        elif isinstance(td_type, TIMESTAMP):
            type_ = TIMESTAMP(precision=time_precision, timezone=td_type.timezone)
            return type_, "TIMESTAMP_{}".format(type_.timezone)
        elif isinstance(td_type, (PERIOD_TIME, PERIOD_TIMESTAMP)):
            type_ = td_type.__class__(frac_precision=frac_precision, timezone=td_type.timezone)
            return type_, "{}_{}".format(type_.__class__.__name__, type_.timezone)
        elif isinstance(td_type, (CHAR, VARCHAR)):
            type_ = td_type.__class__(length=char_length, charset=td_type.charset)
            return type_, "{}_{}".format(type_.__class__.__name__, type_.charset)
        else:
            return None, repr(None)
        
    @staticmethod
    def _get_td_type_from_metadata(col_info):
        """
        DESCRIPTION:
            Get the teradatasqlalchemy type from column metadata.

        PARAMETERS:
            col_info:
                Required Argument.
                Metadata dictionary for the column.
                Types: dict
        
        RETURNS:
            teradatasqlalchemy type instance

        EXAMPLES:
            >>> col_info = {'RawDataType': 757, 'Nullable': True, 'TypeName': 'BYTEINT', ...}
            >>> _Dtypes._get_td_type_from_metadata(col_info)
            VARCHAR(length=20, charset='UNICODE')
        """
       
        # Extract metadata fields
        type_name = col_info.get('TypeName', '')
        precision = col_info.get('Precision', 0)
        scale = col_info.get('Scale', 0)
        max_char_count = col_info.get('MaxCharacterCount', 0)
        byte_count = col_info.get('ByteCount', 0)
        interval_digits = col_info.get('IntervalDigits', 0)
        server_charset_code = col_info.get('ServerCharsetCode', 0)
        format_str = col_info.get('Format', '')
        
        # Determine charset using server charset code mapping
        charset = CHARSET_MAPPING.get(server_charset_code)
        
        # Type name mapping for special cases
        type_name_mapper = {
            'LONG VARCHAR': 'VARCHAR',
            'INTERVAL YEAR': 'INTERVAL_YEAR',
            'INTERVAL MONTH': 'INTERVAL_MONTH',
            'INTERVAL DAY': 'INTERVAL_DAY',
            'INTERVAL YEAR TO MONTH': 'INTERVAL_YEAR_TO_MONTH',
            'INTERVAL DAY TO HOUR': 'INTERVAL_DAY_TO_HOUR',
            'INTERVAL DAY TO MINUTE': 'INTERVAL_DAY_TO_MINUTE',
            'INTERVAL DAY TO SECOND': 'INTERVAL_DAY_TO_SECOND',
            'INTERVAL HOUR': 'INTERVAL_HOUR',
            'INTERVAL HOUR TO MINUTE': 'INTERVAL_HOUR_TO_MINUTE',
            'INTERVAL HOUR TO SECOND': 'INTERVAL_HOUR_TO_SECOND',
            'INTERVAL MINUTE': 'INTERVAL_MINUTE',
            'INTERVAL MINUTE TO SECOND': 'INTERVAL_MINUTE_TO_SECOND',
            'INTERVAL SECOND': 'INTERVAL_SECOND',
            'TIME WITH TIME ZONE': 'TIME',
            'TIMESTAMP WITH TIME ZONE': 'TIMESTAMP',
            'PERIOD(DATE)': 'PERIOD_DATE',
            'PERIOD(TIME)': 'PERIOD_TIME',
            'PERIOD(TIME WITH TIME ZONE)': 'PERIOD_TIME',
            'PERIOD(TIMESTAMP WITH TIME ZONE)': 'PERIOD_TIMESTAMP'
        }
        
        # Get the mapped type name or use original
        mapped_type_name = type_name_mapper.get(type_name, type_name)
        
        params = {}
        # Handle precision and scale for numeric types
        if mapped_type_name in ['DECIMAL', 'NUMBER']:
            # If NUMBER() is defined without precision or scale, 
            # the metadata defaults to precision 40 (DB max).
            # Since teradatasqlalchemy supports a maximum precision of 38, we reset it to 38.
            params['precision'] = None if mapped_type_name == 'NUMBER' and precision > 38 else precision
            params['scale'] = scale

        # Handle length for character and binary types
        elif mapped_type_name in ['CHAR', 'VARCHAR', 'CLOB']:
            params['length'] = max_char_count
            params['charset'] = charset

        # Handle binary types
        elif mapped_type_name in ['BLOB', 'BYTE', 'VARBYTE']:
            params['length'] = byte_count
        
        # Handle time types with precision and timezone
        elif mapped_type_name in ['TIME', 'TIMESTAMP']:
            params['precision'] = scale
            if 'TIME ZONE' in type_name:
                params['timezone'] = True
        
        # Handle interval types
        elif mapped_type_name.startswith('INTERVAL_'):
            params['precision'] = interval_digits
            # frac_precision for second intervals
            if mapped_type_name in ['INTERVAL_DAY_TO_SECOND', 'INTERVAL_HOUR_TO_SECOND',
                                   'INTERVAL_MINUTE_TO_SECOND', 'INTERVAL_SECOND']:
                params['frac_precision'] = scale
        
        # Handle period types
        elif mapped_type_name.startswith('PERIOD_'):
            params['format'] = format_str
            params['frac_precision'] = scale
            if 'TIME ZONE' in type_name:
                params['timezone'] = True

        # Get the Teradata SQLAlchemy type class and return an instance 
        # with the constructed parameters
        type_class = getattr(tdsqlalchemy, mapped_type_name)
        return type_class(**params)

    @staticmethod
    def _get_td_array_type_from_metadata(col_info, connection, dialect_obj):
        """
        DESCRIPTION:
            Reconstruct a Teradata ARRAY_* SQLAlchemy type from fake result-set metadata
            and system dictionary tables.

        PARAMETERS:
            col_info:
                Required Argument.
                Metadata dictionary for the column (element from ColumnMetadata JSON).
                Types: dict

            connection:
                Required Argument.
                Active SQLAlchemy connection used to query ColumnsV and udtinfo.
                Types: sqlalchemy.engine.Connection

            dialect_obj:
                Required Argument.
                Instance of TeradataDialect providing helper methods.
                Types: TeradataDialect

        RETURNS:
            ARRAY_* type instance or None if reconstruction fails.

        NOTES:
            * col_info['UDTKind'] > 0 indicates a UDT (array) column.
            * We derive scope & defaultNull from dbc.udtinfo.
            * Element type code from ColumnsV ColumnType field maps via ischema_names.
            * Additional constructor kwargs set for DECIMAL, CHAR, VARCHAR, TIMESTAMP arrays.

        EXAMPLES:
            >>> arr_type = _Dtypes._get_td_array_type_from_metadata(col_info, conn, td_dial)
        """
        from teradatasqlalchemy.dialect import  ischema_names

        # Array UDT column path.
        # For array columns the fake result set metadata sets TypeName to VARCHAR.
        # Need to reconstruct underlying ARRAY_<BASE> type using ColumnsV + udtinfo.
        udt_name = col_info['UDTName']

        # Format of udt_name : SYSUDTLIB.tdml_array_decimal_10_3_100_dnn
        # Extract only the UDT name part for querying metadata.
        udt_name_simple = udt_name.split('.')[-1]
        meta = dialect_obj._get_type_metadata(connection, udt_name_simple)
        udtinfo = dialect_obj._get_udtinfo(connection, udt_name_simple)

        chartype = meta.get('CharType', 0)
        # Determine charset using server charset code mapping
        charset = CHARSET_MAPPING.get(chartype)

        # Scope & default null taken from udtinfo only (authoritative).
        scope = udtinfo['ArrayScope'].strip()
    
        default_null_flag = udtinfo['DefaultNull'].strip()
        default_null = default_null_flag.startswith('Y')

        # Element type code from ColumnsV metadata: ColumnType (e.g. 'I', 'D', 'CV').
        element_code = meta['ColumnType'].strip()
        element_type_class = ischema_names.get(element_code)
        
        element_type_name = element_type_class.__name__  # e.g. INTEGER, DECIMAL, VARCHAR
        array_class_name = 'ARRAY_' + element_type_name
        import teradatasqlalchemy
        array_class = getattr(teradatasqlalchemy, array_class_name)

        # Build constructor kwargs based on element type specifics.
        params = {'scope': scope, 'default_null': default_null}

        if array_class_name in ['ARRAY_DECIMAL', 'ARRAY_NUMBER']:
            # precision and scale for decimal/number arrays.
            params['precision'] = meta['DecimalTotalDigits']
            params['scale'] = meta['DecimalFractionalDigits']

        elif array_class_name in ['ARRAY_CHAR', 'ARRAY_VARCHAR']:
            # length and charset for char/varchar arrays.
            params['length'] = meta['ColumnLength']
            params['charset'] = charset

        elif array_class_name in ['ARRAY_TIMESTAMP', 'ARRAY_TIME']:
            # precision and timezone flag for time/timestamp arrays when element code indicates timezone.
            params['precision'] = meta['DecimalFractionalDigits']
            if element_code == 'SZ' or element_code == 'TZ':
                params['timezone'] = True

        elif str(array_class_name).startswith('ARRAY_INTERVAL_'):
            # precision and fractional precision for interval arrays.
            params['precision'] = meta['DecimalTotalDigits']
            if  str(array_class_name) in ['ARRAY_INTERVAL_DAY_TO_SECOND', 'ARRAY_INTERVAL_HOUR_TO_SECOND',
                                   'ARRAY_INTERVAL_MINUTE_TO_SECOND', 'ARRAY_INTERVAL_SECOND']:
               params['frac_precision'] = meta['DecimalFractionalDigits']

        elif array_class_name in ['ARRAY_BYTE', 'ARRAY_VARBYTE']:
            # length for byte/varbyte arrays.
            params['length'] = meta['ColumnLength']

        elif str(array_class_name).startswith('ARRAY_PERIOD_'):
            # format, fractional precision, and timezone for period arrays.
            params['format'] = meta['ColumnFormat']
            if str(array_class_name) in ['ARRAY_PERIOD_TIME', 'ARRAY_PERIOD_TIMESTAMP']:
                params['frac_precision'] = meta['DecimalFractionalDigits']
            if element_code == 'PM' or element_code == 'PZ':
                params['timezone'] = True

        # Instantiate array class with consolidated params.
        col_type = array_class(**params)

        return col_type