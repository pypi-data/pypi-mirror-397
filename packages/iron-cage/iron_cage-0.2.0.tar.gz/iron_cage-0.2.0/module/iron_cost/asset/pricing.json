{
    "chatgpt-4o-latest": {
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-3-5-haiku-20241022": {
        "cache_creation_input_token_cost": 1e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 8e-08,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 8e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-5-haiku-latest": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1e-07,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-5-sonnet-20240620": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-20241022": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-10-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-5-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 8192,
        "max_tokens": 8192,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-20250219": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2026-02-19",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-7-sonnet-latest": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-07,
        "deprecation_date": "2025-06-01",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-3-haiku-20240307": {
        "cache_creation_input_token_cost": 3e-07,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 3e-08,
        "input_cost_per_token": 2.5e-07,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.25e-06,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 264
    },
    "claude-3-opus-20240229": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-05-01",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-3-opus-latest": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2025-03-01",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "supports_assistant_prefill": true,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 395
    },
    "claude-4-opus-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-4-sonnet-20250514": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 1000000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-haiku-4-5": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-haiku-4-5-20251001": {
        "cache_creation_input_token_cost": 1.25e-06,
        "cache_creation_input_token_cost_above_1hr": 2e-06,
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 1e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 5e-06,
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "claude-opus-4-1": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-1-20250805": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-08-05",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-20250514": {
        "cache_creation_input_token_cost": 1.875e-05,
        "cache_creation_input_token_cost_above_1hr": 3e-05,
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2026-05-14",
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 32000,
        "max_tokens": 32000,
        "mode": "chat",
        "output_cost_per_token": 7.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-5": {
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_creation_input_token_cost_above_1hr": 1e-05,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-opus-4-5-20251101": {
        "cache_creation_input_token_cost": 6.25e-06,
        "cache_creation_input_token_cost_above_1hr": 1e-05,
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 2.5e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-20250514": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_1hr": 6e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "deprecation_date": "2026-05-14",
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 1000000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 159
    },
    "claude-sonnet-4-5": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "tool_use_system_prompt_tokens": 346
    },
    "claude-sonnet-4-5-20250929": {
        "cache_creation_input_token_cost": 3.75e-06,
        "cache_creation_input_token_cost_above_200k_tokens": 7.5e-06,
        "cache_read_input_token_cost": 3e-07,
        "cache_read_input_token_cost_above_200k_tokens": 6e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_above_200k_tokens": 6e-06,
        "litellm_provider": "anthropic",
        "max_input_tokens": 200000,
        "max_output_tokens": 64000,
        "max_tokens": 64000,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_above_200k_tokens": 2.25e-05,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.01,
            "search_context_size_low": 0.01,
            "search_context_size_medium": 0.01
        },
        "supports_assistant_prefill": true,
        "supports_computer_use": true,
        "supports_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true,
        "tool_use_system_prompt_tokens": 346
    },
    "codex-mini-latest": {
        "cache_read_input_token_cost": 3.75e-07,
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "ft:gpt-3.5-turbo": {
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "output_cost_per_token_batches": 3e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-0125": {
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-0613": {
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4096,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-3.5-turbo-1106": {
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-06,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4-0613": {
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "source": "OpenAI needs to add pricing for this ft model, will be updated when added by OpenAI. Defaulting to base model pricing",
        "supports_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-2025-04-14": {
        "cache_read_input_token_cost": 7.5e-07,
        "input_cost_per_token": 3e-06,
        "input_cost_per_token_batches": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "output_cost_per_token_batches": 6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-mini-2025-04-14": {
        "cache_read_input_token_cost": 2e-07,
        "input_cost_per_token": 8e-07,
        "input_cost_per_token_batches": 4e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 3.2e-06,
        "output_cost_per_token_batches": 1.6e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4.1-nano-2025-04-14": {
        "cache_read_input_token_cost": 5e-08,
        "input_cost_per_token": 2e-07,
        "input_cost_per_token_batches": 1e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-07,
        "output_cost_per_token_batches": 4e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.875e-06,
        "input_cost_per_token": 3.75e-06,
        "input_cost_per_token_batches": 1.875e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "ft:gpt-4o-2024-11-20": {
        "cache_creation_input_token_cost": 1.875e-06,
        "input_cost_per_token": 3.75e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 1.5e-07,
        "input_cost_per_token": 3e-07,
        "input_cost_per_token_batches": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1.2e-06,
        "output_cost_per_token_batches": 6e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "ft:o4-mini-2025-04-16": {
        "cache_read_input_token_cost": 1e-06,
        "input_cost_per_token": 4e-06,
        "input_cost_per_token_batches": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 1.6e-05,
        "output_cost_per_token_batches": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo": {
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0125": {
        "input_cost_per_token": 5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 1.5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0301": {
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-0613": {
        "input_cost_per_token": 1.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 4097,
        "max_output_tokens": 4096,
        "max_tokens": 4097,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-1106": {
        "deprecation_date": "2026-09-28",
        "input_cost_per_token": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k": {
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-3.5-turbo-16k-0613": {
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 16385,
        "max_output_tokens": 4096,
        "max_tokens": 16385,
        "mode": "chat",
        "output_cost_per_token": 4e-06,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4": {
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0125-preview": {
        "deprecation_date": "2026-03-26",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0314": {
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-0613": {
        "deprecation_date": "2025-06-06",
        "input_cost_per_token": 3e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 8192,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-preview": {
        "deprecation_date": "2026-03-26",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-1106-vision-preview": {
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-32k": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0314": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-32k-0613": {
        "input_cost_per_token": 6e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 32768,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 0.00012,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-turbo": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-2024-04-09": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4-turbo-preview": {
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4-vision-preview": {
        "deprecation_date": "2024-12-06",
        "input_cost_per_token": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 3e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1": {
        "cache_read_input_token_cost": 5e-07,
        "cache_read_input_token_cost_priority": 8.75e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "output_cost_per_token_priority": 1.4e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-2025-04-14": {
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-mini": {
        "cache_read_input_token_cost": 1e-07,
        "cache_read_input_token_cost_priority": 1.75e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "input_cost_per_token_priority": 7e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "output_cost_per_token_priority": 2.8e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-mini-2025-04-14": {
        "cache_read_input_token_cost": 1e-07,
        "input_cost_per_token": 4e-07,
        "input_cost_per_token_batches": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 1.6e-06,
        "output_cost_per_token_batches": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-nano": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "input_cost_per_token_priority": 2e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "output_cost_per_token_priority": 8e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.1-nano-2025-04-14": {
        "cache_read_input_token_cost": 2.5e-08,
        "input_cost_per_token": 1e-07,
        "input_cost_per_token_batches": 5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 1047576,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_batches": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.5-preview": {
        "cache_read_input_token_cost": 3.75e-05,
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4.5-preview-2025-02-27": {
        "cache_read_input_token_cost": 3.75e-05,
        "deprecation_date": "2025-07-14",
        "input_cost_per_token": 7.5e-05,
        "input_cost_per_token_batches": 3.75e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 0.00015,
        "output_cost_per_token_batches": 7.5e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o": {
        "cache_read_input_token_cost": 1.25e-06,
        "cache_read_input_token_cost_priority": 2.125e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "input_cost_per_token_priority": 4.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "output_cost_per_token_priority": 1.7e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-05-13": {
        "input_cost_per_token": 5e-06,
        "input_cost_per_token_batches": 2.5e-06,
        "input_cost_per_token_priority": 8.75e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_token": 1.5e-05,
        "output_cost_per_token_batches": 7.5e-06,
        "output_cost_per_token_priority": 2.625e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-08-06": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-2024-11-20": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-audio-preview": {
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-10-01": {
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2024-12-17": {
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-audio-preview-2025-06-03": {
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 1e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini": {
        "cache_read_input_token_cost": 7.5e-08,
        "cache_read_input_token_cost_priority": 1.25e-07,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "input_cost_per_token_priority": 2.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "output_cost_per_token_priority": 1e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-2024-07-18": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-mini-audio-preview": {
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-audio-preview-2024-12-17": {
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 1.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 6e-07,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-realtime-preview-2024-12-17": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-mini-search-preview": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.03,
            "search_context_size_low": 0.025,
            "search_context_size_medium": 0.0275
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-mini-search-preview-2025-03-11": {
        "cache_read_input_token_cost": 7.5e-08,
        "input_cost_per_token": 1.5e-07,
        "input_cost_per_token_batches": 7.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 6e-07,
        "output_cost_per_token_batches": 3e-07,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-4o-realtime-preview": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-10-01": {
        "cache_creation_input_audio_token_cost": 2e-05,
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 0.0001,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 0.0002,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2024-12-17": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-realtime-preview-2025-06-03": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_audio_token": 4e-05,
        "input_cost_per_token": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 8e-05,
        "output_cost_per_token": 2e-05,
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-4o-search-preview": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "search_context_cost_per_query": {
            "search_context_size_high": 0.05,
            "search_context_size_low": 0.03,
            "search_context_size_medium": 0.035
        },
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-4o-search-preview-2025-03-11": {
        "cache_read_input_token_cost": 1.25e-06,
        "input_cost_per_token": 2.5e-06,
        "input_cost_per_token_batches": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_batches": 5e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-2025-08-07": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_flex": 6.25e-08,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_flex": 6.25e-07,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_flex": 5e-06,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-chat": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-chat-latest": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-mini-2025-08-07": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_flex": 1.25e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_flex": 1.25e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_flex": 1e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-nano": {
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-nano-2025-08-07": {
        "cache_read_input_token_cost": 5e-09,
        "cache_read_input_token_cost_flex": 2.5e-09,
        "input_cost_per_token": 5e-08,
        "input_cost_per_token_flex": 2.5e-08,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 4e-07,
        "output_cost_per_token_flex": 2e-07,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5-pro": {
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 0.00012,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5-pro-2025-10-06": {
        "input_cost_per_token": 1.5e-05,
        "input_cost_per_token_batches": 7.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 272000,
        "max_tokens": 272000,
        "mode": "responses",
        "output_cost_per_token": 0.00012,
        "output_cost_per_token_batches": 6e-05,
        "supported_endpoints": [
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true,
        "supports_web_search": true
    },
    "gpt-5.1": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-2025-11-13": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-chat-latest": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 16384,
        "max_tokens": 16384,
        "mode": "chat",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text",
            "image"
        ],
        "supports_function_calling": false,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": false,
        "supports_vision": true
    },
    "gpt-5.1-codex": {
        "cache_read_input_token_cost": 1.25e-07,
        "cache_read_input_token_cost_priority": 2.5e-07,
        "input_cost_per_token": 1.25e-06,
        "input_cost_per_token_priority": 2.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "output_cost_per_token_priority": 2e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-codex-max": {
        "cache_read_input_token_cost": 1.25e-07,
        "input_cost_per_token": 1.25e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 400000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 1e-05,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-5.1-codex-mini": {
        "cache_read_input_token_cost": 2.5e-08,
        "cache_read_input_token_cost_priority": 4.5e-08,
        "input_cost_per_token": 2.5e-07,
        "input_cost_per_token_priority": 4.5e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 272000,
        "max_output_tokens": 128000,
        "max_tokens": 128000,
        "mode": "responses",
        "output_cost_per_token": 2e-06,
        "output_cost_per_token_priority": 3.6e-06,
        "supported_endpoints": [
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": false,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "gpt-realtime": {
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-2025-08-28": {
        "cache_creation_input_audio_token_cost": 4e-07,
        "cache_read_input_token_cost": 4e-07,
        "input_cost_per_audio_token": 3.2e-05,
        "input_cost_per_image": 5e-06,
        "input_cost_per_token": 4e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 32000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 6.4e-05,
        "output_cost_per_token": 1.6e-05,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "gpt-realtime-mini": {
        "cache_creation_input_audio_token_cost": 3e-07,
        "cache_read_input_audio_token_cost": 3e-07,
        "input_cost_per_audio_token": 1e-05,
        "input_cost_per_token": 6e-07,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 4096,
        "max_tokens": 4096,
        "mode": "chat",
        "output_cost_per_audio_token": 2e-05,
        "output_cost_per_token": 2.4e-06,
        "supported_endpoints": [
            "/v1/realtime"
        ],
        "supported_modalities": [
            "text",
            "image",
            "audio"
        ],
        "supported_output_modalities": [
            "text",
            "audio"
        ],
        "supports_audio_input": true,
        "supports_audio_output": true,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_system_messages": true,
        "supports_tool_choice": true
    },
    "o1": {
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-2024-12-17": {
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_function_calling": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-mini": {
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_vision": true
    },
    "o1-mini-2024-09-12": {
        "cache_read_input_token_cost": 1.5e-06,
        "deprecation_date": "2025-10-27",
        "input_cost_per_token": 3e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 65536,
        "max_tokens": 65536,
        "mode": "chat",
        "output_cost_per_token": 1.2e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-preview": {
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-preview-2024-09-12": {
        "cache_read_input_token_cost": 7.5e-06,
        "input_cost_per_token": 1.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 128000,
        "max_output_tokens": 32768,
        "max_tokens": 32768,
        "mode": "chat",
        "output_cost_per_token": 6e-05,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_vision": true
    },
    "o1-pro": {
        "input_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 7.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 0.0006,
        "output_cost_per_token_batches": 0.0003,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o1-pro-2025-03-19": {
        "input_cost_per_token": 0.00015,
        "input_cost_per_token_batches": 7.5e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 0.0006,
        "output_cost_per_token_batches": 0.0003,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": false,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3": {
        "cache_read_input_token_cost": 5e-07,
        "cache_read_input_token_cost_flex": 2.5e-07,
        "cache_read_input_token_cost_priority": 8.75e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_flex": 1e-06,
        "input_cost_per_token_priority": 3.5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_flex": 4e-06,
        "output_cost_per_token_priority": 1.4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-2025-04-16": {
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 8e-06,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/chat/completions",
            "/v1/completions",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-deep-research": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_token": 1e-05,
        "input_cost_per_token_batches": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 4e-05,
        "output_cost_per_token_batches": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-deep-research-2025-06-26": {
        "cache_read_input_token_cost": 2.5e-06,
        "input_cost_per_token": 1e-05,
        "input_cost_per_token_batches": 5e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 4e-05,
        "output_cost_per_token_batches": 2e-05,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-mini": {
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "o3-mini-2025-01-31": {
        "cache_read_input_token_cost": 5.5e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": false
    },
    "o3-pro": {
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o3-pro-2025-06-10": {
        "input_cost_per_token": 2e-05,
        "input_cost_per_token_batches": 1e-05,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-05,
        "output_cost_per_token_batches": 4e-05,
        "supported_endpoints": [
            "/v1/responses",
            "/v1/batch"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini": {
        "cache_read_input_token_cost": 2.75e-07,
        "cache_read_input_token_cost_flex": 1.375e-07,
        "cache_read_input_token_cost_priority": 5e-07,
        "input_cost_per_token": 1.1e-06,
        "input_cost_per_token_flex": 5.5e-07,
        "input_cost_per_token_priority": 2e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "output_cost_per_token_flex": 2.2e-06,
        "output_cost_per_token_priority": 8e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini-2025-04-16": {
        "cache_read_input_token_cost": 2.75e-07,
        "input_cost_per_token": 1.1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "chat",
        "output_cost_per_token": 4.4e-06,
        "supports_function_calling": true,
        "supports_parallel_function_calling": false,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_reasoning": true,
        "supports_response_schema": true,
        "supports_service_tier": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini-deep-research": {
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "o4-mini-deep-research-2025-06-26": {
        "cache_read_input_token_cost": 5e-07,
        "input_cost_per_token": 2e-06,
        "input_cost_per_token_batches": 1e-06,
        "litellm_provider": "openai",
        "max_input_tokens": 200000,
        "max_output_tokens": 100000,
        "max_tokens": 100000,
        "mode": "responses",
        "output_cost_per_token": 8e-06,
        "output_cost_per_token_batches": 4e-06,
        "supported_endpoints": [
            "/v1/chat/completions",
            "/v1/batch",
            "/v1/responses"
        ],
        "supported_modalities": [
            "text",
            "image"
        ],
        "supported_output_modalities": [
            "text"
        ],
        "supports_function_calling": true,
        "supports_native_streaming": true,
        "supports_parallel_function_calling": true,
        "supports_pdf_input": true,
        "supports_prompt_caching": true,
        "supports_response_schema": true,
        "supports_system_messages": true,
        "supports_tool_choice": true,
        "supports_vision": true
    },
    "openai/container": {
        "code_interpreter_cost_per_session": 0.03,
        "litellm_provider": "openai",
        "mode": "chat"
    }
}