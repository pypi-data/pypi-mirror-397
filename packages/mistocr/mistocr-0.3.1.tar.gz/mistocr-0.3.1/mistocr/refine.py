"""Fix heading hierarchy and describe images in OCR'd markdown documents"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_refine.ipynb.

# %% auto 0
__all__ = ['prompt_fix_hdgs', 'describe_img_prompt', 'get_hdgs', 'add_pg_hdgs', 'read_pgs_pg', 'fmt_hdgs_idx',
           'HeadingCorrection', 'HeadingCorrections', 'fix_hdg_hierarchy', 'mk_fixes_lut', 'apply_hdg_fixes',
           'fix_hdgs', 'ImgDescription', 'describe_img', 'limit', 'parse_r', 'describe_imgs', 'save_img_descs',
           'add_descs_to_pg', 'add_descs_to_pgs', 'add_img_descs']

# %% ../nbs/01_refine.ipynb 3
from fastcore.all import *
from .core import read_pgs
from re import sub, findall, MULTILINE
from pydantic import BaseModel
from lisette import *
from lisette.core import completion
from typing import Callable
import os
import json
import shutil
from asyncio import Semaphore, gather, sleep

# %% ../nbs/01_refine.ipynb 7
def get_hdgs(
    md:str # Markdown file string
    ) -> L: # L of strings
    "Return the markdown headings"
    # Sanitize removing '#' in python snippet if any
    md = sub(r'```[\s\S]*?```', '', md)
    return L(findall(r'^#{1,6} .+$', md, MULTILINE))



# %% ../nbs/01_refine.ipynb 8
def add_pg_hdgs(
    md:str, # Markdown file string, 
    n:int # Page number
    ) -> str: # Markdown file string
    "Add page number to all headings in page markdown"
    md = sub(r'```[\s\S]*?```', '', md)
    def repl(m): return m.group(0) + f' ... page {n}'
    return sub(r'^#{1,6} .+$', repl, md, flags=MULTILINE)

# %% ../nbs/01_refine.ipynb 12
def read_pgs_pg(
    path:str # Path to the markdown file
    ) -> L: # List of markdown pages
    "Read all pages of a markdown file and add page numbers to all headings"
    pgs = read_pgs(path, join=False)
    return L([add_pg_hdgs(pg, n) for n, pg in enumerate(pgs, 1)]).concat()

# %% ../nbs/01_refine.ipynb 15
def fmt_hdgs_idx(
    hdgs: list[str] # List of markdown headings
    ) -> str: # Formatted string with index
    "Format the headings with index"
    return '\n'.join(f"{i}. {h}" for i, h in enumerate(hdgs))


# %% ../nbs/01_refine.ipynb 18
class HeadingCorrection(BaseModel):
    "A single heading correction mapping an index to its corrected markdown heading"
    index: int
    corrected: str

# %% ../nbs/01_refine.ipynb 19
class HeadingCorrections(BaseModel):
    "Collection of heading corrections returned by the LLM"
    corrections: list[HeadingCorrection]

# %% ../nbs/01_refine.ipynb 21
prompt_fix_hdgs = """Fix markdown heading hierarchy errors while preserving the document's intended structure.

INPUT FORMAT: Each heading is prefixed with its index number (e.g., "0. # Title ... page 1")

ANALYSIS STEPS (think through these before outputting corrections):
1. For each numbered heading (e.g., "4.1", "2.a", "A.1"), identify its parent heading (e.g., "4", "2", "A")
2. Verify the child heading is exactly one # deeper than its parent
3. If not, mark it for correction

RULES - Apply these fixes in order:

1. **Single H1 rule**: Documents must have exactly ONE # heading (typically the document title at the top)
   - If index 0 is already #, then all subsequent headings (index 1+) must be ## or deeper
   - If no H1 exists, the first major heading should be #, and all others ## or deeper
   - NO exceptions: appendices, references, and all sections are ## or deeper after the title

2. **Infer depth from numbering patterns**: If headings contain section numbers, deeper nesting means deeper heading level
   - Parent section (e.g., "1", "2", "A") MUST be shallower than child (e.g., "1.1", "2.a", "A.1")
   - Child section MUST be exactly one # deeper than parent
   - Works with any numbering: "1/1.1/1.1.1", "A/A.1/A.1.a", "I/I.A/I.A.1", etc.

3. **Level jumps**: Headings can only increase by one # at a time when moving deeper
   - Wrong: ## Section → ##### Subsection
   - Fixed: ## Section → ### Subsection

4. **Decreasing levels is OK**: Moving back up the hierarchy (### to ##) is valid for new sections

5. **Unnumbered headings in numbered documents**: If the document uses numbered headings consistently, any unnumbered heading appearing within that structure is likely misclassified bold text and should be converted to regular text (output the heading text without any # symbols in the corrected field)

OUTPUT: Return a list of corrections, where each correction has:
- index: the heading's index number
- corrected: the fixed heading text (without the index prefix), or empty string "" to remove the heading entirely
IMPORTANT: Preserve the " ... page N" suffix in all corrected headings.
Only include headings that need changes.

Headings to analyze:
{headings_list}
"""

# %% ../nbs/01_refine.ipynb 23
def fix_hdg_hierarchy(
    hdgs: list[str], # List of markdown headings
    prompt: str=None, # Prompt to use
    model: str='claude-sonnet-4-5', # Model to use
    api_key: str=None # API key
    ) -> dict[int, str]: # Dictionary of index → corrected heading
    "Fix the heading hierarchy"
    if api_key is None: api_key = os.getenv('ANTHROPIC_API_KEY')
    if prompt is None: prompt = prompt_fix_hdgs
    prompt = prompt.format(headings_list=fmt_hdgs_idx(hdgs))
    r = completion(model=model, messages=[{"role": "user", "content": prompt}], response_format=HeadingCorrections, api_key=api_key)
    fixes =  json.loads(r.choices[0].message.content)['corrections']
    return {o['index']: o['corrected'] for o in fixes}


# %% ../nbs/01_refine.ipynb 26
@delegates(fix_hdg_hierarchy)
def mk_fixes_lut(
    hdgs: list[str], # List of markdown headings
    model: str='claude-sonnet-4-5', # Model to use
    api_key: str=None, # API key
    **kwargs
    ) -> dict[str, str]: # Dictionary of old → new heading
    "Make a lookup table of fixes"
    if api_key is None: api_key = os.getenv('ANTHROPIC_API_KEY')
    fixes = fix_hdg_hierarchy(hdgs, model=model, api_key=api_key, **kwargs)
    return {hdgs[k]:v for k,v in fixes.items()}

# %% ../nbs/01_refine.ipynb 29
def apply_hdg_fixes(
    p:str, # Page to fix
    lut_fixes: dict[str, str], # Lookup table of fixes
    ) -> str: # Page with fixes applied
    "Apply the fixes to the page"
    for old in get_hdgs(p): p = p.replace(old, lut_fixes.get(old, old))
    return p

# %% ../nbs/01_refine.ipynb 32
@delegates(mk_fixes_lut)
def fix_hdgs(src:str, model:str='claude-sonnet-4-5', dst:str=None, img_folder:str='img', **kwargs):
    "Fix heading hierarchy in markdown document"
    src_path,dst_path = Path(src),Path(dst) if dst else Path(src)
    if dst_path != src_path: dst_path.mkdir(parents=True, exist_ok=True)
    src_imgs = src_path/img_folder
    if src_imgs.exists() and dst_path != src_path: shutil.copytree(src_imgs, dst_path/img_folder, dirs_exist_ok=True)
    pgs_with_pg = read_pgs_pg(src_path)
    lut = mk_fixes_lut(L([get_hdgs(pg) for pg in pgs_with_pg]).concat(), model, **kwargs)
    for i,p in enumerate(pgs_with_pg, 1): (dst_path/f'page_{i}.md').write_text(apply_hdg_fixes(p, lut))

# %% ../nbs/01_refine.ipynb 38
class ImgDescription(BaseModel):
    "Image classification and description for OCR'd documents"
    is_informative:bool # Whether image contains informative content (charts, diagrams, tables) vs decorative (logos, backgrounds)
    description:str # Detailed description of the image content for RAG and accessibility

# %% ../nbs/01_refine.ipynb 41
describe_img_prompt = """Analyze this image from an academic/technical document.

Step 1: Determine if this image is informative for understanding the document content.
- Informative: charts, diagrams, tables, technical illustrations, experimental results, architectural diagrams
- Non-informative: logos, decorative images, generic photos, page backgrounds

Step 2: 
- If informative: Provide a detailed description including the type of visualization, key elements and their relationships, important data or patterns, and relevant technical details.
- If non-informative: Provide a brief label (e.g., "Company logo", "Decorative header image")

Return your response as JSON with 'is_informative' (boolean) and 'description' (string) fields."""

# %% ../nbs/01_refine.ipynb 42
async def describe_img(
    img_path: Path,  # Path to the image file
    model: str = 'claude-sonnet-4-5',  # Model to use
    prompt: str = describe_img_prompt  # Prompt for description
) -> ImgDescription:
    "Describe a single image using AsyncChat"
    chat = AsyncChat(model=model)
    r = await chat([img_path.read_bytes(), prompt], response_format=ImgDescription)
    return r

# %% ../nbs/01_refine.ipynb 46
async def limit(
    semaphore, # Semaphore for concurrency control
    coro, # Coroutine to execute
    delay:float=None # Optional delay in seconds after execution
):
    "Execute coroutine with semaphore-based rate limiting and optional delay"
    async with semaphore:
        r = await coro
        if delay: await sleep(delay)
        return r

# %% ../nbs/01_refine.ipynb 48
def parse_r(
    result # ModelResponse object from API call
): # Dictionary with 'is_informative' and 'description' keys
    "Extract and parse JSON content from model response"
    return json.loads(result.choices[0].message.content)

# %% ../nbs/01_refine.ipynb 50
async def describe_imgs(
    imgs: list[Path], # List of image file paths to describe
    model: str = 'claude-sonnet-4-5', # Model to use for image description
    prompt: str = describe_img_prompt, # Prompt template for description
    semaphore: int = 10, # Max concurrent API requests
    delay: float = 0.1 # Delay in seconds between requests
) -> dict[str, dict]: # Dict mapping filename to parsed description
    "Describe multiple images in parallel with rate limiting"
    sem = Semaphore(semaphore)
    results = await gather(*[limit(sem, describe_img(img, model, prompt), delay) for img in imgs])
    return {img.name: parse_r(r) for img, r in zip(imgs, results)}

# %% ../nbs/01_refine.ipynb 52
def save_img_descs(
    descs: dict, # Dictionary of image descriptions
    dst_fname: Path, # Path to save the JSON file
    ) -> None:    
    "Save image descriptions to JSON file"
    Path(dst_fname).write_text(json.dumps(descs, indent=2))

# %% ../nbs/01_refine.ipynb 57
def add_descs_to_pg(
    pg:str, # Page markdown content
    descs:dict # Dictionary mapping image filenames to their descriptions
) -> str: # Page markdown with descriptions added
    "Add AI-generated descriptions to images in page"
    for link in re.findall(r'!\[[^\]]*\]\([^)]+\)', pg):
        fname = re.findall(r'\(([^)]+)\)', link)[0]
        if fname in descs: pg = pg.replace(link, f"{link}\nAI-generated image description:\n___\n{descs[fname]['description']}\n___")
    return pg

# %% ../nbs/01_refine.ipynb 62
def add_descs_to_pgs(
    pgs:list, # List of page markdown strings
    descs:dict # Dictionary mapping image filenames to their descriptions
) -> list: # List of pages with descriptions added
    "Add AI-generated descriptions to images in all pages"
    return [add_descs_to_pg(pg, descs) for pg in pgs]

# %% ../nbs/01_refine.ipynb 65
async def add_img_descs(
    src:str, # Path to source markdown directory
    dst:str=None, # Destination directory (defaults to src if None)
    model:str='claude-sonnet-4-5', # Vision model for image description
    img_folder:str='img', # Name of folder containing images
    semaphore:int=2, # Max concurrent API requests
    delay:float=1, # Delay in seconds between API calls
    force:bool=False, # Force regeneration even if cache exists
    progress:bool=True # Print progress messages
):
    "Describe all images in markdown document and insert descriptions inline"
    src_path,dst_path = Path(src),Path(dst) if dst else Path(src)
    if dst_path != src_path: dst_path.mkdir(parents=True, exist_ok=True)
    src_imgs = src_path/img_folder
    
    # Check if image folder exists
    if not src_imgs.exists():
        if progress: print(f"No images to describe in the document (no '{img_folder}' folder found)")
        return
    
    if src_imgs.exists() and dst_path != src_path: shutil.copytree(src_imgs, dst_path/img_folder, dirs_exist_ok=True)
    desc_file = src_path/'img_descriptions.json'
    if desc_file.exists() and not force:
        if progress: print(f"Loading existing descriptions from {desc_file}")
        descs = json.loads(desc_file.read_text())
    else:
        imgs = (src_path/img_folder).ls(file_exts=['.jpeg', '.jpg', '.png'])
        if progress: print(f"Describing {len(imgs)} images...")
        descs = await describe_imgs(imgs, model, semaphore=semaphore, delay=delay)
        save_img_descs(descs, desc_file)
        if progress: print(f"Saved descriptions to {desc_file}")
    pgs = read_pgs(src_path, join=False)
    if progress: print(f"Adding descriptions to {len(pgs)} pages...")
    enriched = [add_descs_to_pg(pg, descs) for pg in pgs]
    for i,pg in enumerate(enriched, 1): (dst_path/f'page_{i}.md').write_text(pg)
    if progress: print(f"Done! Enriched pages saved to {dst_path}")

