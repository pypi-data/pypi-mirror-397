"""
Simplified command-line interface with only essential commands.
"""

import click
import logging
import sys
import json
import pandas as pd
from pathlib import Path

from .analyzer import analyze_imputation_requirements
from .models import AnalysisConfig
from .io import save_suggestions


@click.group()
def cli():
    """FunPuter - Intelligent Imputation Analysis"""
    pass


@cli.command()
@click.option("--data", "-d", required=True, help="Path to data CSV file to analyze")
@click.option("--metadata", "-m", help="Path to metadata file (CSV or JSON). If not provided, auto-infers metadata")
@click.option("--output", "-o", help="Output path for analysis results (JSON format)")
@click.option("--verbose", "-v", is_flag=True, help="Enable verbose logging")
@click.option("--percentile-threshold", type=float, default=95.0, help="Percentile threshold for outlier-resistant ranges (50.0-99.9, default: 95.0)")
@click.option("--min-samples-percentiles", type=int, default=20, help="Minimum samples required for percentile calculation (default: 20)")
@click.option("--disable-percentile-ranges", is_flag=True, help="Disable percentile-based range calculation")
@click.option("--min-frequency-count", type=int, default=5, help="Minimum absolute count for categorical value inclusion (default: 5)")
@click.option("--min-frequency-percentage", type=float, default=1.0, help="Minimum percentage for categorical value inclusion (0.1-50.0, default: 1.0)")
@click.option("--min-samples-frequency", type=int, default=20, help="Minimum samples required for frequency filtering (default: 20)")
@click.option("--disable-frequency-filtering", is_flag=True, help="Disable frequency-based categorical filtering")
def analyze(data, metadata, output, verbose, percentile_threshold, min_samples_percentiles, disable_percentile_ranges, 
           min_frequency_count, min_frequency_percentage, min_samples_frequency, disable_frequency_filtering):
    """
    Analyze dataset for missing data imputation recommendations.

    This is the main command that analyzes your data and provides intelligent
    imputation method suggestions based on data patterns and constraints.

    Examples:

    # Auto-infer metadata and analyze
    funputer analyze -d data.csv

    # Use explicit metadata file
    funputer analyze -d data.csv -m metadata.csv

    # Save results to file
    funputer analyze -d data.csv -o results.json
    
    # Use 99th percentile for outlier-resistant ranges
    funputer analyze -d data.csv --percentile-threshold 99.0
    
    # Disable percentile ranges (use only traditional min/max)
    funputer analyze -d data.csv --disable-percentile-ranges
    
    # Use stricter frequency filtering (min 10 occurrences or 2%)
    funputer analyze -d data.csv --min-frequency-count 10 --min-frequency-percentage 2.0
    
    # Disable frequency filtering for categorical data
    funputer analyze -d data.csv --disable-frequency-filtering
    
    # Combined: 99th percentile + strict frequency filtering
    funputer analyze -d data.csv --percentile-threshold 99.0 --min-frequency-percentage 2.0
    """
    if verbose:
        logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
        logger = logging.getLogger(__name__)

    try:
        # Basic data validation
        data_path = Path(data)
        if not data_path.exists():
            click.echo(f"‚ùå Error: Data file not found: {data}", err=True)
            sys.exit(1)

        if verbose:
            click.echo(f"üìä Analyzing dataset: {data}")

        # Validate percentile options
        if not (50.0 <= percentile_threshold <= 99.9):
            click.echo(f"‚ùå Error: Percentile threshold must be between 50.0 and 99.9, got {percentile_threshold}", err=True)
            sys.exit(1)
        
        if min_samples_percentiles < 5:
            click.echo(f"‚ùå Error: Minimum samples for percentiles must be at least 5, got {min_samples_percentiles}", err=True)
            sys.exit(1)
        
        # Validate frequency filtering options
        if min_frequency_count < 1:
            click.echo(f"‚ùå Error: Minimum frequency count must be at least 1, got {min_frequency_count}", err=True)
            sys.exit(1)
        
        if not (0.1 <= min_frequency_percentage <= 50.0):
            click.echo(f"‚ùå Error: Minimum frequency percentage must be between 0.1 and 50.0, got {min_frequency_percentage}", err=True)
            sys.exit(1)
        
        if min_samples_frequency < 10:
            click.echo(f"‚ùå Error: Minimum samples for frequency filtering must be at least 10, got {min_samples_frequency}", err=True)
            sys.exit(1)
        
        # Create analysis configuration
        from .models import AnalysisConfig
        config = AnalysisConfig(
            enable_percentile_ranges=not disable_percentile_ranges,
            default_percentile_threshold=percentile_threshold,
            min_samples_for_percentiles=min_samples_percentiles,
            enable_frequency_filtering=not disable_frequency_filtering,
            min_frequency_count=min_frequency_count,
            min_frequency_percentage=min_frequency_percentage,
            min_samples_for_frequency_filtering=min_samples_frequency
        )
        
        if verbose:
            if config.enable_percentile_ranges:
                click.echo(f"üìà Percentile ranges enabled: {percentile_threshold}% threshold, min {min_samples_percentiles} samples")
            else:
                click.echo("üìà Percentile ranges disabled")
            
            if config.enable_frequency_filtering:
                click.echo(f"üè∑Ô∏è  Frequency filtering enabled: min {min_frequency_count} count OR {min_frequency_percentage}%, min {min_samples_frequency} samples")
            else:
                click.echo("üè∑Ô∏è  Frequency filtering disabled")

        # Run analysis
        if metadata:
            # Use explicit metadata file
            metadata_path = Path(metadata)
            if not metadata_path.exists():
                click.echo(f"‚ùå Error: Metadata file not found: {metadata}", err=True)
                sys.exit(1)
            
            if verbose:
                click.echo(f"üìã Using metadata file: {metadata}")
            
            suggestions = analyze_imputation_requirements(
                data_path=str(data_path),
                metadata_path=str(metadata_path),
                config=config
            )
        else:
            # Auto-infer metadata
            if verbose:
                click.echo("ü§ñ Auto-inferring metadata from data...")
            
            suggestions = analyze_imputation_requirements(data_path=str(data_path), config=config)

        if not suggestions:
            click.echo("‚ö†Ô∏è  No imputation suggestions generated. Check your data file.")
            sys.exit(1)

        # Display results
        click.echo(f"\nüìà Analysis Results ({len(suggestions)} columns):")
        click.echo("=" * 60)

        columns_with_missing = 0
        total_missing = 0
        confidence_scores = []

        for suggestion in suggestions:
            if suggestion.missing_count > 0:
                columns_with_missing += 1
                total_missing += suggestion.missing_count
                
                click.echo(f"\nüîç {suggestion.column_name}")
                click.echo(f"   Missing: {suggestion.missing_count} ({suggestion.missing_percentage:.1%})")
                click.echo(f"   Method: {suggestion.proposed_method}")
                click.echo(f"   Confidence: {suggestion.confidence_score:.2f}")
                click.echo(f"   Rationale: {suggestion.rationale}")
                
                if suggestion.outlier_count > 0:
                    click.echo(f"   Outliers: {suggestion.outlier_count} ({suggestion.outlier_percentage:.1%})")
            
            confidence_scores.append(suggestion.confidence_score)

        # Summary
        avg_confidence = sum(confidence_scores) / len(confidence_scores) if confidence_scores else 0
        click.echo(f"\nüìã Summary:")
        click.echo(f"   Columns with missing data: {columns_with_missing}")
        click.echo(f"   Total missing values: {total_missing}")
        click.echo(f"   Average confidence: {avg_confidence:.2f}")

        # Save results if requested
        if output:
            save_suggestions(suggestions, output)
            click.echo(f"\nüíæ Results saved to: {output}")

        click.echo("\n‚úÖ Analysis complete!")

    except Exception as e:
        click.echo(f"‚ùå Error during analysis: {str(e)}", err=True)
        if verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


@cli.command()
@click.option("--data", "-d", required=True, help="Path to data CSV file to validate")
@click.option("--json-out", help="Save validation report to JSON file")
@click.option("--verbose", "-v", is_flag=True, help="Enable verbose output")
def validate(data, json_out, verbose):
    """
    Run basic data validation checks before analysis.

    This command performs quick validation to check if your data file
    is ready for analysis and provides recommendations for next steps.

    Examples:

    # Basic validation
    funputer validate -d data.csv

    # Save validation report
    funputer validate -d data.csv --json-out report.json
    """
    if verbose:
        logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')

    try:
        # Import preflight functionality
        from .preflight import run_preflight, format_preflight_report

        data_path = Path(data)
        if not data_path.exists():
            click.echo(f"‚ùå Error: Data file not found: {data}", err=True)
            sys.exit(1)

        if verbose:
            click.echo(f"üîç Validating dataset: {data}")

        # Run validation
        report = run_preflight(str(data_path))
        
        # Format and display results
        formatted_report = format_preflight_report(report)
        click.echo(formatted_report)

        # Save JSON report if requested
        if json_out:
            with open(json_out, 'w') as f:
                json.dump(report, f, indent=2, default=str)
            click.echo(f"\nüíæ Validation report saved to: {json_out}")

        # Exit with appropriate code
        exit_code = report.get('exit_code', 0)
        if exit_code == 0:
            click.echo("\n‚úÖ Data validation passed!")
        elif exit_code == 2:
            click.echo("\n‚ö†Ô∏è  Data validation passed with warnings.")
        else:
            click.echo(f"\n‚ùå Data validation failed (code: {exit_code})")
        
        sys.exit(exit_code)

    except Exception as e:
        click.echo(f"‚ùå Error during validation: {str(e)}", err=True)
        if verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    cli()