# Do not edit this file directly. It has been autogenerated from
# src/strawchemy/sqlalchemy/repository/_async.py
from __future__ import annotations

from collections import defaultdict, namedtuple
from inspect import isclass
from typing import TYPE_CHECKING, Any, TypeVar

from sqlalchemy.orm import RelationshipProperty

from sqlalchemy import ColumnElement, Row, and_, delete, inspect, select, update
from strawchemy.sqlalchemy._executor import QueryResult, SyncQueryExecutor
from strawchemy.sqlalchemy._transpiler import QueryTranspiler
from strawchemy.sqlalchemy.repository._base import InsertData, MutationData, SQLAlchemyGraphQLRepository
from strawchemy.sqlalchemy.typing import AnySyncSession, DeclarativeT
from strawchemy.strawberry.mutation.input import UpsertData
from strawchemy.strawberry.mutation.types import RelationType

if TYPE_CHECKING:
    from collections.abc import Sequence

    from sqlalchemy.orm import DeclarativeBase
    from sqlalchemy.orm.util import AliasedClass

    from strawchemy.sqlalchemy.hook import QueryHook
    from strawchemy.sqlalchemy.repository._base import InsertOrUpdate, RowLike
    from strawchemy.strawberry.dto import BooleanFilterDTO, EnumDTO, OrderByDTO
    from strawchemy.strawberry.mutation.input import Input, LevelInput
    from strawchemy.strawberry.typing import QueryNodeType

__all__ = ()

T = TypeVar("T", bound=Any)


class SQLAlchemyGraphQLSyncRepository(SQLAlchemyGraphQLRepository[DeclarativeT, AnySyncSession]):
    def _insert_many(self, data: InsertData) -> Sequence[Row[Any]]:
        if self._dialect.insert_executemany_returning_sort_by_parameter_order and not (
            self._dialect.name == "postgresql" and data.is_upsert
        ):
            results = self.session.execute(
                self._insert_statement(data).returning(*data.pks, sort_by_parameter_order=True),
                data.values,
            )
            return results.all()
        rows: Sequence[Row[Any]] = []
        conn = self.session.connection()
        for value in data.values:
            cursor = conn.execute(self._insert_statement(data).values(**value))
            assert cursor.inserted_primary_key is not None
            rows.append(cursor.inserted_primary_key)
        return rows

    def _insert_nested(self, data: InsertData, level: LevelInput) -> None:
        """Inserts multiple records for a given model type and updates related instances.

        This internal method performs a bulk insert operation for the specified
        SQLAlchemy model type using the provided values. After insertion, it
        retrieves the primary keys of the newly created records and updates
        the corresponding instance objects within the provided `level` input
        with these keys. It also handles updating foreign keys for to-one
        relationships where applicable.

        Args:
            data: An InsertData object containing the model type, values to insert,
                and optional upsert configuration for handling conflicts.
            level: The input level containing information about the instances being
                created and their relationships, used to update instances with
                generated primary and foreign keys.
        """
        instance_ids: Sequence[Row[Any]] = self._insert_many(data)

        pk_names = [pk.name for pk in data.pks]

        pk_index, fk_index = 0, 0
        for relation_input in level.inputs:
            if isclass(data.model_type) and not isinstance(relation_input.instance, data.model_type):
                continue
            # Update Pks
            for column in data.pks:
                setattr(relation_input.instance, column.key, instance_ids[pk_index][pk_names.index(column.key)])
            pk_index += 1
            if relation_input.relation.relation_type is RelationType.TO_MANY:
                continue
            # Update Fks
            prop = relation_input.relation.attribute
            assert isinstance(prop, RelationshipProperty)
            assert prop.local_remote_pairs
            for local, remote in prop.local_remote_pairs:
                assert local.key
                assert remote.key
                setattr(relation_input.relation.parent, local.key, instance_ids[fk_index][pk_names.index(remote.key)])
            fk_index += 1

    def _delete_where(
        self,
        alias: AliasedClass[Any],
        where: list[ColumnElement[bool]] | None = None,
        execution_options: dict[str, Any] | None = None,
    ) -> Sequence[Row[Any]]:
        alias_insp = inspect(alias)
        model_pks = [getattr(alias, pk.key) for pk in alias_insp.mapper.primary_key if pk.key]
        if self._dialect.delete_returning:
            statement = delete(alias_insp).returning(*model_pks)
            if where:
                statement = statement.where(*where)
            result = self.session.execute(statement, execution_options=execution_options or {})
            return result.all()
        affected_statement, delete_statement = select(*model_pks), delete(alias_insp)
        if where:
            affected_statement, delete_statement = affected_statement.where(*where), delete_statement.where(*where)
        affected_rows = (self.session.execute(affected_statement)).all()
        conn = self.session.connection()
        conn.execute(delete_statement, execution_options=execution_options or {})
        return affected_rows

    def _update_where(
        self,
        alias: AliasedClass[Any],
        values: dict[str, Any],
        where: list[ColumnElement[bool]] | None = None,
        execution_options: dict[str, Any] | None = None,
    ) -> Sequence[Row[Any]]:
        alias_insp = inspect(alias)
        model_pks = [getattr(alias, pk.key) for pk in alias_insp.mapper.primary_key if pk.key]
        if self._dialect.update_returning:
            statement = update(alias_insp).values(**values).returning(*model_pks)
            if where:
                statement = statement.where(*where)
            result = self.session.execute(statement, execution_options=execution_options or {})
            return result.all()

        affected_statement, update_statement = select(*model_pks), update(alias_insp).values(**values)
        if where:
            affected_statement, update_statement = affected_statement.where(*where), update_statement.where(*where)
        affected_rows = (self.session.execute(affected_statement)).all()
        conn = self.session.connection()
        conn.execute(update_statement, execution_options=execution_options or {})
        return affected_rows

    def _create_nested_to_one_relations(self, data: Input[DeclarativeT]) -> None:
        """Creates nested related objects for to-one relationships.

        Iterates through the input data levels filtered for 'create' operations
        on to-one relationships. It groups the instances to be created by their
        model type and then calls `_insert` for each type to perform bulk
        insertions.

        Args:
            data: The processed input data containing nested structures and
                relationship information.
        """
        for level in data.filter_by_level(RelationType.TO_ONE, ["create", "upsert"]):
            params = self._to_one_nested_create_params(level)
            for model_type, values in params.insert.items():
                self._insert_nested(InsertData(model_type, values, params.upsert_data_map.get(model_type)), level)

    def _update_to_many_relations(self, data: Input[DeclarativeT], mutated_ids: Sequence[RowLike]) -> None:
        """Updates foreign keys to connect existing related objects for to-many relationships.

        Iterates through the input data levels filtered for 'set' operations
        on to-many relationships. For each relationship, it prepares bulk update
        statements to set the foreign keys on the related models, linking them
        to the parent objects (either newly created or existing).

        Args:
            data: The processed input data containing relationship information.
            mutated_ids: A sequence of RowLike objects containing the primary keys
                of the main objects created or updated in the parent operation.
                Used to link the 'set' relations to the correct parent.
        """
        for level in data.filter_by_level(RelationType.TO_MANY, ["add", "remove"]):
            params = self._to_many_update_params(level, mutated_ids)
            for model_type, values in params.update.items():
                self.session.execute(update(model_type), values)

    def _set_to_many_relations(
        self, mode: InsertOrUpdate, data: Input[DeclarativeT], mutated_ids: Sequence[RowLike]
    ) -> None:
        for level in data.filter_by_level(RelationType.TO_MANY, ["set"]):
            params = self._to_many_set_params(level, mode, mutated_ids)

            for model_type, set_values in params.insert.items():
                if current_ids := params.delete[model_type]:
                    attrs = inspect(model_type, raiseerr=True).attrs
                    remove_previous_stmt = update(model_type).where(
                        and_(*[attrs[key].class_attribute.in_(ids) for key, ids in current_ids.items()])
                    )
                    self.session.execute(remove_previous_stmt, dict.fromkeys(current_ids))
                self.session.execute(update(model_type), set_values)

            for model_type_or_table, set_values in params.insert_m2m.items():
                if current_ids := params.delete_m2m[model_type_or_table]:
                    columns = inspect(model_type_or_table, raiseerr=True).columns
                    remove_previous_stmt = delete(model_type_or_table).where(
                        and_(*[columns[key].in_(ids) for key, ids in current_ids.items()])
                    )
                    self.session.execute(remove_previous_stmt)
                insert_data = InsertData(model_type_or_table, set_values)
                self.session.execute(self._insert_statement(insert_data).values(insert_data.values))

    def _create_to_many_relations(self, data: Input[DeclarativeT], mutated_ids: Sequence[RowLike]) -> None:
        """Creates and connects new related objects for to-many relationships.

        Iterates through the input data levels filtered for 'create' operations
        on to-many relationships. It prepares the data for the new related
        objects, including setting the foreign keys based on the parent object's
        primary key, and then calls `_insert` to perform bulk insertions.

        Args:
            data: The processed input data containing nested structures and
                relationship information.
            mutated_ids: A sequence of RowLike objects containing the primary keys
                of the main objects created in the parent operation. Used to set
                foreign keys on the newly created related objects.
        """
        for level in data.filter_by_level(RelationType.TO_MANY, ["create", "upsert"]):
            params = self._to_many_create_params(level, mutated_ids)
            for model_type, values in params.insert.items():
                self._insert_nested(InsertData(model_type, values, params.upsert_data_map.get(model_type)), level)

            params = self._m2m_create_params(level, mutated_ids)
            for model_type_or_table, set_values in params.insert_m2m.items():
                insert_data = InsertData(model_type_or_table, set_values)
                self.session.execute(self._insert_statement(insert_data).values(*insert_data.values))

    def _execute_insert_or_update(self, data: MutationData[DeclarativeT]) -> Sequence[RowLike]:
        values = [self._to_dict(instance) for instance in data.input.instances]
        if data.mode == "insert":
            return self._insert_many(InsertData(self.model, values))

        if data.mode == "upsert":
            return self._insert_many(
                InsertData(
                    self.model,
                    values,
                    UpsertData(
                        update_fields=data.upsert_update_fields or [], conflict_constraint=data.upsert_conflict_fields
                    ),
                )
            )

        pks = [column.key for column in self.model.__mapper__.primary_key if column.key]
        pk_tuple = namedtuple("AsRow", pks)  # pyright: ignore[reportUntypedNamedTuple]  # noqa: PYI024

        if data.mode == "update_by_pks":
            self.session.execute(update(self.model), values)
            return [pk_tuple(*[instance[name] for name in pks]) for instance in values]

        transpiler = QueryTranspiler(self.model, self._dialect, statement=self.statement)
        where_expressions = transpiler.filter_expressions(data.dto_filter) if data.dto_filter else None
        return self._update_where(transpiler.scope.root_alias, values[0], where_expressions)

    def _mutate(self, data: MutationData[DeclarativeT]) -> Sequence[RowLike]:
        self._connect_to_one_relations(data.input)
        data.input.add_non_input_relations()
        with self.session.begin_nested() as transaction:
            self._create_nested_to_one_relations(data.input)
            instance_ids = self._execute_insert_or_update(data)
            self._create_to_many_relations(data.input, instance_ids)
            self._update_to_many_relations(data.input, instance_ids)
            self._set_to_many_relations(data.mode, data.input, instance_ids)
            transaction.commit()
        return instance_ids

    def _list_by_ids(
        self, id_rows: Sequence[RowLike], selection: QueryNodeType | None = None
    ) -> QueryResult[DeclarativeT]:
        """Retrieves multiple records by their primary keys with optional selection.

        Fetches records from the repository's main model that match the provided
        primary key combinations. Allows specifying a GraphQL selection

        Args:
            id_rows: A sequence of RowLike objects, each containing the primary
                key values for one record to retrieve.
            selection: An optional QueryNodeType representing the GraphQL
                selection set to apply to the query.

        Returns:
            A QueryResult containing the list of fetched records matching the
            provided IDs, structured according to the selection.
        """
        executor = self._get_query_executor(SyncQueryExecutor, selection=selection)
        id_fields = executor.scope.id_field_definitions(self.model)
        executor.base_statement = executor.base_statement.where(
            *[field.model_field.in_([getattr(row, field.model_field_name) for row in id_rows]) for field in id_fields]
        )
        return executor.list(self.session)

    def list(
        self,
        selection: QueryNodeType | None = None,
        dto_filter: BooleanFilterDTO | None = None,
        order_by: list[OrderByDTO] | None = None,
        limit: int | None = None,
        offset: int | None = None,
        distinct_on: list[EnumDTO] | None = None,
        allow_null: bool = False,
        query_hooks: defaultdict[QueryNodeType, list[QueryHook[DeclarativeBase]]] | None = None,
        execution_options: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> QueryResult[DeclarativeT]:
        """Retrieves a list of records based on filtering, ordering, and pagination.

        Fetches records from the repository's main model, applying optional
        filtering, ordering, pagination (limit/offset), and distinct constraints.
        Supports GraphQL selection sets for optimized data retrieval and query hooks
        for customization.

        Args:
            selection: An optional QueryNodeType representing the GraphQL
                selection set.
            dto_filter: An optional filter object derived from GraphQL input.
            order_by: An optional list of ordering criteria.
            limit: An optional integer limiting the number of results.
            offset: An optional integer specifying the starting point for results.
            distinct_on: An optional list of fields for DISTINCT ON clause (if supported).
            allow_null: If True, allows certain operations even if parts of the
                filter path are null (implementation specific to executor).
            query_hooks: Optional hooks to modify the query at different stages.
            execution_options: Optional dictionary of execution options passed to
                SQLAlchemy.
            **kwargs: Additional keyword arguments (currently unused but allows extension).

        Returns:
            A QueryResult containing the list of fetched records and potentially
            pagination info or total count, structured according to the selection.
        """
        executor = self._get_query_executor(
            executor_type=SyncQueryExecutor,
            selection=selection,
            dto_filter=dto_filter,
            order_by=order_by,
            limit=limit,
            offset=offset,
            distinct_on=distinct_on,
            allow_null=allow_null,
            query_hooks=query_hooks,
            execution_options=execution_options,
        )
        return executor.list(self.session)

    def get_one(
        self,
        selection: QueryNodeType | None = None,
        dto_filter: BooleanFilterDTO | None = None,
        order_by: list[OrderByDTO] | None = None,
        limit: int | None = None,
        offset: int | None = None,
        distinct_on: list[EnumDTO] | None = None,
        allow_null: bool = False,
        query_hooks: defaultdict[QueryNodeType, list[QueryHook[DeclarativeBase]]] | None = None,
        execution_options: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> QueryResult[DeclarativeT]:
        """Retrieves a single record based on filtering and ordering criteria.

        Fetches a single record matching the provided filters. If multiple records
        match, ordering, limit, and offset can be used to pinpoint one. Returns
        None if no record matches. Supports GraphQL selection sets and query hooks.

        Args:
            selection: An optional QueryNodeType representing the GraphQL
                selection set.
            dto_filter: An optional filter object derived from GraphQL input.
            order_by: An optional list of ordering criteria.
            limit: An optional integer limiting the number of potential matches
                considered (usually 1 for get_one).
            offset: An optional integer specifying the starting point.
            distinct_on: An optional list of fields for DISTINCT ON clause.
            allow_null: If True, allows certain operations even if parts of the
                filter path are null.
            query_hooks: Optional hooks to modify the query.
            execution_options: Optional dictionary of execution options.
            **kwargs: Additional keyword arguments passed to the query executor setup.

        Returns:
            A QueryResult containing the single fetched record or None, structured
            according to the selection.
        """
        executor = self._get_query_executor(
            executor_type=SyncQueryExecutor,
            selection=selection,
            dto_filter=dto_filter,
            order_by=order_by,
            limit=limit,
            offset=offset,
            distinct_on=distinct_on,
            allow_null=allow_null,
            query_hooks=query_hooks,
            execution_options=execution_options,
            **kwargs,
        )
        return executor.get_one_or_none(self.session)

    def get_by_id(
        self,
        selection: QueryNodeType | None = None,
        query_hooks: defaultdict[QueryNodeType, list[QueryHook[DeclarativeBase]]] | None = None,
        execution_options: dict[str, Any] | None = None,
        **kwargs: Any,
    ) -> QueryResult[DeclarativeT]:
        """Retrieves a single record by its primary key(s).

        Fetches a single record matching the provided primary key values passed
        as keyword arguments. Returns None if no record matches. Supports GraphQL
        selection sets and query hooks.

        Args:
            selection: An optional QueryNodeType representing the GraphQL
                selection set.
            query_hooks: Optional hooks to modify the query.
            execution_options: Optional dictionary of execution options.
            **kwargs: Keyword arguments where keys are the primary key field names
                and values are the corresponding primary key values.

        Returns:
            A QueryResult containing the single fetched record or None, structured
            according to the selection.
        """
        executor = self._get_query_executor(
            SyncQueryExecutor, selection=selection, query_hooks=query_hooks, execution_options=execution_options
        )
        executor.base_statement = executor.base_statement.where(
            *[
                field_def.model_field == kwargs.pop(field_def.name)
                for field_def in executor.scope.id_field_definitions(self.model)
            ]
        )
        return executor.get_one_or_none(self.session)

    def create(self, data: Input[DeclarativeT], selection: QueryNodeType | None = None) -> QueryResult[DeclarativeT]:
        """Creates one or more records with nested relationships and returns them.

        Takes processed input data, performs the creation using `_create_many`,
        and then fetches the newly created records using `_list_by_ids` based on
        the returned primary keys and the provided selection set.

        Args:
            data: The processed input data for creation.
            selection: An optional QueryNodeType representing the GraphQL
                selection set for the returned data.

        Returns:
            A QueryResult containing the newly created records, structured
            according to the selection.
        """
        created_ids = self._mutate(MutationData("insert", data))
        return self._list_by_ids(created_ids, selection)

    def upsert(
        self,
        data: Input[DeclarativeT],
        selection: QueryNodeType | None = None,
        update_fields: list[EnumDTO] | None = None,
        conflict_fields: EnumDTO | None = None,
        dto_filter: BooleanFilterDTO | None = None,
    ) -> QueryResult[DeclarativeT]:
        created_ids = self._mutate(
            MutationData(
                "upsert",
                data,
                dto_filter=dto_filter,
                upsert_update_fields=update_fields,
                upsert_conflict_fields=conflict_fields,
            )
        )
        return self._list_by_ids(created_ids, selection)

    def update_by_ids(
        self, data: Input[DeclarativeT], selection: QueryNodeType | None = None
    ) -> QueryResult[DeclarativeT]:
        """Updates one or more records with nested relationships and returns them.

        Takes processed input data, performs the update using `_update_many`,
        and then fetches the updated records using `_list_by_ids` based on
        the returned primary keys and the provided selection set.

        Args:
            data: The processed input data for update. Must include primary keys.
            selection: An optional QueryNodeType representing the GraphQL
                selection set for the returned data.

        Returns:
            A QueryResult containing the updated records, structured
            according to the selection.
        """
        updated_ids = self._mutate(MutationData("update_by_pks", data))
        return self._list_by_ids(updated_ids, selection)

    def update_by_filter(
        self,
        data: Input[DeclarativeT],
        dto_filter: BooleanFilterDTO,
        selection: QueryNodeType | None = None,
    ) -> QueryResult[DeclarativeT]:
        updated_ids = self._mutate(MutationData("update_where", data, dto_filter))
        return self._list_by_ids(updated_ids, selection)

    def delete(
        self,
        selection: QueryNodeType | None = None,
        dto_filter: BooleanFilterDTO | None = None,
        execution_options: dict[str, Any] | None = None,
    ) -> QueryResult[DeclarativeT]:
        with self.session.begin_nested() as transaction:
            transpiler = QueryTranspiler(self.model, self._dialect, statement=self.statement)
            where_expressions = transpiler.filter_expressions(dto_filter) if dto_filter else None
            to_be_deleted = self.list(selection, dto_filter=dto_filter)
            affected_rows = self._delete_where(transpiler.scope.root_alias, where_expressions, execution_options)
            transaction.commit()
        return to_be_deleted.filter_in(**self._rows_to_filter_dict(affected_rows))
