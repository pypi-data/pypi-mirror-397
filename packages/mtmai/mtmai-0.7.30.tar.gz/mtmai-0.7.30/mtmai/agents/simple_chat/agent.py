import logging
from textwrap import dedent
from typing import Any, Dict, Optional
import uuid

from google.adk.agents import Agent
from google.adk.agents.callback_context import CallbackContext
from google.adk.tools.tool_context import ToolContext
from google.genai import types
from google.adk.agents.readonly_context import ReadonlyContext
from google.adk.models.llm_request import LlmRequest
from google.adk.models.llm_response import LlmResponse
from google.adk.utils import instructions_utils
from google.adk.code_executors import BuiltInCodeExecutor
from datetime import datetime

from mtmai.clients.supabase import get_supabase_async
from mtmai.model_client import get_default_litellm_model

logger = logging.getLogger(__name__)


async def reply_to_user_tool(
    reply_text: str, tool_context: ToolContext
) -> Dict[str, Any]:
    """
    ä¸“ç”¨äºå›å¤ç”¨æˆ·çš„å·¥å…·ã€‚å½“ä½ æƒ³å¯¹ç”¨æˆ·è¯´ä»»ä½•è¯æ—¶ï¼Œå¿…é¡»ä½¿ç”¨æ­¤å·¥å…·ã€‚
    ä¸è¦ç›´æ¥åœ¨æ€ç»´é“¾ä¸­ç»“æŸï¼Œå¿…é¡»è°ƒç”¨æ­¤å·¥å…·æ‰ç®—å›å¤å®Œæˆã€‚

    Args:
        reply_text: å›å¤ç»™ç”¨æˆ·çš„å…·ä½“æ–‡æœ¬å†…å®¹ã€‚
    """
    # 1. è·å–ä¸Šä¸‹æ–‡
    chat_id = tool_context.state.get("chat_id")
    target_user_id = tool_context.state.get("target_user_id")

    if not chat_id:
        return {"status": "error", "message": "Missing chat_id in session state"}
    if not target_user_id:
        logger.error("Missing target_user_id. The AI reply will belong to no one!")
        return {"status": "error", "message": "Missing target_user_id in session state"}

    logger.info(f"ğŸ¤– [Tool] Replying to Chat: {chat_id}, User: {target_user_id}")

    sb = await get_supabase_async()

    try:
        # æ³¨æ„: parts json æ ¼å¼,ä½¿ç”¨çš„æ˜¯ vercel aisdk UIMessageä¸­çš„æ ¼å¼, å› ä¸ºå‰ç«¯ç”¨çš„æ˜¯ vercel "ai"è¿™ä¸ªåŒ….
        parts_json = [{"text": reply_text, "type": "text"}]
        msg_id = str(uuid.uuid4())

        rpc_params = {
            "p_chat_id": chat_id,
            "p_id": msg_id,
            "p_parts": parts_json,
            "p_role": "assistant",
            "p_attachments": [],
            "p_user_id": target_user_id,
        }

        await sb.rpc("chat_message_upsert", rpc_params).execute()
        # logger.info(f"âœ… [Tool] Reply persisted. DB Response: {response.data}")
        return {
            "status": "success",
            "result": "Reply sent successfully.",
            "message_id": msg_id,
        }

    except Exception as e:
        logger.error(f"âŒ [Tool] Failed to persist reply: {e}", exc_info=True)
        return {"status": "error", "message": f"Database error: {str(e)}"}


def before_agent_callback(
    callback_context: CallbackContext,
) -> Optional[types.Content]:
    """é’©å­: æš‚æ—¶ç•™ç©º"""
    # Add new state
    callback_context.state["temp:last_operation_status"] = "success"
    now = datetime.now()

    # æ ¼å¼åŒ–ä¸ºå­—ç¬¦ä¸² (ä¾‹å¦‚: 2025-12-12 14:30:00)
    callback_context.state["current_datetime"] = now.strftime("%Y-%m-%d %H:%M:%S")


def before_model_callback(
    callback_context: CallbackContext, llm_request: LlmRequest
) -> Optional[LlmResponse]:
    """æ˜¾ç¤ºå¿…è¦çš„æ—¥å¿—"""
    # agent_name = callback_context.agent_name
    # history_text = callback_context.state.get("history_text")
    logger.info(f"llm request {llm_request}")

    # Inspect the last user message in the request contents
    # last_user_message = ""
    # if llm_request.contents and llm_request.contents[-1].role == "user":
    #     if llm_request.contents[-1].parts:
    #         last_user_message = llm_request.contents[-1].parts[0].text
    # print(f"[Callback] Inspecting last user message: '{last_user_message}'")


# This is an InstructionProvider
async def instruction_provider(context: ReadonlyContext) -> str:
    # TODO: å°†èŠå¤©å†å²,å’Œç”¨æˆ·æœ€æ–°è¾“å…¥çš„ çŠ¶æ€åšæ­£ç¡®åŒºåˆ†.
    # TODO: æ·»åŠ å’Œå®Œå–„åŸºç¡€ä¸Šä¸‹æ–‡èµ„æ–™,ä¾‹å¦‚å½“å‰æ—¶é—´,åŸºæœ¬ç¯å¢ƒ, è®© ai agent å›å¤ç”¨æˆ·æˆ–è€…å¤„ç†ç›¸å…³ä»»åŠ¡æœ‰æ›´å¤šçš„ä¾æ®.
    template = dedent("""
        <instruction>
        ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½å®¢æœä¸“å‘˜ã€‚
        ç”¨æˆ·å½“å‰åœ¨èŠå¤©é¡µé¢è¾“å…¥äº†æ¶ˆæ¯ã€‚

        ä½ çš„ä»»åŠ¡æ˜¯ï¼š
        1. é˜…è¯» <chat_history> ä¸­çš„ä¸Šä¸‹æ–‡ã€‚
        2. ç†è§£ç”¨æˆ·çš„æœ€æ–°æ„å›¾ã€‚
        3. å¿…é¡»è°ƒç”¨ [reply_to_user_tool] å·¥å…·æ¥å›å¤ç”¨æˆ·ã€‚
        4. è¯­æ°”è¦äº²åˆ‡ã€ä¸“ä¸šã€‚

        å…¶ä»–æç¤º:
        1. èŠå¤©å†å²åˆ—è¡¨çš„æœ€åä¸€ä¸ªuseræ¶ˆæ¯,æœ€æ–°è¾“å…¥çš„èŠå¤©æ¶ˆæ¯.
        2. ä½ æ‹¥æœ‰pythonä»£ç æ‰§è¡Œèƒ½åŠ›,å½“è¿è¡Œå¤æ‚ä»»åŠ¡æ˜¯,åº”å½“è€ƒè™‘è¿è¡Œpythonç¨‹åºè¾…åŠ©è¿›è¡Œæ€è€ƒå’Œè§£å†³é—®é¢˜.
        </instruction>

        <base_info>
        current_datetime: {{current_datetime}}
        </base_info>

        <tools_usage>
        ä½ å¿…é¡»ä½¿ç”¨ reply_to_user_tool è¿›è¡Œå›å¤ã€‚ä¸è¦ç›´æ¥è¾“å‡ºæ–‡æœ¬ã€‚
        </tools_usage>

        <chat_history>
        {{history_text}}
        </chat_history>

        <last_user_message>
        last_user_message
        </last_user_message>


        """)
    return await instructions_utils.inject_session_state(template, context)


def chat_agent():
    """åˆ›å»º Agent å®ä¾‹"""
    model = get_default_litellm_model("qwen2.5-coder-32b-instruct")
    root_agent = Agent(
        name="assistant",
        model=model,
        instruction=instruction_provider,
        description="An AI assistant",
        tools=[reply_to_user_tool],
        before_agent_callback=before_agent_callback,
        before_model_callback=before_model_callback,
        code_executor=BuiltInCodeExecutor(),
    )
    return root_agent
