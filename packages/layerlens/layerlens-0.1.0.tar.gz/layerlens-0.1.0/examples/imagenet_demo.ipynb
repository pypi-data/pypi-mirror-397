{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b542bdef",
   "metadata": {},
   "source": [
    "# LayerLens ImageNet Demo\n",
    "\n",
    "This notebook demonstrates how to use LayerLens to explain a pre-trained ImageNet model (ResNet50)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bee414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Import LayerLens\n",
    "import sys\n",
    "sys.path.append('..')  # Add parent directory to path\n",
    "import layerlens as ll"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e392ed",
   "metadata": {},
   "source": [
    "## 1. Load a pre-trained ResNet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d86dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "model = ResNet50(weights='imagenet')\n",
    "\n",
    "# Display model summary\n",
    "print(\"Model loaded: ResNet50\")\n",
    "print(f\"Number of layers: {len(model.layers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51668ebc",
   "metadata": {},
   "source": [
    "## 2. Load and preprocess an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf58b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(img_path):\n",
    "    \"\"\"Load and preprocess an image for ResNet50.\"\"\"\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    return preprocess_input(img_array), img\n",
    "\n",
    "# You can replace this with any image path\n",
    "img_path = tf.keras.utils.get_file(\n",
    "    \"elephant.jpg\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/elephant.jpg\"\n",
    ")\n",
    "\n",
    "# Load and preprocess the image\n",
    "processed_img, original_img = load_and_preprocess_image(img_path)\n",
    "\n",
    "# Display the original image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(original_img)\n",
    "plt.axis('off')\n",
    "plt.title(\"Original Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991eca6c",
   "metadata": {},
   "source": [
    "## 3. Make predictions with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6686cca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "preds = model.predict(processed_img)\n",
    "\n",
    "# Decode and display the top 5 predictions\n",
    "decoded_preds = decode_predictions(preds, top=5)[0]\n",
    "print(\"Top 5 predictions:\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_preds):\n",
    "    print(f\"{i+1}: {label} ({score:.4f})\")\n",
    "\n",
    "# Set the top prediction\n",
    "top_pred_idx = np.argmax(preds[0])\n",
    "top_pred_label = decoded_preds[0][1]\n",
    "print(f\"\\nTop prediction: {top_pred_label} (index {top_pred_idx})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f26591",
   "metadata": {},
   "source": [
    "## 4. Use LayerLens to explain the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1015d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LayerLens explainer\n",
    "# We'll focus on a subset of layers to speed up the explanation process\n",
    "target_layers = [\n",
    "    'conv1_conv', \n",
    "    'conv2_block3_out', \n",
    "    'conv3_block4_out', \n",
    "    'conv4_block6_out', \n",
    "    'conv5_block3_out',\n",
    "    'avg_pool',\n",
    "    'predictions'\n",
    "]\n",
    "\n",
    "explainer = ll.Explainer(model, layers=target_layers)\n",
    "\n",
    "# Generate explanations\n",
    "print(\"Generating explanations (this may take a while)...\")\n",
    "explanations = explainer.explain(processed_img)\n",
    "\n",
    "print(f\"Generated explanations for {len(explanations.layer_explanations)} layers\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad35dbc7",
   "metadata": {},
   "source": [
    "## 5. Visualize layer activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2277d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract layer outputs\n",
    "from layerlens.core.layer_extractor import LayerExtractor\n",
    "\n",
    "extractor = LayerExtractor(model, layers=target_layers)\n",
    "layer_outputs = extractor.extract(processed_img)\n",
    "\n",
    "# Visualize activations for an intermediate layer\n",
    "from layerlens.visualization.heatmap_generator import generate_heatmap\n",
    "\n",
    "# Select a convolutional layer to visualize\n",
    "conv_layer = 'conv3_block4_out'\n",
    "conv_activations = layer_outputs[conv_layer]\n",
    "\n",
    "# Generate and display the heatmap\n",
    "conv_heatmap = generate_heatmap(conv_activations, conv_layer, processed_img[0], overlay=True)\n",
    "\n",
    "# Display the heatmap\n",
    "from plotly.offline import iplot\n",
    "iplot(conv_heatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8775f8",
   "metadata": {},
   "source": [
    "## 6. Compare activations across multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6248d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare activations across different layers\n",
    "from layerlens.visualization.heatmap_generator import compare_layer_activations\n",
    "\n",
    "# Select conv layers to compare\n",
    "conv_layers = ['conv1_conv', 'conv2_block3_out', 'conv3_block4_out', 'conv4_block6_out']\n",
    "conv_activations = {layer: layer_outputs[layer] for layer in conv_layers}\n",
    "\n",
    "# Generate the comparison visualization\n",
    "comparison_fig = compare_layer_activations(conv_activations, processed_img[0])\n",
    "\n",
    "# Display the comparison\n",
    "iplot(comparison_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151db4f2",
   "metadata": {},
   "source": [
    "## 7. Analyze feature importance for the final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d769ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a surrogate model for the final layer\n",
    "from layerlens.core.surrogate_builder import SurrogateBuilder\n",
    "\n",
    "# We need more samples to build a reliable surrogate\n",
    "# For the demo, we'll use random noise as additional samples\n",
    "n_samples = 20\n",
    "random_samples = np.random.randn(n_samples, 224, 224, 3)\n",
    "random_samples = preprocess_input(random_samples)\n",
    "\n",
    "# Combine with our real sample\n",
    "all_samples = np.concatenate([processed_img, random_samples], axis=0)\n",
    "\n",
    "# Extract features from the penultimate layer\n",
    "extractor = LayerExtractor(model, layers=['avg_pool', 'predictions'])\n",
    "penultimate_outputs = extractor.extract(all_samples)\n",
    "\n",
    "# Build surrogate for the final layer\n",
    "surrogate_builder = SurrogateBuilder(surrogate_type='linear')\n",
    "final_surrogate = surrogate_builder.fit(\n",
    "    'predictions', \n",
    "    penultimate_outputs['avg_pool'].reshape(n_samples + 1, -1), \n",
    "    penultimate_outputs['predictions']\n",
    ")\n",
    "\n",
    "# Get feature importances for the top prediction class\n",
    "if hasattr(final_surrogate, 'coef_'):\n",
    "    # For linear models, we can look at the coefficients\n",
    "    coefs = final_surrogate.coef_[top_pred_idx]\n",
    "    \n",
    "    # Plot the top feature importances\n",
    "    from layerlens.utils.plot_utils import plot_feature_importance\n",
    "    \n",
    "    importance_fig = plot_feature_importance(\n",
    "        np.abs(coefs),  # Use absolute value of coefficients\n",
    "        feature_names=None,\n",
    "        top_n=20\n",
    "    )\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c66957",
   "metadata": {},
   "source": [
    "## 8. Visualize the model graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e2a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model architecture (showing only our target layers)\n",
    "from layerlens.visualization.layer_graph import plot_layer_graph\n",
    "\n",
    "# Create a submodel with only the layers we're analyzing\n",
    "submodel = tf.keras.Model(\n",
    "    inputs=model.input,\n",
    "    outputs=[model.get_layer(layer).output for layer in target_layers]\n",
    ")\n",
    "\n",
    "# Create the graph visualization\n",
    "layer_graph = plot_layer_graph(submodel, highlight_layers='predictions')\n",
    "\n",
    "# Display the graph\n",
    "iplot(layer_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b16425",
   "metadata": {},
   "source": [
    "## 9. Generate a feature flow visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize how features flow through the network\n",
    "from layerlens.visualization.feature_flow import plot_feature_flow\n",
    "\n",
    "# Create the feature flow visualization\n",
    "feature_flow_fig = plot_feature_flow(explanations, processed_img)\n",
    "\n",
    "# Display the visualization\n",
    "iplot(feature_flow_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65d4302",
   "metadata": {},
   "source": [
    "## 10. Compare explanations for different images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35208f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a second image for comparison\n",
    "img_path2 = tf.keras.utils.get_file(\n",
    "    \"tiger.jpg\",\n",
    "    \"https://storage.googleapis.com/download.tensorflow.org/example_images/tiger.jpg\"\n",
    ")\n",
    "\n",
    "# Load and preprocess the image\n",
    "processed_img2, original_img2 = load_and_preprocess_image(img_path2)\n",
    "\n",
    "# Display the second image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(original_img2)\n",
    "plt.axis('off')\n",
    "plt.title(\"Second Image\")\n",
    "plt.show()\n",
    "\n",
    "# Make predictions\n",
    "preds2 = model.predict(processed_img2)\n",
    "decoded_preds2 = decode_predictions(preds2, top=3)[0]\n",
    "print(\"Top 3 predictions for second image:\")\n",
    "for i, (imagenet_id, label, score) in enumerate(decoded_preds2):\n",
    "    print(f\"{i+1}: {label} ({score:.4f})\")\n",
    "\n",
    "# Generate explanations for the second image\n",
    "explanations2 = explainer.explain(processed_img2)\n",
    "\n",
    "# Compare feature flows\n",
    "from layerlens.visualization.feature_flow import compare_feature_flows\n",
    "\n",
    "# Create a comparison of feature flows\n",
    "comparison_fig = compare_feature_flows(\n",
    "    explanations,\n",
    "    [processed_img[0], processed_img2[0]],\n",
    "    sample_labels=[\"Elephant\", \"Tiger\"]\n",
    ")\n",
    "\n",
    "# Display the comparison\n",
    "iplot(comparison_fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51328d9a",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to use LayerLens to explain a pre-trained ResNet50 model on ImageNet data. We've:\n",
    "\n",
    "1. Extracted and visualized activations from different layers\n",
    "2. Built surrogate models to explain the final classification layer\n",
    "3. Analyzed feature importance for specific predictions\n",
    "4. Compared explanations across different images\n",
    "\n",
    "LayerLens helps us understand how complex deep learning models process images and arrive at their final predictions by providing layer-by-layer insights."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
